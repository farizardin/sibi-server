[ Mon May 15 08:50:22 2023 ] NUM WORKER: 1
[ Mon May 15 08:51:19 2023 ] Parameters:
{'work_dir': './work_dir/sibi_merged_inner_group_ShiftGCN_mod_2_joint_n_5_kfold_fold_2', 'model_saved_name': './save_models/sibi_merged_inner_group_ShiftGCN_mod_2_joint_n_5_kfold_fold_2', 'Experiment_name': 'sibi_merged_inner_group_ShiftGCN_mod_2_joint_n_5_kfold', 'config': './config/recalculated/train_sibi_with_mouth_augmented_merged_inner_group_shift_joint_mod_2.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 2, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'n_splits': 5, 'feeder': 'feeders.feeder_hsd.Feeder', 'num_worker': 1, 'train_feeder_args': {'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': -1, 'normalization': False}, 'test_feeder_args': None, 'data_path': './data/augmented_recalculate_normalized', 'model': 'model.shift_gcn.Model', 'model_args': {'num_class': 50, 'num_person': 1, 'num_point': 115, 'graph_group': [[0, 81], [82, 114]], 'method': 'grouped.inner', 'weight': 2, 'graph': 'graph.skeleton_with_mouth.SkeletonWithMouth', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [20, 25], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 5, 'test_batch_size': 5, 'start_epoch': 0, 'num_epoch': 30, 'folds_range': [0, 5], 'weight_decay': 0.0001, 'only_train_part': True, 'only_train_epoch': 1, 'warm_up_epoch': 0}

[ Mon May 15 08:51:19 2023 ] Training epoch: 1
[ Mon May 15 08:52:08 2023 ] 	Batch(99/480) done. Loss: 3.9007  lr:0.100000  network_time: 0.0120
[ Mon May 15 08:52:58 2023 ] 	Batch(199/480) done. Loss: 3.5170  lr:0.100000  network_time: 0.0126
[ Mon May 15 08:53:48 2023 ] 	Batch(299/480) done. Loss: 3.8157  lr:0.100000  network_time: 0.0113
[ Mon May 15 08:54:38 2023 ] 	Batch(399/480) done. Loss: 3.2888  lr:0.100000  network_time: 0.0114
[ Mon May 15 08:55:18 2023 ] 	Training Accuracy: 5.58%
[ Mon May 15 08:55:18 2023 ] Eval epoch: 1
[ Mon May 15 08:55:35 2023 ] 	Mean test loss of 120 batches: 3.9382710456848145.
[ Mon May 15 08:55:35 2023 ] 	Top1: 8.50%
[ Mon May 15 08:55:35 2023 ] 	Top5: 35.33%
[ Mon May 15 08:55:35 2023 ] Training epoch: 2
[ Mon May 15 08:55:45 2023 ] 	Batch(19/480) done. Loss: 4.1778  lr:0.100000  network_time: 0.0114
[ Mon May 15 08:56:35 2023 ] 	Batch(119/480) done. Loss: 3.8289  lr:0.100000  network_time: 0.0117
[ Mon May 15 08:57:25 2023 ] 	Batch(219/480) done. Loss: 2.5731  lr:0.100000  network_time: 0.0119
[ Mon May 15 08:58:15 2023 ] 	Batch(319/480) done. Loss: 3.9834  lr:0.100000  network_time: 0.0124
[ Mon May 15 08:59:05 2023 ] 	Batch(419/480) done. Loss: 1.9019  lr:0.100000  network_time: 0.0132
[ Mon May 15 08:59:35 2023 ] 	Training Accuracy: 15.46%
[ Mon May 15 08:59:35 2023 ] Eval epoch: 2
[ Mon May 15 08:59:52 2023 ] 	Mean test loss of 120 batches: 3.035590171813965.
[ Mon May 15 08:59:52 2023 ] 	Top1: 20.83%
[ Mon May 15 08:59:52 2023 ] 	Top5: 68.17%
[ Mon May 15 08:59:52 2023 ] Training epoch: 3
[ Mon May 15 09:00:12 2023 ] 	Batch(39/480) done. Loss: 2.6828  lr:0.100000  network_time: 0.0117
[ Mon May 15 09:01:02 2023 ] 	Batch(139/480) done. Loss: 2.7380  lr:0.100000  network_time: 0.0124
[ Mon May 15 09:01:52 2023 ] 	Batch(239/480) done. Loss: 3.4344  lr:0.100000  network_time: 0.0120
[ Mon May 15 09:02:42 2023 ] 	Batch(339/480) done. Loss: 3.2030  lr:0.100000  network_time: 0.0115
[ Mon May 15 09:03:32 2023 ] 	Batch(439/480) done. Loss: 2.0302  lr:0.100000  network_time: 0.0115
[ Mon May 15 09:03:52 2023 ] 	Training Accuracy: 26.25%
[ Mon May 15 09:03:52 2023 ] Eval epoch: 3
[ Mon May 15 09:04:09 2023 ] 	Mean test loss of 120 batches: 2.7254490852355957.
[ Mon May 15 09:04:09 2023 ] 	Top1: 32.83%
[ Mon May 15 09:04:09 2023 ] 	Top5: 72.50%
[ Mon May 15 09:04:09 2023 ] Training epoch: 4
[ Mon May 15 09:04:39 2023 ] 	Batch(59/480) done. Loss: 1.6158  lr:0.100000  network_time: 0.0118
[ Mon May 15 09:05:29 2023 ] 	Batch(159/480) done. Loss: 2.1087  lr:0.100000  network_time: 0.0117
[ Mon May 15 09:06:19 2023 ] 	Batch(259/480) done. Loss: 2.0568  lr:0.100000  network_time: 0.0118
[ Mon May 15 09:07:09 2023 ] 	Batch(359/480) done. Loss: 2.4782  lr:0.100000  network_time: 0.0115
[ Mon May 15 09:07:59 2023 ] 	Batch(459/480) done. Loss: 1.6286  lr:0.100000  network_time: 0.0125
[ Mon May 15 09:08:09 2023 ] 	Training Accuracy: 41.29%
[ Mon May 15 09:08:09 2023 ] Eval epoch: 4
[ Mon May 15 09:08:25 2023 ] 	Mean test loss of 120 batches: 1.8577791452407837.
[ Mon May 15 09:08:25 2023 ] 	Top1: 47.00%
[ Mon May 15 09:08:25 2023 ] 	Top5: 84.83%
[ Mon May 15 09:08:25 2023 ] Training epoch: 5
[ Mon May 15 09:09:05 2023 ] 	Batch(79/480) done. Loss: 1.8414  lr:0.100000  network_time: 0.0122
[ Mon May 15 09:09:55 2023 ] 	Batch(179/480) done. Loss: 1.2252  lr:0.100000  network_time: 0.0121
[ Mon May 15 09:10:45 2023 ] 	Batch(279/480) done. Loss: 2.0933  lr:0.100000  network_time: 0.0118
[ Mon May 15 09:11:35 2023 ] 	Batch(379/480) done. Loss: 1.9136  lr:0.100000  network_time: 0.0124
[ Mon May 15 09:12:25 2023 ] 	Batch(479/480) done. Loss: 1.1578  lr:0.100000  network_time: 0.0121
[ Mon May 15 09:12:25 2023 ] 	Training Accuracy: 51.04%
[ Mon May 15 09:12:25 2023 ] Eval epoch: 5
[ Mon May 15 09:12:42 2023 ] 	Mean test loss of 120 batches: 1.5055354833602905.
[ Mon May 15 09:12:42 2023 ] 	Top1: 58.83%
[ Mon May 15 09:12:42 2023 ] 	Top5: 92.17%
[ Mon May 15 09:12:42 2023 ] Training epoch: 6
[ Mon May 15 09:13:32 2023 ] 	Batch(99/480) done. Loss: 0.6792  lr:0.100000  network_time: 0.0115
[ Mon May 15 09:14:22 2023 ] 	Batch(199/480) done. Loss: 1.5041  lr:0.100000  network_time: 0.0115
[ Mon May 15 09:15:12 2023 ] 	Batch(299/480) done. Loss: 0.4227  lr:0.100000  network_time: 0.0123
[ Mon May 15 09:16:02 2023 ] 	Batch(399/480) done. Loss: 1.1185  lr:0.100000  network_time: 0.0143
[ Mon May 15 09:16:42 2023 ] 	Training Accuracy: 61.62%
[ Mon May 15 09:16:42 2023 ] Eval epoch: 6
[ Mon May 15 09:16:59 2023 ] 	Mean test loss of 120 batches: 1.0426374673843384.
[ Mon May 15 09:16:59 2023 ] 	Top1: 71.17%
[ Mon May 15 09:16:59 2023 ] 	Top5: 95.33%
[ Mon May 15 09:16:59 2023 ] Training epoch: 7
[ Mon May 15 09:17:09 2023 ] 	Batch(19/480) done. Loss: 1.9048  lr:0.100000  network_time: 0.0116
[ Mon May 15 09:17:59 2023 ] 	Batch(119/480) done. Loss: 0.6348  lr:0.100000  network_time: 0.0115
[ Mon May 15 09:18:49 2023 ] 	Batch(219/480) done. Loss: 2.5620  lr:0.100000  network_time: 0.0113
[ Mon May 15 09:19:39 2023 ] 	Batch(319/480) done. Loss: 0.9219  lr:0.100000  network_time: 0.0120
[ Mon May 15 09:20:29 2023 ] 	Batch(419/480) done. Loss: 0.7761  lr:0.100000  network_time: 0.0116
[ Mon May 15 09:20:59 2023 ] 	Training Accuracy: 67.75%
[ Mon May 15 09:20:59 2023 ] Eval epoch: 7
[ Mon May 15 09:21:16 2023 ] 	Mean test loss of 120 batches: 1.7475807666778564.
[ Mon May 15 09:21:16 2023 ] 	Top1: 51.50%
[ Mon May 15 09:21:16 2023 ] 	Top5: 87.33%
[ Mon May 15 09:21:16 2023 ] Training epoch: 8
[ Mon May 15 09:21:36 2023 ] 	Batch(39/480) done. Loss: 0.5561  lr:0.100000  network_time: 0.0111
[ Mon May 15 09:22:26 2023 ] 	Batch(139/480) done. Loss: 1.4560  lr:0.100000  network_time: 0.0112
[ Mon May 15 09:23:16 2023 ] 	Batch(239/480) done. Loss: 0.7818  lr:0.100000  network_time: 0.0118
[ Mon May 15 09:24:06 2023 ] 	Batch(339/480) done. Loss: 0.7172  lr:0.100000  network_time: 0.0124
[ Mon May 15 09:24:56 2023 ] 	Batch(439/480) done. Loss: 0.5333  lr:0.100000  network_time: 0.0116
[ Mon May 15 09:25:16 2023 ] 	Training Accuracy: 73.88%
[ Mon May 15 09:25:16 2023 ] Eval epoch: 8
[ Mon May 15 09:25:33 2023 ] 	Mean test loss of 120 batches: 0.768563985824585.
[ Mon May 15 09:25:33 2023 ] 	Top1: 76.50%
[ Mon May 15 09:25:33 2023 ] 	Top5: 98.33%
[ Mon May 15 09:25:33 2023 ] Training epoch: 9
[ Mon May 15 09:26:03 2023 ] 	Batch(59/480) done. Loss: 0.1075  lr:0.100000  network_time: 0.0114
[ Mon May 15 09:26:53 2023 ] 	Batch(159/480) done. Loss: 1.3925  lr:0.100000  network_time: 0.0114
[ Mon May 15 09:27:43 2023 ] 	Batch(259/480) done. Loss: 1.9238  lr:0.100000  network_time: 0.0119
[ Mon May 15 09:28:33 2023 ] 	Batch(359/480) done. Loss: 0.7632  lr:0.100000  network_time: 0.0119
[ Mon May 15 09:29:23 2023 ] 	Batch(459/480) done. Loss: 0.7846  lr:0.100000  network_time: 0.0116
[ Mon May 15 09:29:33 2023 ] 	Training Accuracy: 77.63%
[ Mon May 15 09:29:33 2023 ] Eval epoch: 9
[ Mon May 15 09:29:50 2023 ] 	Mean test loss of 120 batches: 1.4908368587493896.
[ Mon May 15 09:29:50 2023 ] 	Top1: 63.00%
[ Mon May 15 09:29:50 2023 ] 	Top5: 92.17%
[ Mon May 15 09:29:50 2023 ] Training epoch: 10
[ Mon May 15 09:30:30 2023 ] 	Batch(79/480) done. Loss: 1.8211  lr:0.100000  network_time: 0.0117
[ Mon May 15 09:31:20 2023 ] 	Batch(179/480) done. Loss: 1.0675  lr:0.100000  network_time: 0.0119
[ Mon May 15 09:32:10 2023 ] 	Batch(279/480) done. Loss: 0.5842  lr:0.100000  network_time: 0.0122
[ Mon May 15 09:33:00 2023 ] 	Batch(379/480) done. Loss: 0.1804  lr:0.100000  network_time: 0.0124
[ Mon May 15 09:33:50 2023 ] 	Batch(479/480) done. Loss: 0.5744  lr:0.100000  network_time: 0.0117
[ Mon May 15 09:33:50 2023 ] 	Training Accuracy: 80.38%
[ Mon May 15 09:33:50 2023 ] Eval epoch: 10
[ Mon May 15 09:34:07 2023 ] 	Mean test loss of 120 batches: 1.2382992506027222.
[ Mon May 15 09:34:07 2023 ] 	Top1: 68.50%
[ Mon May 15 09:34:07 2023 ] 	Top5: 96.17%
[ Mon May 15 09:34:07 2023 ] Training epoch: 11
[ Mon May 15 09:34:57 2023 ] 	Batch(99/480) done. Loss: 0.3732  lr:0.100000  network_time: 0.0122
[ Mon May 15 09:35:47 2023 ] 	Batch(199/480) done. Loss: 0.5603  lr:0.100000  network_time: 0.0118
[ Mon May 15 09:36:37 2023 ] 	Batch(299/480) done. Loss: 0.4593  lr:0.100000  network_time: 0.0117
[ Mon May 15 09:37:27 2023 ] 	Batch(399/480) done. Loss: 0.4639  lr:0.100000  network_time: 0.0119
[ Mon May 15 09:38:07 2023 ] 	Training Accuracy: 83.63%
[ Mon May 15 09:38:07 2023 ] Eval epoch: 11
[ Mon May 15 09:38:24 2023 ] 	Mean test loss of 120 batches: 0.6019227504730225.
[ Mon May 15 09:38:24 2023 ] 	Top1: 83.50%
[ Mon May 15 09:38:24 2023 ] 	Top5: 99.17%
[ Mon May 15 09:38:24 2023 ] Training epoch: 12
[ Mon May 15 09:38:34 2023 ] 	Batch(19/480) done. Loss: 0.2981  lr:0.100000  network_time: 0.0119
[ Mon May 15 09:39:24 2023 ] 	Batch(119/480) done. Loss: 0.1644  lr:0.100000  network_time: 0.0114
[ Mon May 15 09:40:14 2023 ] 	Batch(219/480) done. Loss: 1.1776  lr:0.100000  network_time: 0.0117
[ Mon May 15 09:41:04 2023 ] 	Batch(319/480) done. Loss: 0.0482  lr:0.100000  network_time: 0.0124
[ Mon May 15 09:41:54 2023 ] 	Batch(419/480) done. Loss: 0.0558  lr:0.100000  network_time: 0.0118
[ Mon May 15 09:42:24 2023 ] 	Training Accuracy: 83.04%
[ Mon May 15 09:42:24 2023 ] Eval epoch: 12
[ Mon May 15 09:42:41 2023 ] 	Mean test loss of 120 batches: 0.4234870374202728.
[ Mon May 15 09:42:41 2023 ] 	Top1: 85.67%
[ Mon May 15 09:42:41 2023 ] 	Top5: 99.33%
[ Mon May 15 09:42:41 2023 ] Training epoch: 13
[ Mon May 15 09:43:01 2023 ] 	Batch(39/480) done. Loss: 0.2552  lr:0.100000  network_time: 0.0120
[ Mon May 15 09:43:51 2023 ] 	Batch(139/480) done. Loss: 0.3007  lr:0.100000  network_time: 0.0122
[ Mon May 15 09:44:41 2023 ] 	Batch(239/480) done. Loss: 0.3091  lr:0.100000  network_time: 0.0121
[ Mon May 15 09:45:31 2023 ] 	Batch(339/480) done. Loss: 0.4878  lr:0.100000  network_time: 0.0119
[ Mon May 15 09:46:21 2023 ] 	Batch(439/480) done. Loss: 0.7995  lr:0.100000  network_time: 0.0122
[ Mon May 15 09:46:41 2023 ] 	Training Accuracy: 86.08%
[ Mon May 15 09:46:41 2023 ] Eval epoch: 13
[ Mon May 15 09:46:58 2023 ] 	Mean test loss of 120 batches: 0.4902478754520416.
[ Mon May 15 09:46:58 2023 ] 	Top1: 83.83%
[ Mon May 15 09:46:58 2023 ] 	Top5: 99.00%
[ Mon May 15 09:46:58 2023 ] Training epoch: 14
[ Mon May 15 09:47:28 2023 ] 	Batch(59/480) done. Loss: 1.0358  lr:0.100000  network_time: 0.0116
[ Mon May 15 09:48:18 2023 ] 	Batch(159/480) done. Loss: 0.0368  lr:0.100000  network_time: 0.0117
[ Mon May 15 09:49:08 2023 ] 	Batch(259/480) done. Loss: 0.1822  lr:0.100000  network_time: 0.0116
[ Mon May 15 09:49:58 2023 ] 	Batch(359/480) done. Loss: 1.7297  lr:0.100000  network_time: 0.0116
[ Mon May 15 09:50:48 2023 ] 	Batch(459/480) done. Loss: 0.3304  lr:0.100000  network_time: 0.0124
[ Mon May 15 09:50:58 2023 ] 	Training Accuracy: 87.67%
[ Mon May 15 09:50:58 2023 ] Eval epoch: 14
[ Mon May 15 09:51:15 2023 ] 	Mean test loss of 120 batches: 1.109025239944458.
[ Mon May 15 09:51:15 2023 ] 	Top1: 75.67%
[ Mon May 15 09:51:15 2023 ] 	Top5: 96.67%
[ Mon May 15 09:51:15 2023 ] Training epoch: 15
[ Mon May 15 09:51:55 2023 ] 	Batch(79/480) done. Loss: 0.3260  lr:0.100000  network_time: 0.0119
[ Mon May 15 09:52:45 2023 ] 	Batch(179/480) done. Loss: 1.5405  lr:0.100000  network_time: 0.0128
[ Mon May 15 09:53:35 2023 ] 	Batch(279/480) done. Loss: 0.1375  lr:0.100000  network_time: 0.0121
[ Mon May 15 09:54:25 2023 ] 	Batch(379/480) done. Loss: 0.0732  lr:0.100000  network_time: 0.0118
[ Mon May 15 09:55:15 2023 ] 	Batch(479/480) done. Loss: 0.1434  lr:0.100000  network_time: 0.0120
[ Mon May 15 09:55:15 2023 ] 	Training Accuracy: 88.63%
[ Mon May 15 09:55:15 2023 ] Eval epoch: 15
[ Mon May 15 09:55:32 2023 ] 	Mean test loss of 120 batches: 0.5837156772613525.
[ Mon May 15 09:55:32 2023 ] 	Top1: 81.50%
[ Mon May 15 09:55:32 2023 ] 	Top5: 98.50%
[ Mon May 15 09:55:32 2023 ] Training epoch: 16
[ Mon May 15 09:56:22 2023 ] 	Batch(99/480) done. Loss: 0.2363  lr:0.100000  network_time: 0.0122
[ Mon May 15 09:57:12 2023 ] 	Batch(199/480) done. Loss: 0.1599  lr:0.100000  network_time: 0.0119
[ Mon May 15 09:58:02 2023 ] 	Batch(299/480) done. Loss: 0.7866  lr:0.100000  network_time: 0.0120
[ Mon May 15 09:58:52 2023 ] 	Batch(399/480) done. Loss: 0.7755  lr:0.100000  network_time: 0.0116
[ Mon May 15 09:59:32 2023 ] 	Training Accuracy: 89.42%
[ Mon May 15 09:59:32 2023 ] Eval epoch: 16
[ Mon May 15 09:59:49 2023 ] 	Mean test loss of 120 batches: 0.2862253189086914.
[ Mon May 15 09:59:49 2023 ] 	Top1: 91.50%
[ Mon May 15 09:59:49 2023 ] 	Top5: 99.67%
[ Mon May 15 09:59:49 2023 ] Training epoch: 17
[ Mon May 15 09:59:59 2023 ] 	Batch(19/480) done. Loss: 0.1695  lr:0.100000  network_time: 0.0118
[ Mon May 15 10:00:49 2023 ] 	Batch(119/480) done. Loss: 0.3463  lr:0.100000  network_time: 0.0114
[ Mon May 15 10:01:39 2023 ] 	Batch(219/480) done. Loss: 0.0637  lr:0.100000  network_time: 0.0116
[ Mon May 15 10:02:29 2023 ] 	Batch(319/480) done. Loss: 0.2803  lr:0.100000  network_time: 0.0116
[ Mon May 15 10:03:19 2023 ] 	Batch(419/480) done. Loss: 0.3225  lr:0.100000  network_time: 0.0131
[ Mon May 15 10:03:49 2023 ] 	Training Accuracy: 88.63%
[ Mon May 15 10:03:49 2023 ] Eval epoch: 17
[ Mon May 15 10:04:06 2023 ] 	Mean test loss of 120 batches: 0.39201292395591736.
[ Mon May 15 10:04:06 2023 ] 	Top1: 88.00%
[ Mon May 15 10:04:06 2023 ] 	Top5: 99.00%
[ Mon May 15 10:04:06 2023 ] Training epoch: 18
[ Mon May 15 10:04:26 2023 ] 	Batch(39/480) done. Loss: 0.4671  lr:0.100000  network_time: 0.0114
[ Mon May 15 10:05:16 2023 ] 	Batch(139/480) done. Loss: 0.2358  lr:0.100000  network_time: 0.0116
[ Mon May 15 10:06:06 2023 ] 	Batch(239/480) done. Loss: 0.0168  lr:0.100000  network_time: 0.0116
[ Mon May 15 10:06:56 2023 ] 	Batch(339/480) done. Loss: 0.0291  lr:0.100000  network_time: 0.0120
[ Mon May 15 10:07:46 2023 ] 	Batch(439/480) done. Loss: 0.1971  lr:0.100000  network_time: 0.0114
[ Mon May 15 10:08:06 2023 ] 	Training Accuracy: 89.79%
[ Mon May 15 10:08:06 2023 ] Eval epoch: 18
[ Mon May 15 10:08:23 2023 ] 	Mean test loss of 120 batches: 0.6526171565055847.
[ Mon May 15 10:08:23 2023 ] 	Top1: 83.83%
[ Mon May 15 10:08:23 2023 ] 	Top5: 98.00%
[ Mon May 15 10:08:23 2023 ] Training epoch: 19
[ Mon May 15 10:08:53 2023 ] 	Batch(59/480) done. Loss: 0.1230  lr:0.100000  network_time: 0.0116
[ Mon May 15 10:09:43 2023 ] 	Batch(159/480) done. Loss: 0.3129  lr:0.100000  network_time: 0.0112
[ Mon May 15 10:10:33 2023 ] 	Batch(259/480) done. Loss: 0.4652  lr:0.100000  network_time: 0.0119
[ Mon May 15 10:11:23 2023 ] 	Batch(359/480) done. Loss: 0.1562  lr:0.100000  network_time: 0.0117
[ Mon May 15 10:12:13 2023 ] 	Batch(459/480) done. Loss: 0.0378  lr:0.100000  network_time: 0.0118
[ Mon May 15 10:12:23 2023 ] 	Training Accuracy: 91.04%
[ Mon May 15 10:12:23 2023 ] Eval epoch: 19
[ Mon May 15 10:12:40 2023 ] 	Mean test loss of 120 batches: 0.09283880889415741.
[ Mon May 15 10:12:40 2023 ] 	Top1: 96.17%
[ Mon May 15 10:12:40 2023 ] 	Top5: 99.83%
[ Mon May 15 10:12:40 2023 ] Training epoch: 20
[ Mon May 15 10:13:20 2023 ] 	Batch(79/480) done. Loss: 0.0952  lr:0.100000  network_time: 0.0119
[ Mon May 15 10:14:10 2023 ] 	Batch(179/480) done. Loss: 0.2374  lr:0.100000  network_time: 0.0115
[ Mon May 15 10:15:00 2023 ] 	Batch(279/480) done. Loss: 0.0329  lr:0.100000  network_time: 0.0113
[ Mon May 15 10:15:50 2023 ] 	Batch(379/480) done. Loss: 0.0309  lr:0.100000  network_time: 0.0113
[ Mon May 15 10:16:40 2023 ] 	Batch(479/480) done. Loss: 0.0176  lr:0.100000  network_time: 0.0112
[ Mon May 15 10:16:40 2023 ] 	Training Accuracy: 91.79%
[ Mon May 15 10:16:41 2023 ] Eval epoch: 20
[ Mon May 15 10:16:57 2023 ] 	Mean test loss of 120 batches: 0.14212340116500854.
[ Mon May 15 10:16:57 2023 ] 	Top1: 97.33%
[ Mon May 15 10:16:57 2023 ] 	Top5: 99.83%
[ Mon May 15 10:16:57 2023 ] Training epoch: 21
[ Mon May 15 10:17:48 2023 ] 	Batch(99/480) done. Loss: 0.0764  lr:0.010000  network_time: 0.0116
[ Mon May 15 10:18:38 2023 ] 	Batch(199/480) done. Loss: 0.0392  lr:0.010000  network_time: 0.0118
[ Mon May 15 10:19:28 2023 ] 	Batch(299/480) done. Loss: 0.0623  lr:0.010000  network_time: 0.0131
[ Mon May 15 10:20:18 2023 ] 	Batch(399/480) done. Loss: 0.0368  lr:0.010000  network_time: 0.0126
[ Mon May 15 10:20:58 2023 ] 	Training Accuracy: 98.00%
[ Mon May 15 10:20:58 2023 ] Eval epoch: 21
[ Mon May 15 10:21:15 2023 ] 	Mean test loss of 120 batches: 0.030620766803622246.
[ Mon May 15 10:21:15 2023 ] 	Top1: 99.50%
[ Mon May 15 10:21:15 2023 ] 	Top5: 100.00%
[ Mon May 15 10:21:15 2023 ] Training epoch: 22
[ Mon May 15 10:21:25 2023 ] 	Batch(19/480) done. Loss: 0.0024  lr:0.010000  network_time: 0.0122
[ Mon May 15 10:22:15 2023 ] 	Batch(119/480) done. Loss: 0.0132  lr:0.010000  network_time: 0.0116
[ Mon May 15 10:23:05 2023 ] 	Batch(219/480) done. Loss: 0.0012  lr:0.010000  network_time: 0.0121
[ Mon May 15 10:23:55 2023 ] 	Batch(319/480) done. Loss: 0.0114  lr:0.010000  network_time: 0.0118
[ Mon May 15 10:24:45 2023 ] 	Batch(419/480) done. Loss: 0.0028  lr:0.010000  network_time: 0.0114
[ Mon May 15 10:25:15 2023 ] 	Training Accuracy: 99.08%
[ Mon May 15 10:25:15 2023 ] Eval epoch: 22
[ Mon May 15 10:25:32 2023 ] 	Mean test loss of 120 batches: 0.019048934802412987.
[ Mon May 15 10:25:32 2023 ] 	Top1: 99.33%
[ Mon May 15 10:25:32 2023 ] 	Top5: 100.00%
[ Mon May 15 10:25:32 2023 ] Training epoch: 23
[ Mon May 15 10:25:52 2023 ] 	Batch(39/480) done. Loss: 0.0064  lr:0.010000  network_time: 0.0111
[ Mon May 15 10:26:42 2023 ] 	Batch(139/480) done. Loss: 0.0461  lr:0.010000  network_time: 0.0118
[ Mon May 15 10:27:32 2023 ] 	Batch(239/480) done. Loss: 0.0044  lr:0.010000  network_time: 0.0118
[ Mon May 15 10:28:22 2023 ] 	Batch(339/480) done. Loss: 0.0064  lr:0.010000  network_time: 0.0118
[ Mon May 15 10:29:12 2023 ] 	Batch(439/480) done. Loss: 0.0067  lr:0.010000  network_time: 0.0123
[ Mon May 15 10:29:32 2023 ] 	Training Accuracy: 99.21%
[ Mon May 15 10:29:32 2023 ] Eval epoch: 23
[ Mon May 15 10:29:49 2023 ] 	Mean test loss of 120 batches: 0.018460555002093315.
[ Mon May 15 10:29:49 2023 ] 	Top1: 99.50%
[ Mon May 15 10:29:49 2023 ] 	Top5: 100.00%
[ Mon May 15 10:29:49 2023 ] Training epoch: 24
[ Mon May 15 10:30:19 2023 ] 	Batch(59/480) done. Loss: 0.0422  lr:0.010000  network_time: 0.0128
[ Mon May 15 10:31:09 2023 ] 	Batch(159/480) done. Loss: 0.0032  lr:0.010000  network_time: 0.0122
[ Mon May 15 10:31:59 2023 ] 	Batch(259/480) done. Loss: 0.0129  lr:0.010000  network_time: 0.0116
[ Mon May 15 10:32:49 2023 ] 	Batch(359/480) done. Loss: 0.0462  lr:0.010000  network_time: 0.0115
[ Mon May 15 10:33:39 2023 ] 	Batch(459/480) done. Loss: 0.0920  lr:0.010000  network_time: 0.0116
[ Mon May 15 10:33:49 2023 ] 	Training Accuracy: 99.21%
[ Mon May 15 10:33:49 2023 ] Eval epoch: 24
[ Mon May 15 10:34:06 2023 ] 	Mean test loss of 120 batches: 0.015418356284499168.
[ Mon May 15 10:34:06 2023 ] 	Top1: 99.50%
[ Mon May 15 10:34:06 2023 ] 	Top5: 100.00%
[ Mon May 15 10:34:06 2023 ] Training epoch: 25
[ Mon May 15 10:34:46 2023 ] 	Batch(79/480) done. Loss: 0.0250  lr:0.010000  network_time: 0.0120
[ Mon May 15 10:35:36 2023 ] 	Batch(179/480) done. Loss: 0.0482  lr:0.010000  network_time: 0.0120
[ Mon May 15 10:36:26 2023 ] 	Batch(279/480) done. Loss: 0.0194  lr:0.010000  network_time: 0.0122
[ Mon May 15 10:37:16 2023 ] 	Batch(379/480) done. Loss: 0.0016  lr:0.010000  network_time: 0.0120
[ Mon May 15 10:38:06 2023 ] 	Batch(479/480) done. Loss: 0.0037  lr:0.010000  network_time: 0.0123
[ Mon May 15 10:38:06 2023 ] 	Training Accuracy: 99.38%
[ Mon May 15 10:38:06 2023 ] Eval epoch: 25
[ Mon May 15 10:38:23 2023 ] 	Mean test loss of 120 batches: 0.008975060656666756.
[ Mon May 15 10:38:23 2023 ] 	Top1: 99.67%
[ Mon May 15 10:38:23 2023 ] 	Top5: 100.00%
[ Mon May 15 10:38:23 2023 ] Training epoch: 26
[ Mon May 15 10:39:13 2023 ] 	Batch(99/480) done. Loss: 0.0058  lr:0.001000  network_time: 0.0117
[ Mon May 15 10:40:03 2023 ] 	Batch(199/480) done. Loss: 0.0634  lr:0.001000  network_time: 0.0118
[ Mon May 15 10:40:53 2023 ] 	Batch(299/480) done. Loss: 0.0281  lr:0.001000  network_time: 0.0117
[ Mon May 15 10:41:43 2023 ] 	Batch(399/480) done. Loss: 0.0010  lr:0.001000  network_time: 0.0116
[ Mon May 15 10:42:23 2023 ] 	Training Accuracy: 99.75%
[ Mon May 15 10:42:23 2023 ] Eval epoch: 26
[ Mon May 15 10:42:40 2023 ] 	Mean test loss of 120 batches: 0.008707787841558456.
[ Mon May 15 10:42:40 2023 ] 	Top1: 99.83%
[ Mon May 15 10:42:40 2023 ] 	Top5: 100.00%
[ Mon May 15 10:42:40 2023 ] Training epoch: 27
[ Mon May 15 10:42:50 2023 ] 	Batch(19/480) done. Loss: 0.0096  lr:0.001000  network_time: 0.0114
[ Mon May 15 10:43:40 2023 ] 	Batch(119/480) done. Loss: 0.1136  lr:0.001000  network_time: 0.0118
[ Mon May 15 10:44:30 2023 ] 	Batch(219/480) done. Loss: 0.0087  lr:0.001000  network_time: 0.0113
[ Mon May 15 10:45:20 2023 ] 	Batch(319/480) done. Loss: 0.0720  lr:0.001000  network_time: 0.0116
[ Mon May 15 10:46:10 2023 ] 	Batch(419/480) done. Loss: 0.0497  lr:0.001000  network_time: 0.0116
[ Mon May 15 10:46:40 2023 ] 	Training Accuracy: 99.54%
[ Mon May 15 10:46:40 2023 ] Eval epoch: 27
[ Mon May 15 10:46:57 2023 ] 	Mean test loss of 120 batches: 0.00777830183506012.
[ Mon May 15 10:46:57 2023 ] 	Top1: 99.83%
[ Mon May 15 10:46:57 2023 ] 	Top5: 100.00%
[ Mon May 15 10:46:57 2023 ] Training epoch: 28
[ Mon May 15 10:47:17 2023 ] 	Batch(39/480) done. Loss: 0.0134  lr:0.001000  network_time: 0.0113
[ Mon May 15 10:48:08 2023 ] 	Batch(139/480) done. Loss: 0.0057  lr:0.001000  network_time: 0.0116
[ Mon May 15 10:48:58 2023 ] 	Batch(239/480) done. Loss: 0.0042  lr:0.001000  network_time: 0.0116
[ Mon May 15 10:49:48 2023 ] 	Batch(339/480) done. Loss: 0.0100  lr:0.001000  network_time: 0.0116
[ Mon May 15 10:50:38 2023 ] 	Batch(439/480) done. Loss: 0.0112  lr:0.001000  network_time: 0.0113
[ Mon May 15 10:50:58 2023 ] 	Training Accuracy: 99.50%
[ Mon May 15 10:50:58 2023 ] Eval epoch: 28
[ Mon May 15 10:51:15 2023 ] 	Mean test loss of 120 batches: 0.009049437008798122.
[ Mon May 15 10:51:15 2023 ] 	Top1: 99.83%
[ Mon May 15 10:51:15 2023 ] 	Top5: 100.00%
[ Mon May 15 10:51:15 2023 ] Training epoch: 29
[ Mon May 15 10:51:45 2023 ] 	Batch(59/480) done. Loss: 0.0793  lr:0.001000  network_time: 0.0119
[ Mon May 15 10:52:35 2023 ] 	Batch(159/480) done. Loss: 0.0379  lr:0.001000  network_time: 0.0116
[ Mon May 15 10:53:25 2023 ] 	Batch(259/480) done. Loss: 0.0062  lr:0.001000  network_time: 0.0117
[ Mon May 15 10:54:15 2023 ] 	Batch(359/480) done. Loss: 0.0059  lr:0.001000  network_time: 0.0119
[ Mon May 15 10:55:05 2023 ] 	Batch(459/480) done. Loss: 0.0066  lr:0.001000  network_time: 0.0119
[ Mon May 15 10:55:15 2023 ] 	Training Accuracy: 99.50%
[ Mon May 15 10:55:15 2023 ] Eval epoch: 29
[ Mon May 15 10:55:32 2023 ] 	Mean test loss of 120 batches: 0.020955931395292282.
[ Mon May 15 10:55:32 2023 ] 	Top1: 99.50%
[ Mon May 15 10:55:32 2023 ] 	Top5: 100.00%
[ Mon May 15 10:55:32 2023 ] Training epoch: 30
[ Mon May 15 10:56:12 2023 ] 	Batch(79/480) done. Loss: 0.0028  lr:0.001000  network_time: 0.0113
[ Mon May 15 10:57:02 2023 ] 	Batch(179/480) done. Loss: 0.0082  lr:0.001000  network_time: 0.0118
[ Mon May 15 10:57:52 2023 ] 	Batch(279/480) done. Loss: 0.0085  lr:0.001000  network_time: 0.0121
[ Mon May 15 10:58:42 2023 ] 	Batch(379/480) done. Loss: 0.0068  lr:0.001000  network_time: 0.0115
[ Mon May 15 10:59:32 2023 ] 	Batch(479/480) done. Loss: 0.0194  lr:0.001000  network_time: 0.0115
[ Mon May 15 10:59:32 2023 ] 	Training Accuracy: 99.67%
[ Mon May 15 10:59:32 2023 ] Eval epoch: 30
[ Mon May 15 10:59:49 2023 ] 	Mean test loss of 120 batches: 0.010037166997790337.
[ Mon May 15 10:59:49 2023 ] 	Top1: 99.67%
[ Mon May 15 10:59:49 2023 ] 	Top5: 100.00%
