[ Fri May 12 20:59:35 2023 ] NUM WORKER: 1
[ Fri May 12 21:00:26 2023 ] Parameters:
{'work_dir': './work_dir/sibi_individual_inner_group_ShiftGCN_mod_3_joint_n_5_kfold_fold_4', 'model_saved_name': './save_models/sibi_individual_inner_group_ShiftGCN_mod_3_joint_n_5_kfold_fold_4', 'Experiment_name': 'sibi_individual_inner_group_ShiftGCN_mod_3_joint_n_5_kfold', 'config': './config/recalculated/train_sibi_with_mouth_augmented_individual_inner_group_shift_joint_mod_3.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 2, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'n_splits': 5, 'feeder': 'feeders.feeder_hsd.Feeder', 'num_worker': 1, 'train_feeder_args': {'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': -1, 'normalization': False}, 'test_feeder_args': None, 'data_path': './data/augmented_recalculate_normalized', 'model': 'model.shift_gcn.Model', 'model_args': {'num_class': 50, 'num_person': 1, 'num_point': 115, 'graph_group': [[0, 39], [40, 60], [61, 81], [82, 114]], 'method': 'grouped.inner', 'weight': 3, 'graph': 'graph.skeleton_with_mouth.SkeletonWithMouth', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [20, 25], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 5, 'test_batch_size': 5, 'start_epoch': 0, 'num_epoch': 30, 'folds_range': [2, 5], 'weight_decay': 0.0001, 'only_train_part': True, 'only_train_epoch': 1, 'warm_up_epoch': 0}

[ Fri May 12 21:00:26 2023 ] Training epoch: 1
[ Fri May 12 21:01:15 2023 ] 	Batch(99/480) done. Loss: 3.9746  lr:0.100000  network_time: 0.0131
[ Fri May 12 21:02:04 2023 ] 	Batch(199/480) done. Loss: 3.8907  lr:0.100000  network_time: 0.0107
[ Fri May 12 21:02:52 2023 ] 	Batch(299/480) done. Loss: 3.4315  lr:0.100000  network_time: 0.0113
[ Fri May 12 21:03:41 2023 ] 	Batch(399/480) done. Loss: 3.3642  lr:0.100000  network_time: 0.0111
[ Fri May 12 21:04:20 2023 ] 	Training Accuracy: 5.79%
[ Fri May 12 21:04:20 2023 ] Eval epoch: 1
[ Fri May 12 21:04:37 2023 ] 	Mean test loss of 120 batches: 5.087772846221924.
[ Fri May 12 21:04:37 2023 ] 	Top1: 11.67%
[ Fri May 12 21:04:37 2023 ] 	Top5: 45.67%
[ Fri May 12 21:04:37 2023 ] Training epoch: 2
[ Fri May 12 21:04:47 2023 ] 	Batch(19/480) done. Loss: 2.9431  lr:0.100000  network_time: 0.0111
[ Fri May 12 21:05:35 2023 ] 	Batch(119/480) done. Loss: 3.6514  lr:0.100000  network_time: 0.0110
[ Fri May 12 21:06:24 2023 ] 	Batch(219/480) done. Loss: 3.2566  lr:0.100000  network_time: 0.0109
[ Fri May 12 21:07:13 2023 ] 	Batch(319/480) done. Loss: 2.8169  lr:0.100000  network_time: 0.0136
[ Fri May 12 21:08:01 2023 ] 	Batch(419/480) done. Loss: 1.5358  lr:0.100000  network_time: 0.0112
[ Fri May 12 21:08:31 2023 ] 	Training Accuracy: 15.38%
[ Fri May 12 21:08:31 2023 ] Eval epoch: 2
[ Fri May 12 21:08:48 2023 ] 	Mean test loss of 120 batches: 2.602306365966797.
[ Fri May 12 21:08:48 2023 ] 	Top1: 23.67%
[ Fri May 12 21:08:48 2023 ] 	Top5: 69.33%
[ Fri May 12 21:08:48 2023 ] Training epoch: 3
[ Fri May 12 21:09:07 2023 ] 	Batch(39/480) done. Loss: 2.9562  lr:0.100000  network_time: 0.0110
[ Fri May 12 21:09:56 2023 ] 	Batch(139/480) done. Loss: 2.2177  lr:0.100000  network_time: 0.0112
[ Fri May 12 21:10:44 2023 ] 	Batch(239/480) done. Loss: 2.5496  lr:0.100000  network_time: 0.0107
[ Fri May 12 21:11:33 2023 ] 	Batch(339/480) done. Loss: 3.2031  lr:0.100000  network_time: 0.0112
[ Fri May 12 21:12:22 2023 ] 	Batch(439/480) done. Loss: 2.2490  lr:0.100000  network_time: 0.0107
[ Fri May 12 21:12:41 2023 ] 	Training Accuracy: 21.71%
[ Fri May 12 21:12:41 2023 ] Eval epoch: 3
[ Fri May 12 21:12:58 2023 ] 	Mean test loss of 120 batches: 2.583285093307495.
[ Fri May 12 21:12:58 2023 ] 	Top1: 23.83%
[ Fri May 12 21:12:58 2023 ] 	Top5: 70.67%
[ Fri May 12 21:12:58 2023 ] Training epoch: 4
[ Fri May 12 21:13:27 2023 ] 	Batch(59/480) done. Loss: 2.2974  lr:0.100000  network_time: 0.0107
[ Fri May 12 21:14:16 2023 ] 	Batch(159/480) done. Loss: 2.6039  lr:0.100000  network_time: 0.0135
[ Fri May 12 21:15:05 2023 ] 	Batch(259/480) done. Loss: 1.6219  lr:0.100000  network_time: 0.0109
[ Fri May 12 21:15:53 2023 ] 	Batch(359/480) done. Loss: 1.7341  lr:0.100000  network_time: 0.0155
[ Fri May 12 21:16:42 2023 ] 	Batch(459/480) done. Loss: 2.2543  lr:0.100000  network_time: 0.0135
[ Fri May 12 21:16:52 2023 ] 	Training Accuracy: 28.50%
[ Fri May 12 21:16:52 2023 ] Eval epoch: 4
[ Fri May 12 21:17:09 2023 ] 	Mean test loss of 120 batches: 3.970027208328247.
[ Fri May 12 21:17:09 2023 ] 	Top1: 17.83%
[ Fri May 12 21:17:09 2023 ] 	Top5: 49.00%
[ Fri May 12 21:17:09 2023 ] Training epoch: 5
[ Fri May 12 21:17:48 2023 ] 	Batch(79/480) done. Loss: 3.0442  lr:0.100000  network_time: 0.0116
[ Fri May 12 21:18:36 2023 ] 	Batch(179/480) done. Loss: 1.6873  lr:0.100000  network_time: 0.0109
[ Fri May 12 21:19:25 2023 ] 	Batch(279/480) done. Loss: 2.9648  lr:0.100000  network_time: 0.0112
[ Fri May 12 21:20:13 2023 ] 	Batch(379/480) done. Loss: 2.2882  lr:0.100000  network_time: 0.0122
[ Fri May 12 21:21:02 2023 ] 	Batch(479/480) done. Loss: 1.4363  lr:0.100000  network_time: 0.0113
[ Fri May 12 21:21:02 2023 ] 	Training Accuracy: 35.42%
[ Fri May 12 21:21:02 2023 ] Eval epoch: 5
[ Fri May 12 21:21:19 2023 ] 	Mean test loss of 120 batches: 2.526028871536255.
[ Fri May 12 21:21:19 2023 ] 	Top1: 34.00%
[ Fri May 12 21:21:19 2023 ] 	Top5: 85.33%
[ Fri May 12 21:21:19 2023 ] Training epoch: 6
[ Fri May 12 21:22:08 2023 ] 	Batch(99/480) done. Loss: 1.8781  lr:0.100000  network_time: 0.0111
[ Fri May 12 21:22:56 2023 ] 	Batch(199/480) done. Loss: 2.4582  lr:0.100000  network_time: 0.0132
[ Fri May 12 21:23:45 2023 ] 	Batch(299/480) done. Loss: 1.6076  lr:0.100000  network_time: 0.0135
[ Fri May 12 21:24:34 2023 ] 	Batch(399/480) done. Loss: 2.1345  lr:0.100000  network_time: 0.0108
[ Fri May 12 21:25:13 2023 ] 	Training Accuracy: 43.21%
[ Fri May 12 21:25:13 2023 ] Eval epoch: 6
[ Fri May 12 21:25:30 2023 ] 	Mean test loss of 120 batches: 1.78371000289917.
[ Fri May 12 21:25:30 2023 ] 	Top1: 51.33%
[ Fri May 12 21:25:30 2023 ] 	Top5: 90.33%
[ Fri May 12 21:25:30 2023 ] Training epoch: 7
[ Fri May 12 21:25:39 2023 ] 	Batch(19/480) done. Loss: 1.1327  lr:0.100000  network_time: 0.0111
[ Fri May 12 21:26:28 2023 ] 	Batch(119/480) done. Loss: 2.2705  lr:0.100000  network_time: 0.0120
[ Fri May 12 21:27:17 2023 ] 	Batch(219/480) done. Loss: 1.3821  lr:0.100000  network_time: 0.0115
[ Fri May 12 21:28:05 2023 ] 	Batch(319/480) done. Loss: 1.4304  lr:0.100000  network_time: 0.0111
[ Fri May 12 21:28:54 2023 ] 	Batch(419/480) done. Loss: 1.6633  lr:0.100000  network_time: 0.0115
[ Fri May 12 21:29:23 2023 ] 	Training Accuracy: 47.71%
[ Fri May 12 21:29:23 2023 ] Eval epoch: 7
[ Fri May 12 21:29:40 2023 ] 	Mean test loss of 120 batches: 1.447275996208191.
[ Fri May 12 21:29:40 2023 ] 	Top1: 53.83%
[ Fri May 12 21:29:40 2023 ] 	Top5: 93.17%
[ Fri May 12 21:29:40 2023 ] Training epoch: 8
[ Fri May 12 21:30:00 2023 ] 	Batch(39/480) done. Loss: 0.5041  lr:0.100000  network_time: 0.0109
[ Fri May 12 21:30:48 2023 ] 	Batch(139/480) done. Loss: 1.4253  lr:0.100000  network_time: 0.0109
[ Fri May 12 21:31:37 2023 ] 	Batch(239/480) done. Loss: 1.2561  lr:0.100000  network_time: 0.0124
[ Fri May 12 21:32:26 2023 ] 	Batch(339/480) done. Loss: 0.9944  lr:0.100000  network_time: 0.0114
[ Fri May 12 21:33:14 2023 ] 	Batch(439/480) done. Loss: 1.9454  lr:0.100000  network_time: 0.0112
[ Fri May 12 21:33:34 2023 ] 	Training Accuracy: 55.13%
[ Fri May 12 21:33:34 2023 ] Eval epoch: 8
[ Fri May 12 21:33:51 2023 ] 	Mean test loss of 120 batches: 1.3158729076385498.
[ Fri May 12 21:33:51 2023 ] 	Top1: 58.67%
[ Fri May 12 21:33:51 2023 ] 	Top5: 95.33%
[ Fri May 12 21:33:51 2023 ] Training epoch: 9
[ Fri May 12 21:34:20 2023 ] 	Batch(59/480) done. Loss: 0.6800  lr:0.100000  network_time: 0.0109
[ Fri May 12 21:35:09 2023 ] 	Batch(159/480) done. Loss: 2.1154  lr:0.100000  network_time: 0.0112
[ Fri May 12 21:35:58 2023 ] 	Batch(259/480) done. Loss: 1.1633  lr:0.100000  network_time: 0.0114
[ Fri May 12 21:36:46 2023 ] 	Batch(359/480) done. Loss: 0.6653  lr:0.100000  network_time: 0.0111
[ Fri May 12 21:37:35 2023 ] 	Batch(459/480) done. Loss: 1.0974  lr:0.100000  network_time: 0.0109
[ Fri May 12 21:37:45 2023 ] 	Training Accuracy: 60.58%
[ Fri May 12 21:37:45 2023 ] Eval epoch: 9
[ Fri May 12 21:38:02 2023 ] 	Mean test loss of 120 batches: 4.27985954284668.
[ Fri May 12 21:38:02 2023 ] 	Top1: 47.33%
[ Fri May 12 21:38:02 2023 ] 	Top5: 85.33%
[ Fri May 12 21:38:02 2023 ] Training epoch: 10
[ Fri May 12 21:38:41 2023 ] 	Batch(79/480) done. Loss: 1.1847  lr:0.100000  network_time: 0.0108
[ Fri May 12 21:39:29 2023 ] 	Batch(179/480) done. Loss: 3.1061  lr:0.100000  network_time: 0.0110
[ Fri May 12 21:40:18 2023 ] 	Batch(279/480) done. Loss: 2.0603  lr:0.100000  network_time: 0.0137
[ Fri May 12 21:41:07 2023 ] 	Batch(379/480) done. Loss: 1.2362  lr:0.100000  network_time: 0.0111
[ Fri May 12 21:41:55 2023 ] 	Batch(479/480) done. Loss: 0.6966  lr:0.100000  network_time: 0.0106
[ Fri May 12 21:41:55 2023 ] 	Training Accuracy: 65.83%
[ Fri May 12 21:41:55 2023 ] Eval epoch: 10
[ Fri May 12 21:42:13 2023 ] 	Mean test loss of 120 batches: 1.1218730211257935.
[ Fri May 12 21:42:13 2023 ] 	Top1: 69.00%
[ Fri May 12 21:42:13 2023 ] 	Top5: 96.67%
[ Fri May 12 21:42:13 2023 ] Training epoch: 11
[ Fri May 12 21:43:01 2023 ] 	Batch(99/480) done. Loss: 1.0675  lr:0.100000  network_time: 0.0107
[ Fri May 12 21:43:50 2023 ] 	Batch(199/480) done. Loss: 0.6960  lr:0.100000  network_time: 0.0114
[ Fri May 12 21:44:39 2023 ] 	Batch(299/480) done. Loss: 0.5758  lr:0.100000  network_time: 0.0120
[ Fri May 12 21:45:27 2023 ] 	Batch(399/480) done. Loss: 0.4169  lr:0.100000  network_time: 0.0110
[ Fri May 12 21:46:06 2023 ] 	Training Accuracy: 69.17%
[ Fri May 12 21:46:06 2023 ] Eval epoch: 11
[ Fri May 12 21:46:23 2023 ] 	Mean test loss of 120 batches: 2.95133113861084.
[ Fri May 12 21:46:23 2023 ] 	Top1: 42.00%
[ Fri May 12 21:46:23 2023 ] 	Top5: 86.67%
[ Fri May 12 21:46:23 2023 ] Training epoch: 12
[ Fri May 12 21:46:33 2023 ] 	Batch(19/480) done. Loss: 1.3059  lr:0.100000  network_time: 0.0134
[ Fri May 12 21:47:22 2023 ] 	Batch(119/480) done. Loss: 0.4481  lr:0.100000  network_time: 0.0109
[ Fri May 12 21:48:10 2023 ] 	Batch(219/480) done. Loss: 0.7867  lr:0.100000  network_time: 0.0108
[ Fri May 12 21:48:59 2023 ] 	Batch(319/480) done. Loss: 0.5211  lr:0.100000  network_time: 0.0113
[ Fri May 12 21:49:48 2023 ] 	Batch(419/480) done. Loss: 1.0480  lr:0.100000  network_time: 0.0112
[ Fri May 12 21:50:17 2023 ] 	Training Accuracy: 73.29%
[ Fri May 12 21:50:17 2023 ] Eval epoch: 12
[ Fri May 12 21:50:34 2023 ] 	Mean test loss of 120 batches: 0.9842998385429382.
[ Fri May 12 21:50:34 2023 ] 	Top1: 71.17%
[ Fri May 12 21:50:34 2023 ] 	Top5: 96.67%
[ Fri May 12 21:50:34 2023 ] Training epoch: 13
[ Fri May 12 21:50:54 2023 ] 	Batch(39/480) done. Loss: 1.7746  lr:0.100000  network_time: 0.0114
[ Fri May 12 21:51:42 2023 ] 	Batch(139/480) done. Loss: 0.2631  lr:0.100000  network_time: 0.0111
[ Fri May 12 21:52:31 2023 ] 	Batch(239/480) done. Loss: 0.6319  lr:0.100000  network_time: 0.0110
[ Fri May 12 21:53:20 2023 ] 	Batch(339/480) done. Loss: 0.8898  lr:0.100000  network_time: 0.0133
[ Fri May 12 21:54:08 2023 ] 	Batch(439/480) done. Loss: 0.1228  lr:0.100000  network_time: 0.0127
[ Fri May 12 21:54:28 2023 ] 	Training Accuracy: 75.50%
[ Fri May 12 21:54:28 2023 ] Eval epoch: 13
[ Fri May 12 21:54:45 2023 ] 	Mean test loss of 120 batches: 0.6021270751953125.
[ Fri May 12 21:54:45 2023 ] 	Top1: 81.67%
[ Fri May 12 21:54:45 2023 ] 	Top5: 99.50%
[ Fri May 12 21:54:45 2023 ] Training epoch: 14
[ Fri May 12 21:55:14 2023 ] 	Batch(59/480) done. Loss: 0.3105  lr:0.100000  network_time: 0.0136
[ Fri May 12 21:56:03 2023 ] 	Batch(159/480) done. Loss: 0.7714  lr:0.100000  network_time: 0.0112
[ Fri May 12 21:56:51 2023 ] 	Batch(259/480) done. Loss: 0.4922  lr:0.100000  network_time: 0.0109
[ Fri May 12 21:57:40 2023 ] 	Batch(359/480) done. Loss: 0.6921  lr:0.100000  network_time: 0.0132
[ Fri May 12 21:58:29 2023 ] 	Batch(459/480) done. Loss: 1.0609  lr:0.100000  network_time: 0.0114
[ Fri May 12 21:58:38 2023 ] 	Training Accuracy: 78.71%
[ Fri May 12 21:58:38 2023 ] Eval epoch: 14
[ Fri May 12 21:58:55 2023 ] 	Mean test loss of 120 batches: 0.9147078394889832.
[ Fri May 12 21:58:55 2023 ] 	Top1: 80.67%
[ Fri May 12 21:58:55 2023 ] 	Top5: 99.50%
[ Fri May 12 21:58:55 2023 ] Training epoch: 15
[ Fri May 12 21:59:34 2023 ] 	Batch(79/480) done. Loss: 1.0430  lr:0.100000  network_time: 0.0135
[ Fri May 12 22:00:23 2023 ] 	Batch(179/480) done. Loss: 0.4571  lr:0.100000  network_time: 0.0108
[ Fri May 12 22:01:12 2023 ] 	Batch(279/480) done. Loss: 0.2352  lr:0.100000  network_time: 0.0114
[ Fri May 12 22:02:01 2023 ] 	Batch(379/480) done. Loss: 0.3718  lr:0.100000  network_time: 0.0137
[ Fri May 12 22:02:49 2023 ] 	Batch(479/480) done. Loss: 0.5744  lr:0.100000  network_time: 0.0111
[ Fri May 12 22:02:49 2023 ] 	Training Accuracy: 80.33%
[ Fri May 12 22:02:49 2023 ] Eval epoch: 15
[ Fri May 12 22:03:06 2023 ] 	Mean test loss of 120 batches: 1.41353178024292.
[ Fri May 12 22:03:06 2023 ] 	Top1: 60.83%
[ Fri May 12 22:03:06 2023 ] 	Top5: 91.50%
[ Fri May 12 22:03:06 2023 ] Training epoch: 16
[ Fri May 12 22:03:55 2023 ] 	Batch(99/480) done. Loss: 0.9463  lr:0.100000  network_time: 0.0110
[ Fri May 12 22:04:44 2023 ] 	Batch(199/480) done. Loss: 0.4795  lr:0.100000  network_time: 0.0109
[ Fri May 12 22:05:32 2023 ] 	Batch(299/480) done. Loss: 0.2057  lr:0.100000  network_time: 0.0129
[ Fri May 12 22:06:21 2023 ] 	Batch(399/480) done. Loss: 0.5220  lr:0.100000  network_time: 0.0132
[ Fri May 12 22:07:00 2023 ] 	Training Accuracy: 80.88%
[ Fri May 12 22:07:00 2023 ] Eval epoch: 16
[ Fri May 12 22:07:17 2023 ] 	Mean test loss of 120 batches: 0.7822629809379578.
[ Fri May 12 22:07:17 2023 ] 	Top1: 75.67%
[ Fri May 12 22:07:17 2023 ] 	Top5: 98.00%
[ Fri May 12 22:07:17 2023 ] Training epoch: 17
[ Fri May 12 22:07:27 2023 ] 	Batch(19/480) done. Loss: 0.1604  lr:0.100000  network_time: 0.0136
[ Fri May 12 22:08:16 2023 ] 	Batch(119/480) done. Loss: 0.8341  lr:0.100000  network_time: 0.0108
[ Fri May 12 22:09:04 2023 ] 	Batch(219/480) done. Loss: 0.1370  lr:0.100000  network_time: 0.0109
[ Fri May 12 22:09:53 2023 ] 	Batch(319/480) done. Loss: 0.3083  lr:0.100000  network_time: 0.0125
[ Fri May 12 22:10:42 2023 ] 	Batch(419/480) done. Loss: 0.9305  lr:0.100000  network_time: 0.0109
[ Fri May 12 22:11:11 2023 ] 	Training Accuracy: 85.54%
[ Fri May 12 22:11:11 2023 ] Eval epoch: 17
[ Fri May 12 22:11:28 2023 ] 	Mean test loss of 120 batches: 0.6771981716156006.
[ Fri May 12 22:11:28 2023 ] 	Top1: 81.83%
[ Fri May 12 22:11:28 2023 ] 	Top5: 99.00%
[ Fri May 12 22:11:28 2023 ] Training epoch: 18
[ Fri May 12 22:11:47 2023 ] 	Batch(39/480) done. Loss: 0.8783  lr:0.100000  network_time: 0.0109
[ Fri May 12 22:12:36 2023 ] 	Batch(139/480) done. Loss: 0.0578  lr:0.100000  network_time: 0.0113
[ Fri May 12 22:13:25 2023 ] 	Batch(239/480) done. Loss: 0.0975  lr:0.100000  network_time: 0.0121
[ Fri May 12 22:14:14 2023 ] 	Batch(339/480) done. Loss: 0.0144  lr:0.100000  network_time: 0.0108
[ Fri May 12 22:15:02 2023 ] 	Batch(439/480) done. Loss: 1.3466  lr:0.100000  network_time: 0.0110
[ Fri May 12 22:15:22 2023 ] 	Training Accuracy: 83.88%
[ Fri May 12 22:15:22 2023 ] Eval epoch: 18
[ Fri May 12 22:15:39 2023 ] 	Mean test loss of 120 batches: 0.3031332194805145.
[ Fri May 12 22:15:39 2023 ] 	Top1: 89.83%
[ Fri May 12 22:15:39 2023 ] 	Top5: 100.00%
[ Fri May 12 22:15:39 2023 ] Training epoch: 19
[ Fri May 12 22:16:08 2023 ] 	Batch(59/480) done. Loss: 0.0883  lr:0.100000  network_time: 0.0132
[ Fri May 12 22:16:57 2023 ] 	Batch(159/480) done. Loss: 0.4860  lr:0.100000  network_time: 0.0107
[ Fri May 12 22:17:46 2023 ] 	Batch(259/480) done. Loss: 0.6504  lr:0.100000  network_time: 0.0133
[ Fri May 12 22:18:34 2023 ] 	Batch(359/480) done. Loss: 0.7144  lr:0.100000  network_time: 0.0122
[ Fri May 12 22:19:23 2023 ] 	Batch(459/480) done. Loss: 0.9884  lr:0.100000  network_time: 0.0122
[ Fri May 12 22:19:33 2023 ] 	Training Accuracy: 85.17%
[ Fri May 12 22:19:33 2023 ] Eval epoch: 19
[ Fri May 12 22:19:50 2023 ] 	Mean test loss of 120 batches: 0.4431486427783966.
[ Fri May 12 22:19:50 2023 ] 	Top1: 82.67%
[ Fri May 12 22:19:50 2023 ] 	Top5: 98.50%
[ Fri May 12 22:19:50 2023 ] Training epoch: 20
[ Fri May 12 22:20:29 2023 ] 	Batch(79/480) done. Loss: 1.4782  lr:0.100000  network_time: 0.0111
[ Fri May 12 22:21:17 2023 ] 	Batch(179/480) done. Loss: 1.1986  lr:0.100000  network_time: 0.0115
[ Fri May 12 22:22:06 2023 ] 	Batch(279/480) done. Loss: 0.3661  lr:0.100000  network_time: 0.0115
[ Fri May 12 22:22:55 2023 ] 	Batch(379/480) done. Loss: 0.3012  lr:0.100000  network_time: 0.0112
[ Fri May 12 22:23:44 2023 ] 	Batch(479/480) done. Loss: 0.8438  lr:0.100000  network_time: 0.0109
[ Fri May 12 22:23:44 2023 ] 	Training Accuracy: 88.00%
[ Fri May 12 22:23:44 2023 ] Eval epoch: 20
[ Fri May 12 22:24:01 2023 ] 	Mean test loss of 120 batches: 0.3170536160469055.
[ Fri May 12 22:24:01 2023 ] 	Top1: 89.67%
[ Fri May 12 22:24:01 2023 ] 	Top5: 99.83%
[ Fri May 12 22:24:01 2023 ] Training epoch: 21
[ Fri May 12 22:24:50 2023 ] 	Batch(99/480) done. Loss: 0.4918  lr:0.010000  network_time: 0.0112
[ Fri May 12 22:25:38 2023 ] 	Batch(199/480) done. Loss: 0.1035  lr:0.010000  network_time: 0.0109
[ Fri May 12 22:26:27 2023 ] 	Batch(299/480) done. Loss: 0.5361  lr:0.010000  network_time: 0.0108
[ Fri May 12 22:27:16 2023 ] 	Batch(399/480) done. Loss: 0.0359  lr:0.010000  network_time: 0.0111
[ Fri May 12 22:27:55 2023 ] 	Training Accuracy: 96.08%
[ Fri May 12 22:27:55 2023 ] Eval epoch: 21
[ Fri May 12 22:28:12 2023 ] 	Mean test loss of 120 batches: 0.07401509582996368.
[ Fri May 12 22:28:12 2023 ] 	Top1: 98.50%
[ Fri May 12 22:28:12 2023 ] 	Top5: 100.00%
[ Fri May 12 22:28:12 2023 ] Training epoch: 22
[ Fri May 12 22:28:22 2023 ] 	Batch(19/480) done. Loss: 0.0270  lr:0.010000  network_time: 0.0110
[ Fri May 12 22:29:10 2023 ] 	Batch(119/480) done. Loss: 0.1135  lr:0.010000  network_time: 0.0109
[ Fri May 12 22:29:59 2023 ] 	Batch(219/480) done. Loss: 0.2907  lr:0.010000  network_time: 0.0109
[ Fri May 12 22:30:48 2023 ] 	Batch(319/480) done. Loss: 0.0256  lr:0.010000  network_time: 0.0111
[ Fri May 12 22:31:36 2023 ] 	Batch(419/480) done. Loss: 0.1618  lr:0.010000  network_time: 0.0112
[ Fri May 12 22:32:06 2023 ] 	Training Accuracy: 97.00%
[ Fri May 12 22:32:06 2023 ] Eval epoch: 22
[ Fri May 12 22:32:23 2023 ] 	Mean test loss of 120 batches: 0.05685138329863548.
[ Fri May 12 22:32:23 2023 ] 	Top1: 98.00%
[ Fri May 12 22:32:23 2023 ] 	Top5: 100.00%
[ Fri May 12 22:32:23 2023 ] Training epoch: 23
[ Fri May 12 22:32:42 2023 ] 	Batch(39/480) done. Loss: 0.0472  lr:0.010000  network_time: 0.0106
[ Fri May 12 22:33:31 2023 ] 	Batch(139/480) done. Loss: 0.0428  lr:0.010000  network_time: 0.0110
[ Fri May 12 22:34:20 2023 ] 	Batch(239/480) done. Loss: 0.0409  lr:0.010000  network_time: 0.0150
[ Fri May 12 22:35:08 2023 ] 	Batch(339/480) done. Loss: 0.0301  lr:0.010000  network_time: 0.0110
[ Fri May 12 22:35:57 2023 ] 	Batch(439/480) done. Loss: 0.0145  lr:0.010000  network_time: 0.0134
[ Fri May 12 22:36:17 2023 ] 	Training Accuracy: 98.17%
[ Fri May 12 22:36:17 2023 ] Eval epoch: 23
[ Fri May 12 22:36:34 2023 ] 	Mean test loss of 120 batches: 0.04374173656105995.
[ Fri May 12 22:36:34 2023 ] 	Top1: 99.00%
[ Fri May 12 22:36:34 2023 ] 	Top5: 100.00%
[ Fri May 12 22:36:34 2023 ] Training epoch: 24
[ Fri May 12 22:37:03 2023 ] 	Batch(59/480) done. Loss: 0.0466  lr:0.010000  network_time: 0.0134
[ Fri May 12 22:37:52 2023 ] 	Batch(159/480) done. Loss: 0.0113  lr:0.010000  network_time: 0.0115
[ Fri May 12 22:38:40 2023 ] 	Batch(259/480) done. Loss: 0.1203  lr:0.010000  network_time: 0.0110
[ Fri May 12 22:39:29 2023 ] 	Batch(359/480) done. Loss: 0.1860  lr:0.010000  network_time: 0.0109
[ Fri May 12 22:40:18 2023 ] 	Batch(459/480) done. Loss: 0.1133  lr:0.010000  network_time: 0.0108
[ Fri May 12 22:40:27 2023 ] 	Training Accuracy: 98.17%
[ Fri May 12 22:40:28 2023 ] Eval epoch: 24
[ Fri May 12 22:40:44 2023 ] 	Mean test loss of 120 batches: 0.03705199062824249.
[ Fri May 12 22:40:45 2023 ] 	Top1: 99.00%
[ Fri May 12 22:40:45 2023 ] 	Top5: 100.00%
[ Fri May 12 22:40:45 2023 ] Training epoch: 25
[ Fri May 12 22:41:24 2023 ] 	Batch(79/480) done. Loss: 0.0256  lr:0.010000  network_time: 0.0110
[ Fri May 12 22:42:12 2023 ] 	Batch(179/480) done. Loss: 0.1030  lr:0.010000  network_time: 0.0110
[ Fri May 12 22:43:01 2023 ] 	Batch(279/480) done. Loss: 0.0445  lr:0.010000  network_time: 0.0134
[ Fri May 12 22:43:50 2023 ] 	Batch(379/480) done. Loss: 0.0125  lr:0.010000  network_time: 0.0107
[ Fri May 12 22:44:38 2023 ] 	Batch(479/480) done. Loss: 0.0045  lr:0.010000  network_time: 0.0109
[ Fri May 12 22:44:39 2023 ] 	Training Accuracy: 99.08%
[ Fri May 12 22:44:39 2023 ] Eval epoch: 25
[ Fri May 12 22:44:56 2023 ] 	Mean test loss of 120 batches: 0.03732036054134369.
[ Fri May 12 22:44:56 2023 ] 	Top1: 99.00%
[ Fri May 12 22:44:56 2023 ] 	Top5: 100.00%
[ Fri May 12 22:44:56 2023 ] Training epoch: 26
[ Fri May 12 22:45:44 2023 ] 	Batch(99/480) done. Loss: 0.0143  lr:0.001000  network_time: 0.0119
[ Fri May 12 22:46:33 2023 ] 	Batch(199/480) done. Loss: 0.0488  lr:0.001000  network_time: 0.0135
[ Fri May 12 22:47:22 2023 ] 	Batch(299/480) done. Loss: 0.0703  lr:0.001000  network_time: 0.0135
[ Fri May 12 22:48:11 2023 ] 	Batch(399/480) done. Loss: 0.0561  lr:0.001000  network_time: 0.0111
[ Fri May 12 22:48:50 2023 ] 	Training Accuracy: 98.75%
[ Fri May 12 22:48:50 2023 ] Eval epoch: 26
[ Fri May 12 22:49:07 2023 ] 	Mean test loss of 120 batches: 0.0378500334918499.
[ Fri May 12 22:49:07 2023 ] 	Top1: 99.00%
[ Fri May 12 22:49:07 2023 ] 	Top5: 100.00%
[ Fri May 12 22:49:07 2023 ] Training epoch: 27
[ Fri May 12 22:49:16 2023 ] 	Batch(19/480) done. Loss: 0.0212  lr:0.001000  network_time: 0.0111
[ Fri May 12 22:50:05 2023 ] 	Batch(119/480) done. Loss: 0.0317  lr:0.001000  network_time: 0.0108
[ Fri May 12 22:50:54 2023 ] 	Batch(219/480) done. Loss: 0.0464  lr:0.001000  network_time: 0.0110
[ Fri May 12 22:51:43 2023 ] 	Batch(319/480) done. Loss: 0.0226  lr:0.001000  network_time: 0.0109
[ Fri May 12 22:52:31 2023 ] 	Batch(419/480) done. Loss: 0.4703  lr:0.001000  network_time: 0.0109
[ Fri May 12 22:53:01 2023 ] 	Training Accuracy: 99.21%
[ Fri May 12 22:53:01 2023 ] Eval epoch: 27
[ Fri May 12 22:53:18 2023 ] 	Mean test loss of 120 batches: 0.026506755501031876.
[ Fri May 12 22:53:18 2023 ] 	Top1: 99.50%
[ Fri May 12 22:53:18 2023 ] 	Top5: 100.00%
[ Fri May 12 22:53:18 2023 ] Training epoch: 28
[ Fri May 12 22:53:37 2023 ] 	Batch(39/480) done. Loss: 0.0294  lr:0.001000  network_time: 0.0138
[ Fri May 12 22:54:26 2023 ] 	Batch(139/480) done. Loss: 0.0045  lr:0.001000  network_time: 0.0109
[ Fri May 12 22:55:15 2023 ] 	Batch(239/480) done. Loss: 0.0461  lr:0.001000  network_time: 0.0126
[ Fri May 12 22:56:03 2023 ] 	Batch(339/480) done. Loss: 0.0253  lr:0.001000  network_time: 0.0112
[ Fri May 12 22:56:52 2023 ] 	Batch(439/480) done. Loss: 0.0575  lr:0.001000  network_time: 0.0110
[ Fri May 12 22:57:11 2023 ] 	Training Accuracy: 99.21%
[ Fri May 12 22:57:11 2023 ] Eval epoch: 28
[ Fri May 12 22:57:28 2023 ] 	Mean test loss of 120 batches: 0.022839440032839775.
[ Fri May 12 22:57:28 2023 ] 	Top1: 99.50%
[ Fri May 12 22:57:28 2023 ] 	Top5: 100.00%
[ Fri May 12 22:57:28 2023 ] Training epoch: 29
[ Fri May 12 22:57:58 2023 ] 	Batch(59/480) done. Loss: 0.0367  lr:0.001000  network_time: 0.0117
[ Fri May 12 22:58:46 2023 ] 	Batch(159/480) done. Loss: 0.0671  lr:0.001000  network_time: 0.0132
[ Fri May 12 22:59:35 2023 ] 	Batch(259/480) done. Loss: 0.0204  lr:0.001000  network_time: 0.0108
[ Fri May 12 23:00:24 2023 ] 	Batch(359/480) done. Loss: 0.0156  lr:0.001000  network_time: 0.0110
[ Fri May 12 23:01:12 2023 ] 	Batch(459/480) done. Loss: 0.0595  lr:0.001000  network_time: 0.0108
[ Fri May 12 23:01:22 2023 ] 	Training Accuracy: 99.29%
[ Fri May 12 23:01:22 2023 ] Eval epoch: 29
[ Fri May 12 23:01:39 2023 ] 	Mean test loss of 120 batches: 0.031690217554569244.
[ Fri May 12 23:01:39 2023 ] 	Top1: 99.17%
[ Fri May 12 23:01:39 2023 ] 	Top5: 100.00%
[ Fri May 12 23:01:39 2023 ] Training epoch: 30
[ Fri May 12 23:02:18 2023 ] 	Batch(79/480) done. Loss: 0.0615  lr:0.001000  network_time: 0.0108
[ Fri May 12 23:03:07 2023 ] 	Batch(179/480) done. Loss: 0.0322  lr:0.001000  network_time: 0.0108
[ Fri May 12 23:03:55 2023 ] 	Batch(279/480) done. Loss: 0.0527  lr:0.001000  network_time: 0.0112
[ Fri May 12 23:04:44 2023 ] 	Batch(379/480) done. Loss: 0.0282  lr:0.001000  network_time: 0.0135
[ Fri May 12 23:05:33 2023 ] 	Batch(479/480) done. Loss: 0.0312  lr:0.001000  network_time: 0.0108
[ Fri May 12 23:05:33 2023 ] 	Training Accuracy: 99.50%
[ Fri May 12 23:05:33 2023 ] Eval epoch: 30
[ Fri May 12 23:05:50 2023 ] 	Mean test loss of 120 batches: 0.025411034002900124.
[ Fri May 12 23:05:50 2023 ] 	Top1: 99.50%
[ Fri May 12 23:05:50 2023 ] 	Top5: 100.00%
