[ Wed May 17 18:08:57 2023 ] NUM WORKER: 1
[ Wed May 17 18:12:21 2023 ] Parameters:
{'work_dir': './work_dir/sibi_merged_outer_group_ShiftGCN_mod_3_joint_n_5_kfold_fold_5', 'model_saved_name': './save_models/sibi_merged_outer_group_ShiftGCN_mod_3_joint_n_5_kfold_fold_5', 'Experiment_name': 'sibi_merged_outer_group_ShiftGCN_mod_3_joint_n_5_kfold', 'config': './config/recalculated/train_sibi_with_mouth_augmented_merged_outer_group_shift_joint_mod_3.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 2, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'n_splits': 5, 'feeder': 'feeders.feeder_hsd.Feeder', 'num_worker': 1, 'train_feeder_args': {'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': -1, 'normalization': False}, 'test_feeder_args': None, 'data_path': './data/augmented_recalculate_normalized', 'model': 'model.shift_gcn.Model', 'model_args': {'num_class': 50, 'num_person': 1, 'num_point': 115, 'graph_group': [[0, 81], [82, 114]], 'method': 'grouped.outer', 'weight': 3, 'graph': 'graph.skeleton_with_mouth.SkeletonWithMouth', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [20, 25], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 5, 'test_batch_size': 5, 'start_epoch': 0, 'num_epoch': 30, 'folds_range': [4, 5], 'weight_decay': 0.0001, 'only_train_part': True, 'only_train_epoch': 1, 'warm_up_epoch': 0}

[ Wed May 17 18:12:21 2023 ] Training epoch: 1
[ Wed May 17 18:13:08 2023 ] 	Batch(99/480) done. Loss: 3.4562  lr:0.100000  network_time: 0.0118
[ Wed May 17 18:13:54 2023 ] 	Batch(199/480) done. Loss: 3.4555  lr:0.100000  network_time: 0.0111
[ Wed May 17 18:14:39 2023 ] 	Batch(299/480) done. Loss: 3.4201  lr:0.100000  network_time: 0.0111
[ Wed May 17 18:15:25 2023 ] 	Batch(399/480) done. Loss: 3.8768  lr:0.100000  network_time: 0.0111
[ Wed May 17 18:16:02 2023 ] 	Training Accuracy: 5.29%
[ Wed May 17 18:16:02 2023 ] Eval epoch: 1
[ Wed May 17 18:16:18 2023 ] 	Mean test loss of 120 batches: 4.079263210296631.
[ Wed May 17 18:16:18 2023 ] 	Top1: 8.17%
[ Wed May 17 18:16:18 2023 ] 	Top5: 41.83%
[ Wed May 17 18:16:18 2023 ] Training epoch: 2
[ Wed May 17 18:16:27 2023 ] 	Batch(19/480) done. Loss: 3.0787  lr:0.100000  network_time: 0.0112
[ Wed May 17 18:17:13 2023 ] 	Batch(119/480) done. Loss: 3.0235  lr:0.100000  network_time: 0.0126
[ Wed May 17 18:17:59 2023 ] 	Batch(219/480) done. Loss: 2.7821  lr:0.100000  network_time: 0.0118
[ Wed May 17 18:18:45 2023 ] 	Batch(319/480) done. Loss: 2.5503  lr:0.100000  network_time: 0.0144
[ Wed May 17 18:19:31 2023 ] 	Batch(419/480) done. Loss: 2.7185  lr:0.100000  network_time: 0.0113
[ Wed May 17 18:19:59 2023 ] 	Training Accuracy: 13.08%
[ Wed May 17 18:19:59 2023 ] Eval epoch: 2
[ Wed May 17 18:20:15 2023 ] 	Mean test loss of 120 batches: 4.04622745513916.
[ Wed May 17 18:20:15 2023 ] 	Top1: 17.33%
[ Wed May 17 18:20:15 2023 ] 	Top5: 57.67%
[ Wed May 17 18:20:15 2023 ] Training epoch: 3
[ Wed May 17 18:20:33 2023 ] 	Batch(39/480) done. Loss: 2.5649  lr:0.100000  network_time: 0.0135
[ Wed May 17 18:21:19 2023 ] 	Batch(139/480) done. Loss: 3.2990  lr:0.100000  network_time: 0.0112
[ Wed May 17 18:22:05 2023 ] 	Batch(239/480) done. Loss: 2.3087  lr:0.100000  network_time: 0.0112
[ Wed May 17 18:22:51 2023 ] 	Batch(339/480) done. Loss: 3.1909  lr:0.100000  network_time: 0.0135
[ Wed May 17 18:23:37 2023 ] 	Batch(439/480) done. Loss: 2.3679  lr:0.100000  network_time: 0.0121
[ Wed May 17 18:23:55 2023 ] 	Training Accuracy: 18.21%
[ Wed May 17 18:23:55 2023 ] Eval epoch: 3
[ Wed May 17 18:24:12 2023 ] 	Mean test loss of 120 batches: 3.4587132930755615.
[ Wed May 17 18:24:12 2023 ] 	Top1: 16.67%
[ Wed May 17 18:24:12 2023 ] 	Top5: 50.50%
[ Wed May 17 18:24:12 2023 ] Training epoch: 4
[ Wed May 17 18:24:39 2023 ] 	Batch(59/480) done. Loss: 2.5137  lr:0.100000  network_time: 0.0108
[ Wed May 17 18:25:25 2023 ] 	Batch(159/480) done. Loss: 2.6666  lr:0.100000  network_time: 0.0137
[ Wed May 17 18:26:11 2023 ] 	Batch(259/480) done. Loss: 1.8627  lr:0.100000  network_time: 0.0113
[ Wed May 17 18:26:57 2023 ] 	Batch(359/480) done. Loss: 2.2235  lr:0.100000  network_time: 0.0116
[ Wed May 17 18:27:43 2023 ] 	Batch(459/480) done. Loss: 4.6289  lr:0.100000  network_time: 0.0111
[ Wed May 17 18:27:52 2023 ] 	Training Accuracy: 24.71%
[ Wed May 17 18:27:52 2023 ] Eval epoch: 4
[ Wed May 17 18:28:08 2023 ] 	Mean test loss of 120 batches: 2.3090035915374756.
[ Wed May 17 18:28:08 2023 ] 	Top1: 25.50%
[ Wed May 17 18:28:08 2023 ] 	Top5: 74.50%
[ Wed May 17 18:28:08 2023 ] Training epoch: 5
[ Wed May 17 18:28:45 2023 ] 	Batch(79/480) done. Loss: 2.0576  lr:0.100000  network_time: 0.0118
[ Wed May 17 18:29:31 2023 ] 	Batch(179/480) done. Loss: 1.3408  lr:0.100000  network_time: 0.0118
[ Wed May 17 18:30:17 2023 ] 	Batch(279/480) done. Loss: 1.4996  lr:0.100000  network_time: 0.0113
[ Wed May 17 18:31:03 2023 ] 	Batch(379/480) done. Loss: 1.6757  lr:0.100000  network_time: 0.0117
[ Wed May 17 18:31:49 2023 ] 	Batch(479/480) done. Loss: 1.8732  lr:0.100000  network_time: 0.0112
[ Wed May 17 18:31:49 2023 ] 	Training Accuracy: 32.38%
[ Wed May 17 18:31:49 2023 ] Eval epoch: 5
[ Wed May 17 18:32:05 2023 ] 	Mean test loss of 120 batches: 1.8058972358703613.
[ Wed May 17 18:32:05 2023 ] 	Top1: 42.83%
[ Wed May 17 18:32:05 2023 ] 	Top5: 87.00%
[ Wed May 17 18:32:05 2023 ] Training epoch: 6
[ Wed May 17 18:32:51 2023 ] 	Batch(99/480) done. Loss: 1.2707  lr:0.100000  network_time: 0.0109
[ Wed May 17 18:33:37 2023 ] 	Batch(199/480) done. Loss: 2.1938  lr:0.100000  network_time: 0.0141
[ Wed May 17 18:34:23 2023 ] 	Batch(299/480) done. Loss: 0.9381  lr:0.100000  network_time: 0.0139
[ Wed May 17 18:35:09 2023 ] 	Batch(399/480) done. Loss: 1.8056  lr:0.100000  network_time: 0.0114
[ Wed May 17 18:35:46 2023 ] 	Training Accuracy: 41.42%
[ Wed May 17 18:35:46 2023 ] Eval epoch: 6
[ Wed May 17 18:36:02 2023 ] 	Mean test loss of 120 batches: 1.684935212135315.
[ Wed May 17 18:36:02 2023 ] 	Top1: 47.17%
[ Wed May 17 18:36:02 2023 ] 	Top5: 86.83%
[ Wed May 17 18:36:02 2023 ] Training epoch: 7
[ Wed May 17 18:36:11 2023 ] 	Batch(19/480) done. Loss: 1.2291  lr:0.100000  network_time: 0.0140
[ Wed May 17 18:36:57 2023 ] 	Batch(119/480) done. Loss: 2.3463  lr:0.100000  network_time: 0.0137
[ Wed May 17 18:37:43 2023 ] 	Batch(219/480) done. Loss: 2.0792  lr:0.100000  network_time: 0.0109
[ Wed May 17 18:38:29 2023 ] 	Batch(319/480) done. Loss: 1.0562  lr:0.100000  network_time: 0.0115
[ Wed May 17 18:39:15 2023 ] 	Batch(419/480) done. Loss: 3.1890  lr:0.100000  network_time: 0.0116
[ Wed May 17 18:39:42 2023 ] 	Training Accuracy: 50.04%
[ Wed May 17 18:39:42 2023 ] Eval epoch: 7
[ Wed May 17 18:39:59 2023 ] 	Mean test loss of 120 batches: 1.4752814769744873.
[ Wed May 17 18:39:59 2023 ] 	Top1: 51.83%
[ Wed May 17 18:39:59 2023 ] 	Top5: 94.17%
[ Wed May 17 18:39:59 2023 ] Training epoch: 8
[ Wed May 17 18:40:17 2023 ] 	Batch(39/480) done. Loss: 0.7977  lr:0.100000  network_time: 0.0134
[ Wed May 17 18:41:03 2023 ] 	Batch(139/480) done. Loss: 1.8763  lr:0.100000  network_time: 0.0110
[ Wed May 17 18:41:49 2023 ] 	Batch(239/480) done. Loss: 3.7461  lr:0.100000  network_time: 0.0114
[ Wed May 17 18:42:35 2023 ] 	Batch(339/480) done. Loss: 1.0935  lr:0.100000  network_time: 0.0111
[ Wed May 17 18:43:21 2023 ] 	Batch(439/480) done. Loss: 0.8000  lr:0.100000  network_time: 0.0109
[ Wed May 17 18:43:39 2023 ] 	Training Accuracy: 58.46%
[ Wed May 17 18:43:39 2023 ] Eval epoch: 8
[ Wed May 17 18:43:55 2023 ] 	Mean test loss of 120 batches: 0.9052220582962036.
[ Wed May 17 18:43:55 2023 ] 	Top1: 69.50%
[ Wed May 17 18:43:55 2023 ] 	Top5: 96.17%
[ Wed May 17 18:43:55 2023 ] Training epoch: 9
[ Wed May 17 18:44:23 2023 ] 	Batch(59/480) done. Loss: 1.4992  lr:0.100000  network_time: 0.0110
[ Wed May 17 18:45:09 2023 ] 	Batch(159/480) done. Loss: 1.3515  lr:0.100000  network_time: 0.0112
[ Wed May 17 18:45:55 2023 ] 	Batch(259/480) done. Loss: 0.6850  lr:0.100000  network_time: 0.0112
[ Wed May 17 18:46:41 2023 ] 	Batch(359/480) done. Loss: 0.7174  lr:0.100000  network_time: 0.0137
[ Wed May 17 18:47:27 2023 ] 	Batch(459/480) done. Loss: 0.7617  lr:0.100000  network_time: 0.0110
[ Wed May 17 18:47:36 2023 ] 	Training Accuracy: 65.67%
[ Wed May 17 18:47:36 2023 ] Eval epoch: 9
[ Wed May 17 18:47:52 2023 ] 	Mean test loss of 120 batches: 1.3135666847229004.
[ Wed May 17 18:47:52 2023 ] 	Top1: 64.67%
[ Wed May 17 18:47:52 2023 ] 	Top5: 94.00%
[ Wed May 17 18:47:52 2023 ] Training epoch: 10
[ Wed May 17 18:48:29 2023 ] 	Batch(79/480) done. Loss: 0.7627  lr:0.100000  network_time: 0.0112
[ Wed May 17 18:49:15 2023 ] 	Batch(179/480) done. Loss: 1.3609  lr:0.100000  network_time: 0.0136
[ Wed May 17 18:50:01 2023 ] 	Batch(279/480) done. Loss: 0.6715  lr:0.100000  network_time: 0.0111
[ Wed May 17 18:50:46 2023 ] 	Batch(379/480) done. Loss: 1.6613  lr:0.100000  network_time: 0.0114
[ Wed May 17 18:51:32 2023 ] 	Batch(479/480) done. Loss: 0.4304  lr:0.100000  network_time: 0.0110
[ Wed May 17 18:51:32 2023 ] 	Training Accuracy: 69.75%
[ Wed May 17 18:51:32 2023 ] Eval epoch: 10
[ Wed May 17 18:51:49 2023 ] 	Mean test loss of 120 batches: 1.0076696872711182.
[ Wed May 17 18:51:49 2023 ] 	Top1: 66.83%
[ Wed May 17 18:51:49 2023 ] 	Top5: 96.67%
[ Wed May 17 18:51:49 2023 ] Training epoch: 11
[ Wed May 17 18:52:35 2023 ] 	Batch(99/480) done. Loss: 1.1672  lr:0.100000  network_time: 0.0111
[ Wed May 17 18:53:20 2023 ] 	Batch(199/480) done. Loss: 0.2961  lr:0.100000  network_time: 0.0108
[ Wed May 17 18:54:06 2023 ] 	Batch(299/480) done. Loss: 0.4609  lr:0.100000  network_time: 0.0137
[ Wed May 17 18:54:52 2023 ] 	Batch(399/480) done. Loss: 0.1132  lr:0.100000  network_time: 0.0112
[ Wed May 17 18:55:29 2023 ] 	Training Accuracy: 73.96%
[ Wed May 17 18:55:29 2023 ] Eval epoch: 11
[ Wed May 17 18:55:45 2023 ] 	Mean test loss of 120 batches: 0.9444610476493835.
[ Wed May 17 18:55:45 2023 ] 	Top1: 73.17%
[ Wed May 17 18:55:45 2023 ] 	Top5: 95.67%
[ Wed May 17 18:55:45 2023 ] Training epoch: 12
[ Wed May 17 18:55:55 2023 ] 	Batch(19/480) done. Loss: 0.6872  lr:0.100000  network_time: 0.0111
[ Wed May 17 18:56:40 2023 ] 	Batch(119/480) done. Loss: 0.5720  lr:0.100000  network_time: 0.0140
[ Wed May 17 18:57:26 2023 ] 	Batch(219/480) done. Loss: 0.1294  lr:0.100000  network_time: 0.0116
[ Wed May 17 18:58:12 2023 ] 	Batch(319/480) done. Loss: 0.7041  lr:0.100000  network_time: 0.0116
[ Wed May 17 18:58:58 2023 ] 	Batch(419/480) done. Loss: 0.9194  lr:0.100000  network_time: 0.0109
[ Wed May 17 18:59:26 2023 ] 	Training Accuracy: 76.92%
[ Wed May 17 18:59:26 2023 ] Eval epoch: 12
[ Wed May 17 18:59:42 2023 ] 	Mean test loss of 120 batches: 0.6237390637397766.
[ Wed May 17 18:59:42 2023 ] 	Top1: 83.17%
[ Wed May 17 18:59:42 2023 ] 	Top5: 99.17%
[ Wed May 17 18:59:42 2023 ] Training epoch: 13
[ Wed May 17 19:00:00 2023 ] 	Batch(39/480) done. Loss: 1.0464  lr:0.100000  network_time: 0.0113
[ Wed May 17 19:00:46 2023 ] 	Batch(139/480) done. Loss: 0.1428  lr:0.100000  network_time: 0.0132
[ Wed May 17 19:01:32 2023 ] 	Batch(239/480) done. Loss: 1.0955  lr:0.100000  network_time: 0.0133
[ Wed May 17 19:02:18 2023 ] 	Batch(339/480) done. Loss: 0.1501  lr:0.100000  network_time: 0.0110
[ Wed May 17 19:03:04 2023 ] 	Batch(439/480) done. Loss: 0.3929  lr:0.100000  network_time: 0.0109
[ Wed May 17 19:03:22 2023 ] 	Training Accuracy: 80.54%
[ Wed May 17 19:03:22 2023 ] Eval epoch: 13
[ Wed May 17 19:03:38 2023 ] 	Mean test loss of 120 batches: 0.6308377385139465.
[ Wed May 17 19:03:38 2023 ] 	Top1: 81.33%
[ Wed May 17 19:03:38 2023 ] 	Top5: 98.83%
[ Wed May 17 19:03:39 2023 ] Training epoch: 14
[ Wed May 17 19:04:06 2023 ] 	Batch(59/480) done. Loss: 0.5454  lr:0.100000  network_time: 0.0134
[ Wed May 17 19:04:52 2023 ] 	Batch(159/480) done. Loss: 0.1250  lr:0.100000  network_time: 0.0131
[ Wed May 17 19:05:38 2023 ] 	Batch(259/480) done. Loss: 0.9236  lr:0.100000  network_time: 0.0135
[ Wed May 17 19:06:24 2023 ] 	Batch(359/480) done. Loss: 0.2424  lr:0.100000  network_time: 0.0133
[ Wed May 17 19:07:10 2023 ] 	Batch(459/480) done. Loss: 0.6191  lr:0.100000  network_time: 0.0113
[ Wed May 17 19:07:19 2023 ] 	Training Accuracy: 82.17%
[ Wed May 17 19:07:19 2023 ] Eval epoch: 14
[ Wed May 17 19:07:35 2023 ] 	Mean test loss of 120 batches: 0.5024445056915283.
[ Wed May 17 19:07:35 2023 ] 	Top1: 84.50%
[ Wed May 17 19:07:35 2023 ] 	Top5: 99.67%
[ Wed May 17 19:07:35 2023 ] Training epoch: 15
[ Wed May 17 19:08:12 2023 ] 	Batch(79/480) done. Loss: 1.8346  lr:0.100000  network_time: 0.0121
[ Wed May 17 19:08:58 2023 ] 	Batch(179/480) done. Loss: 1.0067  lr:0.100000  network_time: 0.0135
[ Wed May 17 19:09:44 2023 ] 	Batch(279/480) done. Loss: 0.0898  lr:0.100000  network_time: 0.0112
[ Wed May 17 19:10:29 2023 ] 	Batch(379/480) done. Loss: 0.8792  lr:0.100000  network_time: 0.0110
[ Wed May 17 19:11:15 2023 ] 	Batch(479/480) done. Loss: 0.3049  lr:0.100000  network_time: 0.0109
[ Wed May 17 19:11:15 2023 ] 	Training Accuracy: 83.29%
[ Wed May 17 19:11:15 2023 ] Eval epoch: 15
[ Wed May 17 19:11:32 2023 ] 	Mean test loss of 120 batches: 0.5137692093849182.
[ Wed May 17 19:11:32 2023 ] 	Top1: 85.00%
[ Wed May 17 19:11:32 2023 ] 	Top5: 99.83%
[ Wed May 17 19:11:32 2023 ] Training epoch: 16
[ Wed May 17 19:12:17 2023 ] 	Batch(99/480) done. Loss: 1.2020  lr:0.100000  network_time: 0.0111
[ Wed May 17 19:13:03 2023 ] 	Batch(199/480) done. Loss: 0.3535  lr:0.100000  network_time: 0.0109
[ Wed May 17 19:13:49 2023 ] 	Batch(299/480) done. Loss: 1.3555  lr:0.100000  network_time: 0.0121
[ Wed May 17 19:14:35 2023 ] 	Batch(399/480) done. Loss: 0.4006  lr:0.100000  network_time: 0.0111
[ Wed May 17 19:15:12 2023 ] 	Training Accuracy: 86.00%
[ Wed May 17 19:15:12 2023 ] Eval epoch: 16
[ Wed May 17 19:15:28 2023 ] 	Mean test loss of 120 batches: 0.26657071709632874.
[ Wed May 17 19:15:28 2023 ] 	Top1: 92.33%
[ Wed May 17 19:15:28 2023 ] 	Top5: 99.50%
[ Wed May 17 19:15:28 2023 ] Training epoch: 17
[ Wed May 17 19:15:37 2023 ] 	Batch(19/480) done. Loss: 0.2068  lr:0.100000  network_time: 0.0108
[ Wed May 17 19:16:23 2023 ] 	Batch(119/480) done. Loss: 0.4960  lr:0.100000  network_time: 0.0107
[ Wed May 17 19:17:09 2023 ] 	Batch(219/480) done. Loss: 0.7261  lr:0.100000  network_time: 0.0111
[ Wed May 17 19:17:55 2023 ] 	Batch(319/480) done. Loss: 0.2209  lr:0.100000  network_time: 0.0134
[ Wed May 17 19:18:41 2023 ] 	Batch(419/480) done. Loss: 0.9085  lr:0.100000  network_time: 0.0110
[ Wed May 17 19:19:08 2023 ] 	Training Accuracy: 87.75%
[ Wed May 17 19:19:08 2023 ] Eval epoch: 17
[ Wed May 17 19:19:25 2023 ] 	Mean test loss of 120 batches: 0.6099424958229065.
[ Wed May 17 19:19:25 2023 ] 	Top1: 83.33%
[ Wed May 17 19:19:25 2023 ] 	Top5: 98.83%
[ Wed May 17 19:19:25 2023 ] Training epoch: 18
[ Wed May 17 19:19:43 2023 ] 	Batch(39/480) done. Loss: 0.2043  lr:0.100000  network_time: 0.0121
[ Wed May 17 19:20:29 2023 ] 	Batch(139/480) done. Loss: 0.6289  lr:0.100000  network_time: 0.0109
[ Wed May 17 19:21:15 2023 ] 	Batch(239/480) done. Loss: 0.1473  lr:0.100000  network_time: 0.0111
[ Wed May 17 19:22:01 2023 ] 	Batch(339/480) done. Loss: 0.3806  lr:0.100000  network_time: 0.0107
[ Wed May 17 19:22:47 2023 ] 	Batch(439/480) done. Loss: 0.1831  lr:0.100000  network_time: 0.0112
[ Wed May 17 19:23:05 2023 ] 	Training Accuracy: 87.17%
[ Wed May 17 19:23:05 2023 ] Eval epoch: 18
[ Wed May 17 19:23:21 2023 ] 	Mean test loss of 120 batches: 0.2031775414943695.
[ Wed May 17 19:23:21 2023 ] 	Top1: 93.67%
[ Wed May 17 19:23:21 2023 ] 	Top5: 99.83%
[ Wed May 17 19:23:21 2023 ] Training epoch: 19
[ Wed May 17 19:23:49 2023 ] 	Batch(59/480) done. Loss: 0.2957  lr:0.100000  network_time: 0.0110
[ Wed May 17 19:24:35 2023 ] 	Batch(159/480) done. Loss: 0.3043  lr:0.100000  network_time: 0.0134
[ Wed May 17 19:25:21 2023 ] 	Batch(259/480) done. Loss: 0.4216  lr:0.100000  network_time: 0.0136
[ Wed May 17 19:26:06 2023 ] 	Batch(359/480) done. Loss: 0.0207  lr:0.100000  network_time: 0.0110
[ Wed May 17 19:26:52 2023 ] 	Batch(459/480) done. Loss: 0.0558  lr:0.100000  network_time: 0.0112
[ Wed May 17 19:27:02 2023 ] 	Training Accuracy: 88.62%
[ Wed May 17 19:27:02 2023 ] Eval epoch: 19
[ Wed May 17 19:27:18 2023 ] 	Mean test loss of 120 batches: 0.2776069641113281.
[ Wed May 17 19:27:18 2023 ] 	Top1: 92.83%
[ Wed May 17 19:27:18 2023 ] 	Top5: 99.83%
[ Wed May 17 19:27:18 2023 ] Training epoch: 20
[ Wed May 17 19:27:55 2023 ] 	Batch(79/480) done. Loss: 0.3105  lr:0.100000  network_time: 0.0107
[ Wed May 17 19:28:40 2023 ] 	Batch(179/480) done. Loss: 0.2825  lr:0.100000  network_time: 0.0106
[ Wed May 17 19:29:26 2023 ] 	Batch(279/480) done. Loss: 0.0317  lr:0.100000  network_time: 0.0109
[ Wed May 17 19:30:12 2023 ] 	Batch(379/480) done. Loss: 0.2798  lr:0.100000  network_time: 0.0109
[ Wed May 17 19:30:58 2023 ] 	Batch(479/480) done. Loss: 0.1152  lr:0.100000  network_time: 0.0111
[ Wed May 17 19:30:58 2023 ] 	Training Accuracy: 89.33%
[ Wed May 17 19:30:58 2023 ] Eval epoch: 20
[ Wed May 17 19:31:14 2023 ] 	Mean test loss of 120 batches: 1.3905540704727173.
[ Wed May 17 19:31:14 2023 ] 	Top1: 73.67%
[ Wed May 17 19:31:14 2023 ] 	Top5: 96.67%
[ Wed May 17 19:31:14 2023 ] Training epoch: 21
[ Wed May 17 19:32:00 2023 ] 	Batch(99/480) done. Loss: 0.3561  lr:0.010000  network_time: 0.0113
[ Wed May 17 19:32:46 2023 ] 	Batch(199/480) done. Loss: 0.0195  lr:0.010000  network_time: 0.0107
[ Wed May 17 19:33:32 2023 ] 	Batch(299/480) done. Loss: 0.0233  lr:0.010000  network_time: 0.0108
[ Wed May 17 19:34:18 2023 ] 	Batch(399/480) done. Loss: 0.1396  lr:0.010000  network_time: 0.0110
[ Wed May 17 19:34:55 2023 ] 	Training Accuracy: 95.88%
[ Wed May 17 19:34:55 2023 ] Eval epoch: 21
[ Wed May 17 19:35:11 2023 ] 	Mean test loss of 120 batches: 0.038768406957387924.
[ Wed May 17 19:35:11 2023 ] 	Top1: 99.00%
[ Wed May 17 19:35:11 2023 ] 	Top5: 100.00%
[ Wed May 17 19:35:11 2023 ] Training epoch: 22
[ Wed May 17 19:35:20 2023 ] 	Batch(19/480) done. Loss: 0.0887  lr:0.010000  network_time: 0.0126
[ Wed May 17 19:36:06 2023 ] 	Batch(119/480) done. Loss: 0.0137  lr:0.010000  network_time: 0.0108
[ Wed May 17 19:36:52 2023 ] 	Batch(219/480) done. Loss: 0.0453  lr:0.010000  network_time: 0.0106
[ Wed May 17 19:37:38 2023 ] 	Batch(319/480) done. Loss: 0.0067  lr:0.010000  network_time: 0.0111
[ Wed May 17 19:38:24 2023 ] 	Batch(419/480) done. Loss: 0.1008  lr:0.010000  network_time: 0.0110
[ Wed May 17 19:38:51 2023 ] 	Training Accuracy: 98.08%
[ Wed May 17 19:38:52 2023 ] Eval epoch: 22
[ Wed May 17 19:39:08 2023 ] 	Mean test loss of 120 batches: 0.01937001198530197.
[ Wed May 17 19:39:08 2023 ] 	Top1: 99.83%
[ Wed May 17 19:39:08 2023 ] 	Top5: 100.00%
[ Wed May 17 19:39:08 2023 ] Training epoch: 23
[ Wed May 17 19:39:26 2023 ] 	Batch(39/480) done. Loss: 0.4416  lr:0.010000  network_time: 0.0110
[ Wed May 17 19:40:12 2023 ] 	Batch(139/480) done. Loss: 0.2072  lr:0.010000  network_time: 0.0109
[ Wed May 17 19:40:58 2023 ] 	Batch(239/480) done. Loss: 0.0191  lr:0.010000  network_time: 0.0110
[ Wed May 17 19:41:44 2023 ] 	Batch(339/480) done. Loss: 0.0569  lr:0.010000  network_time: 0.0108
[ Wed May 17 19:42:30 2023 ] 	Batch(439/480) done. Loss: 0.0109  lr:0.010000  network_time: 0.0134
[ Wed May 17 19:42:48 2023 ] 	Training Accuracy: 98.63%
[ Wed May 17 19:42:48 2023 ] Eval epoch: 23
[ Wed May 17 19:43:04 2023 ] 	Mean test loss of 120 batches: 0.02313211001455784.
[ Wed May 17 19:43:04 2023 ] 	Top1: 99.67%
[ Wed May 17 19:43:04 2023 ] 	Top5: 100.00%
[ Wed May 17 19:43:04 2023 ] Training epoch: 24
[ Wed May 17 19:43:32 2023 ] 	Batch(59/480) done. Loss: 0.0130  lr:0.010000  network_time: 0.0109
[ Wed May 17 19:44:18 2023 ] 	Batch(159/480) done. Loss: 0.0132  lr:0.010000  network_time: 0.0112
[ Wed May 17 19:45:04 2023 ] 	Batch(259/480) done. Loss: 0.0331  lr:0.010000  network_time: 0.0108
[ Wed May 17 19:45:50 2023 ] 	Batch(359/480) done. Loss: 0.0024  lr:0.010000  network_time: 0.0111
[ Wed May 17 19:46:36 2023 ] 	Batch(459/480) done. Loss: 0.0132  lr:0.010000  network_time: 0.0134
[ Wed May 17 19:46:45 2023 ] 	Training Accuracy: 98.92%
[ Wed May 17 19:46:45 2023 ] Eval epoch: 24
[ Wed May 17 19:47:01 2023 ] 	Mean test loss of 120 batches: 0.016988171264529228.
[ Wed May 17 19:47:01 2023 ] 	Top1: 99.67%
[ Wed May 17 19:47:01 2023 ] 	Top5: 100.00%
[ Wed May 17 19:47:01 2023 ] Training epoch: 25
[ Wed May 17 19:47:38 2023 ] 	Batch(79/480) done. Loss: 0.0366  lr:0.010000  network_time: 0.0111
[ Wed May 17 19:48:24 2023 ] 	Batch(179/480) done. Loss: 0.0317  lr:0.010000  network_time: 0.0132
[ Wed May 17 19:49:10 2023 ] 	Batch(279/480) done. Loss: 0.0241  lr:0.010000  network_time: 0.0136
[ Wed May 17 19:49:56 2023 ] 	Batch(379/480) done. Loss: 0.0168  lr:0.010000  network_time: 0.0134
[ Wed May 17 19:50:42 2023 ] 	Batch(479/480) done. Loss: 0.0144  lr:0.010000  network_time: 0.0135
[ Wed May 17 19:50:42 2023 ] 	Training Accuracy: 99.33%
[ Wed May 17 19:50:42 2023 ] Eval epoch: 25
[ Wed May 17 19:50:58 2023 ] 	Mean test loss of 120 batches: 0.012186607345938683.
[ Wed May 17 19:50:58 2023 ] 	Top1: 99.67%
[ Wed May 17 19:50:58 2023 ] 	Top5: 100.00%
[ Wed May 17 19:50:58 2023 ] Training epoch: 26
[ Wed May 17 19:51:44 2023 ] 	Batch(99/480) done. Loss: 0.0484  lr:0.001000  network_time: 0.0110
[ Wed May 17 19:52:30 2023 ] 	Batch(199/480) done. Loss: 0.0330  lr:0.001000  network_time: 0.0108
[ Wed May 17 19:53:16 2023 ] 	Batch(299/480) done. Loss: 0.0035  lr:0.001000  network_time: 0.0143
[ Wed May 17 19:54:02 2023 ] 	Batch(399/480) done. Loss: 0.0478  lr:0.001000  network_time: 0.0139
[ Wed May 17 19:54:38 2023 ] 	Training Accuracy: 99.42%
[ Wed May 17 19:54:38 2023 ] Eval epoch: 26
[ Wed May 17 19:54:54 2023 ] 	Mean test loss of 120 batches: 0.012811217457056046.
[ Wed May 17 19:54:54 2023 ] 	Top1: 99.67%
[ Wed May 17 19:54:54 2023 ] 	Top5: 100.00%
[ Wed May 17 19:54:54 2023 ] Training epoch: 27
[ Wed May 17 19:55:04 2023 ] 	Batch(19/480) done. Loss: 0.0148  lr:0.001000  network_time: 0.0112
[ Wed May 17 19:55:50 2023 ] 	Batch(119/480) done. Loss: 0.0042  lr:0.001000  network_time: 0.0109
[ Wed May 17 19:56:36 2023 ] 	Batch(219/480) done. Loss: 0.0131  lr:0.001000  network_time: 0.0112
[ Wed May 17 19:57:21 2023 ] 	Batch(319/480) done. Loss: 0.0073  lr:0.001000  network_time: 0.0131
[ Wed May 17 19:58:07 2023 ] 	Batch(419/480) done. Loss: 0.0136  lr:0.001000  network_time: 0.0111
[ Wed May 17 19:58:35 2023 ] 	Training Accuracy: 99.38%
[ Wed May 17 19:58:35 2023 ] Eval epoch: 27
[ Wed May 17 19:58:51 2023 ] 	Mean test loss of 120 batches: 0.010039839893579483.
[ Wed May 17 19:58:51 2023 ] 	Top1: 100.00%
[ Wed May 17 19:58:51 2023 ] 	Top5: 100.00%
[ Wed May 17 19:58:51 2023 ] Training epoch: 28
[ Wed May 17 19:59:09 2023 ] 	Batch(39/480) done. Loss: 0.0361  lr:0.001000  network_time: 0.0135
[ Wed May 17 19:59:55 2023 ] 	Batch(139/480) done. Loss: 0.0134  lr:0.001000  network_time: 0.0133
[ Wed May 17 20:00:41 2023 ] 	Batch(239/480) done. Loss: 0.3412  lr:0.001000  network_time: 0.0130
[ Wed May 17 20:01:27 2023 ] 	Batch(339/480) done. Loss: 0.0379  lr:0.001000  network_time: 0.0109
[ Wed May 17 20:02:13 2023 ] 	Batch(439/480) done. Loss: 0.0043  lr:0.001000  network_time: 0.0109
[ Wed May 17 20:02:32 2023 ] 	Training Accuracy: 99.38%
[ Wed May 17 20:02:32 2023 ] Eval epoch: 28
[ Wed May 17 20:02:48 2023 ] 	Mean test loss of 120 batches: 0.010358505882322788.
[ Wed May 17 20:02:48 2023 ] 	Top1: 100.00%
[ Wed May 17 20:02:48 2023 ] 	Top5: 100.00%
[ Wed May 17 20:02:48 2023 ] Training epoch: 29
[ Wed May 17 20:03:15 2023 ] 	Batch(59/480) done. Loss: 0.0604  lr:0.001000  network_time: 0.0108
[ Wed May 17 20:04:01 2023 ] 	Batch(159/480) done. Loss: 0.0139  lr:0.001000  network_time: 0.0109
[ Wed May 17 20:04:47 2023 ] 	Batch(259/480) done. Loss: 0.0056  lr:0.001000  network_time: 0.0112
[ Wed May 17 20:05:33 2023 ] 	Batch(359/480) done. Loss: 0.0197  lr:0.001000  network_time: 0.0110
[ Wed May 17 20:06:19 2023 ] 	Batch(459/480) done. Loss: 0.1796  lr:0.001000  network_time: 0.0136
[ Wed May 17 20:06:28 2023 ] 	Training Accuracy: 99.42%
[ Wed May 17 20:06:28 2023 ] Eval epoch: 29
[ Wed May 17 20:06:44 2023 ] 	Mean test loss of 120 batches: 0.007925361394882202.
[ Wed May 17 20:06:44 2023 ] 	Top1: 100.00%
[ Wed May 17 20:06:44 2023 ] 	Top5: 100.00%
[ Wed May 17 20:06:44 2023 ] Training epoch: 30
[ Wed May 17 20:07:21 2023 ] 	Batch(79/480) done. Loss: 0.0134  lr:0.001000  network_time: 0.0109
[ Wed May 17 20:08:07 2023 ] 	Batch(179/480) done. Loss: 0.0098  lr:0.001000  network_time: 0.0109
[ Wed May 17 20:08:53 2023 ] 	Batch(279/480) done. Loss: 0.0108  lr:0.001000  network_time: 0.0109
[ Wed May 17 20:09:39 2023 ] 	Batch(379/480) done. Loss: 0.0424  lr:0.001000  network_time: 0.0109
[ Wed May 17 20:10:25 2023 ] 	Batch(479/480) done. Loss: 0.0194  lr:0.001000  network_time: 0.0131
[ Wed May 17 20:10:25 2023 ] 	Training Accuracy: 99.33%
[ Wed May 17 20:10:25 2023 ] Eval epoch: 30
[ Wed May 17 20:10:41 2023 ] 	Mean test loss of 120 batches: 0.008977430872619152.
[ Wed May 17 20:10:41 2023 ] 	Top1: 100.00%
[ Wed May 17 20:10:41 2023 ] 	Top5: 100.00%
