[ Thu May 11 14:42:20 2023 ] NUM WORKER: 1
[ Thu May 11 14:43:14 2023 ] Parameters:
{'work_dir': './work_dir/sibi_individual_inner_group_ShiftGCN_mod_4_joint_n_5_kfold_fold_2', 'model_saved_name': './save_models/sibi_individual_inner_group_ShiftGCN_mod_4_joint_n_5_kfold_fold_2', 'Experiment_name': 'sibi_individual_inner_group_ShiftGCN_mod_4_joint_n_5_kfold', 'config': './config/recalculated/train_sibi_with_mouth_augmented_individual_inner_group_shift_joint_mod_4.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 2, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'n_splits': 5, 'feeder': 'feeders.feeder_hsd.Feeder', 'num_worker': 1, 'train_feeder_args': {'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': -1, 'normalization': False}, 'test_feeder_args': None, 'data_path': './data/augmented_recalculate_normalized', 'model': 'model.shift_gcn.Model', 'model_args': {'num_class': 50, 'num_person': 1, 'num_point': 115, 'graph_group': [[0, 39], [40, 60], [61, 81], [82, 114]], 'method': 'grouped.inner', 'weight': 4, 'graph': 'graph.skeleton_with_mouth.SkeletonWithMouth', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [20, 25], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 5, 'test_batch_size': 5, 'start_epoch': 0, 'num_epoch': 30, 'folds_range': [0, 5], 'weight_decay': 0.0001, 'only_train_part': True, 'only_train_epoch': 1, 'warm_up_epoch': 0}

[ Thu May 11 14:43:14 2023 ] Training epoch: 1
[ Thu May 11 14:44:01 2023 ] 	Batch(99/480) done. Loss: 3.8310  lr:0.100000  network_time: 0.0117
[ Thu May 11 14:44:48 2023 ] 	Batch(199/480) done. Loss: 3.6487  lr:0.100000  network_time: 0.0117
[ Thu May 11 14:45:35 2023 ] 	Batch(299/480) done. Loss: 3.3885  lr:0.100000  network_time: 0.0111
[ Thu May 11 14:46:22 2023 ] 	Batch(399/480) done. Loss: 3.4946  lr:0.100000  network_time: 0.0113
[ Thu May 11 14:47:00 2023 ] 	Training Accuracy: 6.96%
[ Thu May 11 14:47:00 2023 ] Eval epoch: 1
[ Thu May 11 14:47:16 2023 ] 	Mean test loss of 120 batches: 4.693260669708252.
[ Thu May 11 14:47:16 2023 ] 	Top1: 6.33%
[ Thu May 11 14:47:16 2023 ] 	Top5: 27.17%
[ Thu May 11 14:47:16 2023 ] Training epoch: 2
[ Thu May 11 14:47:26 2023 ] 	Batch(19/480) done. Loss: 3.9256  lr:0.100000  network_time: 0.0119
[ Thu May 11 14:48:13 2023 ] 	Batch(119/480) done. Loss: 3.5085  lr:0.100000  network_time: 0.0114
[ Thu May 11 14:49:00 2023 ] 	Batch(219/480) done. Loss: 3.0050  lr:0.100000  network_time: 0.0112
[ Thu May 11 14:49:47 2023 ] 	Batch(319/480) done. Loss: 2.6545  lr:0.100000  network_time: 0.0116
[ Thu May 11 14:50:34 2023 ] 	Batch(419/480) done. Loss: 1.5388  lr:0.100000  network_time: 0.0111
[ Thu May 11 14:51:02 2023 ] 	Training Accuracy: 14.88%
[ Thu May 11 14:51:02 2023 ] Eval epoch: 2
[ Thu May 11 14:51:19 2023 ] 	Mean test loss of 120 batches: 3.0399694442749023.
[ Thu May 11 14:51:19 2023 ] 	Top1: 12.33%
[ Thu May 11 14:51:19 2023 ] 	Top5: 56.17%
[ Thu May 11 14:51:19 2023 ] Training epoch: 3
[ Thu May 11 14:51:38 2023 ] 	Batch(39/480) done. Loss: 2.4298  lr:0.100000  network_time: 0.0110
[ Thu May 11 14:52:25 2023 ] 	Batch(139/480) done. Loss: 2.6495  lr:0.100000  network_time: 0.0117
[ Thu May 11 14:53:12 2023 ] 	Batch(239/480) done. Loss: 2.9276  lr:0.100000  network_time: 0.0118
[ Thu May 11 14:53:59 2023 ] 	Batch(339/480) done. Loss: 3.5100  lr:0.100000  network_time: 0.0118
[ Thu May 11 14:54:46 2023 ] 	Batch(439/480) done. Loss: 2.7807  lr:0.100000  network_time: 0.0111
[ Thu May 11 14:55:05 2023 ] 	Training Accuracy: 19.46%
[ Thu May 11 14:55:05 2023 ] Eval epoch: 3
[ Thu May 11 14:55:21 2023 ] 	Mean test loss of 120 batches: 2.6550278663635254.
[ Thu May 11 14:55:21 2023 ] 	Top1: 22.83%
[ Thu May 11 14:55:21 2023 ] 	Top5: 71.67%
[ Thu May 11 14:55:21 2023 ] Training epoch: 4
[ Thu May 11 14:55:49 2023 ] 	Batch(59/480) done. Loss: 2.7552  lr:0.100000  network_time: 0.0111
[ Thu May 11 14:56:36 2023 ] 	Batch(159/480) done. Loss: 2.2973  lr:0.100000  network_time: 0.0115
[ Thu May 11 14:57:23 2023 ] 	Batch(259/480) done. Loss: 1.6802  lr:0.100000  network_time: 0.0113
[ Thu May 11 14:58:10 2023 ] 	Batch(359/480) done. Loss: 1.9776  lr:0.100000  network_time: 0.0115
[ Thu May 11 14:58:57 2023 ] 	Batch(459/480) done. Loss: 2.0379  lr:0.100000  network_time: 0.0115
[ Thu May 11 14:59:07 2023 ] 	Training Accuracy: 28.38%
[ Thu May 11 14:59:07 2023 ] Eval epoch: 4
[ Thu May 11 14:59:23 2023 ] 	Mean test loss of 120 batches: 2.2302403450012207.
[ Thu May 11 14:59:23 2023 ] 	Top1: 30.17%
[ Thu May 11 14:59:23 2023 ] 	Top5: 82.67%
[ Thu May 11 14:59:23 2023 ] Training epoch: 5
[ Thu May 11 15:00:01 2023 ] 	Batch(79/480) done. Loss: 3.0648  lr:0.100000  network_time: 0.0115
[ Thu May 11 15:00:48 2023 ] 	Batch(179/480) done. Loss: 1.9676  lr:0.100000  network_time: 0.0109
[ Thu May 11 15:01:35 2023 ] 	Batch(279/480) done. Loss: 2.7019  lr:0.100000  network_time: 0.0109
[ Thu May 11 15:02:22 2023 ] 	Batch(379/480) done. Loss: 2.7849  lr:0.100000  network_time: 0.0110
[ Thu May 11 15:03:09 2023 ] 	Batch(479/480) done. Loss: 1.4997  lr:0.100000  network_time: 0.0118
[ Thu May 11 15:03:09 2023 ] 	Training Accuracy: 35.33%
[ Thu May 11 15:03:09 2023 ] Eval epoch: 5
[ Thu May 11 15:03:26 2023 ] 	Mean test loss of 120 batches: 1.6353665590286255.
[ Thu May 11 15:03:26 2023 ] 	Top1: 49.67%
[ Thu May 11 15:03:26 2023 ] 	Top5: 91.33%
[ Thu May 11 15:03:26 2023 ] Training epoch: 6
[ Thu May 11 15:04:13 2023 ] 	Batch(99/480) done. Loss: 2.0078  lr:0.100000  network_time: 0.0112
[ Thu May 11 15:05:00 2023 ] 	Batch(199/480) done. Loss: 2.1755  lr:0.100000  network_time: 0.0112
[ Thu May 11 15:05:47 2023 ] 	Batch(299/480) done. Loss: 0.7149  lr:0.100000  network_time: 0.0108
[ Thu May 11 15:06:34 2023 ] 	Batch(399/480) done. Loss: 2.7779  lr:0.100000  network_time: 0.0112
[ Thu May 11 15:07:12 2023 ] 	Training Accuracy: 41.50%
[ Thu May 11 15:07:12 2023 ] Eval epoch: 6
[ Thu May 11 15:07:28 2023 ] 	Mean test loss of 120 batches: 1.4583348035812378.
[ Thu May 11 15:07:28 2023 ] 	Top1: 54.00%
[ Thu May 11 15:07:28 2023 ] 	Top5: 92.00%
[ Thu May 11 15:07:28 2023 ] Training epoch: 7
[ Thu May 11 15:07:38 2023 ] 	Batch(19/480) done. Loss: 2.3316  lr:0.100000  network_time: 0.0113
[ Thu May 11 15:08:25 2023 ] 	Batch(119/480) done. Loss: 1.6110  lr:0.100000  network_time: 0.0113
[ Thu May 11 15:09:12 2023 ] 	Batch(219/480) done. Loss: 1.6735  lr:0.100000  network_time: 0.0112
[ Thu May 11 15:09:59 2023 ] 	Batch(319/480) done. Loss: 0.9279  lr:0.100000  network_time: 0.0112
[ Thu May 11 15:10:46 2023 ] 	Batch(419/480) done. Loss: 1.5964  lr:0.100000  network_time: 0.0114
[ Thu May 11 15:11:15 2023 ] 	Training Accuracy: 47.33%
[ Thu May 11 15:11:15 2023 ] Eval epoch: 7
[ Thu May 11 15:11:31 2023 ] 	Mean test loss of 120 batches: 1.5463553667068481.
[ Thu May 11 15:11:31 2023 ] 	Top1: 51.33%
[ Thu May 11 15:11:31 2023 ] 	Top5: 95.17%
[ Thu May 11 15:11:31 2023 ] Training epoch: 8
[ Thu May 11 15:11:50 2023 ] 	Batch(39/480) done. Loss: 0.8818  lr:0.100000  network_time: 0.0111
[ Thu May 11 15:12:37 2023 ] 	Batch(139/480) done. Loss: 2.6764  lr:0.100000  network_time: 0.0108
[ Thu May 11 15:13:24 2023 ] 	Batch(239/480) done. Loss: 0.9094  lr:0.100000  network_time: 0.0111
[ Thu May 11 15:14:11 2023 ] 	Batch(339/480) done. Loss: 1.6170  lr:0.100000  network_time: 0.0113
[ Thu May 11 15:14:58 2023 ] 	Batch(439/480) done. Loss: 1.5142  lr:0.100000  network_time: 0.0119
[ Thu May 11 15:15:17 2023 ] 	Training Accuracy: 52.83%
[ Thu May 11 15:15:17 2023 ] Eval epoch: 8
[ Thu May 11 15:15:34 2023 ] 	Mean test loss of 120 batches: 1.488242268562317.
[ Thu May 11 15:15:34 2023 ] 	Top1: 53.33%
[ Thu May 11 15:15:34 2023 ] 	Top5: 93.17%
[ Thu May 11 15:15:34 2023 ] Training epoch: 9
[ Thu May 11 15:16:02 2023 ] 	Batch(59/480) done. Loss: 0.3931  lr:0.100000  network_time: 0.0110
[ Thu May 11 15:16:49 2023 ] 	Batch(159/480) done. Loss: 1.1683  lr:0.100000  network_time: 0.0126
[ Thu May 11 15:17:36 2023 ] 	Batch(259/480) done. Loss: 1.5389  lr:0.100000  network_time: 0.0109
[ Thu May 11 15:18:24 2023 ] 	Batch(359/480) done. Loss: 0.3671  lr:0.100000  network_time: 0.0113
[ Thu May 11 15:19:11 2023 ] 	Batch(459/480) done. Loss: 0.9264  lr:0.100000  network_time: 0.0115
[ Thu May 11 15:19:20 2023 ] 	Training Accuracy: 60.58%
[ Thu May 11 15:19:20 2023 ] Eval epoch: 9
[ Thu May 11 15:19:36 2023 ] 	Mean test loss of 120 batches: 1.8737947940826416.
[ Thu May 11 15:19:36 2023 ] 	Top1: 53.50%
[ Thu May 11 15:19:36 2023 ] 	Top5: 90.50%
[ Thu May 11 15:19:36 2023 ] Training epoch: 10
[ Thu May 11 15:20:14 2023 ] 	Batch(79/480) done. Loss: 1.8209  lr:0.100000  network_time: 0.0109
[ Thu May 11 15:21:01 2023 ] 	Batch(179/480) done. Loss: 1.8036  lr:0.100000  network_time: 0.0117
[ Thu May 11 15:21:48 2023 ] 	Batch(279/480) done. Loss: 1.0442  lr:0.100000  network_time: 0.0111
[ Thu May 11 15:22:36 2023 ] 	Batch(379/480) done. Loss: 0.6965  lr:0.100000  network_time: 0.0114
[ Thu May 11 15:23:23 2023 ] 	Batch(479/480) done. Loss: 1.2450  lr:0.100000  network_time: 0.0115
[ Thu May 11 15:23:23 2023 ] 	Training Accuracy: 64.54%
[ Thu May 11 15:23:23 2023 ] Eval epoch: 10
[ Thu May 11 15:23:39 2023 ] 	Mean test loss of 120 batches: 1.5305992364883423.
[ Thu May 11 15:23:39 2023 ] 	Top1: 64.67%
[ Thu May 11 15:23:39 2023 ] 	Top5: 95.17%
[ Thu May 11 15:23:39 2023 ] Training epoch: 11
[ Thu May 11 15:24:26 2023 ] 	Batch(99/480) done. Loss: 0.4465  lr:0.100000  network_time: 0.0113
[ Thu May 11 15:25:13 2023 ] 	Batch(199/480) done. Loss: 1.8643  lr:0.100000  network_time: 0.0110
[ Thu May 11 15:26:01 2023 ] 	Batch(299/480) done. Loss: 1.2061  lr:0.100000  network_time: 0.0113
[ Thu May 11 15:26:48 2023 ] 	Batch(399/480) done. Loss: 0.6710  lr:0.100000  network_time: 0.0113
[ Thu May 11 15:27:25 2023 ] 	Training Accuracy: 69.75%
[ Thu May 11 15:27:25 2023 ] Eval epoch: 11
[ Thu May 11 15:27:42 2023 ] 	Mean test loss of 120 batches: 9.830574989318848.
[ Thu May 11 15:27:42 2023 ] 	Top1: 18.50%
[ Thu May 11 15:27:42 2023 ] 	Top5: 48.33%
[ Thu May 11 15:27:42 2023 ] Training epoch: 12
[ Thu May 11 15:27:51 2023 ] 	Batch(19/480) done. Loss: 0.1216  lr:0.100000  network_time: 0.0112
[ Thu May 11 15:28:38 2023 ] 	Batch(119/480) done. Loss: 0.4277  lr:0.100000  network_time: 0.0125
[ Thu May 11 15:29:26 2023 ] 	Batch(219/480) done. Loss: 0.9240  lr:0.100000  network_time: 0.0112
[ Thu May 11 15:30:13 2023 ] 	Batch(319/480) done. Loss: 0.8440  lr:0.100000  network_time: 0.0116
[ Thu May 11 15:31:00 2023 ] 	Batch(419/480) done. Loss: 0.3325  lr:0.100000  network_time: 0.0117
[ Thu May 11 15:31:28 2023 ] 	Training Accuracy: 73.46%
[ Thu May 11 15:31:28 2023 ] Eval epoch: 12
[ Thu May 11 15:31:45 2023 ] 	Mean test loss of 120 batches: 1.4691293239593506.
[ Thu May 11 15:31:45 2023 ] 	Top1: 70.67%
[ Thu May 11 15:31:45 2023 ] 	Top5: 96.33%
[ Thu May 11 15:31:45 2023 ] Training epoch: 13
[ Thu May 11 15:32:04 2023 ] 	Batch(39/480) done. Loss: 1.1371  lr:0.100000  network_time: 0.0111
[ Thu May 11 15:32:51 2023 ] 	Batch(139/480) done. Loss: 0.4472  lr:0.100000  network_time: 0.0114
[ Thu May 11 15:33:38 2023 ] 	Batch(239/480) done. Loss: 0.4676  lr:0.100000  network_time: 0.0112
[ Thu May 11 15:34:25 2023 ] 	Batch(339/480) done. Loss: 1.8148  lr:0.100000  network_time: 0.0112
[ Thu May 11 15:35:12 2023 ] 	Batch(439/480) done. Loss: 0.8774  lr:0.100000  network_time: 0.0112
[ Thu May 11 15:35:31 2023 ] 	Training Accuracy: 75.75%
[ Thu May 11 15:35:31 2023 ] Eval epoch: 13
[ Thu May 11 15:35:47 2023 ] 	Mean test loss of 120 batches: 0.7709740996360779.
[ Thu May 11 15:35:47 2023 ] 	Top1: 77.17%
[ Thu May 11 15:35:47 2023 ] 	Top5: 98.17%
[ Thu May 11 15:35:47 2023 ] Training epoch: 14
[ Thu May 11 15:36:16 2023 ] 	Batch(59/480) done. Loss: 0.4502  lr:0.100000  network_time: 0.0107
[ Thu May 11 15:37:03 2023 ] 	Batch(159/480) done. Loss: 0.3213  lr:0.100000  network_time: 0.0110
[ Thu May 11 15:37:50 2023 ] 	Batch(259/480) done. Loss: 0.6375  lr:0.100000  network_time: 0.0109
[ Thu May 11 15:38:37 2023 ] 	Batch(359/480) done. Loss: 1.2159  lr:0.100000  network_time: 0.0114
[ Thu May 11 15:39:24 2023 ] 	Batch(459/480) done. Loss: 0.3193  lr:0.100000  network_time: 0.0111
[ Thu May 11 15:39:34 2023 ] 	Training Accuracy: 76.79%
[ Thu May 11 15:39:34 2023 ] Eval epoch: 14
[ Thu May 11 15:39:50 2023 ] 	Mean test loss of 120 batches: 1.1602394580841064.
[ Thu May 11 15:39:50 2023 ] 	Top1: 68.33%
[ Thu May 11 15:39:50 2023 ] 	Top5: 97.67%
[ Thu May 11 15:39:50 2023 ] Training epoch: 15
[ Thu May 11 15:40:28 2023 ] 	Batch(79/480) done. Loss: 0.5714  lr:0.100000  network_time: 0.0109
[ Thu May 11 15:41:15 2023 ] 	Batch(179/480) done. Loss: 1.6722  lr:0.100000  network_time: 0.0112
[ Thu May 11 15:42:02 2023 ] 	Batch(279/480) done. Loss: 0.1043  lr:0.100000  network_time: 0.0111
[ Thu May 11 15:42:49 2023 ] 	Batch(379/480) done. Loss: 1.1128  lr:0.100000  network_time: 0.0110
[ Thu May 11 15:43:36 2023 ] 	Batch(479/480) done. Loss: 0.6745  lr:0.100000  network_time: 0.0115
[ Thu May 11 15:43:36 2023 ] 	Training Accuracy: 78.92%
[ Thu May 11 15:43:36 2023 ] Eval epoch: 15
[ Thu May 11 15:43:53 2023 ] 	Mean test loss of 120 batches: 5.710296154022217.
[ Thu May 11 15:43:53 2023 ] 	Top1: 56.00%
[ Thu May 11 15:43:53 2023 ] 	Top5: 85.00%
[ Thu May 11 15:43:53 2023 ] Training epoch: 16
[ Thu May 11 15:44:40 2023 ] 	Batch(99/480) done. Loss: 0.4288  lr:0.100000  network_time: 0.0111
[ Thu May 11 15:45:27 2023 ] 	Batch(199/480) done. Loss: 0.3972  lr:0.100000  network_time: 0.0119
[ Thu May 11 15:46:14 2023 ] 	Batch(299/480) done. Loss: 0.8872  lr:0.100000  network_time: 0.0117
[ Thu May 11 15:47:01 2023 ] 	Batch(399/480) done. Loss: 0.7038  lr:0.100000  network_time: 0.0112
[ Thu May 11 15:47:39 2023 ] 	Training Accuracy: 82.38%
[ Thu May 11 15:47:39 2023 ] Eval epoch: 16
[ Thu May 11 15:47:56 2023 ] 	Mean test loss of 120 batches: 0.7220874428749084.
[ Thu May 11 15:47:56 2023 ] 	Top1: 80.00%
[ Thu May 11 15:47:56 2023 ] 	Top5: 98.67%
[ Thu May 11 15:47:56 2023 ] Training epoch: 17
[ Thu May 11 15:48:05 2023 ] 	Batch(19/480) done. Loss: 0.0487  lr:0.100000  network_time: 0.0110
[ Thu May 11 15:48:52 2023 ] 	Batch(119/480) done. Loss: 0.2006  lr:0.100000  network_time: 0.0108
[ Thu May 11 15:49:39 2023 ] 	Batch(219/480) done. Loss: 0.6361  lr:0.100000  network_time: 0.0112
[ Thu May 11 15:50:26 2023 ] 	Batch(319/480) done. Loss: 0.6194  lr:0.100000  network_time: 0.0108
[ Thu May 11 15:51:14 2023 ] 	Batch(419/480) done. Loss: 0.3402  lr:0.100000  network_time: 0.0115
[ Thu May 11 15:51:42 2023 ] 	Training Accuracy: 82.63%
[ Thu May 11 15:51:42 2023 ] Eval epoch: 17
[ Thu May 11 15:51:58 2023 ] 	Mean test loss of 120 batches: 0.2832479774951935.
[ Thu May 11 15:51:58 2023 ] 	Top1: 91.33%
[ Thu May 11 15:51:58 2023 ] 	Top5: 99.33%
[ Thu May 11 15:51:58 2023 ] Training epoch: 18
[ Thu May 11 15:52:17 2023 ] 	Batch(39/480) done. Loss: 0.2796  lr:0.100000  network_time: 0.0122
[ Thu May 11 15:53:04 2023 ] 	Batch(139/480) done. Loss: 1.4667  lr:0.100000  network_time: 0.0116
[ Thu May 11 15:53:51 2023 ] 	Batch(239/480) done. Loss: 0.5630  lr:0.100000  network_time: 0.0110
[ Thu May 11 15:54:39 2023 ] 	Batch(339/480) done. Loss: 0.3748  lr:0.100000  network_time: 0.0120
[ Thu May 11 15:55:26 2023 ] 	Batch(439/480) done. Loss: 1.0951  lr:0.100000  network_time: 0.0111
[ Thu May 11 15:55:45 2023 ] 	Training Accuracy: 83.63%
[ Thu May 11 15:55:45 2023 ] Eval epoch: 18
[ Thu May 11 15:56:01 2023 ] 	Mean test loss of 120 batches: 0.5317723751068115.
[ Thu May 11 15:56:01 2023 ] 	Top1: 85.00%
[ Thu May 11 15:56:01 2023 ] 	Top5: 99.17%
[ Thu May 11 15:56:01 2023 ] Training epoch: 19
[ Thu May 11 15:56:29 2023 ] 	Batch(59/480) done. Loss: 0.3842  lr:0.100000  network_time: 0.0111
[ Thu May 11 15:57:16 2023 ] 	Batch(159/480) done. Loss: 0.6793  lr:0.100000  network_time: 0.0111
[ Thu May 11 15:58:04 2023 ] 	Batch(259/480) done. Loss: 0.4766  lr:0.100000  network_time: 0.0109
[ Thu May 11 15:58:51 2023 ] 	Batch(359/480) done. Loss: 0.1500  lr:0.100000  network_time: 0.0117
[ Thu May 11 15:59:38 2023 ] 	Batch(459/480) done. Loss: 0.6310  lr:0.100000  network_time: 0.0115
[ Thu May 11 15:59:47 2023 ] 	Training Accuracy: 84.88%
[ Thu May 11 15:59:48 2023 ] Eval epoch: 19
[ Thu May 11 16:00:04 2023 ] 	Mean test loss of 120 batches: 0.3409353494644165.
[ Thu May 11 16:00:04 2023 ] 	Top1: 91.67%
[ Thu May 11 16:00:04 2023 ] 	Top5: 99.67%
[ Thu May 11 16:00:04 2023 ] Training epoch: 20
[ Thu May 11 16:00:42 2023 ] 	Batch(79/480) done. Loss: 0.2388  lr:0.100000  network_time: 0.0121
[ Thu May 11 16:01:29 2023 ] 	Batch(179/480) done. Loss: 1.7428  lr:0.100000  network_time: 0.0115
[ Thu May 11 16:02:16 2023 ] 	Batch(279/480) done. Loss: 0.3856  lr:0.100000  network_time: 0.0118
[ Thu May 11 16:03:03 2023 ] 	Batch(379/480) done. Loss: 0.4479  lr:0.100000  network_time: 0.0112
[ Thu May 11 16:03:50 2023 ] 	Batch(479/480) done. Loss: 0.2267  lr:0.100000  network_time: 0.0117
[ Thu May 11 16:03:50 2023 ] 	Training Accuracy: 87.25%
[ Thu May 11 16:03:50 2023 ] Eval epoch: 20
[ Thu May 11 16:04:07 2023 ] 	Mean test loss of 120 batches: 0.25765228271484375.
[ Thu May 11 16:04:07 2023 ] 	Top1: 90.33%
[ Thu May 11 16:04:07 2023 ] 	Top5: 99.83%
[ Thu May 11 16:04:07 2023 ] Training epoch: 21
[ Thu May 11 16:04:54 2023 ] 	Batch(99/480) done. Loss: 0.0810  lr:0.010000  network_time: 0.0126
[ Thu May 11 16:05:41 2023 ] 	Batch(199/480) done. Loss: 0.0798  lr:0.010000  network_time: 0.0112
[ Thu May 11 16:06:28 2023 ] 	Batch(299/480) done. Loss: 0.6147  lr:0.010000  network_time: 0.0112
[ Thu May 11 16:07:16 2023 ] 	Batch(399/480) done. Loss: 0.0148  lr:0.010000  network_time: 0.0117
[ Thu May 11 16:07:53 2023 ] 	Training Accuracy: 95.17%
[ Thu May 11 16:07:53 2023 ] Eval epoch: 21
[ Thu May 11 16:08:10 2023 ] 	Mean test loss of 120 batches: 0.07513532787561417.
[ Thu May 11 16:08:10 2023 ] 	Top1: 98.17%
[ Thu May 11 16:08:10 2023 ] 	Top5: 100.00%
[ Thu May 11 16:08:10 2023 ] Training epoch: 22
[ Thu May 11 16:08:19 2023 ] 	Batch(19/480) done. Loss: 0.0360  lr:0.010000  network_time: 0.0114
[ Thu May 11 16:09:06 2023 ] 	Batch(119/480) done. Loss: 0.0192  lr:0.010000  network_time: 0.0113
[ Thu May 11 16:09:53 2023 ] 	Batch(219/480) done. Loss: 0.0570  lr:0.010000  network_time: 0.0117
[ Thu May 11 16:10:40 2023 ] 	Batch(319/480) done. Loss: 0.0688  lr:0.010000  network_time: 0.0112
[ Thu May 11 16:11:28 2023 ] 	Batch(419/480) done. Loss: 0.0365  lr:0.010000  network_time: 0.0113
[ Thu May 11 16:11:56 2023 ] 	Training Accuracy: 98.04%
[ Thu May 11 16:11:56 2023 ] Eval epoch: 22
[ Thu May 11 16:12:12 2023 ] 	Mean test loss of 120 batches: 0.07619576901197433.
[ Thu May 11 16:12:12 2023 ] 	Top1: 98.50%
[ Thu May 11 16:12:12 2023 ] 	Top5: 100.00%
[ Thu May 11 16:12:12 2023 ] Training epoch: 23
[ Thu May 11 16:12:31 2023 ] 	Batch(39/480) done. Loss: 0.0988  lr:0.010000  network_time: 0.0112
[ Thu May 11 16:13:18 2023 ] 	Batch(139/480) done. Loss: 0.0265  lr:0.010000  network_time: 0.0116
[ Thu May 11 16:14:05 2023 ] 	Batch(239/480) done. Loss: 0.0160  lr:0.010000  network_time: 0.0114
[ Thu May 11 16:14:53 2023 ] 	Batch(339/480) done. Loss: 0.0221  lr:0.010000  network_time: 0.0112
[ Thu May 11 16:15:40 2023 ] 	Batch(439/480) done. Loss: 0.0204  lr:0.010000  network_time: 0.0113
[ Thu May 11 16:15:59 2023 ] 	Training Accuracy: 98.33%
[ Thu May 11 16:15:59 2023 ] Eval epoch: 23
[ Thu May 11 16:16:15 2023 ] 	Mean test loss of 120 batches: 0.05276653915643692.
[ Thu May 11 16:16:15 2023 ] 	Top1: 99.17%
[ Thu May 11 16:16:15 2023 ] 	Top5: 100.00%
[ Thu May 11 16:16:15 2023 ] Training epoch: 24
[ Thu May 11 16:16:43 2023 ] 	Batch(59/480) done. Loss: 0.3143  lr:0.010000  network_time: 0.0111
[ Thu May 11 16:17:31 2023 ] 	Batch(159/480) done. Loss: 0.1525  lr:0.010000  network_time: 0.0116
[ Thu May 11 16:18:18 2023 ] 	Batch(259/480) done. Loss: 0.1538  lr:0.010000  network_time: 0.0109
[ Thu May 11 16:19:05 2023 ] 	Batch(359/480) done. Loss: 0.0820  lr:0.010000  network_time: 0.0112
[ Thu May 11 16:19:52 2023 ] 	Batch(459/480) done. Loss: 0.4086  lr:0.010000  network_time: 0.0112
[ Thu May 11 16:20:01 2023 ] 	Training Accuracy: 98.42%
[ Thu May 11 16:20:02 2023 ] Eval epoch: 24
[ Thu May 11 16:20:18 2023 ] 	Mean test loss of 120 batches: 0.1364223212003708.
[ Thu May 11 16:20:18 2023 ] 	Top1: 98.67%
[ Thu May 11 16:20:18 2023 ] 	Top5: 100.00%
[ Thu May 11 16:20:18 2023 ] Training epoch: 25
[ Thu May 11 16:20:56 2023 ] 	Batch(79/480) done. Loss: 0.0504  lr:0.010000  network_time: 0.0117
[ Thu May 11 16:21:43 2023 ] 	Batch(179/480) done. Loss: 0.0221  lr:0.010000  network_time: 0.0111
[ Thu May 11 16:22:30 2023 ] 	Batch(279/480) done. Loss: 0.0201  lr:0.010000  network_time: 0.0115
[ Thu May 11 16:23:17 2023 ] 	Batch(379/480) done. Loss: 0.0362  lr:0.010000  network_time: 0.0116
[ Thu May 11 16:24:04 2023 ] 	Batch(479/480) done. Loss: 0.0147  lr:0.010000  network_time: 0.0115
[ Thu May 11 16:24:04 2023 ] 	Training Accuracy: 98.62%
[ Thu May 11 16:24:04 2023 ] Eval epoch: 25
[ Thu May 11 16:24:21 2023 ] 	Mean test loss of 120 batches: 0.1395755112171173.
[ Thu May 11 16:24:21 2023 ] 	Top1: 98.50%
[ Thu May 11 16:24:21 2023 ] 	Top5: 100.00%
[ Thu May 11 16:24:21 2023 ] Training epoch: 26
[ Thu May 11 16:25:08 2023 ] 	Batch(99/480) done. Loss: 0.0285  lr:0.001000  network_time: 0.0115
[ Thu May 11 16:25:55 2023 ] 	Batch(199/480) done. Loss: 0.2037  lr:0.001000  network_time: 0.0109
[ Thu May 11 16:26:42 2023 ] 	Batch(299/480) done. Loss: 0.0161  lr:0.001000  network_time: 0.0112
[ Thu May 11 16:27:29 2023 ] 	Batch(399/480) done. Loss: 0.0501  lr:0.001000  network_time: 0.0117
[ Thu May 11 16:28:07 2023 ] 	Training Accuracy: 98.96%
[ Thu May 11 16:28:07 2023 ] Eval epoch: 26
[ Thu May 11 16:28:24 2023 ] 	Mean test loss of 120 batches: 0.11151255667209625.
[ Thu May 11 16:28:24 2023 ] 	Top1: 98.83%
[ Thu May 11 16:28:24 2023 ] 	Top5: 100.00%
[ Thu May 11 16:28:24 2023 ] Training epoch: 27
[ Thu May 11 16:28:33 2023 ] 	Batch(19/480) done. Loss: 0.0106  lr:0.001000  network_time: 0.0107
[ Thu May 11 16:29:20 2023 ] 	Batch(119/480) done. Loss: 0.2361  lr:0.001000  network_time: 0.0109
[ Thu May 11 16:30:07 2023 ] 	Batch(219/480) done. Loss: 0.0085  lr:0.001000  network_time: 0.0113
[ Thu May 11 16:30:55 2023 ] 	Batch(319/480) done. Loss: 0.0439  lr:0.001000  network_time: 0.0109
[ Thu May 11 16:31:42 2023 ] 	Batch(419/480) done. Loss: 0.0252  lr:0.001000  network_time: 0.0118
[ Thu May 11 16:32:10 2023 ] 	Training Accuracy: 98.88%
[ Thu May 11 16:32:10 2023 ] Eval epoch: 27
[ Thu May 11 16:32:26 2023 ] 	Mean test loss of 120 batches: 0.1396794617176056.
[ Thu May 11 16:32:26 2023 ] 	Top1: 98.83%
[ Thu May 11 16:32:26 2023 ] 	Top5: 100.00%
[ Thu May 11 16:32:26 2023 ] Training epoch: 28
[ Thu May 11 16:32:45 2023 ] 	Batch(39/480) done. Loss: 0.0620  lr:0.001000  network_time: 0.0111
[ Thu May 11 16:33:33 2023 ] 	Batch(139/480) done. Loss: 0.0574  lr:0.001000  network_time: 0.0129
[ Thu May 11 16:34:20 2023 ] 	Batch(239/480) done. Loss: 0.0270  lr:0.001000  network_time: 0.0111
[ Thu May 11 16:35:07 2023 ] 	Batch(339/480) done. Loss: 0.0249  lr:0.001000  network_time: 0.0109
[ Thu May 11 16:35:54 2023 ] 	Batch(439/480) done. Loss: 0.0854  lr:0.001000  network_time: 0.0112
[ Thu May 11 16:36:13 2023 ] 	Training Accuracy: 99.04%
[ Thu May 11 16:36:13 2023 ] Eval epoch: 28
[ Thu May 11 16:36:29 2023 ] 	Mean test loss of 120 batches: 0.07536826282739639.
[ Thu May 11 16:36:29 2023 ] 	Top1: 98.83%
[ Thu May 11 16:36:29 2023 ] 	Top5: 100.00%
[ Thu May 11 16:36:29 2023 ] Training epoch: 29
[ Thu May 11 16:36:58 2023 ] 	Batch(59/480) done. Loss: 0.0861  lr:0.001000  network_time: 0.0110
[ Thu May 11 16:37:45 2023 ] 	Batch(159/480) done. Loss: 0.0315  lr:0.001000  network_time: 0.0113
[ Thu May 11 16:38:32 2023 ] 	Batch(259/480) done. Loss: 0.1177  lr:0.001000  network_time: 0.0113
[ Thu May 11 16:39:19 2023 ] 	Batch(359/480) done. Loss: 0.0340  lr:0.001000  network_time: 0.0119
[ Thu May 11 16:40:06 2023 ] 	Batch(459/480) done. Loss: 0.0271  lr:0.001000  network_time: 0.0111
[ Thu May 11 16:40:16 2023 ] 	Training Accuracy: 98.79%
[ Thu May 11 16:40:16 2023 ] Eval epoch: 29
[ Thu May 11 16:40:32 2023 ] 	Mean test loss of 120 batches: 0.17476177215576172.
[ Thu May 11 16:40:32 2023 ] 	Top1: 98.67%
[ Thu May 11 16:40:32 2023 ] 	Top5: 100.00%
[ Thu May 11 16:40:32 2023 ] Training epoch: 30
[ Thu May 11 16:41:10 2023 ] 	Batch(79/480) done. Loss: 0.0184  lr:0.001000  network_time: 0.0111
[ Thu May 11 16:41:57 2023 ] 	Batch(179/480) done. Loss: 0.0085  lr:0.001000  network_time: 0.0111
[ Thu May 11 16:42:44 2023 ] 	Batch(279/480) done. Loss: 0.0512  lr:0.001000  network_time: 0.0112
[ Thu May 11 16:43:31 2023 ] 	Batch(379/480) done. Loss: 0.1632  lr:0.001000  network_time: 0.0109
[ Thu May 11 16:44:18 2023 ] 	Batch(479/480) done. Loss: 0.0152  lr:0.001000  network_time: 0.0109
[ Thu May 11 16:44:18 2023 ] 	Training Accuracy: 98.92%
[ Thu May 11 16:44:18 2023 ] Eval epoch: 30
[ Thu May 11 16:44:35 2023 ] 	Mean test loss of 120 batches: 0.046755075454711914.
[ Thu May 11 16:44:35 2023 ] 	Top1: 99.00%
[ Thu May 11 16:44:35 2023 ] 	Top5: 100.00%
