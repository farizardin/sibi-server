[ Fri May 12 21:05:14 2023 ] NUM WORKER: 1
[ Fri May 12 21:06:08 2023 ] Parameters:
{'work_dir': './work_dir/sibi_individual_outer_group_ShiftGCN_mod_3_joint_n_5_kfold_fold_4', 'model_saved_name': './save_models/sibi_individual_outer_group_ShiftGCN_mod_3_joint_n_5_kfold_fold_4', 'Experiment_name': 'sibi_individual_outer_group_ShiftGCN_mod_3_joint_n_5_kfold', 'config': './config/recalculated/train_sibi_with_mouth_augmented_individual_outer_group_shift_joint_mod_3.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 2, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'n_splits': 5, 'feeder': 'feeders.feeder_hsd.Feeder', 'num_worker': 1, 'train_feeder_args': {'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': -1, 'normalization': False}, 'test_feeder_args': None, 'data_path': './data/augmented_recalculate_normalized', 'model': 'model.shift_gcn.Model', 'model_args': {'num_class': 50, 'num_person': 1, 'num_point': 115, 'graph_group': [[0, 39], [40, 60], [61, 81], [82, 114]], 'method': 'grouped.outer', 'weight': 3, 'graph': 'graph.skeleton_with_mouth.SkeletonWithMouth', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [20, 25], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 5, 'test_batch_size': 5, 'start_epoch': 0, 'num_epoch': 30, 'folds_range': [2, 5], 'weight_decay': 0.0001, 'only_train_part': True, 'only_train_epoch': 1, 'warm_up_epoch': 0}

[ Fri May 12 21:06:08 2023 ] Training epoch: 1
[ Fri May 12 21:06:58 2023 ] 	Batch(99/480) done. Loss: 3.9853  lr:0.100000  network_time: 0.0111
[ Fri May 12 21:07:46 2023 ] 	Batch(199/480) done. Loss: 3.7949  lr:0.100000  network_time: 0.0109
[ Fri May 12 21:08:35 2023 ] 	Batch(299/480) done. Loss: 3.9580  lr:0.100000  network_time: 0.0112
[ Fri May 12 21:09:23 2023 ] 	Batch(399/480) done. Loss: 3.5415  lr:0.100000  network_time: 0.0110
[ Fri May 12 21:10:02 2023 ] 	Training Accuracy: 4.58%
[ Fri May 12 21:10:02 2023 ] Eval epoch: 1
[ Fri May 12 21:10:19 2023 ] 	Mean test loss of 120 batches: 5.006221294403076.
[ Fri May 12 21:10:19 2023 ] 	Top1: 6.33%
[ Fri May 12 21:10:19 2023 ] 	Top5: 31.83%
[ Fri May 12 21:10:19 2023 ] Training epoch: 2
[ Fri May 12 21:10:29 2023 ] 	Batch(19/480) done. Loss: 3.0295  lr:0.100000  network_time: 0.0110
[ Fri May 12 21:11:18 2023 ] 	Batch(119/480) done. Loss: 3.9180  lr:0.100000  network_time: 0.0108
[ Fri May 12 21:12:06 2023 ] 	Batch(219/480) done. Loss: 3.7538  lr:0.100000  network_time: 0.0129
[ Fri May 12 21:12:55 2023 ] 	Batch(319/480) done. Loss: 3.5144  lr:0.100000  network_time: 0.0112
[ Fri May 12 21:13:43 2023 ] 	Batch(419/480) done. Loss: 2.7243  lr:0.100000  network_time: 0.0112
[ Fri May 12 21:14:13 2023 ] 	Training Accuracy: 7.38%
[ Fri May 12 21:14:13 2023 ] Eval epoch: 2
[ Fri May 12 21:14:29 2023 ] 	Mean test loss of 120 batches: 3.5718395709991455.
[ Fri May 12 21:14:29 2023 ] 	Top1: 8.50%
[ Fri May 12 21:14:29 2023 ] 	Top5: 38.33%
[ Fri May 12 21:14:29 2023 ] Training epoch: 3
[ Fri May 12 21:14:49 2023 ] 	Batch(39/480) done. Loss: 3.2400  lr:0.100000  network_time: 0.0113
[ Fri May 12 21:15:38 2023 ] 	Batch(139/480) done. Loss: 3.1293  lr:0.100000  network_time: 0.0109
[ Fri May 12 21:16:26 2023 ] 	Batch(239/480) done. Loss: 3.0842  lr:0.100000  network_time: 0.0113
[ Fri May 12 21:17:15 2023 ] 	Batch(339/480) done. Loss: 2.7778  lr:0.100000  network_time: 0.0113
[ Fri May 12 21:18:04 2023 ] 	Batch(439/480) done. Loss: 3.1041  lr:0.100000  network_time: 0.0112
[ Fri May 12 21:18:23 2023 ] 	Training Accuracy: 14.58%
[ Fri May 12 21:18:23 2023 ] Eval epoch: 3
[ Fri May 12 21:18:40 2023 ] 	Mean test loss of 120 batches: 3.16532039642334.
[ Fri May 12 21:18:40 2023 ] 	Top1: 14.83%
[ Fri May 12 21:18:40 2023 ] 	Top5: 47.50%
[ Fri May 12 21:18:40 2023 ] Training epoch: 4
[ Fri May 12 21:19:09 2023 ] 	Batch(59/480) done. Loss: 2.3896  lr:0.100000  network_time: 0.0113
[ Fri May 12 21:19:58 2023 ] 	Batch(159/480) done. Loss: 2.7726  lr:0.100000  network_time: 0.0113
[ Fri May 12 21:20:46 2023 ] 	Batch(259/480) done. Loss: 2.2250  lr:0.100000  network_time: 0.0117
[ Fri May 12 21:21:35 2023 ] 	Batch(359/480) done. Loss: 2.4739  lr:0.100000  network_time: 0.0111
[ Fri May 12 21:22:24 2023 ] 	Batch(459/480) done. Loss: 2.9861  lr:0.100000  network_time: 0.0114
[ Fri May 12 21:22:33 2023 ] 	Training Accuracy: 19.17%
[ Fri May 12 21:22:33 2023 ] Eval epoch: 4
[ Fri May 12 21:22:50 2023 ] 	Mean test loss of 120 batches: 2.5355889797210693.
[ Fri May 12 21:22:50 2023 ] 	Top1: 24.00%
[ Fri May 12 21:22:50 2023 ] 	Top5: 68.67%
[ Fri May 12 21:22:50 2023 ] Training epoch: 5
[ Fri May 12 21:23:29 2023 ] 	Batch(79/480) done. Loss: 2.7392  lr:0.100000  network_time: 0.0113
[ Fri May 12 21:24:18 2023 ] 	Batch(179/480) done. Loss: 2.4793  lr:0.100000  network_time: 0.0112
[ Fri May 12 21:25:06 2023 ] 	Batch(279/480) done. Loss: 2.5264  lr:0.100000  network_time: 0.0118
[ Fri May 12 21:25:55 2023 ] 	Batch(379/480) done. Loss: 2.0282  lr:0.100000  network_time: 0.0112
[ Fri May 12 21:26:44 2023 ] 	Batch(479/480) done. Loss: 1.5870  lr:0.100000  network_time: 0.0114
[ Fri May 12 21:26:44 2023 ] 	Training Accuracy: 27.25%
[ Fri May 12 21:26:44 2023 ] Eval epoch: 5
[ Fri May 12 21:27:01 2023 ] 	Mean test loss of 120 batches: 3.275653600692749.
[ Fri May 12 21:27:01 2023 ] 	Top1: 18.50%
[ Fri May 12 21:27:01 2023 ] 	Top5: 58.00%
[ Fri May 12 21:27:01 2023 ] Training epoch: 6
[ Fri May 12 21:27:49 2023 ] 	Batch(99/480) done. Loss: 2.4603  lr:0.100000  network_time: 0.0112
[ Fri May 12 21:28:38 2023 ] 	Batch(199/480) done. Loss: 2.1127  lr:0.100000  network_time: 0.0131
[ Fri May 12 21:29:27 2023 ] 	Batch(299/480) done. Loss: 1.7738  lr:0.100000  network_time: 0.0113
[ Fri May 12 21:30:15 2023 ] 	Batch(399/480) done. Loss: 2.3169  lr:0.100000  network_time: 0.0116
[ Fri May 12 21:30:54 2023 ] 	Training Accuracy: 33.54%
[ Fri May 12 21:30:54 2023 ] Eval epoch: 6
[ Fri May 12 21:31:11 2023 ] 	Mean test loss of 120 batches: 1.7926684617996216.
[ Fri May 12 21:31:11 2023 ] 	Top1: 39.17%
[ Fri May 12 21:31:11 2023 ] 	Top5: 79.33%
[ Fri May 12 21:31:11 2023 ] Training epoch: 7
[ Fri May 12 21:31:21 2023 ] 	Batch(19/480) done. Loss: 1.3289  lr:0.100000  network_time: 0.0113
[ Fri May 12 21:32:09 2023 ] 	Batch(119/480) done. Loss: 1.7039  lr:0.100000  network_time: 0.0113
[ Fri May 12 21:32:58 2023 ] 	Batch(219/480) done. Loss: 2.2630  lr:0.100000  network_time: 0.0110
[ Fri May 12 21:33:47 2023 ] 	Batch(319/480) done. Loss: 1.5272  lr:0.100000  network_time: 0.0112
[ Fri May 12 21:34:35 2023 ] 	Batch(419/480) done. Loss: 1.6216  lr:0.100000  network_time: 0.0111
[ Fri May 12 21:35:04 2023 ] 	Training Accuracy: 40.58%
[ Fri May 12 21:35:05 2023 ] Eval epoch: 7
[ Fri May 12 21:35:21 2023 ] 	Mean test loss of 120 batches: 1.434003233909607.
[ Fri May 12 21:35:21 2023 ] 	Top1: 53.17%
[ Fri May 12 21:35:21 2023 ] 	Top5: 90.00%
[ Fri May 12 21:35:21 2023 ] Training epoch: 8
[ Fri May 12 21:35:41 2023 ] 	Batch(39/480) done. Loss: 0.7780  lr:0.100000  network_time: 0.0111
[ Fri May 12 21:36:29 2023 ] 	Batch(139/480) done. Loss: 2.3361  lr:0.100000  network_time: 0.0111
[ Fri May 12 21:37:18 2023 ] 	Batch(239/480) done. Loss: 0.5651  lr:0.100000  network_time: 0.0107
[ Fri May 12 21:38:07 2023 ] 	Batch(339/480) done. Loss: 0.8193  lr:0.100000  network_time: 0.0113
[ Fri May 12 21:38:55 2023 ] 	Batch(439/480) done. Loss: 2.2870  lr:0.100000  network_time: 0.0112
[ Fri May 12 21:39:15 2023 ] 	Training Accuracy: 49.50%
[ Fri May 12 21:39:15 2023 ] Eval epoch: 8
[ Fri May 12 21:39:32 2023 ] 	Mean test loss of 120 batches: 2.7181129455566406.
[ Fri May 12 21:39:32 2023 ] 	Top1: 27.83%
[ Fri May 12 21:39:32 2023 ] 	Top5: 70.33%
[ Fri May 12 21:39:32 2023 ] Training epoch: 9
[ Fri May 12 21:40:01 2023 ] 	Batch(59/480) done. Loss: 1.5897  lr:0.100000  network_time: 0.0120
[ Fri May 12 21:40:50 2023 ] 	Batch(159/480) done. Loss: 1.9657  lr:0.100000  network_time: 0.0116
[ Fri May 12 21:41:38 2023 ] 	Batch(259/480) done. Loss: 1.3811  lr:0.100000  network_time: 0.0108
[ Fri May 12 21:42:27 2023 ] 	Batch(359/480) done. Loss: 1.3709  lr:0.100000  network_time: 0.0115
[ Fri May 12 21:43:15 2023 ] 	Batch(459/480) done. Loss: 1.6226  lr:0.100000  network_time: 0.0114
[ Fri May 12 21:43:25 2023 ] 	Training Accuracy: 56.79%
[ Fri May 12 21:43:25 2023 ] Eval epoch: 9
[ Fri May 12 21:43:42 2023 ] 	Mean test loss of 120 batches: 3.7161457538604736.
[ Fri May 12 21:43:42 2023 ] 	Top1: 31.33%
[ Fri May 12 21:43:42 2023 ] 	Top5: 71.83%
[ Fri May 12 21:43:42 2023 ] Training epoch: 10
[ Fri May 12 21:44:21 2023 ] 	Batch(79/480) done. Loss: 1.2665  lr:0.100000  network_time: 0.0116
[ Fri May 12 21:45:10 2023 ] 	Batch(179/480) done. Loss: 1.4378  lr:0.100000  network_time: 0.0113
[ Fri May 12 21:45:58 2023 ] 	Batch(279/480) done. Loss: 2.2166  lr:0.100000  network_time: 0.0119
[ Fri May 12 21:46:47 2023 ] 	Batch(379/480) done. Loss: 0.8064  lr:0.100000  network_time: 0.0113
[ Fri May 12 21:47:35 2023 ] 	Batch(479/480) done. Loss: 0.9903  lr:0.100000  network_time: 0.0121
[ Fri May 12 21:47:36 2023 ] 	Training Accuracy: 61.33%
[ Fri May 12 21:47:36 2023 ] Eval epoch: 10
[ Fri May 12 21:47:52 2023 ] 	Mean test loss of 120 batches: 0.920705258846283.
[ Fri May 12 21:47:52 2023 ] 	Top1: 67.33%
[ Fri May 12 21:47:52 2023 ] 	Top5: 97.17%
[ Fri May 12 21:47:52 2023 ] Training epoch: 11
[ Fri May 12 21:48:41 2023 ] 	Batch(99/480) done. Loss: 0.7257  lr:0.100000  network_time: 0.0113
[ Fri May 12 21:49:30 2023 ] 	Batch(199/480) done. Loss: 1.1153  lr:0.100000  network_time: 0.0113
[ Fri May 12 21:50:18 2023 ] 	Batch(299/480) done. Loss: 1.2706  lr:0.100000  network_time: 0.0115
[ Fri May 12 21:51:07 2023 ] 	Batch(399/480) done. Loss: 0.3997  lr:0.100000  network_time: 0.0108
[ Fri May 12 21:51:46 2023 ] 	Training Accuracy: 65.04%
[ Fri May 12 21:51:46 2023 ] Eval epoch: 11
[ Fri May 12 21:52:03 2023 ] 	Mean test loss of 120 batches: 1.1762174367904663.
[ Fri May 12 21:52:03 2023 ] 	Top1: 63.50%
[ Fri May 12 21:52:03 2023 ] 	Top5: 94.83%
[ Fri May 12 21:52:03 2023 ] Training epoch: 12
[ Fri May 12 21:52:13 2023 ] 	Batch(19/480) done. Loss: 1.1668  lr:0.100000  network_time: 0.0114
[ Fri May 12 21:53:01 2023 ] 	Batch(119/480) done. Loss: 0.6019  lr:0.100000  network_time: 0.0110
[ Fri May 12 21:53:50 2023 ] 	Batch(219/480) done. Loss: 2.9735  lr:0.100000  network_time: 0.0111
[ Fri May 12 21:54:39 2023 ] 	Batch(319/480) done. Loss: 0.3570  lr:0.100000  network_time: 0.0111
[ Fri May 12 21:55:27 2023 ] 	Batch(419/480) done. Loss: 0.2444  lr:0.100000  network_time: 0.0115
[ Fri May 12 21:55:56 2023 ] 	Training Accuracy: 72.29%
[ Fri May 12 21:55:56 2023 ] Eval epoch: 12
[ Fri May 12 21:56:13 2023 ] 	Mean test loss of 120 batches: 1.5678280591964722.
[ Fri May 12 21:56:13 2023 ] 	Top1: 59.50%
[ Fri May 12 21:56:13 2023 ] 	Top5: 91.17%
[ Fri May 12 21:56:13 2023 ] Training epoch: 13
[ Fri May 12 21:56:33 2023 ] 	Batch(39/480) done. Loss: 0.5813  lr:0.100000  network_time: 0.0111
[ Fri May 12 21:57:21 2023 ] 	Batch(139/480) done. Loss: 0.3748  lr:0.100000  network_time: 0.0108
[ Fri May 12 21:58:10 2023 ] 	Batch(239/480) done. Loss: 0.7122  lr:0.100000  network_time: 0.0109
[ Fri May 12 21:58:59 2023 ] 	Batch(339/480) done. Loss: 0.4569  lr:0.100000  network_time: 0.0110
[ Fri May 12 21:59:47 2023 ] 	Batch(439/480) done. Loss: 0.7621  lr:0.100000  network_time: 0.0109
[ Fri May 12 22:00:07 2023 ] 	Training Accuracy: 75.25%
[ Fri May 12 22:00:07 2023 ] Eval epoch: 13
[ Fri May 12 22:00:24 2023 ] 	Mean test loss of 120 batches: 0.5017232894897461.
[ Fri May 12 22:00:24 2023 ] 	Top1: 84.83%
[ Fri May 12 22:00:24 2023 ] 	Top5: 99.50%
[ Fri May 12 22:00:24 2023 ] Training epoch: 14
[ Fri May 12 22:00:53 2023 ] 	Batch(59/480) done. Loss: 0.1599  lr:0.100000  network_time: 0.0113
[ Fri May 12 22:01:41 2023 ] 	Batch(159/480) done. Loss: 0.2484  lr:0.100000  network_time: 0.0111
[ Fri May 12 22:02:30 2023 ] 	Batch(259/480) done. Loss: 1.0418  lr:0.100000  network_time: 0.0114
[ Fri May 12 22:03:19 2023 ] 	Batch(359/480) done. Loss: 0.7784  lr:0.100000  network_time: 0.0111
[ Fri May 12 22:04:07 2023 ] 	Batch(459/480) done. Loss: 0.4719  lr:0.100000  network_time: 0.0110
[ Fri May 12 22:04:17 2023 ] 	Training Accuracy: 80.04%
[ Fri May 12 22:04:17 2023 ] Eval epoch: 14
[ Fri May 12 22:04:34 2023 ] 	Mean test loss of 120 batches: 0.9779489636421204.
[ Fri May 12 22:04:34 2023 ] 	Top1: 71.50%
[ Fri May 12 22:04:34 2023 ] 	Top5: 97.67%
[ Fri May 12 22:04:34 2023 ] Training epoch: 15
[ Fri May 12 22:05:13 2023 ] 	Batch(79/480) done. Loss: 0.6078  lr:0.100000  network_time: 0.0108
[ Fri May 12 22:06:02 2023 ] 	Batch(179/480) done. Loss: 1.1046  lr:0.100000  network_time: 0.0112
[ Fri May 12 22:06:50 2023 ] 	Batch(279/480) done. Loss: 0.2818  lr:0.100000  network_time: 0.0110
[ Fri May 12 22:07:39 2023 ] 	Batch(379/480) done. Loss: 0.4985  lr:0.100000  network_time: 0.0114
[ Fri May 12 22:08:27 2023 ] 	Batch(479/480) done. Loss: 0.3431  lr:0.100000  network_time: 0.0114
[ Fri May 12 22:08:28 2023 ] 	Training Accuracy: 82.08%
[ Fri May 12 22:08:28 2023 ] Eval epoch: 15
[ Fri May 12 22:08:44 2023 ] 	Mean test loss of 120 batches: 0.4880402982234955.
[ Fri May 12 22:08:44 2023 ] 	Top1: 84.50%
[ Fri May 12 22:08:44 2023 ] 	Top5: 99.50%
[ Fri May 12 22:08:44 2023 ] Training epoch: 16
[ Fri May 12 22:09:33 2023 ] 	Batch(99/480) done. Loss: 0.7134  lr:0.100000  network_time: 0.0113
[ Fri May 12 22:10:22 2023 ] 	Batch(199/480) done. Loss: 0.1317  lr:0.100000  network_time: 0.0113
[ Fri May 12 22:11:10 2023 ] 	Batch(299/480) done. Loss: 0.3120  lr:0.100000  network_time: 0.0115
[ Fri May 12 22:11:59 2023 ] 	Batch(399/480) done. Loss: 0.0680  lr:0.100000  network_time: 0.0113
[ Fri May 12 22:12:38 2023 ] 	Training Accuracy: 85.42%
[ Fri May 12 22:12:38 2023 ] Eval epoch: 16
[ Fri May 12 22:12:55 2023 ] 	Mean test loss of 120 batches: 0.825005829334259.
[ Fri May 12 22:12:55 2023 ] 	Top1: 76.67%
[ Fri May 12 22:12:55 2023 ] 	Top5: 98.00%
[ Fri May 12 22:12:55 2023 ] Training epoch: 17
[ Fri May 12 22:13:05 2023 ] 	Batch(19/480) done. Loss: 0.4874  lr:0.100000  network_time: 0.0118
[ Fri May 12 22:13:53 2023 ] 	Batch(119/480) done. Loss: 0.3790  lr:0.100000  network_time: 0.0115
[ Fri May 12 22:14:42 2023 ] 	Batch(219/480) done. Loss: 0.4551  lr:0.100000  network_time: 0.0112
[ Fri May 12 22:15:31 2023 ] 	Batch(319/480) done. Loss: 0.0531  lr:0.100000  network_time: 0.0115
[ Fri May 12 22:16:19 2023 ] 	Batch(419/480) done. Loss: 0.7146  lr:0.100000  network_time: 0.0117
[ Fri May 12 22:16:48 2023 ] 	Training Accuracy: 85.29%
[ Fri May 12 22:16:48 2023 ] Eval epoch: 17
[ Fri May 12 22:17:05 2023 ] 	Mean test loss of 120 batches: 0.928820013999939.
[ Fri May 12 22:17:05 2023 ] 	Top1: 82.67%
[ Fri May 12 22:17:05 2023 ] 	Top5: 95.67%
[ Fri May 12 22:17:05 2023 ] Training epoch: 18
[ Fri May 12 22:17:25 2023 ] 	Batch(39/480) done. Loss: 1.0322  lr:0.100000  network_time: 0.0118
[ Fri May 12 22:18:13 2023 ] 	Batch(139/480) done. Loss: 0.1885  lr:0.100000  network_time: 0.0113
[ Fri May 12 22:19:02 2023 ] 	Batch(239/480) done. Loss: 0.5137  lr:0.100000  network_time: 0.0115
[ Fri May 12 22:19:51 2023 ] 	Batch(339/480) done. Loss: 0.2344  lr:0.100000  network_time: 0.0124
[ Fri May 12 22:20:39 2023 ] 	Batch(439/480) done. Loss: 0.1626  lr:0.100000  network_time: 0.0121
[ Fri May 12 22:20:59 2023 ] 	Training Accuracy: 86.46%
[ Fri May 12 22:20:59 2023 ] Eval epoch: 18
[ Fri May 12 22:21:16 2023 ] 	Mean test loss of 120 batches: 0.2178511917591095.
[ Fri May 12 22:21:16 2023 ] 	Top1: 93.33%
[ Fri May 12 22:21:16 2023 ] 	Top5: 100.00%
[ Fri May 12 22:21:16 2023 ] Training epoch: 19
[ Fri May 12 22:21:45 2023 ] 	Batch(59/480) done. Loss: 0.0126  lr:0.100000  network_time: 0.0113
[ Fri May 12 22:22:34 2023 ] 	Batch(159/480) done. Loss: 0.5084  lr:0.100000  network_time: 0.0115
[ Fri May 12 22:23:22 2023 ] 	Batch(259/480) done. Loss: 0.0540  lr:0.100000  network_time: 0.0116
[ Fri May 12 22:24:11 2023 ] 	Batch(359/480) done. Loss: 0.8163  lr:0.100000  network_time: 0.0115
[ Fri May 12 22:25:00 2023 ] 	Batch(459/480) done. Loss: 0.3160  lr:0.100000  network_time: 0.0116
[ Fri May 12 22:25:09 2023 ] 	Training Accuracy: 87.88%
[ Fri May 12 22:25:09 2023 ] Eval epoch: 19
[ Fri May 12 22:25:26 2023 ] 	Mean test loss of 120 batches: 0.37338531017303467.
[ Fri May 12 22:25:26 2023 ] 	Top1: 88.00%
[ Fri May 12 22:25:26 2023 ] 	Top5: 99.50%
[ Fri May 12 22:25:26 2023 ] Training epoch: 20
[ Fri May 12 22:26:05 2023 ] 	Batch(79/480) done. Loss: 0.4812  lr:0.100000  network_time: 0.0121
[ Fri May 12 22:26:54 2023 ] 	Batch(179/480) done. Loss: 0.7137  lr:0.100000  network_time: 0.0123
[ Fri May 12 22:27:42 2023 ] 	Batch(279/480) done. Loss: 0.0414  lr:0.100000  network_time: 0.0122
[ Fri May 12 22:28:31 2023 ] 	Batch(379/480) done. Loss: 0.3010  lr:0.100000  network_time: 0.0116
[ Fri May 12 22:29:20 2023 ] 	Batch(479/480) done. Loss: 0.0939  lr:0.100000  network_time: 0.0113
[ Fri May 12 22:29:20 2023 ] 	Training Accuracy: 88.21%
[ Fri May 12 22:29:20 2023 ] Eval epoch: 20
[ Fri May 12 22:29:36 2023 ] 	Mean test loss of 120 batches: 0.335784912109375.
[ Fri May 12 22:29:36 2023 ] 	Top1: 88.83%
[ Fri May 12 22:29:36 2023 ] 	Top5: 99.83%
[ Fri May 12 22:29:36 2023 ] Training epoch: 21
[ Fri May 12 22:30:25 2023 ] 	Batch(99/480) done. Loss: 0.3220  lr:0.010000  network_time: 0.0112
[ Fri May 12 22:31:14 2023 ] 	Batch(199/480) done. Loss: 0.0501  lr:0.010000  network_time: 0.0115
[ Fri May 12 22:32:02 2023 ] 	Batch(299/480) done. Loss: 1.0471  lr:0.010000  network_time: 0.0116
[ Fri May 12 22:32:51 2023 ] 	Batch(399/480) done. Loss: 0.0144  lr:0.010000  network_time: 0.0112
[ Fri May 12 22:33:30 2023 ] 	Training Accuracy: 96.04%
[ Fri May 12 22:33:30 2023 ] Eval epoch: 21
[ Fri May 12 22:33:47 2023 ] 	Mean test loss of 120 batches: 0.06037062034010887.
[ Fri May 12 22:33:47 2023 ] 	Top1: 98.33%
[ Fri May 12 22:33:47 2023 ] 	Top5: 100.00%
[ Fri May 12 22:33:47 2023 ] Training epoch: 22
[ Fri May 12 22:33:57 2023 ] 	Batch(19/480) done. Loss: 0.0334  lr:0.010000  network_time: 0.0115
[ Fri May 12 22:34:45 2023 ] 	Batch(119/480) done. Loss: 0.0297  lr:0.010000  network_time: 0.0112
[ Fri May 12 22:35:34 2023 ] 	Batch(219/480) done. Loss: 0.0152  lr:0.010000  network_time: 0.0115
[ Fri May 12 22:36:23 2023 ] 	Batch(319/480) done. Loss: 0.1090  lr:0.010000  network_time: 0.0114
[ Fri May 12 22:37:11 2023 ] 	Batch(419/480) done. Loss: 0.0644  lr:0.010000  network_time: 0.0117
[ Fri May 12 22:37:41 2023 ] 	Training Accuracy: 98.63%
[ Fri May 12 22:37:41 2023 ] Eval epoch: 22
[ Fri May 12 22:37:57 2023 ] 	Mean test loss of 120 batches: 0.029515929520130157.
[ Fri May 12 22:37:57 2023 ] 	Top1: 99.33%
[ Fri May 12 22:37:57 2023 ] 	Top5: 100.00%
[ Fri May 12 22:37:57 2023 ] Training epoch: 23
[ Fri May 12 22:38:17 2023 ] 	Batch(39/480) done. Loss: 0.0067  lr:0.010000  network_time: 0.0112
[ Fri May 12 22:39:06 2023 ] 	Batch(139/480) done. Loss: 0.0731  lr:0.010000  network_time: 0.0112
[ Fri May 12 22:39:54 2023 ] 	Batch(239/480) done. Loss: 0.0238  lr:0.010000  network_time: 0.0115
[ Fri May 12 22:40:43 2023 ] 	Batch(339/480) done. Loss: 0.0079  lr:0.010000  network_time: 0.0113
[ Fri May 12 22:41:32 2023 ] 	Batch(439/480) done. Loss: 0.0209  lr:0.010000  network_time: 0.0114
[ Fri May 12 22:41:51 2023 ] 	Training Accuracy: 98.83%
[ Fri May 12 22:41:51 2023 ] Eval epoch: 23
[ Fri May 12 22:42:08 2023 ] 	Mean test loss of 120 batches: 0.022835109382867813.
[ Fri May 12 22:42:08 2023 ] 	Top1: 99.83%
[ Fri May 12 22:42:08 2023 ] 	Top5: 100.00%
[ Fri May 12 22:42:08 2023 ] Training epoch: 24
[ Fri May 12 22:42:37 2023 ] 	Batch(59/480) done. Loss: 0.0834  lr:0.010000  network_time: 0.0112
[ Fri May 12 22:43:26 2023 ] 	Batch(159/480) done. Loss: 0.0117  lr:0.010000  network_time: 0.0122
[ Fri May 12 22:44:14 2023 ] 	Batch(259/480) done. Loss: 0.0269  lr:0.010000  network_time: 0.0115
[ Fri May 12 22:45:03 2023 ] 	Batch(359/480) done. Loss: 0.2061  lr:0.010000  network_time: 0.0115
[ Fri May 12 22:45:52 2023 ] 	Batch(459/480) done. Loss: 0.0354  lr:0.010000  network_time: 0.0115
[ Fri May 12 22:46:01 2023 ] 	Training Accuracy: 99.08%
[ Fri May 12 22:46:02 2023 ] Eval epoch: 24
[ Fri May 12 22:46:18 2023 ] 	Mean test loss of 120 batches: 0.023263609036803246.
[ Fri May 12 22:46:18 2023 ] 	Top1: 100.00%
[ Fri May 12 22:46:18 2023 ] 	Top5: 100.00%
[ Fri May 12 22:46:18 2023 ] Training epoch: 25
[ Fri May 12 22:46:57 2023 ] 	Batch(79/480) done. Loss: 0.0263  lr:0.010000  network_time: 0.0116
[ Fri May 12 22:47:46 2023 ] 	Batch(179/480) done. Loss: 0.0311  lr:0.010000  network_time: 0.0115
[ Fri May 12 22:48:35 2023 ] 	Batch(279/480) done. Loss: 0.0012  lr:0.010000  network_time: 0.0122
[ Fri May 12 22:49:23 2023 ] 	Batch(379/480) done. Loss: 0.0013  lr:0.010000  network_time: 0.0112
[ Fri May 12 22:50:12 2023 ] 	Batch(479/480) done. Loss: 0.0120  lr:0.010000  network_time: 0.0113
[ Fri May 12 22:50:12 2023 ] 	Training Accuracy: 99.38%
[ Fri May 12 22:50:12 2023 ] Eval epoch: 25
[ Fri May 12 22:50:29 2023 ] 	Mean test loss of 120 batches: 0.014240718446671963.
[ Fri May 12 22:50:29 2023 ] 	Top1: 100.00%
[ Fri May 12 22:50:29 2023 ] 	Top5: 100.00%
[ Fri May 12 22:50:29 2023 ] Training epoch: 26
[ Fri May 12 22:51:17 2023 ] 	Batch(99/480) done. Loss: 0.0943  lr:0.001000  network_time: 0.0111
[ Fri May 12 22:52:06 2023 ] 	Batch(199/480) done. Loss: 0.0243  lr:0.001000  network_time: 0.0112
[ Fri May 12 22:52:55 2023 ] 	Batch(299/480) done. Loss: 0.0084  lr:0.001000  network_time: 0.0122
[ Fri May 12 22:53:43 2023 ] 	Batch(399/480) done. Loss: 0.0099  lr:0.001000  network_time: 0.0114
[ Fri May 12 22:54:22 2023 ] 	Training Accuracy: 99.62%
[ Fri May 12 22:54:22 2023 ] Eval epoch: 26
[ Fri May 12 22:54:39 2023 ] 	Mean test loss of 120 batches: 0.016691694036126137.
[ Fri May 12 22:54:39 2023 ] 	Top1: 100.00%
[ Fri May 12 22:54:39 2023 ] 	Top5: 100.00%
[ Fri May 12 22:54:39 2023 ] Training epoch: 27
[ Fri May 12 22:54:49 2023 ] 	Batch(19/480) done. Loss: 0.0321  lr:0.001000  network_time: 0.0116
[ Fri May 12 22:55:38 2023 ] 	Batch(119/480) done. Loss: 0.0034  lr:0.001000  network_time: 0.0109
[ Fri May 12 22:56:26 2023 ] 	Batch(219/480) done. Loss: 0.0020  lr:0.001000  network_time: 0.0112
[ Fri May 12 22:57:15 2023 ] 	Batch(319/480) done. Loss: 0.0059  lr:0.001000  network_time: 0.0110
[ Fri May 12 22:58:04 2023 ] 	Batch(419/480) done. Loss: 0.0644  lr:0.001000  network_time: 0.0114
[ Fri May 12 22:58:33 2023 ] 	Training Accuracy: 99.54%
[ Fri May 12 22:58:33 2023 ] Eval epoch: 27
[ Fri May 12 22:58:50 2023 ] 	Mean test loss of 120 batches: 0.012289697304368019.
[ Fri May 12 22:58:50 2023 ] 	Top1: 100.00%
[ Fri May 12 22:58:50 2023 ] 	Top5: 100.00%
[ Fri May 12 22:58:50 2023 ] Training epoch: 28
[ Fri May 12 22:59:09 2023 ] 	Batch(39/480) done. Loss: 0.0040  lr:0.001000  network_time: 0.0114
[ Fri May 12 22:59:58 2023 ] 	Batch(139/480) done. Loss: 0.0089  lr:0.001000  network_time: 0.0113
[ Fri May 12 23:00:46 2023 ] 	Batch(239/480) done. Loss: 0.0094  lr:0.001000  network_time: 0.0116
[ Fri May 12 23:01:35 2023 ] 	Batch(339/480) done. Loss: 0.0411  lr:0.001000  network_time: 0.0112
[ Fri May 12 23:02:24 2023 ] 	Batch(439/480) done. Loss: 0.0196  lr:0.001000  network_time: 0.0111
[ Fri May 12 23:02:43 2023 ] 	Training Accuracy: 99.46%
[ Fri May 12 23:02:43 2023 ] Eval epoch: 28
[ Fri May 12 23:03:00 2023 ] 	Mean test loss of 120 batches: 0.013748624362051487.
[ Fri May 12 23:03:00 2023 ] 	Top1: 100.00%
[ Fri May 12 23:03:00 2023 ] 	Top5: 100.00%
[ Fri May 12 23:03:00 2023 ] Training epoch: 29
[ Fri May 12 23:03:29 2023 ] 	Batch(59/480) done. Loss: 0.0095  lr:0.001000  network_time: 0.0113
[ Fri May 12 23:04:18 2023 ] 	Batch(159/480) done. Loss: 0.0125  lr:0.001000  network_time: 0.0119
[ Fri May 12 23:05:07 2023 ] 	Batch(259/480) done. Loss: 0.0066  lr:0.001000  network_time: 0.0118
[ Fri May 12 23:05:55 2023 ] 	Batch(359/480) done. Loss: 0.0477  lr:0.001000  network_time: 0.0112
[ Fri May 12 23:06:44 2023 ] 	Batch(459/480) done. Loss: 0.0101  lr:0.001000  network_time: 0.0111
[ Fri May 12 23:06:54 2023 ] 	Training Accuracy: 99.25%
[ Fri May 12 23:06:54 2023 ] Eval epoch: 29
[ Fri May 12 23:07:11 2023 ] 	Mean test loss of 120 batches: 0.01706744357943535.
[ Fri May 12 23:07:11 2023 ] 	Top1: 100.00%
[ Fri May 12 23:07:11 2023 ] 	Top5: 100.00%
[ Fri May 12 23:07:11 2023 ] Training epoch: 30
[ Fri May 12 23:07:50 2023 ] 	Batch(79/480) done. Loss: 0.0050  lr:0.001000  network_time: 0.0114
[ Fri May 12 23:08:38 2023 ] 	Batch(179/480) done. Loss: 0.0553  lr:0.001000  network_time: 0.0112
[ Fri May 12 23:09:27 2023 ] 	Batch(279/480) done. Loss: 0.0078  lr:0.001000  network_time: 0.0112
[ Fri May 12 23:10:16 2023 ] 	Batch(379/480) done. Loss: 0.0031  lr:0.001000  network_time: 0.0113
[ Fri May 12 23:11:04 2023 ] 	Batch(479/480) done. Loss: 0.0237  lr:0.001000  network_time: 0.0111
[ Fri May 12 23:11:04 2023 ] 	Training Accuracy: 99.67%
[ Fri May 12 23:11:04 2023 ] Eval epoch: 30
[ Fri May 12 23:11:21 2023 ] 	Mean test loss of 120 batches: 0.014950813725590706.
[ Fri May 12 23:11:21 2023 ] 	Top1: 99.83%
[ Fri May 12 23:11:21 2023 ] 	Top5: 100.00%
