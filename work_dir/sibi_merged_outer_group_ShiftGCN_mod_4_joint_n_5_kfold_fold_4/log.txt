[ Wed May 17 11:19:16 2023 ] NUM WORKER: 1
[ Wed May 17 11:20:16 2023 ] Parameters:
{'work_dir': './work_dir/sibi_merged_outer_group_ShiftGCN_mod_4_joint_n_5_kfold_fold_4', 'model_saved_name': './save_models/sibi_merged_outer_group_ShiftGCN_mod_4_joint_n_5_kfold_fold_4', 'Experiment_name': 'sibi_merged_outer_group_ShiftGCN_mod_4_joint_n_5_kfold', 'config': './config/recalculated/train_sibi_with_mouth_augmented_merged_outer_group_shift_joint_mod_4.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 2, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'n_splits': 5, 'feeder': 'feeders.feeder_hsd.Feeder', 'num_worker': 1, 'train_feeder_args': {'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': -1, 'normalization': False}, 'test_feeder_args': None, 'data_path': './data/augmented_recalculate_normalized', 'model': 'model.shift_gcn.Model', 'model_args': {'num_class': 50, 'num_person': 1, 'num_point': 115, 'graph_group': [[0, 81], [82, 114]], 'method': 'grouped.outer', 'weight': 4, 'graph': 'graph.skeleton_with_mouth.SkeletonWithMouth', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [20, 25], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 5, 'test_batch_size': 5, 'start_epoch': 0, 'num_epoch': 30, 'folds_range': [1, 5], 'weight_decay': 0.0001, 'only_train_part': True, 'only_train_epoch': 1, 'warm_up_epoch': 0}

[ Wed May 17 11:20:16 2023 ] Training epoch: 1
[ Wed May 17 11:21:00 2023 ] 	Batch(99/480) done. Loss: 4.2646  lr:0.100000  network_time: 0.0116
[ Wed May 17 11:21:45 2023 ] 	Batch(199/480) done. Loss: 3.7964  lr:0.100000  network_time: 0.0116
[ Wed May 17 11:22:30 2023 ] 	Batch(299/480) done. Loss: 3.5288  lr:0.100000  network_time: 0.0120
[ Wed May 17 11:23:15 2023 ] 	Batch(399/480) done. Loss: 3.4898  lr:0.100000  network_time: 0.0118
[ Wed May 17 11:23:51 2023 ] 	Training Accuracy: 6.63%
[ Wed May 17 11:23:51 2023 ] Eval epoch: 1
[ Wed May 17 11:24:07 2023 ] 	Mean test loss of 120 batches: 3.226862668991089.
[ Wed May 17 11:24:07 2023 ] 	Top1: 11.83%
[ Wed May 17 11:24:07 2023 ] 	Top5: 48.50%
[ Wed May 17 11:24:07 2023 ] Training epoch: 2
[ Wed May 17 11:24:16 2023 ] 	Batch(19/480) done. Loss: 3.1149  lr:0.100000  network_time: 0.0122
[ Wed May 17 11:25:01 2023 ] 	Batch(119/480) done. Loss: 3.0697  lr:0.100000  network_time: 0.0119
[ Wed May 17 11:25:46 2023 ] 	Batch(219/480) done. Loss: 2.2256  lr:0.100000  network_time: 0.0118
[ Wed May 17 11:26:31 2023 ] 	Batch(319/480) done. Loss: 1.9173  lr:0.100000  network_time: 0.0122
[ Wed May 17 11:27:16 2023 ] 	Batch(419/480) done. Loss: 3.2552  lr:0.100000  network_time: 0.0120
[ Wed May 17 11:27:43 2023 ] 	Training Accuracy: 16.08%
[ Wed May 17 11:27:43 2023 ] Eval epoch: 2
[ Wed May 17 11:28:00 2023 ] 	Mean test loss of 120 batches: 3.018643379211426.
[ Wed May 17 11:28:00 2023 ] 	Top1: 25.67%
[ Wed May 17 11:28:00 2023 ] 	Top5: 61.33%
[ Wed May 17 11:28:00 2023 ] Training epoch: 3
[ Wed May 17 11:28:18 2023 ] 	Batch(39/480) done. Loss: 2.3224  lr:0.100000  network_time: 0.0125
[ Wed May 17 11:29:03 2023 ] 	Batch(139/480) done. Loss: 2.7547  lr:0.100000  network_time: 0.0117
[ Wed May 17 11:29:48 2023 ] 	Batch(239/480) done. Loss: 2.9437  lr:0.100000  network_time: 0.0125
[ Wed May 17 11:30:33 2023 ] 	Batch(339/480) done. Loss: 2.5087  lr:0.100000  network_time: 0.0126
[ Wed May 17 11:31:18 2023 ] 	Batch(439/480) done. Loss: 2.4271  lr:0.100000  network_time: 0.0121
[ Wed May 17 11:31:36 2023 ] 	Training Accuracy: 26.13%
[ Wed May 17 11:31:36 2023 ] Eval epoch: 3
[ Wed May 17 11:31:52 2023 ] 	Mean test loss of 120 batches: 4.158822536468506.
[ Wed May 17 11:31:52 2023 ] 	Top1: 32.50%
[ Wed May 17 11:31:52 2023 ] 	Top5: 72.33%
[ Wed May 17 11:31:52 2023 ] Training epoch: 4
[ Wed May 17 11:32:19 2023 ] 	Batch(59/480) done. Loss: 2.0281  lr:0.100000  network_time: 0.0121
[ Wed May 17 11:33:04 2023 ] 	Batch(159/480) done. Loss: 2.6049  lr:0.100000  network_time: 0.0120
[ Wed May 17 11:33:49 2023 ] 	Batch(259/480) done. Loss: 2.1719  lr:0.100000  network_time: 0.0118
[ Wed May 17 11:34:35 2023 ] 	Batch(359/480) done. Loss: 2.5875  lr:0.100000  network_time: 0.0122
[ Wed May 17 11:35:20 2023 ] 	Batch(459/480) done. Loss: 3.0964  lr:0.100000  network_time: 0.0125
[ Wed May 17 11:35:29 2023 ] 	Training Accuracy: 34.13%
[ Wed May 17 11:35:29 2023 ] Eval epoch: 4
[ Wed May 17 11:35:45 2023 ] 	Mean test loss of 120 batches: 3.1544394493103027.
[ Wed May 17 11:35:45 2023 ] 	Top1: 33.83%
[ Wed May 17 11:35:45 2023 ] 	Top5: 78.83%
[ Wed May 17 11:35:45 2023 ] Training epoch: 5
[ Wed May 17 11:36:21 2023 ] 	Batch(79/480) done. Loss: 1.9649  lr:0.100000  network_time: 0.0121
[ Wed May 17 11:37:06 2023 ] 	Batch(179/480) done. Loss: 1.1909  lr:0.100000  network_time: 0.0127
[ Wed May 17 11:37:51 2023 ] 	Batch(279/480) done. Loss: 1.8054  lr:0.100000  network_time: 0.0119
[ Wed May 17 11:38:36 2023 ] 	Batch(379/480) done. Loss: 1.7351  lr:0.100000  network_time: 0.0120
[ Wed May 17 11:39:21 2023 ] 	Batch(479/480) done. Loss: 2.0177  lr:0.100000  network_time: 0.0116
[ Wed May 17 11:39:21 2023 ] 	Training Accuracy: 42.83%
[ Wed May 17 11:39:21 2023 ] Eval epoch: 5
[ Wed May 17 11:39:38 2023 ] 	Mean test loss of 120 batches: 1.541541337966919.
[ Wed May 17 11:39:38 2023 ] 	Top1: 50.17%
[ Wed May 17 11:39:38 2023 ] 	Top5: 92.33%
[ Wed May 17 11:39:38 2023 ] Training epoch: 6
[ Wed May 17 11:40:23 2023 ] 	Batch(99/480) done. Loss: 2.8792  lr:0.100000  network_time: 0.0118
[ Wed May 17 11:41:08 2023 ] 	Batch(199/480) done. Loss: 2.3527  lr:0.100000  network_time: 0.0119
[ Wed May 17 11:41:53 2023 ] 	Batch(299/480) done. Loss: 1.2064  lr:0.100000  network_time: 0.0123
[ Wed May 17 11:42:38 2023 ] 	Batch(399/480) done. Loss: 0.8180  lr:0.100000  network_time: 0.0118
[ Wed May 17 11:43:14 2023 ] 	Training Accuracy: 51.38%
[ Wed May 17 11:43:14 2023 ] Eval epoch: 6
[ Wed May 17 11:43:31 2023 ] 	Mean test loss of 120 batches: 1.4872485399246216.
[ Wed May 17 11:43:31 2023 ] 	Top1: 56.17%
[ Wed May 17 11:43:31 2023 ] 	Top5: 91.00%
[ Wed May 17 11:43:31 2023 ] Training epoch: 7
[ Wed May 17 11:43:40 2023 ] 	Batch(19/480) done. Loss: 0.8392  lr:0.100000  network_time: 0.0120
[ Wed May 17 11:44:25 2023 ] 	Batch(119/480) done. Loss: 1.0689  lr:0.100000  network_time: 0.0114
[ Wed May 17 11:45:10 2023 ] 	Batch(219/480) done. Loss: 1.6100  lr:0.100000  network_time: 0.0127
[ Wed May 17 11:45:55 2023 ] 	Batch(319/480) done. Loss: 0.8847  lr:0.100000  network_time: 0.0120
[ Wed May 17 11:46:40 2023 ] 	Batch(419/480) done. Loss: 3.1299  lr:0.100000  network_time: 0.0124
[ Wed May 17 11:47:07 2023 ] 	Training Accuracy: 56.21%
[ Wed May 17 11:47:07 2023 ] Eval epoch: 7
[ Wed May 17 11:47:24 2023 ] 	Mean test loss of 120 batches: 1.0374401807785034.
[ Wed May 17 11:47:24 2023 ] 	Top1: 65.67%
[ Wed May 17 11:47:24 2023 ] 	Top5: 95.50%
[ Wed May 17 11:47:24 2023 ] Training epoch: 8
[ Wed May 17 11:47:42 2023 ] 	Batch(39/480) done. Loss: 0.7540  lr:0.100000  network_time: 0.0116
[ Wed May 17 11:48:27 2023 ] 	Batch(139/480) done. Loss: 0.2268  lr:0.100000  network_time: 0.0119
[ Wed May 17 11:49:12 2023 ] 	Batch(239/480) done. Loss: 0.3813  lr:0.100000  network_time: 0.0116
[ Wed May 17 11:49:57 2023 ] 	Batch(339/480) done. Loss: 1.4387  lr:0.100000  network_time: 0.0122
[ Wed May 17 11:50:42 2023 ] 	Batch(439/480) done. Loss: 0.3959  lr:0.100000  network_time: 0.0121
[ Wed May 17 11:51:00 2023 ] 	Training Accuracy: 66.13%
[ Wed May 17 11:51:00 2023 ] Eval epoch: 8
[ Wed May 17 11:51:17 2023 ] 	Mean test loss of 120 batches: 3.605360984802246.
[ Wed May 17 11:51:17 2023 ] 	Top1: 29.17%
[ Wed May 17 11:51:17 2023 ] 	Top5: 68.67%
[ Wed May 17 11:51:17 2023 ] Training epoch: 9
[ Wed May 17 11:51:44 2023 ] 	Batch(59/480) done. Loss: 1.2351  lr:0.100000  network_time: 0.0116
[ Wed May 17 11:52:29 2023 ] 	Batch(159/480) done. Loss: 1.3750  lr:0.100000  network_time: 0.0119
[ Wed May 17 11:53:14 2023 ] 	Batch(259/480) done. Loss: 0.4495  lr:0.100000  network_time: 0.0119
[ Wed May 17 11:53:59 2023 ] 	Batch(359/480) done. Loss: 1.0976  lr:0.100000  network_time: 0.0118
[ Wed May 17 11:54:44 2023 ] 	Batch(459/480) done. Loss: 0.6316  lr:0.100000  network_time: 0.0121
[ Wed May 17 11:54:53 2023 ] 	Training Accuracy: 69.25%
[ Wed May 17 11:54:53 2023 ] Eval epoch: 9
[ Wed May 17 11:55:10 2023 ] 	Mean test loss of 120 batches: 1.9887187480926514.
[ Wed May 17 11:55:10 2023 ] 	Top1: 54.50%
[ Wed May 17 11:55:10 2023 ] 	Top5: 89.50%
[ Wed May 17 11:55:10 2023 ] Training epoch: 10
[ Wed May 17 11:55:46 2023 ] 	Batch(79/480) done. Loss: 0.3751  lr:0.100000  network_time: 0.0117
[ Wed May 17 11:56:31 2023 ] 	Batch(179/480) done. Loss: 0.9464  lr:0.100000  network_time: 0.0121
[ Wed May 17 11:57:16 2023 ] 	Batch(279/480) done. Loss: 0.8580  lr:0.100000  network_time: 0.0120
[ Wed May 17 11:58:01 2023 ] 	Batch(379/480) done. Loss: 0.7985  lr:0.100000  network_time: 0.0124
[ Wed May 17 11:58:46 2023 ] 	Batch(479/480) done. Loss: 1.1527  lr:0.100000  network_time: 0.0124
[ Wed May 17 11:58:46 2023 ] 	Training Accuracy: 72.12%
[ Wed May 17 11:58:46 2023 ] Eval epoch: 10
[ Wed May 17 11:59:02 2023 ] 	Mean test loss of 120 batches: 0.9603538513183594.
[ Wed May 17 11:59:02 2023 ] 	Top1: 68.17%
[ Wed May 17 11:59:02 2023 ] 	Top5: 96.67%
[ Wed May 17 11:59:02 2023 ] Training epoch: 11
[ Wed May 17 11:59:47 2023 ] 	Batch(99/480) done. Loss: 0.4375  lr:0.100000  network_time: 0.0122
[ Wed May 17 12:00:33 2023 ] 	Batch(199/480) done. Loss: 0.5008  lr:0.100000  network_time: 0.0120
[ Wed May 17 12:01:18 2023 ] 	Batch(299/480) done. Loss: 0.4319  lr:0.100000  network_time: 0.0121
[ Wed May 17 12:02:03 2023 ] 	Batch(399/480) done. Loss: 0.8584  lr:0.100000  network_time: 0.0115
[ Wed May 17 12:02:39 2023 ] 	Training Accuracy: 76.13%
[ Wed May 17 12:02:39 2023 ] Eval epoch: 11
[ Wed May 17 12:02:55 2023 ] 	Mean test loss of 120 batches: 1.5795207023620605.
[ Wed May 17 12:02:55 2023 ] 	Top1: 64.17%
[ Wed May 17 12:02:55 2023 ] 	Top5: 95.33%
[ Wed May 17 12:02:55 2023 ] Training epoch: 12
[ Wed May 17 12:03:04 2023 ] 	Batch(19/480) done. Loss: 0.4459  lr:0.100000  network_time: 0.0133
[ Wed May 17 12:03:49 2023 ] 	Batch(119/480) done. Loss: 0.8489  lr:0.100000  network_time: 0.0117
[ Wed May 17 12:04:34 2023 ] 	Batch(219/480) done. Loss: 0.8066  lr:0.100000  network_time: 0.0120
[ Wed May 17 12:05:19 2023 ] 	Batch(319/480) done. Loss: 0.7137  lr:0.100000  network_time: 0.0121
[ Wed May 17 12:06:04 2023 ] 	Batch(419/480) done. Loss: 1.1940  lr:0.100000  network_time: 0.0122
[ Wed May 17 12:06:31 2023 ] 	Training Accuracy: 79.21%
[ Wed May 17 12:06:32 2023 ] Eval epoch: 12
[ Wed May 17 12:06:48 2023 ] 	Mean test loss of 120 batches: 0.48468077182769775.
[ Wed May 17 12:06:48 2023 ] 	Top1: 83.83%
[ Wed May 17 12:06:48 2023 ] 	Top5: 99.50%
[ Wed May 17 12:06:48 2023 ] Training epoch: 13
[ Wed May 17 12:07:06 2023 ] 	Batch(39/480) done. Loss: 0.0776  lr:0.100000  network_time: 0.0118
[ Wed May 17 12:07:51 2023 ] 	Batch(139/480) done. Loss: 0.5935  lr:0.100000  network_time: 0.0120
[ Wed May 17 12:08:36 2023 ] 	Batch(239/480) done. Loss: 0.3233  lr:0.100000  network_time: 0.0121
[ Wed May 17 12:09:21 2023 ] 	Batch(339/480) done. Loss: 0.7461  lr:0.100000  network_time: 0.0120
[ Wed May 17 12:10:06 2023 ] 	Batch(439/480) done. Loss: 0.6425  lr:0.100000  network_time: 0.0121
[ Wed May 17 12:10:24 2023 ] 	Training Accuracy: 81.42%
[ Wed May 17 12:10:25 2023 ] Eval epoch: 13
[ Wed May 17 12:10:41 2023 ] 	Mean test loss of 120 batches: 0.5911808609962463.
[ Wed May 17 12:10:41 2023 ] 	Top1: 85.17%
[ Wed May 17 12:10:41 2023 ] 	Top5: 98.83%
[ Wed May 17 12:10:41 2023 ] Training epoch: 14
[ Wed May 17 12:11:08 2023 ] 	Batch(59/480) done. Loss: 0.8511  lr:0.100000  network_time: 0.0119
[ Wed May 17 12:11:53 2023 ] 	Batch(159/480) done. Loss: 0.2862  lr:0.100000  network_time: 0.0143
[ Wed May 17 12:12:38 2023 ] 	Batch(259/480) done. Loss: 0.3330  lr:0.100000  network_time: 0.0119
[ Wed May 17 12:13:23 2023 ] 	Batch(359/480) done. Loss: 0.3261  lr:0.100000  network_time: 0.0116
[ Wed May 17 12:14:08 2023 ] 	Batch(459/480) done. Loss: 0.2332  lr:0.100000  network_time: 0.0120
[ Wed May 17 12:14:17 2023 ] 	Training Accuracy: 82.29%
[ Wed May 17 12:14:17 2023 ] Eval epoch: 14
[ Wed May 17 12:14:34 2023 ] 	Mean test loss of 120 batches: 0.43599578738212585.
[ Wed May 17 12:14:34 2023 ] 	Top1: 86.33%
[ Wed May 17 12:14:34 2023 ] 	Top5: 99.17%
[ Wed May 17 12:14:34 2023 ] Training epoch: 15
[ Wed May 17 12:15:10 2023 ] 	Batch(79/480) done. Loss: 0.4990  lr:0.100000  network_time: 0.0115
[ Wed May 17 12:15:55 2023 ] 	Batch(179/480) done. Loss: 0.0599  lr:0.100000  network_time: 0.0120
[ Wed May 17 12:16:40 2023 ] 	Batch(279/480) done. Loss: 0.6657  lr:0.100000  network_time: 0.0120
[ Wed May 17 12:17:25 2023 ] 	Batch(379/480) done. Loss: 0.7332  lr:0.100000  network_time: 0.0121
[ Wed May 17 12:18:10 2023 ] 	Batch(479/480) done. Loss: 0.3272  lr:0.100000  network_time: 0.0120
[ Wed May 17 12:18:10 2023 ] 	Training Accuracy: 83.96%
[ Wed May 17 12:18:10 2023 ] Eval epoch: 15
[ Wed May 17 12:18:27 2023 ] 	Mean test loss of 120 batches: 0.4584011435508728.
[ Wed May 17 12:18:27 2023 ] 	Top1: 87.50%
[ Wed May 17 12:18:27 2023 ] 	Top5: 100.00%
[ Wed May 17 12:18:27 2023 ] Training epoch: 16
[ Wed May 17 12:19:12 2023 ] 	Batch(99/480) done. Loss: 0.0701  lr:0.100000  network_time: 0.0116
[ Wed May 17 12:19:57 2023 ] 	Batch(199/480) done. Loss: 0.0358  lr:0.100000  network_time: 0.0115
[ Wed May 17 12:20:42 2023 ] 	Batch(299/480) done. Loss: 0.3949  lr:0.100000  network_time: 0.0112
[ Wed May 17 12:21:27 2023 ] 	Batch(399/480) done. Loss: 1.0913  lr:0.100000  network_time: 0.0120
[ Wed May 17 12:22:03 2023 ] 	Training Accuracy: 85.42%
[ Wed May 17 12:22:03 2023 ] Eval epoch: 16
[ Wed May 17 12:22:19 2023 ] 	Mean test loss of 120 batches: 0.8452795743942261.
[ Wed May 17 12:22:19 2023 ] 	Top1: 79.17%
[ Wed May 17 12:22:19 2023 ] 	Top5: 98.67%
[ Wed May 17 12:22:19 2023 ] Training epoch: 17
[ Wed May 17 12:22:29 2023 ] 	Batch(19/480) done. Loss: 0.0499  lr:0.100000  network_time: 0.0120
[ Wed May 17 12:23:14 2023 ] 	Batch(119/480) done. Loss: 0.2436  lr:0.100000  network_time: 0.0121
[ Wed May 17 12:23:59 2023 ] 	Batch(219/480) done. Loss: 0.1326  lr:0.100000  network_time: 0.0121
[ Wed May 17 12:24:44 2023 ] 	Batch(319/480) done. Loss: 0.1003  lr:0.100000  network_time: 0.0120
[ Wed May 17 12:25:29 2023 ] 	Batch(419/480) done. Loss: 0.0387  lr:0.100000  network_time: 0.0117
[ Wed May 17 12:25:56 2023 ] 	Training Accuracy: 87.04%
[ Wed May 17 12:25:56 2023 ] Eval epoch: 17
[ Wed May 17 12:26:12 2023 ] 	Mean test loss of 120 batches: 0.5270326733589172.
[ Wed May 17 12:26:12 2023 ] 	Top1: 86.83%
[ Wed May 17 12:26:12 2023 ] 	Top5: 98.17%
[ Wed May 17 12:26:12 2023 ] Training epoch: 18
[ Wed May 17 12:26:30 2023 ] 	Batch(39/480) done. Loss: 0.1683  lr:0.100000  network_time: 0.0118
[ Wed May 17 12:27:15 2023 ] 	Batch(139/480) done. Loss: 0.0364  lr:0.100000  network_time: 0.0114
[ Wed May 17 12:28:00 2023 ] 	Batch(239/480) done. Loss: 0.0257  lr:0.100000  network_time: 0.0122
[ Wed May 17 12:28:45 2023 ] 	Batch(339/480) done. Loss: 0.1107  lr:0.100000  network_time: 0.0115
[ Wed May 17 12:29:30 2023 ] 	Batch(439/480) done. Loss: 0.2448  lr:0.100000  network_time: 0.0121
[ Wed May 17 12:29:49 2023 ] 	Training Accuracy: 89.42%
[ Wed May 17 12:29:49 2023 ] Eval epoch: 18
[ Wed May 17 12:30:05 2023 ] 	Mean test loss of 120 batches: 0.411567747592926.
[ Wed May 17 12:30:05 2023 ] 	Top1: 86.33%
[ Wed May 17 12:30:05 2023 ] 	Top5: 99.50%
[ Wed May 17 12:30:05 2023 ] Training epoch: 19
[ Wed May 17 12:30:32 2023 ] 	Batch(59/480) done. Loss: 0.0159  lr:0.100000  network_time: 0.0118
[ Wed May 17 12:31:17 2023 ] 	Batch(159/480) done. Loss: 0.1007  lr:0.100000  network_time: 0.0117
[ Wed May 17 12:32:02 2023 ] 	Batch(259/480) done. Loss: 0.2116  lr:0.100000  network_time: 0.0119
[ Wed May 17 12:32:47 2023 ] 	Batch(359/480) done. Loss: 1.4895  lr:0.100000  network_time: 0.0120
[ Wed May 17 12:33:32 2023 ] 	Batch(459/480) done. Loss: 0.1042  lr:0.100000  network_time: 0.0117
[ Wed May 17 12:33:41 2023 ] 	Training Accuracy: 90.50%
[ Wed May 17 12:33:42 2023 ] Eval epoch: 19
[ Wed May 17 12:33:58 2023 ] 	Mean test loss of 120 batches: 0.1939983069896698.
[ Wed May 17 12:33:58 2023 ] 	Top1: 93.83%
[ Wed May 17 12:33:58 2023 ] 	Top5: 100.00%
[ Wed May 17 12:33:58 2023 ] Training epoch: 20
[ Wed May 17 12:34:34 2023 ] 	Batch(79/480) done. Loss: 0.5219  lr:0.100000  network_time: 0.0122
[ Wed May 17 12:35:19 2023 ] 	Batch(179/480) done. Loss: 0.0690  lr:0.100000  network_time: 0.0122
[ Wed May 17 12:36:04 2023 ] 	Batch(279/480) done. Loss: 1.0559  lr:0.100000  network_time: 0.0120
[ Wed May 17 12:36:49 2023 ] 	Batch(379/480) done. Loss: 0.4986  lr:0.100000  network_time: 0.0119
[ Wed May 17 12:37:34 2023 ] 	Batch(479/480) done. Loss: 1.4567  lr:0.100000  network_time: 0.0121
[ Wed May 17 12:37:34 2023 ] 	Training Accuracy: 88.58%
[ Wed May 17 12:37:34 2023 ] Eval epoch: 20
[ Wed May 17 12:37:51 2023 ] 	Mean test loss of 120 batches: 1.6470569372177124.
[ Wed May 17 12:37:51 2023 ] 	Top1: 69.50%
[ Wed May 17 12:37:51 2023 ] 	Top5: 93.17%
[ Wed May 17 12:37:51 2023 ] Training epoch: 21
[ Wed May 17 12:38:36 2023 ] 	Batch(99/480) done. Loss: 0.0210  lr:0.010000  network_time: 0.0119
[ Wed May 17 12:39:21 2023 ] 	Batch(199/480) done. Loss: 0.0288  lr:0.010000  network_time: 0.0116
[ Wed May 17 12:40:06 2023 ] 	Batch(299/480) done. Loss: 0.0884  lr:0.010000  network_time: 0.0119
[ Wed May 17 12:40:51 2023 ] 	Batch(399/480) done. Loss: 0.0232  lr:0.010000  network_time: 0.0129
[ Wed May 17 12:41:27 2023 ] 	Training Accuracy: 96.00%
[ Wed May 17 12:41:27 2023 ] Eval epoch: 21
[ Wed May 17 12:41:44 2023 ] 	Mean test loss of 120 batches: 0.04444162920117378.
[ Wed May 17 12:41:44 2023 ] 	Top1: 99.17%
[ Wed May 17 12:41:44 2023 ] 	Top5: 100.00%
[ Wed May 17 12:41:44 2023 ] Training epoch: 22
[ Wed May 17 12:41:53 2023 ] 	Batch(19/480) done. Loss: 0.0705  lr:0.010000  network_time: 0.0115
[ Wed May 17 12:42:38 2023 ] 	Batch(119/480) done. Loss: 0.5416  lr:0.010000  network_time: 0.0116
[ Wed May 17 12:43:23 2023 ] 	Batch(219/480) done. Loss: 0.1119  lr:0.010000  network_time: 0.0118
[ Wed May 17 12:44:08 2023 ] 	Batch(319/480) done. Loss: 0.0320  lr:0.010000  network_time: 0.0122
[ Wed May 17 12:44:53 2023 ] 	Batch(419/480) done. Loss: 0.0088  lr:0.010000  network_time: 0.0121
[ Wed May 17 12:45:20 2023 ] 	Training Accuracy: 98.50%
[ Wed May 17 12:45:20 2023 ] Eval epoch: 22
[ Wed May 17 12:45:36 2023 ] 	Mean test loss of 120 batches: 0.056004010140895844.
[ Wed May 17 12:45:36 2023 ] 	Top1: 98.00%
[ Wed May 17 12:45:36 2023 ] 	Top5: 100.00%
[ Wed May 17 12:45:36 2023 ] Training epoch: 23
[ Wed May 17 12:45:55 2023 ] 	Batch(39/480) done. Loss: 0.0142  lr:0.010000  network_time: 0.0118
[ Wed May 17 12:46:40 2023 ] 	Batch(139/480) done. Loss: 0.0341  lr:0.010000  network_time: 0.0124
[ Wed May 17 12:47:25 2023 ] 	Batch(239/480) done. Loss: 0.0284  lr:0.010000  network_time: 0.0119
[ Wed May 17 12:48:10 2023 ] 	Batch(339/480) done. Loss: 0.0092  lr:0.010000  network_time: 0.0118
[ Wed May 17 12:48:55 2023 ] 	Batch(439/480) done. Loss: 0.0059  lr:0.010000  network_time: 0.0118
[ Wed May 17 12:49:13 2023 ] 	Training Accuracy: 99.04%
[ Wed May 17 12:49:13 2023 ] Eval epoch: 23
[ Wed May 17 12:49:29 2023 ] 	Mean test loss of 120 batches: 0.03226754814386368.
[ Wed May 17 12:49:29 2023 ] 	Top1: 99.50%
[ Wed May 17 12:49:29 2023 ] 	Top5: 100.00%
[ Wed May 17 12:49:29 2023 ] Training epoch: 24
[ Wed May 17 12:49:56 2023 ] 	Batch(59/480) done. Loss: 0.0623  lr:0.010000  network_time: 0.0117
[ Wed May 17 12:50:41 2023 ] 	Batch(159/480) done. Loss: 0.0323  lr:0.010000  network_time: 0.0118
[ Wed May 17 12:51:26 2023 ] 	Batch(259/480) done. Loss: 0.0170  lr:0.010000  network_time: 0.0122
[ Wed May 17 12:52:11 2023 ] 	Batch(359/480) done. Loss: 0.0091  lr:0.010000  network_time: 0.0121
[ Wed May 17 12:52:57 2023 ] 	Batch(459/480) done. Loss: 0.0306  lr:0.010000  network_time: 0.0119
[ Wed May 17 12:53:06 2023 ] 	Training Accuracy: 98.67%
[ Wed May 17 12:53:06 2023 ] Eval epoch: 24
[ Wed May 17 12:53:22 2023 ] 	Mean test loss of 120 batches: 0.030086606740951538.
[ Wed May 17 12:53:22 2023 ] 	Top1: 99.50%
[ Wed May 17 12:53:22 2023 ] 	Top5: 100.00%
[ Wed May 17 12:53:22 2023 ] Training epoch: 25
[ Wed May 17 12:53:58 2023 ] 	Batch(79/480) done. Loss: 0.0140  lr:0.010000  network_time: 0.0117
[ Wed May 17 12:54:43 2023 ] 	Batch(179/480) done. Loss: 0.0129  lr:0.010000  network_time: 0.0119
[ Wed May 17 12:55:28 2023 ] 	Batch(279/480) done. Loss: 0.0020  lr:0.010000  network_time: 0.0118
[ Wed May 17 12:56:13 2023 ] 	Batch(379/480) done. Loss: 0.0261  lr:0.010000  network_time: 0.0122
[ Wed May 17 12:56:58 2023 ] 	Batch(479/480) done. Loss: 0.0216  lr:0.010000  network_time: 0.0120
[ Wed May 17 12:56:58 2023 ] 	Training Accuracy: 99.33%
[ Wed May 17 12:56:59 2023 ] Eval epoch: 25
[ Wed May 17 12:57:15 2023 ] 	Mean test loss of 120 batches: 0.022334078326821327.
[ Wed May 17 12:57:15 2023 ] 	Top1: 99.67%
[ Wed May 17 12:57:15 2023 ] 	Top5: 100.00%
[ Wed May 17 12:57:15 2023 ] Training epoch: 26
[ Wed May 17 12:58:00 2023 ] 	Batch(99/480) done. Loss: 0.1880  lr:0.001000  network_time: 0.0121
[ Wed May 17 12:58:45 2023 ] 	Batch(199/480) done. Loss: 0.0328  lr:0.001000  network_time: 0.0120
[ Wed May 17 12:59:30 2023 ] 	Batch(299/480) done. Loss: 0.0147  lr:0.001000  network_time: 0.0121
[ Wed May 17 13:00:15 2023 ] 	Batch(399/480) done. Loss: 0.0095  lr:0.001000  network_time: 0.0123
[ Wed May 17 13:00:51 2023 ] 	Training Accuracy: 99.50%
[ Wed May 17 13:00:51 2023 ] Eval epoch: 26
[ Wed May 17 13:01:08 2023 ] 	Mean test loss of 120 batches: 0.020711394026875496.
[ Wed May 17 13:01:08 2023 ] 	Top1: 99.50%
[ Wed May 17 13:01:08 2023 ] 	Top5: 100.00%
[ Wed May 17 13:01:08 2023 ] Training epoch: 27
[ Wed May 17 13:01:17 2023 ] 	Batch(19/480) done. Loss: 0.0025  lr:0.001000  network_time: 0.0117
[ Wed May 17 13:02:02 2023 ] 	Batch(119/480) done. Loss: 0.0056  lr:0.001000  network_time: 0.0120
[ Wed May 17 13:02:47 2023 ] 	Batch(219/480) done. Loss: 0.0159  lr:0.001000  network_time: 0.0121
[ Wed May 17 13:03:32 2023 ] 	Batch(319/480) done. Loss: 0.0173  lr:0.001000  network_time: 0.0120
[ Wed May 17 13:04:17 2023 ] 	Batch(419/480) done. Loss: 0.0129  lr:0.001000  network_time: 0.0122
[ Wed May 17 13:04:44 2023 ] 	Training Accuracy: 99.71%
[ Wed May 17 13:04:44 2023 ] Eval epoch: 27
[ Wed May 17 13:05:01 2023 ] 	Mean test loss of 120 batches: 0.016343260183930397.
[ Wed May 17 13:05:01 2023 ] 	Top1: 99.67%
[ Wed May 17 13:05:01 2023 ] 	Top5: 100.00%
[ Wed May 17 13:05:01 2023 ] Training epoch: 28
[ Wed May 17 13:05:19 2023 ] 	Batch(39/480) done. Loss: 0.0186  lr:0.001000  network_time: 0.0120
[ Wed May 17 13:06:04 2023 ] 	Batch(139/480) done. Loss: 0.0097  lr:0.001000  network_time: 0.0125
[ Wed May 17 13:06:49 2023 ] 	Batch(239/480) done. Loss: 0.0208  lr:0.001000  network_time: 0.0120
[ Wed May 17 13:07:34 2023 ] 	Batch(339/480) done. Loss: 0.0823  lr:0.001000  network_time: 0.0121
[ Wed May 17 13:08:19 2023 ] 	Batch(439/480) done. Loss: 0.0206  lr:0.001000  network_time: 0.0121
[ Wed May 17 13:08:37 2023 ] 	Training Accuracy: 99.25%
[ Wed May 17 13:08:37 2023 ] Eval epoch: 28
[ Wed May 17 13:08:54 2023 ] 	Mean test loss of 120 batches: 0.036567576229572296.
[ Wed May 17 13:08:54 2023 ] 	Top1: 99.33%
[ Wed May 17 13:08:54 2023 ] 	Top5: 99.83%
[ Wed May 17 13:08:54 2023 ] Training epoch: 29
[ Wed May 17 13:09:21 2023 ] 	Batch(59/480) done. Loss: 0.0159  lr:0.001000  network_time: 0.0122
[ Wed May 17 13:10:06 2023 ] 	Batch(159/480) done. Loss: 0.0533  lr:0.001000  network_time: 0.0121
[ Wed May 17 13:10:51 2023 ] 	Batch(259/480) done. Loss: 0.0602  lr:0.001000  network_time: 0.0115
[ Wed May 17 13:11:36 2023 ] 	Batch(359/480) done. Loss: 0.0013  lr:0.001000  network_time: 0.0121
[ Wed May 17 13:12:21 2023 ] 	Batch(459/480) done. Loss: 0.0231  lr:0.001000  network_time: 0.0120
[ Wed May 17 13:12:30 2023 ] 	Training Accuracy: 99.38%
[ Wed May 17 13:12:30 2023 ] Eval epoch: 29
[ Wed May 17 13:12:46 2023 ] 	Mean test loss of 120 batches: 0.023881694301962852.
[ Wed May 17 13:12:46 2023 ] 	Top1: 99.50%
[ Wed May 17 13:12:46 2023 ] 	Top5: 100.00%
[ Wed May 17 13:12:46 2023 ] Training epoch: 30
[ Wed May 17 13:13:23 2023 ] 	Batch(79/480) done. Loss: 0.0154  lr:0.001000  network_time: 0.0114
[ Wed May 17 13:14:08 2023 ] 	Batch(179/480) done. Loss: 0.0052  lr:0.001000  network_time: 0.0120
[ Wed May 17 13:14:53 2023 ] 	Batch(279/480) done. Loss: 0.0018  lr:0.001000  network_time: 0.0122
[ Wed May 17 13:15:38 2023 ] 	Batch(379/480) done. Loss: 0.0040  lr:0.001000  network_time: 0.0117
[ Wed May 17 13:16:23 2023 ] 	Batch(479/480) done. Loss: 0.2458  lr:0.001000  network_time: 0.0116
[ Wed May 17 13:16:23 2023 ] 	Training Accuracy: 99.58%
[ Wed May 17 13:16:23 2023 ] Eval epoch: 30
[ Wed May 17 13:16:39 2023 ] 	Mean test loss of 120 batches: 0.02114301547408104.
[ Wed May 17 13:16:39 2023 ] 	Top1: 99.67%
[ Wed May 17 13:16:39 2023 ] 	Top5: 100.00%
