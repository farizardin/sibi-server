[ Thu May 11 14:44:45 2023 ] NUM WORKER: 1
[ Thu May 11 14:45:39 2023 ] Parameters:
{'work_dir': './work_dir/sibi_individual_inner_group_ShiftGCN_mod_2_joint_n_5_kfold_fold_2', 'model_saved_name': './save_models/sibi_individual_inner_group_ShiftGCN_mod_2_joint_n_5_kfold_fold_2', 'Experiment_name': 'sibi_individual_inner_group_ShiftGCN_mod_2_joint_n_5_kfold', 'config': './config/recalculated/train_sibi_with_mouth_augmented_individual_inner_group_shift_joint_mod_2.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 2, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'n_splits': 5, 'feeder': 'feeders.feeder_hsd.Feeder', 'num_worker': 1, 'train_feeder_args': {'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': -1, 'normalization': False}, 'test_feeder_args': None, 'data_path': './data/augmented_recalculate_normalized', 'model': 'model.shift_gcn.Model', 'model_args': {'num_class': 50, 'num_person': 1, 'num_point': 115, 'graph_group': [[0, 39], [40, 60], [61, 81], [82, 114]], 'method': 'grouped.inner', 'weight': 2, 'graph': 'graph.skeleton_with_mouth.SkeletonWithMouth', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [20, 25], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 5, 'test_batch_size': 5, 'start_epoch': 0, 'num_epoch': 30, 'folds_range': [0, 5], 'weight_decay': 0.0001, 'only_train_part': True, 'only_train_epoch': 1, 'warm_up_epoch': 0}

[ Thu May 11 14:45:39 2023 ] Training epoch: 1
[ Thu May 11 14:46:29 2023 ] 	Batch(99/480) done. Loss: 3.9441  lr:0.100000  network_time: 0.0115
[ Thu May 11 14:47:17 2023 ] 	Batch(199/480) done. Loss: 3.9781  lr:0.100000  network_time: 0.0112
[ Thu May 11 14:48:06 2023 ] 	Batch(299/480) done. Loss: 3.0370  lr:0.100000  network_time: 0.0115
[ Thu May 11 14:48:55 2023 ] 	Batch(399/480) done. Loss: 3.0532  lr:0.100000  network_time: 0.0119
[ Thu May 11 14:49:34 2023 ] 	Training Accuracy: 10.38%
[ Thu May 11 14:49:34 2023 ] Eval epoch: 1
[ Thu May 11 14:49:50 2023 ] 	Mean test loss of 120 batches: 2.8038837909698486.
[ Thu May 11 14:49:50 2023 ] 	Top1: 19.00%
[ Thu May 11 14:49:50 2023 ] 	Top5: 63.83%
[ Thu May 11 14:49:50 2023 ] Training epoch: 2
[ Thu May 11 14:50:00 2023 ] 	Batch(19/480) done. Loss: 2.9924  lr:0.100000  network_time: 0.0120
[ Thu May 11 14:50:49 2023 ] 	Batch(119/480) done. Loss: 3.4021  lr:0.100000  network_time: 0.0117
[ Thu May 11 14:51:37 2023 ] 	Batch(219/480) done. Loss: 1.8414  lr:0.100000  network_time: 0.0113
[ Thu May 11 14:52:26 2023 ] 	Batch(319/480) done. Loss: 3.2292  lr:0.100000  network_time: 0.0113
[ Thu May 11 14:53:15 2023 ] 	Batch(419/480) done. Loss: 1.2364  lr:0.100000  network_time: 0.0115
[ Thu May 11 14:53:44 2023 ] 	Training Accuracy: 23.92%
[ Thu May 11 14:53:44 2023 ] Eval epoch: 2
[ Thu May 11 14:54:01 2023 ] 	Mean test loss of 120 batches: 1.978906273841858.
[ Thu May 11 14:54:01 2023 ] 	Top1: 39.83%
[ Thu May 11 14:54:01 2023 ] 	Top5: 88.50%
[ Thu May 11 14:54:01 2023 ] Training epoch: 3
[ Thu May 11 14:54:20 2023 ] 	Batch(39/480) done. Loss: 1.9638  lr:0.100000  network_time: 0.0121
[ Thu May 11 14:55:09 2023 ] 	Batch(139/480) done. Loss: 1.8121  lr:0.100000  network_time: 0.0122
[ Thu May 11 14:55:58 2023 ] 	Batch(239/480) done. Loss: 2.6944  lr:0.100000  network_time: 0.0114
[ Thu May 11 14:56:46 2023 ] 	Batch(339/480) done. Loss: 2.9350  lr:0.100000  network_time: 0.0115
[ Thu May 11 14:57:35 2023 ] 	Batch(439/480) done. Loss: 2.5652  lr:0.100000  network_time: 0.0115
[ Thu May 11 14:57:54 2023 ] 	Training Accuracy: 34.33%
[ Thu May 11 14:57:54 2023 ] Eval epoch: 3
[ Thu May 11 14:58:11 2023 ] 	Mean test loss of 120 batches: 2.29980731010437.
[ Thu May 11 14:58:11 2023 ] 	Top1: 35.83%
[ Thu May 11 14:58:11 2023 ] 	Top5: 81.33%
[ Thu May 11 14:58:11 2023 ] Training epoch: 4
[ Thu May 11 14:58:40 2023 ] 	Batch(59/480) done. Loss: 1.6167  lr:0.100000  network_time: 0.0114
[ Thu May 11 14:59:29 2023 ] 	Batch(159/480) done. Loss: 2.1567  lr:0.100000  network_time: 0.0114
[ Thu May 11 15:00:18 2023 ] 	Batch(259/480) done. Loss: 1.1984  lr:0.100000  network_time: 0.0117
[ Thu May 11 15:01:06 2023 ] 	Batch(359/480) done. Loss: 1.6717  lr:0.100000  network_time: 0.0112
[ Thu May 11 15:01:55 2023 ] 	Batch(459/480) done. Loss: 1.8390  lr:0.100000  network_time: 0.0114
[ Thu May 11 15:02:05 2023 ] 	Training Accuracy: 44.92%
[ Thu May 11 15:02:05 2023 ] Eval epoch: 4
[ Thu May 11 15:02:22 2023 ] 	Mean test loss of 120 batches: 1.5101394653320312.
[ Thu May 11 15:02:22 2023 ] 	Top1: 50.50%
[ Thu May 11 15:02:22 2023 ] 	Top5: 93.17%
[ Thu May 11 15:02:22 2023 ] Training epoch: 5
[ Thu May 11 15:03:01 2023 ] 	Batch(79/480) done. Loss: 1.9984  lr:0.100000  network_time: 0.0120
[ Thu May 11 15:03:49 2023 ] 	Batch(179/480) done. Loss: 0.5846  lr:0.100000  network_time: 0.0113
[ Thu May 11 15:04:38 2023 ] 	Batch(279/480) done. Loss: 1.8637  lr:0.100000  network_time: 0.0114
[ Thu May 11 15:05:26 2023 ] 	Batch(379/480) done. Loss: 1.9156  lr:0.100000  network_time: 0.0116
[ Thu May 11 15:06:15 2023 ] 	Batch(479/480) done. Loss: 0.7278  lr:0.100000  network_time: 0.0123
[ Thu May 11 15:06:15 2023 ] 	Training Accuracy: 55.08%
[ Thu May 11 15:06:15 2023 ] Eval epoch: 5
[ Thu May 11 15:06:32 2023 ] 	Mean test loss of 120 batches: 1.4628143310546875.
[ Thu May 11 15:06:32 2023 ] 	Top1: 57.67%
[ Thu May 11 15:06:32 2023 ] 	Top5: 93.67%
[ Thu May 11 15:06:32 2023 ] Training epoch: 6
[ Thu May 11 15:07:21 2023 ] 	Batch(99/480) done. Loss: 0.9000  lr:0.100000  network_time: 0.0115
[ Thu May 11 15:08:09 2023 ] 	Batch(199/480) done. Loss: 1.5748  lr:0.100000  network_time: 0.0128
[ Thu May 11 15:08:58 2023 ] 	Batch(299/480) done. Loss: 0.3880  lr:0.100000  network_time: 0.0129
[ Thu May 11 15:09:47 2023 ] 	Batch(399/480) done. Loss: 1.9516  lr:0.100000  network_time: 0.0115
[ Thu May 11 15:10:26 2023 ] 	Training Accuracy: 60.29%
[ Thu May 11 15:10:26 2023 ] Eval epoch: 6
[ Thu May 11 15:10:42 2023 ] 	Mean test loss of 120 batches: 1.0405112504959106.
[ Thu May 11 15:10:42 2023 ] 	Top1: 71.17%
[ Thu May 11 15:10:42 2023 ] 	Top5: 97.67%
[ Thu May 11 15:10:42 2023 ] Training epoch: 7
[ Thu May 11 15:10:52 2023 ] 	Batch(19/480) done. Loss: 1.8552  lr:0.100000  network_time: 0.0114
[ Thu May 11 15:11:41 2023 ] 	Batch(119/480) done. Loss: 0.8830  lr:0.100000  network_time: 0.0116
[ Thu May 11 15:12:29 2023 ] 	Batch(219/480) done. Loss: 0.9166  lr:0.100000  network_time: 0.0120
[ Thu May 11 15:13:18 2023 ] 	Batch(319/480) done. Loss: 0.3323  lr:0.100000  network_time: 0.0117
[ Thu May 11 15:14:07 2023 ] 	Batch(419/480) done. Loss: 0.6247  lr:0.100000  network_time: 0.0115
[ Thu May 11 15:14:36 2023 ] 	Training Accuracy: 65.79%
[ Thu May 11 15:14:36 2023 ] Eval epoch: 7
[ Thu May 11 15:14:53 2023 ] 	Mean test loss of 120 batches: 0.96174156665802.
[ Thu May 11 15:14:53 2023 ] 	Top1: 72.17%
[ Thu May 11 15:14:53 2023 ] 	Top5: 97.83%
[ Thu May 11 15:14:53 2023 ] Training epoch: 8
[ Thu May 11 15:15:12 2023 ] 	Batch(39/480) done. Loss: 0.4155  lr:0.100000  network_time: 0.0113
[ Thu May 11 15:16:01 2023 ] 	Batch(139/480) done. Loss: 0.9760  lr:0.100000  network_time: 0.0114
[ Thu May 11 15:16:50 2023 ] 	Batch(239/480) done. Loss: 0.4281  lr:0.100000  network_time: 0.0122
[ Thu May 11 15:17:38 2023 ] 	Batch(339/480) done. Loss: 0.4226  lr:0.100000  network_time: 0.0132
[ Thu May 11 15:18:27 2023 ] 	Batch(439/480) done. Loss: 1.7678  lr:0.100000  network_time: 0.0115
[ Thu May 11 15:18:46 2023 ] 	Training Accuracy: 70.38%
[ Thu May 11 15:18:46 2023 ] Eval epoch: 8
[ Thu May 11 15:19:03 2023 ] 	Mean test loss of 120 batches: 0.761932909488678.
[ Thu May 11 15:19:03 2023 ] 	Top1: 75.00%
[ Thu May 11 15:19:03 2023 ] 	Top5: 98.00%
[ Thu May 11 15:19:03 2023 ] Training epoch: 9
[ Thu May 11 15:19:32 2023 ] 	Batch(59/480) done. Loss: 0.2567  lr:0.100000  network_time: 0.0114
[ Thu May 11 15:20:21 2023 ] 	Batch(159/480) done. Loss: 1.2325  lr:0.100000  network_time: 0.0118
[ Thu May 11 15:21:10 2023 ] 	Batch(259/480) done. Loss: 0.7186  lr:0.100000  network_time: 0.0117
[ Thu May 11 15:21:58 2023 ] 	Batch(359/480) done. Loss: 0.9230  lr:0.100000  network_time: 0.0114
[ Thu May 11 15:22:47 2023 ] 	Batch(459/480) done. Loss: 0.1650  lr:0.100000  network_time: 0.0117
[ Thu May 11 15:22:57 2023 ] 	Training Accuracy: 73.88%
[ Thu May 11 15:22:57 2023 ] Eval epoch: 9
[ Thu May 11 15:23:14 2023 ] 	Mean test loss of 120 batches: 0.6269959211349487.
[ Thu May 11 15:23:14 2023 ] 	Top1: 81.83%
[ Thu May 11 15:23:14 2023 ] 	Top5: 98.33%
[ Thu May 11 15:23:14 2023 ] Training epoch: 10
[ Thu May 11 15:23:53 2023 ] 	Batch(79/480) done. Loss: 0.9316  lr:0.100000  network_time: 0.0115
[ Thu May 11 15:24:41 2023 ] 	Batch(179/480) done. Loss: 1.1210  lr:0.100000  network_time: 0.0112
[ Thu May 11 15:25:30 2023 ] 	Batch(279/480) done. Loss: 0.8069  lr:0.100000  network_time: 0.0118
[ Thu May 11 15:26:19 2023 ] 	Batch(379/480) done. Loss: 1.1753  lr:0.100000  network_time: 0.0120
[ Thu May 11 15:27:07 2023 ] 	Batch(479/480) done. Loss: 0.6433  lr:0.100000  network_time: 0.0120
[ Thu May 11 15:27:07 2023 ] 	Training Accuracy: 76.75%
[ Thu May 11 15:27:07 2023 ] Eval epoch: 10
[ Thu May 11 15:27:24 2023 ] 	Mean test loss of 120 batches: 0.6485647559165955.
[ Thu May 11 15:27:24 2023 ] 	Top1: 83.67%
[ Thu May 11 15:27:24 2023 ] 	Top5: 98.67%
[ Thu May 11 15:27:24 2023 ] Training epoch: 11
[ Thu May 11 15:28:13 2023 ] 	Batch(99/480) done. Loss: 0.3459  lr:0.100000  network_time: 0.0119
[ Thu May 11 15:29:02 2023 ] 	Batch(199/480) done. Loss: 0.7013  lr:0.100000  network_time: 0.0119
[ Thu May 11 15:29:50 2023 ] 	Batch(299/480) done. Loss: 0.8440  lr:0.100000  network_time: 0.0116
[ Thu May 11 15:30:39 2023 ] 	Batch(399/480) done. Loss: 0.3134  lr:0.100000  network_time: 0.0115
[ Thu May 11 15:31:18 2023 ] 	Training Accuracy: 80.62%
[ Thu May 11 15:31:18 2023 ] Eval epoch: 11
[ Thu May 11 15:31:35 2023 ] 	Mean test loss of 120 batches: 0.41193491220474243.
[ Thu May 11 15:31:35 2023 ] 	Top1: 88.00%
[ Thu May 11 15:31:35 2023 ] 	Top5: 99.33%
[ Thu May 11 15:31:35 2023 ] Training epoch: 12
[ Thu May 11 15:31:44 2023 ] 	Batch(19/480) done. Loss: 0.5143  lr:0.100000  network_time: 0.0112
[ Thu May 11 15:32:33 2023 ] 	Batch(119/480) done. Loss: 0.2948  lr:0.100000  network_time: 0.0119
[ Thu May 11 15:33:22 2023 ] 	Batch(219/480) done. Loss: 0.6616  lr:0.100000  network_time: 0.0117
[ Thu May 11 15:34:10 2023 ] 	Batch(319/480) done. Loss: 0.4234  lr:0.100000  network_time: 0.0121
[ Thu May 11 15:34:59 2023 ] 	Batch(419/480) done. Loss: 0.1816  lr:0.100000  network_time: 0.0120
[ Thu May 11 15:35:28 2023 ] 	Training Accuracy: 81.96%
[ Thu May 11 15:35:28 2023 ] Eval epoch: 12
[ Thu May 11 15:35:45 2023 ] 	Mean test loss of 120 batches: 0.650345504283905.
[ Thu May 11 15:35:45 2023 ] 	Top1: 80.17%
[ Thu May 11 15:35:45 2023 ] 	Top5: 98.50%
[ Thu May 11 15:35:45 2023 ] Training epoch: 13
[ Thu May 11 15:36:05 2023 ] 	Batch(39/480) done. Loss: 0.3135  lr:0.100000  network_time: 0.0115
[ Thu May 11 15:36:53 2023 ] 	Batch(139/480) done. Loss: 0.3323  lr:0.100000  network_time: 0.0114
[ Thu May 11 15:37:42 2023 ] 	Batch(239/480) done. Loss: 0.0596  lr:0.100000  network_time: 0.0113
[ Thu May 11 15:38:31 2023 ] 	Batch(339/480) done. Loss: 0.8396  lr:0.100000  network_time: 0.0113
[ Thu May 11 15:39:19 2023 ] 	Batch(439/480) done. Loss: 0.4537  lr:0.100000  network_time: 0.0113
[ Thu May 11 15:39:39 2023 ] 	Training Accuracy: 84.58%
[ Thu May 11 15:39:39 2023 ] Eval epoch: 13
[ Thu May 11 15:39:56 2023 ] 	Mean test loss of 120 batches: 0.3772868812084198.
[ Thu May 11 15:39:56 2023 ] 	Top1: 89.33%
[ Thu May 11 15:39:56 2023 ] 	Top5: 99.83%
[ Thu May 11 15:39:56 2023 ] Training epoch: 14
[ Thu May 11 15:40:25 2023 ] 	Batch(59/480) done. Loss: 0.1876  lr:0.100000  network_time: 0.0124
[ Thu May 11 15:41:14 2023 ] 	Batch(159/480) done. Loss: 0.4192  lr:0.100000  network_time: 0.0118
[ Thu May 11 15:42:02 2023 ] 	Batch(259/480) done. Loss: 1.1308  lr:0.100000  network_time: 0.0120
[ Thu May 11 15:42:51 2023 ] 	Batch(359/480) done. Loss: 0.5540  lr:0.100000  network_time: 0.0115
[ Thu May 11 15:43:39 2023 ] 	Batch(459/480) done. Loss: 0.3210  lr:0.100000  network_time: 0.0114
[ Thu May 11 15:43:49 2023 ] 	Training Accuracy: 85.25%
[ Thu May 11 15:43:49 2023 ] Eval epoch: 14
[ Thu May 11 15:44:06 2023 ] 	Mean test loss of 120 batches: 2.296295642852783.
[ Thu May 11 15:44:06 2023 ] 	Top1: 49.67%
[ Thu May 11 15:44:06 2023 ] 	Top5: 83.83%
[ Thu May 11 15:44:06 2023 ] Training epoch: 15
[ Thu May 11 15:44:45 2023 ] 	Batch(79/480) done. Loss: 0.2719  lr:0.100000  network_time: 0.0113
[ Thu May 11 15:45:34 2023 ] 	Batch(179/480) done. Loss: 0.8856  lr:0.100000  network_time: 0.0116
[ Thu May 11 15:46:22 2023 ] 	Batch(279/480) done. Loss: 0.0203  lr:0.100000  network_time: 0.0117
[ Thu May 11 15:47:11 2023 ] 	Batch(379/480) done. Loss: 0.0969  lr:0.100000  network_time: 0.0115
[ Thu May 11 15:48:00 2023 ] 	Batch(479/480) done. Loss: 0.5864  lr:0.100000  network_time: 0.0114
[ Thu May 11 15:48:00 2023 ] 	Training Accuracy: 86.33%
[ Thu May 11 15:48:00 2023 ] Eval epoch: 15
[ Thu May 11 15:48:17 2023 ] 	Mean test loss of 120 batches: 0.4856362044811249.
[ Thu May 11 15:48:17 2023 ] 	Top1: 87.17%
[ Thu May 11 15:48:17 2023 ] 	Top5: 99.33%
[ Thu May 11 15:48:17 2023 ] Training epoch: 16
[ Thu May 11 15:49:05 2023 ] 	Batch(99/480) done. Loss: 0.0497  lr:0.100000  network_time: 0.0117
[ Thu May 11 15:49:54 2023 ] 	Batch(199/480) done. Loss: 0.9324  lr:0.100000  network_time: 0.0116
[ Thu May 11 15:50:43 2023 ] 	Batch(299/480) done. Loss: 0.1166  lr:0.100000  network_time: 0.0112
[ Thu May 11 15:51:31 2023 ] 	Batch(399/480) done. Loss: 0.1471  lr:0.100000  network_time: 0.0115
[ Thu May 11 15:52:10 2023 ] 	Training Accuracy: 88.50%
[ Thu May 11 15:52:10 2023 ] Eval epoch: 16
[ Thu May 11 15:52:27 2023 ] 	Mean test loss of 120 batches: 0.5466792583465576.
[ Thu May 11 15:52:27 2023 ] 	Top1: 86.67%
[ Thu May 11 15:52:27 2023 ] 	Top5: 100.00%
[ Thu May 11 15:52:27 2023 ] Training epoch: 17
[ Thu May 11 15:52:37 2023 ] 	Batch(19/480) done. Loss: 0.3466  lr:0.100000  network_time: 0.0120
[ Thu May 11 15:53:26 2023 ] 	Batch(119/480) done. Loss: 0.1973  lr:0.100000  network_time: 0.0115
[ Thu May 11 15:54:14 2023 ] 	Batch(219/480) done. Loss: 0.1956  lr:0.100000  network_time: 0.0113
[ Thu May 11 15:55:03 2023 ] 	Batch(319/480) done. Loss: 0.1863  lr:0.100000  network_time: 0.0115
[ Thu May 11 15:55:52 2023 ] 	Batch(419/480) done. Loss: 0.0840  lr:0.100000  network_time: 0.0116
[ Thu May 11 15:56:21 2023 ] 	Training Accuracy: 87.67%
[ Thu May 11 15:56:21 2023 ] Eval epoch: 17
[ Thu May 11 15:56:38 2023 ] 	Mean test loss of 120 batches: 0.4581214487552643.
[ Thu May 11 15:56:38 2023 ] 	Top1: 90.33%
[ Thu May 11 15:56:38 2023 ] 	Top5: 99.33%
[ Thu May 11 15:56:38 2023 ] Training epoch: 18
[ Thu May 11 15:56:57 2023 ] 	Batch(39/480) done. Loss: 0.9696  lr:0.100000  network_time: 0.0114
[ Thu May 11 15:57:46 2023 ] 	Batch(139/480) done. Loss: 0.8035  lr:0.100000  network_time: 0.0117
[ Thu May 11 15:58:34 2023 ] 	Batch(239/480) done. Loss: 0.5036  lr:0.100000  network_time: 0.0126
[ Thu May 11 15:59:23 2023 ] 	Batch(339/480) done. Loss: 0.2568  lr:0.100000  network_time: 0.0135
[ Thu May 11 16:00:12 2023 ] 	Batch(439/480) done. Loss: 0.5072  lr:0.100000  network_time: 0.0116
[ Thu May 11 16:00:31 2023 ] 	Training Accuracy: 89.71%
[ Thu May 11 16:00:31 2023 ] Eval epoch: 18
[ Thu May 11 16:00:48 2023 ] 	Mean test loss of 120 batches: 0.2874712646007538.
[ Thu May 11 16:00:48 2023 ] 	Top1: 92.00%
[ Thu May 11 16:00:48 2023 ] 	Top5: 100.00%
[ Thu May 11 16:00:48 2023 ] Training epoch: 19
[ Thu May 11 16:01:17 2023 ] 	Batch(59/480) done. Loss: 0.4186  lr:0.100000  network_time: 0.0115
[ Thu May 11 16:02:06 2023 ] 	Batch(159/480) done. Loss: 0.5898  lr:0.100000  network_time: 0.0117
[ Thu May 11 16:02:55 2023 ] 	Batch(259/480) done. Loss: 0.1499  lr:0.100000  network_time: 0.0116
[ Thu May 11 16:03:43 2023 ] 	Batch(359/480) done. Loss: 0.0909  lr:0.100000  network_time: 0.0119
[ Thu May 11 16:04:32 2023 ] 	Batch(459/480) done. Loss: 0.2286  lr:0.100000  network_time: 0.0118
[ Thu May 11 16:04:42 2023 ] 	Training Accuracy: 89.42%
[ Thu May 11 16:04:42 2023 ] Eval epoch: 19
[ Thu May 11 16:04:59 2023 ] 	Mean test loss of 120 batches: 0.49543899297714233.
[ Thu May 11 16:04:59 2023 ] 	Top1: 85.83%
[ Thu May 11 16:04:59 2023 ] 	Top5: 98.67%
[ Thu May 11 16:04:59 2023 ] Training epoch: 20
[ Thu May 11 16:05:38 2023 ] 	Batch(79/480) done. Loss: 0.0534  lr:0.100000  network_time: 0.0114
[ Thu May 11 16:06:26 2023 ] 	Batch(179/480) done. Loss: 0.4010  lr:0.100000  network_time: 0.0115
[ Thu May 11 16:07:15 2023 ] 	Batch(279/480) done. Loss: 0.2602  lr:0.100000  network_time: 0.0119
[ Thu May 11 16:08:04 2023 ] 	Batch(379/480) done. Loss: 0.0706  lr:0.100000  network_time: 0.0120
[ Thu May 11 16:08:52 2023 ] 	Batch(479/480) done. Loss: 0.0924  lr:0.100000  network_time: 0.0118
[ Thu May 11 16:08:52 2023 ] 	Training Accuracy: 91.17%
[ Thu May 11 16:08:52 2023 ] Eval epoch: 20
[ Thu May 11 16:09:09 2023 ] 	Mean test loss of 120 batches: 0.19496788084506989.
[ Thu May 11 16:09:09 2023 ] 	Top1: 92.67%
[ Thu May 11 16:09:09 2023 ] 	Top5: 99.67%
[ Thu May 11 16:09:09 2023 ] Training epoch: 21
[ Thu May 11 16:09:58 2023 ] 	Batch(99/480) done. Loss: 0.0172  lr:0.010000  network_time: 0.0117
[ Thu May 11 16:10:47 2023 ] 	Batch(199/480) done. Loss: 0.0567  lr:0.010000  network_time: 0.0114
[ Thu May 11 16:11:35 2023 ] 	Batch(299/480) done. Loss: 0.1706  lr:0.010000  network_time: 0.0114
[ Thu May 11 16:12:24 2023 ] 	Batch(399/480) done. Loss: 0.0106  lr:0.010000  network_time: 0.0115
[ Thu May 11 16:13:03 2023 ] 	Training Accuracy: 97.75%
[ Thu May 11 16:13:03 2023 ] Eval epoch: 21
[ Thu May 11 16:13:20 2023 ] 	Mean test loss of 120 batches: 0.038846295326948166.
[ Thu May 11 16:13:20 2023 ] 	Top1: 99.17%
[ Thu May 11 16:13:20 2023 ] 	Top5: 100.00%
[ Thu May 11 16:13:20 2023 ] Training epoch: 22
[ Thu May 11 16:13:30 2023 ] 	Batch(19/480) done. Loss: 0.0181  lr:0.010000  network_time: 0.0114
[ Thu May 11 16:14:18 2023 ] 	Batch(119/480) done. Loss: 0.0167  lr:0.010000  network_time: 0.0117
[ Thu May 11 16:15:07 2023 ] 	Batch(219/480) done. Loss: 0.0807  lr:0.010000  network_time: 0.0118
[ Thu May 11 16:15:56 2023 ] 	Batch(319/480) done. Loss: 0.0059  lr:0.010000  network_time: 0.0115
[ Thu May 11 16:16:44 2023 ] 	Batch(419/480) done. Loss: 0.0096  lr:0.010000  network_time: 0.0119
[ Thu May 11 16:17:14 2023 ] 	Training Accuracy: 98.83%
[ Thu May 11 16:17:14 2023 ] Eval epoch: 22
[ Thu May 11 16:17:30 2023 ] 	Mean test loss of 120 batches: 0.04216678813099861.
[ Thu May 11 16:17:30 2023 ] 	Top1: 99.50%
[ Thu May 11 16:17:30 2023 ] 	Top5: 100.00%
[ Thu May 11 16:17:31 2023 ] Training epoch: 23
[ Thu May 11 16:17:50 2023 ] 	Batch(39/480) done. Loss: 0.0135  lr:0.010000  network_time: 0.0117
[ Thu May 11 16:18:39 2023 ] 	Batch(139/480) done. Loss: 0.0229  lr:0.010000  network_time: 0.0116
[ Thu May 11 16:19:27 2023 ] 	Batch(239/480) done. Loss: 0.0637  lr:0.010000  network_time: 0.0115
[ Thu May 11 16:20:16 2023 ] 	Batch(339/480) done. Loss: 0.0057  lr:0.010000  network_time: 0.0113
[ Thu May 11 16:21:05 2023 ] 	Batch(439/480) done. Loss: 0.0084  lr:0.010000  network_time: 0.0116
[ Thu May 11 16:21:24 2023 ] 	Training Accuracy: 99.50%
[ Thu May 11 16:21:24 2023 ] Eval epoch: 23
[ Thu May 11 16:21:41 2023 ] 	Mean test loss of 120 batches: 0.022809624671936035.
[ Thu May 11 16:21:41 2023 ] 	Top1: 99.67%
[ Thu May 11 16:21:41 2023 ] 	Top5: 100.00%
[ Thu May 11 16:21:41 2023 ] Training epoch: 24
[ Thu May 11 16:22:10 2023 ] 	Batch(59/480) done. Loss: 0.1794  lr:0.010000  network_time: 0.0114
[ Thu May 11 16:22:59 2023 ] 	Batch(159/480) done. Loss: 0.0146  lr:0.010000  network_time: 0.0113
[ Thu May 11 16:23:48 2023 ] 	Batch(259/480) done. Loss: 0.0113  lr:0.010000  network_time: 0.0111
[ Thu May 11 16:24:36 2023 ] 	Batch(359/480) done. Loss: 0.1532  lr:0.010000  network_time: 0.0115
[ Thu May 11 16:25:25 2023 ] 	Batch(459/480) done. Loss: 0.0943  lr:0.010000  network_time: 0.0115
[ Thu May 11 16:25:35 2023 ] 	Training Accuracy: 99.38%
[ Thu May 11 16:25:35 2023 ] Eval epoch: 24
[ Thu May 11 16:25:52 2023 ] 	Mean test loss of 120 batches: 0.015259393490850925.
[ Thu May 11 16:25:52 2023 ] 	Top1: 99.67%
[ Thu May 11 16:25:52 2023 ] 	Top5: 100.00%
[ Thu May 11 16:25:52 2023 ] Training epoch: 25
[ Thu May 11 16:26:31 2023 ] 	Batch(79/480) done. Loss: 0.0276  lr:0.010000  network_time: 0.0113
[ Thu May 11 16:27:19 2023 ] 	Batch(179/480) done. Loss: 0.0099  lr:0.010000  network_time: 0.0116
[ Thu May 11 16:28:08 2023 ] 	Batch(279/480) done. Loss: 0.0872  lr:0.010000  network_time: 0.0113
[ Thu May 11 16:28:57 2023 ] 	Batch(379/480) done. Loss: 0.0019  lr:0.010000  network_time: 0.0113
[ Thu May 11 16:29:45 2023 ] 	Batch(479/480) done. Loss: 0.0079  lr:0.010000  network_time: 0.0112
[ Thu May 11 16:29:45 2023 ] 	Training Accuracy: 99.42%
[ Thu May 11 16:29:45 2023 ] Eval epoch: 25
[ Thu May 11 16:30:02 2023 ] 	Mean test loss of 120 batches: 0.01794602908194065.
[ Thu May 11 16:30:02 2023 ] 	Top1: 99.67%
[ Thu May 11 16:30:02 2023 ] 	Top5: 100.00%
[ Thu May 11 16:30:02 2023 ] Training epoch: 26
[ Thu May 11 16:30:51 2023 ] 	Batch(99/480) done. Loss: 0.0232  lr:0.001000  network_time: 0.0117
[ Thu May 11 16:31:40 2023 ] 	Batch(199/480) done. Loss: 0.0622  lr:0.001000  network_time: 0.0126
[ Thu May 11 16:32:28 2023 ] 	Batch(299/480) done. Loss: 0.0125  lr:0.001000  network_time: 0.0115
[ Thu May 11 16:33:17 2023 ] 	Batch(399/480) done. Loss: 0.0027  lr:0.001000  network_time: 0.0122
[ Thu May 11 16:33:56 2023 ] 	Training Accuracy: 99.33%
[ Thu May 11 16:33:56 2023 ] Eval epoch: 26
[ Thu May 11 16:34:13 2023 ] 	Mean test loss of 120 batches: 0.026987850666046143.
[ Thu May 11 16:34:13 2023 ] 	Top1: 99.67%
[ Thu May 11 16:34:13 2023 ] 	Top5: 100.00%
[ Thu May 11 16:34:13 2023 ] Training epoch: 27
[ Thu May 11 16:34:22 2023 ] 	Batch(19/480) done. Loss: 0.0168  lr:0.001000  network_time: 0.0115
[ Thu May 11 16:35:11 2023 ] 	Batch(119/480) done. Loss: 0.1713  lr:0.001000  network_time: 0.0114
[ Thu May 11 16:36:00 2023 ] 	Batch(219/480) done. Loss: 0.0117  lr:0.001000  network_time: 0.0115
[ Thu May 11 16:36:48 2023 ] 	Batch(319/480) done. Loss: 0.0273  lr:0.001000  network_time: 0.0115
[ Thu May 11 16:37:37 2023 ] 	Batch(419/480) done. Loss: 0.0316  lr:0.001000  network_time: 0.0111
[ Thu May 11 16:38:06 2023 ] 	Training Accuracy: 99.62%
[ Thu May 11 16:38:06 2023 ] Eval epoch: 27
[ Thu May 11 16:38:23 2023 ] 	Mean test loss of 120 batches: 0.023974835872650146.
[ Thu May 11 16:38:23 2023 ] 	Top1: 99.67%
[ Thu May 11 16:38:23 2023 ] 	Top5: 100.00%
[ Thu May 11 16:38:23 2023 ] Training epoch: 28
[ Thu May 11 16:38:43 2023 ] 	Batch(39/480) done. Loss: 0.0074  lr:0.001000  network_time: 0.0113
[ Thu May 11 16:39:31 2023 ] 	Batch(139/480) done. Loss: 0.0231  lr:0.001000  network_time: 0.0114
[ Thu May 11 16:40:20 2023 ] 	Batch(239/480) done. Loss: 0.0150  lr:0.001000  network_time: 0.0117
[ Thu May 11 16:41:09 2023 ] 	Batch(339/480) done. Loss: 0.0862  lr:0.001000  network_time: 0.0115
[ Thu May 11 16:41:57 2023 ] 	Batch(439/480) done. Loss: 0.0393  lr:0.001000  network_time: 0.0115
[ Thu May 11 16:42:17 2023 ] 	Training Accuracy: 99.46%
[ Thu May 11 16:42:17 2023 ] Eval epoch: 28
[ Thu May 11 16:42:34 2023 ] 	Mean test loss of 120 batches: 0.026265788823366165.
[ Thu May 11 16:42:34 2023 ] 	Top1: 99.67%
[ Thu May 11 16:42:34 2023 ] 	Top5: 100.00%
[ Thu May 11 16:42:34 2023 ] Training epoch: 29
[ Thu May 11 16:43:03 2023 ] 	Batch(59/480) done. Loss: 0.0308  lr:0.001000  network_time: 0.0118
[ Thu May 11 16:43:52 2023 ] 	Batch(159/480) done. Loss: 0.0077  lr:0.001000  network_time: 0.0113
[ Thu May 11 16:44:40 2023 ] 	Batch(259/480) done. Loss: 0.1342  lr:0.001000  network_time: 0.0114
[ Thu May 11 16:45:29 2023 ] 	Batch(359/480) done. Loss: 0.0628  lr:0.001000  network_time: 0.0114
[ Thu May 11 16:46:18 2023 ] 	Batch(459/480) done. Loss: 0.0274  lr:0.001000  network_time: 0.0114
[ Thu May 11 16:46:27 2023 ] 	Training Accuracy: 99.79%
[ Thu May 11 16:46:27 2023 ] Eval epoch: 29
[ Thu May 11 16:46:44 2023 ] 	Mean test loss of 120 batches: 0.0244758240878582.
[ Thu May 11 16:46:44 2023 ] 	Top1: 99.67%
[ Thu May 11 16:46:44 2023 ] 	Top5: 100.00%
[ Thu May 11 16:46:44 2023 ] Training epoch: 30
[ Thu May 11 16:47:23 2023 ] 	Batch(79/480) done. Loss: 0.0089  lr:0.001000  network_time: 0.0114
[ Thu May 11 16:48:12 2023 ] 	Batch(179/480) done. Loss: 0.0031  lr:0.001000  network_time: 0.0125
[ Thu May 11 16:49:00 2023 ] 	Batch(279/480) done. Loss: 0.0021  lr:0.001000  network_time: 0.0114
[ Thu May 11 16:49:49 2023 ] 	Batch(379/480) done. Loss: 0.0175  lr:0.001000  network_time: 0.0116
[ Thu May 11 16:50:38 2023 ] 	Batch(479/480) done. Loss: 0.0128  lr:0.001000  network_time: 0.0114
[ Thu May 11 16:50:38 2023 ] 	Training Accuracy: 99.50%
[ Thu May 11 16:50:38 2023 ] Eval epoch: 30
[ Thu May 11 16:50:55 2023 ] 	Mean test loss of 120 batches: 0.019003668799996376.
[ Thu May 11 16:50:55 2023 ] 	Top1: 99.67%
[ Thu May 11 16:50:55 2023 ] 	Top5: 100.00%
