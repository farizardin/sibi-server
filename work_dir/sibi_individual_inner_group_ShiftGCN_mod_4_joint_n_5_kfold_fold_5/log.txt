[ Fri May 12 07:17:36 2023 ] NUM WORKER: 1
[ Fri May 12 07:18:32 2023 ] Parameters:
{'work_dir': './work_dir/sibi_individual_inner_group_ShiftGCN_mod_4_joint_n_5_kfold_fold_5', 'model_saved_name': './save_models/sibi_individual_inner_group_ShiftGCN_mod_4_joint_n_5_kfold_fold_5', 'Experiment_name': 'sibi_individual_inner_group_ShiftGCN_mod_4_joint_n_5_kfold', 'config': './config/recalculated/train_sibi_with_mouth_augmented_individual_inner_group_shift_joint_mod_4.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 2, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'n_splits': 5, 'feeder': 'feeders.feeder_hsd.Feeder', 'num_worker': 1, 'train_feeder_args': {'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': -1, 'normalization': False}, 'test_feeder_args': None, 'data_path': './data/augmented_recalculate_normalized', 'model': 'model.shift_gcn.Model', 'model_args': {'num_class': 50, 'num_person': 1, 'num_point': 115, 'graph_group': [[0, 39], [40, 60], [61, 81], [82, 114]], 'method': 'grouped.inner', 'weight': 4, 'graph': 'graph.skeleton_with_mouth.SkeletonWithMouth', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [20, 25], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 5, 'test_batch_size': 5, 'start_epoch': 0, 'num_epoch': 30, 'folds_range': [3, 5], 'weight_decay': 0.0001, 'only_train_part': True, 'only_train_epoch': 1, 'warm_up_epoch': 0}

[ Fri May 12 07:18:32 2023 ] Training epoch: 1
[ Fri May 12 07:19:20 2023 ] 	Batch(99/480) done. Loss: 3.8383  lr:0.100000  network_time: 0.0115
[ Fri May 12 07:20:07 2023 ] 	Batch(199/480) done. Loss: 3.8693  lr:0.100000  network_time: 0.0118
[ Fri May 12 07:20:55 2023 ] 	Batch(299/480) done. Loss: 3.2398  lr:0.100000  network_time: 0.0116
[ Fri May 12 07:21:42 2023 ] 	Batch(399/480) done. Loss: 3.0868  lr:0.100000  network_time: 0.0113
[ Fri May 12 07:22:20 2023 ] 	Training Accuracy: 6.00%
[ Fri May 12 07:22:20 2023 ] Eval epoch: 1
[ Fri May 12 07:22:37 2023 ] 	Mean test loss of 120 batches: 3.1858928203582764.
[ Fri May 12 07:22:37 2023 ] 	Top1: 10.00%
[ Fri May 12 07:22:37 2023 ] 	Top5: 42.17%
[ Fri May 12 07:22:37 2023 ] Training epoch: 2
[ Fri May 12 07:22:46 2023 ] 	Batch(19/480) done. Loss: 3.6452  lr:0.100000  network_time: 0.0120
[ Fri May 12 07:23:34 2023 ] 	Batch(119/480) done. Loss: 3.6718  lr:0.100000  network_time: 0.0122
[ Fri May 12 07:24:21 2023 ] 	Batch(219/480) done. Loss: 2.6537  lr:0.100000  network_time: 0.0114
[ Fri May 12 07:25:09 2023 ] 	Batch(319/480) done. Loss: 3.3201  lr:0.100000  network_time: 0.0117
[ Fri May 12 07:25:56 2023 ] 	Batch(419/480) done. Loss: 2.0263  lr:0.100000  network_time: 0.0125
[ Fri May 12 07:26:25 2023 ] 	Training Accuracy: 12.62%
[ Fri May 12 07:26:25 2023 ] Eval epoch: 2
[ Fri May 12 07:26:41 2023 ] 	Mean test loss of 120 batches: 3.076218605041504.
[ Fri May 12 07:26:41 2023 ] 	Top1: 16.33%
[ Fri May 12 07:26:41 2023 ] 	Top5: 51.83%
[ Fri May 12 07:26:41 2023 ] Training epoch: 3
[ Fri May 12 07:27:00 2023 ] 	Batch(39/480) done. Loss: 2.8199  lr:0.100000  network_time: 0.0112
[ Fri May 12 07:27:48 2023 ] 	Batch(139/480) done. Loss: 3.1836  lr:0.100000  network_time: 0.0113
[ Fri May 12 07:28:35 2023 ] 	Batch(239/480) done. Loss: 2.5915  lr:0.100000  network_time: 0.0115
[ Fri May 12 07:29:23 2023 ] 	Batch(339/480) done. Loss: 3.3368  lr:0.100000  network_time: 0.0118
[ Fri May 12 07:30:10 2023 ] 	Batch(439/480) done. Loss: 3.0295  lr:0.100000  network_time: 0.0113
[ Fri May 12 07:30:29 2023 ] 	Training Accuracy: 19.04%
[ Fri May 12 07:30:29 2023 ] Eval epoch: 3
[ Fri May 12 07:30:46 2023 ] 	Mean test loss of 120 batches: 2.506829261779785.
[ Fri May 12 07:30:46 2023 ] 	Top1: 26.83%
[ Fri May 12 07:30:46 2023 ] 	Top5: 69.33%
[ Fri May 12 07:30:46 2023 ] Training epoch: 4
[ Fri May 12 07:31:14 2023 ] 	Batch(59/480) done. Loss: 2.7049  lr:0.100000  network_time: 0.0112
[ Fri May 12 07:32:02 2023 ] 	Batch(159/480) done. Loss: 2.2435  lr:0.100000  network_time: 0.0119
[ Fri May 12 07:32:49 2023 ] 	Batch(259/480) done. Loss: 2.0400  lr:0.100000  network_time: 0.0117
[ Fri May 12 07:33:37 2023 ] 	Batch(359/480) done. Loss: 1.8700  lr:0.100000  network_time: 0.0119
[ Fri May 12 07:34:24 2023 ] 	Batch(459/480) done. Loss: 3.0414  lr:0.100000  network_time: 0.0116
[ Fri May 12 07:34:34 2023 ] 	Training Accuracy: 28.08%
[ Fri May 12 07:34:34 2023 ] Eval epoch: 4
[ Fri May 12 07:34:50 2023 ] 	Mean test loss of 120 batches: 5.617269515991211.
[ Fri May 12 07:34:50 2023 ] 	Top1: 9.83%
[ Fri May 12 07:34:50 2023 ] 	Top5: 43.00%
[ Fri May 12 07:34:50 2023 ] Training epoch: 5
[ Fri May 12 07:35:28 2023 ] 	Batch(79/480) done. Loss: 2.0086  lr:0.100000  network_time: 0.0122
[ Fri May 12 07:36:16 2023 ] 	Batch(179/480) done. Loss: 2.4952  lr:0.100000  network_time: 0.0111
[ Fri May 12 07:37:03 2023 ] 	Batch(279/480) done. Loss: 2.0555  lr:0.100000  network_time: 0.0121
[ Fri May 12 07:37:51 2023 ] 	Batch(379/480) done. Loss: 2.2747  lr:0.100000  network_time: 0.0117
[ Fri May 12 07:38:38 2023 ] 	Batch(479/480) done. Loss: 1.8641  lr:0.100000  network_time: 0.0118
[ Fri May 12 07:38:38 2023 ] 	Training Accuracy: 33.58%
[ Fri May 12 07:38:38 2023 ] Eval epoch: 5
[ Fri May 12 07:38:55 2023 ] 	Mean test loss of 120 batches: 2.0543911457061768.
[ Fri May 12 07:38:55 2023 ] 	Top1: 40.83%
[ Fri May 12 07:38:55 2023 ] 	Top5: 88.17%
[ Fri May 12 07:38:55 2023 ] Training epoch: 6
[ Fri May 12 07:39:42 2023 ] 	Batch(99/480) done. Loss: 2.1888  lr:0.100000  network_time: 0.0115
[ Fri May 12 07:40:30 2023 ] 	Batch(199/480) done. Loss: 2.7409  lr:0.100000  network_time: 0.0116
[ Fri May 12 07:41:17 2023 ] 	Batch(299/480) done. Loss: 1.7126  lr:0.100000  network_time: 0.0122
[ Fri May 12 07:42:05 2023 ] 	Batch(399/480) done. Loss: 1.4843  lr:0.100000  network_time: 0.0120
[ Fri May 12 07:42:43 2023 ] 	Training Accuracy: 38.42%
[ Fri May 12 07:42:43 2023 ] Eval epoch: 6
[ Fri May 12 07:42:59 2023 ] 	Mean test loss of 120 batches: 1.6633931398391724.
[ Fri May 12 07:42:59 2023 ] 	Top1: 48.33%
[ Fri May 12 07:42:59 2023 ] 	Top5: 87.50%
[ Fri May 12 07:42:59 2023 ] Training epoch: 7
[ Fri May 12 07:43:09 2023 ] 	Batch(19/480) done. Loss: 1.6323  lr:0.100000  network_time: 0.0113
[ Fri May 12 07:43:56 2023 ] 	Batch(119/480) done. Loss: 1.8456  lr:0.100000  network_time: 0.0125
[ Fri May 12 07:44:44 2023 ] 	Batch(219/480) done. Loss: 1.6964  lr:0.100000  network_time: 0.0124
[ Fri May 12 07:45:31 2023 ] 	Batch(319/480) done. Loss: 1.6135  lr:0.100000  network_time: 0.0119
[ Fri May 12 07:46:19 2023 ] 	Batch(419/480) done. Loss: 3.0661  lr:0.100000  network_time: 0.0114
[ Fri May 12 07:46:48 2023 ] 	Training Accuracy: 43.29%
[ Fri May 12 07:46:48 2023 ] Eval epoch: 7
[ Fri May 12 07:47:04 2023 ] 	Mean test loss of 120 batches: 1.6538276672363281.
[ Fri May 12 07:47:04 2023 ] 	Top1: 50.83%
[ Fri May 12 07:47:04 2023 ] 	Top5: 90.33%
[ Fri May 12 07:47:04 2023 ] Training epoch: 8
[ Fri May 12 07:47:23 2023 ] 	Batch(39/480) done. Loss: 1.3354  lr:0.100000  network_time: 0.0118
[ Fri May 12 07:48:11 2023 ] 	Batch(139/480) done. Loss: 1.0987  lr:0.100000  network_time: 0.0118
[ Fri May 12 07:48:58 2023 ] 	Batch(239/480) done. Loss: 0.9163  lr:0.100000  network_time: 0.0117
[ Fri May 12 07:49:46 2023 ] 	Batch(339/480) done. Loss: 0.9495  lr:0.100000  network_time: 0.0116
[ Fri May 12 07:50:33 2023 ] 	Batch(439/480) done. Loss: 2.2701  lr:0.100000  network_time: 0.0119
[ Fri May 12 07:50:52 2023 ] 	Training Accuracy: 49.88%
[ Fri May 12 07:50:52 2023 ] Eval epoch: 8
[ Fri May 12 07:51:09 2023 ] 	Mean test loss of 120 batches: 1.657355546951294.
[ Fri May 12 07:51:09 2023 ] 	Top1: 49.17%
[ Fri May 12 07:51:09 2023 ] 	Top5: 92.67%
[ Fri May 12 07:51:09 2023 ] Training epoch: 9
[ Fri May 12 07:51:37 2023 ] 	Batch(59/480) done. Loss: 1.4447  lr:0.100000  network_time: 0.0118
[ Fri May 12 07:52:25 2023 ] 	Batch(159/480) done. Loss: 1.2023  lr:0.100000  network_time: 0.0117
[ Fri May 12 07:53:12 2023 ] 	Batch(259/480) done. Loss: 1.3395  lr:0.100000  network_time: 0.0117
[ Fri May 12 07:54:00 2023 ] 	Batch(359/480) done. Loss: 0.5539  lr:0.100000  network_time: 0.0115
[ Fri May 12 07:54:47 2023 ] 	Batch(459/480) done. Loss: 1.3746  lr:0.100000  network_time: 0.0114
[ Fri May 12 07:54:57 2023 ] 	Training Accuracy: 57.58%
[ Fri May 12 07:54:57 2023 ] Eval epoch: 9
[ Fri May 12 07:55:13 2023 ] 	Mean test loss of 120 batches: 2.5313608646392822.
[ Fri May 12 07:55:13 2023 ] 	Top1: 54.83%
[ Fri May 12 07:55:13 2023 ] 	Top5: 91.83%
[ Fri May 12 07:55:13 2023 ] Training epoch: 10
[ Fri May 12 07:55:51 2023 ] 	Batch(79/480) done. Loss: 2.7769  lr:0.100000  network_time: 0.0123
[ Fri May 12 07:56:39 2023 ] 	Batch(179/480) done. Loss: 1.8969  lr:0.100000  network_time: 0.0113
[ Fri May 12 07:57:26 2023 ] 	Batch(279/480) done. Loss: 1.9212  lr:0.100000  network_time: 0.0120
[ Fri May 12 07:58:14 2023 ] 	Batch(379/480) done. Loss: 0.7559  lr:0.100000  network_time: 0.0119
[ Fri May 12 07:59:01 2023 ] 	Batch(479/480) done. Loss: 2.0996  lr:0.100000  network_time: 0.0114
[ Fri May 12 07:59:01 2023 ] 	Training Accuracy: 63.00%
[ Fri May 12 07:59:01 2023 ] Eval epoch: 10
[ Fri May 12 07:59:18 2023 ] 	Mean test loss of 120 batches: 2.2853353023529053.
[ Fri May 12 07:59:18 2023 ] 	Top1: 56.00%
[ Fri May 12 07:59:18 2023 ] 	Top5: 89.17%
[ Fri May 12 07:59:18 2023 ] Training epoch: 11
[ Fri May 12 08:00:05 2023 ] 	Batch(99/480) done. Loss: 1.0495  lr:0.100000  network_time: 0.0114
[ Fri May 12 08:00:53 2023 ] 	Batch(199/480) done. Loss: 0.9476  lr:0.100000  network_time: 0.0115
[ Fri May 12 08:01:40 2023 ] 	Batch(299/480) done. Loss: 1.3126  lr:0.100000  network_time: 0.0118
[ Fri May 12 08:02:28 2023 ] 	Batch(399/480) done. Loss: 0.5780  lr:0.100000  network_time: 0.0122
[ Fri May 12 08:03:06 2023 ] 	Training Accuracy: 67.96%
[ Fri May 12 08:03:06 2023 ] Eval epoch: 11
[ Fri May 12 08:03:22 2023 ] 	Mean test loss of 120 batches: 1.2697426080703735.
[ Fri May 12 08:03:22 2023 ] 	Top1: 63.50%
[ Fri May 12 08:03:22 2023 ] 	Top5: 94.50%
[ Fri May 12 08:03:22 2023 ] Training epoch: 12
[ Fri May 12 08:03:32 2023 ] 	Batch(19/480) done. Loss: 0.5584  lr:0.100000  network_time: 0.0110
[ Fri May 12 08:04:19 2023 ] 	Batch(119/480) done. Loss: 0.4624  lr:0.100000  network_time: 0.0122
[ Fri May 12 08:05:07 2023 ] 	Batch(219/480) done. Loss: 1.0310  lr:0.100000  network_time: 0.0115
[ Fri May 12 08:05:54 2023 ] 	Batch(319/480) done. Loss: 0.3749  lr:0.100000  network_time: 0.0127
[ Fri May 12 08:06:42 2023 ] 	Batch(419/480) done. Loss: 1.1539  lr:0.100000  network_time: 0.0115
[ Fri May 12 08:07:10 2023 ] 	Training Accuracy: 73.50%
[ Fri May 12 08:07:11 2023 ] Eval epoch: 12
[ Fri May 12 08:07:27 2023 ] 	Mean test loss of 120 batches: 0.7761774063110352.
[ Fri May 12 08:07:27 2023 ] 	Top1: 80.33%
[ Fri May 12 08:07:27 2023 ] 	Top5: 97.83%
[ Fri May 12 08:07:27 2023 ] Training epoch: 13
[ Fri May 12 08:07:46 2023 ] 	Batch(39/480) done. Loss: 0.7685  lr:0.100000  network_time: 0.0113
[ Fri May 12 08:08:34 2023 ] 	Batch(139/480) done. Loss: 0.6820  lr:0.100000  network_time: 0.0118
[ Fri May 12 08:09:21 2023 ] 	Batch(239/480) done. Loss: 0.3542  lr:0.100000  network_time: 0.0112
[ Fri May 12 08:10:09 2023 ] 	Batch(339/480) done. Loss: 1.1711  lr:0.100000  network_time: 0.0116
[ Fri May 12 08:10:56 2023 ] 	Batch(439/480) done. Loss: 0.4376  lr:0.100000  network_time: 0.0122
[ Fri May 12 08:11:15 2023 ] 	Training Accuracy: 77.04%
[ Fri May 12 08:11:15 2023 ] Eval epoch: 13
[ Fri May 12 08:11:32 2023 ] 	Mean test loss of 120 batches: 0.76197749376297.
[ Fri May 12 08:11:32 2023 ] 	Top1: 76.00%
[ Fri May 12 08:11:32 2023 ] 	Top5: 98.17%
[ Fri May 12 08:11:32 2023 ] Training epoch: 14
[ Fri May 12 08:12:00 2023 ] 	Batch(59/480) done. Loss: 0.2211  lr:0.100000  network_time: 0.0115
[ Fri May 12 08:12:48 2023 ] 	Batch(159/480) done. Loss: 0.2043  lr:0.100000  network_time: 0.0115
[ Fri May 12 08:13:35 2023 ] 	Batch(259/480) done. Loss: 0.3192  lr:0.100000  network_time: 0.0123
[ Fri May 12 08:14:23 2023 ] 	Batch(359/480) done. Loss: 1.3312  lr:0.100000  network_time: 0.0122
[ Fri May 12 08:15:11 2023 ] 	Batch(459/480) done. Loss: 0.2184  lr:0.100000  network_time: 0.0117
[ Fri May 12 08:15:20 2023 ] 	Training Accuracy: 77.79%
[ Fri May 12 08:15:20 2023 ] Eval epoch: 14
[ Fri May 12 08:15:37 2023 ] 	Mean test loss of 120 batches: 0.7629220485687256.
[ Fri May 12 08:15:37 2023 ] 	Top1: 75.00%
[ Fri May 12 08:15:37 2023 ] 	Top5: 97.67%
[ Fri May 12 08:15:37 2023 ] Training epoch: 15
[ Fri May 12 08:16:15 2023 ] 	Batch(79/480) done. Loss: 1.1299  lr:0.100000  network_time: 0.0112
[ Fri May 12 08:17:02 2023 ] 	Batch(179/480) done. Loss: 0.1878  lr:0.100000  network_time: 0.0115
[ Fri May 12 08:17:50 2023 ] 	Batch(279/480) done. Loss: 0.1731  lr:0.100000  network_time: 0.0119
[ Fri May 12 08:18:37 2023 ] 	Batch(379/480) done. Loss: 0.1000  lr:0.100000  network_time: 0.0114
[ Fri May 12 08:19:25 2023 ] 	Batch(479/480) done. Loss: 0.5931  lr:0.100000  network_time: 0.0114
[ Fri May 12 08:19:25 2023 ] 	Training Accuracy: 80.29%
[ Fri May 12 08:19:25 2023 ] Eval epoch: 15
[ Fri May 12 08:19:42 2023 ] 	Mean test loss of 120 batches: 0.49177876114845276.
[ Fri May 12 08:19:42 2023 ] 	Top1: 84.67%
[ Fri May 12 08:19:42 2023 ] 	Top5: 99.00%
[ Fri May 12 08:19:42 2023 ] Training epoch: 16
[ Fri May 12 08:20:29 2023 ] 	Batch(99/480) done. Loss: 0.0296  lr:0.100000  network_time: 0.0113
[ Fri May 12 08:21:17 2023 ] 	Batch(199/480) done. Loss: 0.5781  lr:0.100000  network_time: 0.0115
[ Fri May 12 08:22:04 2023 ] 	Batch(299/480) done. Loss: 0.5003  lr:0.100000  network_time: 0.0117
[ Fri May 12 08:22:52 2023 ] 	Batch(399/480) done. Loss: 0.5520  lr:0.100000  network_time: 0.0116
[ Fri May 12 08:23:30 2023 ] 	Training Accuracy: 82.63%
[ Fri May 12 08:23:30 2023 ] Eval epoch: 16
[ Fri May 12 08:23:46 2023 ] 	Mean test loss of 120 batches: 0.7495534420013428.
[ Fri May 12 08:23:46 2023 ] 	Top1: 77.17%
[ Fri May 12 08:23:46 2023 ] 	Top5: 98.50%
[ Fri May 12 08:23:46 2023 ] Training epoch: 17
[ Fri May 12 08:23:56 2023 ] 	Batch(19/480) done. Loss: 0.1007  lr:0.100000  network_time: 0.0125
[ Fri May 12 08:24:43 2023 ] 	Batch(119/480) done. Loss: 1.5046  lr:0.100000  network_time: 0.0123
[ Fri May 12 08:25:31 2023 ] 	Batch(219/480) done. Loss: 0.4712  lr:0.100000  network_time: 0.0113
[ Fri May 12 08:26:18 2023 ] 	Batch(319/480) done. Loss: 0.3219  lr:0.100000  network_time: 0.0120
[ Fri May 12 08:27:06 2023 ] 	Batch(419/480) done. Loss: 0.7059  lr:0.100000  network_time: 0.0115
[ Fri May 12 08:27:34 2023 ] 	Training Accuracy: 82.58%
[ Fri May 12 08:27:34 2023 ] Eval epoch: 17
[ Fri May 12 08:27:51 2023 ] 	Mean test loss of 120 batches: 0.4281693696975708.
[ Fri May 12 08:27:51 2023 ] 	Top1: 88.83%
[ Fri May 12 08:27:51 2023 ] 	Top5: 98.33%
[ Fri May 12 08:27:51 2023 ] Training epoch: 18
[ Fri May 12 08:28:10 2023 ] 	Batch(39/480) done. Loss: 1.9251  lr:0.100000  network_time: 0.0120
[ Fri May 12 08:28:57 2023 ] 	Batch(139/480) done. Loss: 0.3240  lr:0.100000  network_time: 0.0115
[ Fri May 12 08:29:45 2023 ] 	Batch(239/480) done. Loss: 0.7822  lr:0.100000  network_time: 0.0112
[ Fri May 12 08:30:33 2023 ] 	Batch(339/480) done. Loss: 0.9021  lr:0.100000  network_time: 0.0113
[ Fri May 12 08:31:20 2023 ] 	Batch(439/480) done. Loss: 0.3849  lr:0.100000  network_time: 0.0117
[ Fri May 12 08:31:39 2023 ] 	Training Accuracy: 87.08%
[ Fri May 12 08:31:39 2023 ] Eval epoch: 18
[ Fri May 12 08:31:56 2023 ] 	Mean test loss of 120 batches: 0.580837607383728.
[ Fri May 12 08:31:56 2023 ] 	Top1: 83.33%
[ Fri May 12 08:31:56 2023 ] 	Top5: 98.00%
[ Fri May 12 08:31:56 2023 ] Training epoch: 19
[ Fri May 12 08:32:24 2023 ] 	Batch(59/480) done. Loss: 0.3815  lr:0.100000  network_time: 0.0117
[ Fri May 12 08:33:12 2023 ] 	Batch(159/480) done. Loss: 0.0613  lr:0.100000  network_time: 0.0117
[ Fri May 12 08:33:59 2023 ] 	Batch(259/480) done. Loss: 0.4395  lr:0.100000  network_time: 0.0114
[ Fri May 12 08:34:47 2023 ] 	Batch(359/480) done. Loss: 0.3504  lr:0.100000  network_time: 0.0115
[ Fri May 12 08:35:34 2023 ] 	Batch(459/480) done. Loss: 0.3144  lr:0.100000  network_time: 0.0114
[ Fri May 12 08:35:44 2023 ] 	Training Accuracy: 88.25%
[ Fri May 12 08:35:44 2023 ] Eval epoch: 19
[ Fri May 12 08:36:00 2023 ] 	Mean test loss of 120 batches: 0.9316609501838684.
[ Fri May 12 08:36:00 2023 ] 	Top1: 84.83%
[ Fri May 12 08:36:00 2023 ] 	Top5: 97.83%
[ Fri May 12 08:36:00 2023 ] Training epoch: 20
[ Fri May 12 08:36:38 2023 ] 	Batch(79/480) done. Loss: 0.1718  lr:0.100000  network_time: 0.0115
[ Fri May 12 08:37:26 2023 ] 	Batch(179/480) done. Loss: 0.6305  lr:0.100000  network_time: 0.0112
[ Fri May 12 08:38:13 2023 ] 	Batch(279/480) done. Loss: 0.4345  lr:0.100000  network_time: 0.0116
[ Fri May 12 08:39:01 2023 ] 	Batch(379/480) done. Loss: 0.7182  lr:0.100000  network_time: 0.0114
[ Fri May 12 08:39:48 2023 ] 	Batch(479/480) done. Loss: 0.3823  lr:0.100000  network_time: 0.0117
[ Fri May 12 08:39:48 2023 ] 	Training Accuracy: 88.96%
[ Fri May 12 08:39:48 2023 ] Eval epoch: 20
[ Fri May 12 08:40:05 2023 ] 	Mean test loss of 120 batches: 0.5820111036300659.
[ Fri May 12 08:40:05 2023 ] 	Top1: 88.33%
[ Fri May 12 08:40:05 2023 ] 	Top5: 99.17%
[ Fri May 12 08:40:05 2023 ] Training epoch: 21
[ Fri May 12 08:40:52 2023 ] 	Batch(99/480) done. Loss: 0.0796  lr:0.010000  network_time: 0.0116
[ Fri May 12 08:41:40 2023 ] 	Batch(199/480) done. Loss: 0.0680  lr:0.010000  network_time: 0.0117
[ Fri May 12 08:42:27 2023 ] 	Batch(299/480) done. Loss: 0.1391  lr:0.010000  network_time: 0.0115
[ Fri May 12 08:43:15 2023 ] 	Batch(399/480) done. Loss: 0.0771  lr:0.010000  network_time: 0.0120
[ Fri May 12 08:43:53 2023 ] 	Training Accuracy: 95.87%
[ Fri May 12 08:43:53 2023 ] Eval epoch: 21
[ Fri May 12 08:44:09 2023 ] 	Mean test loss of 120 batches: 0.05442649498581886.
[ Fri May 12 08:44:09 2023 ] 	Top1: 98.83%
[ Fri May 12 08:44:09 2023 ] 	Top5: 100.00%
[ Fri May 12 08:44:09 2023 ] Training epoch: 22
[ Fri May 12 08:44:19 2023 ] 	Batch(19/480) done. Loss: 0.0992  lr:0.010000  network_time: 0.0119
[ Fri May 12 08:45:07 2023 ] 	Batch(119/480) done. Loss: 0.0239  lr:0.010000  network_time: 0.0115
[ Fri May 12 08:45:54 2023 ] 	Batch(219/480) done. Loss: 0.0237  lr:0.010000  network_time: 0.0122
[ Fri May 12 08:46:42 2023 ] 	Batch(319/480) done. Loss: 0.0177  lr:0.010000  network_time: 0.0123
[ Fri May 12 08:47:29 2023 ] 	Batch(419/480) done. Loss: 0.1126  lr:0.010000  network_time: 0.0120
[ Fri May 12 08:47:58 2023 ] 	Training Accuracy: 97.83%
[ Fri May 12 08:47:58 2023 ] Eval epoch: 22
[ Fri May 12 08:48:14 2023 ] 	Mean test loss of 120 batches: 0.08098476380109787.
[ Fri May 12 08:48:14 2023 ] 	Top1: 99.00%
[ Fri May 12 08:48:14 2023 ] 	Top5: 99.83%
[ Fri May 12 08:48:14 2023 ] Training epoch: 23
[ Fri May 12 08:48:33 2023 ] 	Batch(39/480) done. Loss: 0.0167  lr:0.010000  network_time: 0.0125
[ Fri May 12 08:49:21 2023 ] 	Batch(139/480) done. Loss: 0.1068  lr:0.010000  network_time: 0.0119
[ Fri May 12 08:50:08 2023 ] 	Batch(239/480) done. Loss: 0.0380  lr:0.010000  network_time: 0.0115
[ Fri May 12 08:50:56 2023 ] 	Batch(339/480) done. Loss: 0.0211  lr:0.010000  network_time: 0.0119
[ Fri May 12 08:51:44 2023 ] 	Batch(439/480) done. Loss: 0.0295  lr:0.010000  network_time: 0.0119
[ Fri May 12 08:52:03 2023 ] 	Training Accuracy: 98.25%
[ Fri May 12 08:52:03 2023 ] Eval epoch: 23
[ Fri May 12 08:52:19 2023 ] 	Mean test loss of 120 batches: 0.14293649792671204.
[ Fri May 12 08:52:19 2023 ] 	Top1: 97.50%
[ Fri May 12 08:52:19 2023 ] 	Top5: 99.83%
[ Fri May 12 08:52:19 2023 ] Training epoch: 24
[ Fri May 12 08:52:48 2023 ] 	Batch(59/480) done. Loss: 0.1829  lr:0.010000  network_time: 0.0112
[ Fri May 12 08:53:35 2023 ] 	Batch(159/480) done. Loss: 0.0179  lr:0.010000  network_time: 0.0115
[ Fri May 12 08:54:23 2023 ] 	Batch(259/480) done. Loss: 0.0437  lr:0.010000  network_time: 0.0115
[ Fri May 12 08:55:10 2023 ] 	Batch(359/480) done. Loss: 0.2077  lr:0.010000  network_time: 0.0113
[ Fri May 12 08:55:58 2023 ] 	Batch(459/480) done. Loss: 0.2709  lr:0.010000  network_time: 0.0122
[ Fri May 12 08:56:07 2023 ] 	Training Accuracy: 98.71%
[ Fri May 12 08:56:07 2023 ] Eval epoch: 24
[ Fri May 12 08:56:24 2023 ] 	Mean test loss of 120 batches: 0.023221004754304886.
[ Fri May 12 08:56:24 2023 ] 	Top1: 99.67%
[ Fri May 12 08:56:24 2023 ] 	Top5: 100.00%
[ Fri May 12 08:56:24 2023 ] Training epoch: 25
[ Fri May 12 08:57:02 2023 ] 	Batch(79/480) done. Loss: 0.0533  lr:0.010000  network_time: 0.0117
[ Fri May 12 08:57:50 2023 ] 	Batch(179/480) done. Loss: 0.0596  lr:0.010000  network_time: 0.0111
[ Fri May 12 08:58:37 2023 ] 	Batch(279/480) done. Loss: 0.0181  lr:0.010000  network_time: 0.0113
[ Fri May 12 08:59:25 2023 ] 	Batch(379/480) done. Loss: 0.0110  lr:0.010000  network_time: 0.0117
[ Fri May 12 09:00:12 2023 ] 	Batch(479/480) done. Loss: 0.0322  lr:0.010000  network_time: 0.0110
[ Fri May 12 09:00:12 2023 ] 	Training Accuracy: 98.67%
[ Fri May 12 09:00:12 2023 ] Eval epoch: 25
[ Fri May 12 09:00:29 2023 ] 	Mean test loss of 120 batches: 0.027365632355213165.
[ Fri May 12 09:00:29 2023 ] 	Top1: 99.17%
[ Fri May 12 09:00:29 2023 ] 	Top5: 100.00%
[ Fri May 12 09:00:29 2023 ] Training epoch: 26
[ Fri May 12 09:01:16 2023 ] 	Batch(99/480) done. Loss: 0.0221  lr:0.001000  network_time: 0.0115
[ Fri May 12 09:02:04 2023 ] 	Batch(199/480) done. Loss: 0.0820  lr:0.001000  network_time: 0.0113
[ Fri May 12 09:02:52 2023 ] 	Batch(299/480) done. Loss: 0.0124  lr:0.001000  network_time: 0.0111
[ Fri May 12 09:03:39 2023 ] 	Batch(399/480) done. Loss: 0.0019  lr:0.001000  network_time: 0.0116
[ Fri May 12 09:04:17 2023 ] 	Training Accuracy: 99.17%
[ Fri May 12 09:04:17 2023 ] Eval epoch: 26
[ Fri May 12 09:04:34 2023 ] 	Mean test loss of 120 batches: 0.026602784171700478.
[ Fri May 12 09:04:34 2023 ] 	Top1: 99.50%
[ Fri May 12 09:04:34 2023 ] 	Top5: 100.00%
[ Fri May 12 09:04:34 2023 ] Training epoch: 27
[ Fri May 12 09:04:43 2023 ] 	Batch(19/480) done. Loss: 0.0069  lr:0.001000  network_time: 0.0125
[ Fri May 12 09:05:31 2023 ] 	Batch(119/480) done. Loss: 0.0365  lr:0.001000  network_time: 0.0116
[ Fri May 12 09:06:18 2023 ] 	Batch(219/480) done. Loss: 0.0701  lr:0.001000  network_time: 0.0112
[ Fri May 12 09:07:06 2023 ] 	Batch(319/480) done. Loss: 0.0237  lr:0.001000  network_time: 0.0114
[ Fri May 12 09:07:53 2023 ] 	Batch(419/480) done. Loss: 0.0412  lr:0.001000  network_time: 0.0126
[ Fri May 12 09:08:22 2023 ] 	Training Accuracy: 99.33%
[ Fri May 12 09:08:22 2023 ] Eval epoch: 27
[ Fri May 12 09:08:38 2023 ] 	Mean test loss of 120 batches: 0.015786681324243546.
[ Fri May 12 09:08:38 2023 ] 	Top1: 99.83%
[ Fri May 12 09:08:38 2023 ] 	Top5: 100.00%
[ Fri May 12 09:08:38 2023 ] Training epoch: 28
[ Fri May 12 09:08:58 2023 ] 	Batch(39/480) done. Loss: 0.0511  lr:0.001000  network_time: 0.0119
[ Fri May 12 09:09:45 2023 ] 	Batch(139/480) done. Loss: 0.0374  lr:0.001000  network_time: 0.0111
[ Fri May 12 09:10:33 2023 ] 	Batch(239/480) done. Loss: 0.0070  lr:0.001000  network_time: 0.0114
[ Fri May 12 09:11:20 2023 ] 	Batch(339/480) done. Loss: 0.4575  lr:0.001000  network_time: 0.0114
[ Fri May 12 09:12:08 2023 ] 	Batch(439/480) done. Loss: 0.0874  lr:0.001000  network_time: 0.0118
[ Fri May 12 09:12:27 2023 ] 	Training Accuracy: 99.29%
[ Fri May 12 09:12:27 2023 ] Eval epoch: 28
[ Fri May 12 09:12:43 2023 ] 	Mean test loss of 120 batches: 0.017571423202753067.
[ Fri May 12 09:12:43 2023 ] 	Top1: 99.67%
[ Fri May 12 09:12:43 2023 ] 	Top5: 100.00%
[ Fri May 12 09:12:43 2023 ] Training epoch: 29
[ Fri May 12 09:13:12 2023 ] 	Batch(59/480) done. Loss: 0.2327  lr:0.001000  network_time: 0.0117
[ Fri May 12 09:13:59 2023 ] 	Batch(159/480) done. Loss: 0.0106  lr:0.001000  network_time: 0.0114
[ Fri May 12 09:14:47 2023 ] 	Batch(259/480) done. Loss: 0.1978  lr:0.001000  network_time: 0.0111
[ Fri May 12 09:15:35 2023 ] 	Batch(359/480) done. Loss: 0.0591  lr:0.001000  network_time: 0.0110
[ Fri May 12 09:16:22 2023 ] 	Batch(459/480) done. Loss: 0.0372  lr:0.001000  network_time: 0.0112
[ Fri May 12 09:16:32 2023 ] 	Training Accuracy: 99.25%
[ Fri May 12 09:16:32 2023 ] Eval epoch: 29
[ Fri May 12 09:16:48 2023 ] 	Mean test loss of 120 batches: 0.025848986580967903.
[ Fri May 12 09:16:48 2023 ] 	Top1: 99.50%
[ Fri May 12 09:16:48 2023 ] 	Top5: 100.00%
[ Fri May 12 09:16:48 2023 ] Training epoch: 30
[ Fri May 12 09:17:26 2023 ] 	Batch(79/480) done. Loss: 0.0028  lr:0.001000  network_time: 0.0114
[ Fri May 12 09:18:14 2023 ] 	Batch(179/480) done. Loss: 0.0525  lr:0.001000  network_time: 0.0114
[ Fri May 12 09:19:01 2023 ] 	Batch(279/480) done. Loss: 0.0147  lr:0.001000  network_time: 0.0113
[ Fri May 12 09:19:49 2023 ] 	Batch(379/480) done. Loss: 0.0623  lr:0.001000  network_time: 0.0114
[ Fri May 12 09:20:36 2023 ] 	Batch(479/480) done. Loss: 0.0191  lr:0.001000  network_time: 0.0119
[ Fri May 12 09:20:36 2023 ] 	Training Accuracy: 99.13%
[ Fri May 12 09:20:36 2023 ] Eval epoch: 30
[ Fri May 12 09:20:53 2023 ] 	Mean test loss of 120 batches: 0.02042149379849434.
[ Fri May 12 09:20:53 2023 ] 	Top1: 99.67%
[ Fri May 12 09:20:53 2023 ] 	Top5: 100.00%
