[ Fri May 12 18:57:18 2023 ] NUM WORKER: 1
[ Fri May 12 19:00:00 2023 ] Parameters:
{'work_dir': './work_dir/sibi_individual_outer_group_ShiftGCN_mod_3_joint_n_5_kfold_fold_3', 'model_saved_name': './save_models/sibi_individual_outer_group_ShiftGCN_mod_3_joint_n_5_kfold_fold_3', 'Experiment_name': 'sibi_individual_outer_group_ShiftGCN_mod_3_joint_n_5_kfold', 'config': './config/recalculated/train_sibi_with_mouth_augmented_individual_outer_group_shift_joint_mod_3.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 2, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'n_splits': 5, 'feeder': 'feeders.feeder_hsd.Feeder', 'num_worker': 1, 'train_feeder_args': {'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': -1, 'normalization': False}, 'test_feeder_args': None, 'data_path': './data/augmented_recalculate_normalized', 'model': 'model.shift_gcn.Model', 'model_args': {'num_class': 50, 'num_person': 1, 'num_point': 115, 'graph_group': [[0, 39], [40, 60], [61, 81], [82, 114]], 'method': 'grouped.outer', 'weight': 3, 'graph': 'graph.skeleton_with_mouth.SkeletonWithMouth', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [20, 25], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 5, 'test_batch_size': 5, 'start_epoch': 0, 'num_epoch': 30, 'folds_range': [2, 5], 'weight_decay': 0.0001, 'only_train_part': True, 'only_train_epoch': 1, 'warm_up_epoch': 0}

[ Fri May 12 19:00:00 2023 ] Training epoch: 1
[ Fri May 12 19:00:49 2023 ] 	Batch(99/480) done. Loss: 3.5781  lr:0.100000  network_time: 0.0111
[ Fri May 12 19:01:38 2023 ] 	Batch(199/480) done. Loss: 3.4281  lr:0.100000  network_time: 0.0110
[ Fri May 12 19:02:27 2023 ] 	Batch(299/480) done. Loss: 3.5131  lr:0.100000  network_time: 0.0110
[ Fri May 12 19:03:15 2023 ] 	Batch(399/480) done. Loss: 3.9329  lr:0.100000  network_time: 0.0118
[ Fri May 12 19:03:54 2023 ] 	Training Accuracy: 5.17%
[ Fri May 12 19:03:54 2023 ] Eval epoch: 1
[ Fri May 12 19:04:11 2023 ] 	Mean test loss of 120 batches: 6.6954569816589355.
[ Fri May 12 19:04:11 2023 ] 	Top1: 8.50%
[ Fri May 12 19:04:11 2023 ] 	Top5: 29.83%
[ Fri May 12 19:04:11 2023 ] Training epoch: 2
[ Fri May 12 19:04:21 2023 ] 	Batch(19/480) done. Loss: 3.3251  lr:0.100000  network_time: 0.0111
[ Fri May 12 19:05:09 2023 ] 	Batch(119/480) done. Loss: 3.7958  lr:0.100000  network_time: 0.0114
[ Fri May 12 19:05:58 2023 ] 	Batch(219/480) done. Loss: 3.1777  lr:0.100000  network_time: 0.0114
[ Fri May 12 19:06:47 2023 ] 	Batch(319/480) done. Loss: 3.4693  lr:0.100000  network_time: 0.0112
[ Fri May 12 19:07:35 2023 ] 	Batch(419/480) done. Loss: 3.5326  lr:0.100000  network_time: 0.0114
[ Fri May 12 19:08:04 2023 ] 	Training Accuracy: 8.42%
[ Fri May 12 19:08:04 2023 ] Eval epoch: 2
[ Fri May 12 19:08:21 2023 ] 	Mean test loss of 120 batches: 6.917640686035156.
[ Fri May 12 19:08:21 2023 ] 	Top1: 12.83%
[ Fri May 12 19:08:21 2023 ] 	Top5: 43.67%
[ Fri May 12 19:08:21 2023 ] Training epoch: 3
[ Fri May 12 19:08:41 2023 ] 	Batch(39/480) done. Loss: 3.0221  lr:0.100000  network_time: 0.0111
[ Fri May 12 19:09:29 2023 ] 	Batch(139/480) done. Loss: 3.1364  lr:0.100000  network_time: 0.0110
[ Fri May 12 19:10:18 2023 ] 	Batch(239/480) done. Loss: 2.4971  lr:0.100000  network_time: 0.0111
[ Fri May 12 19:11:07 2023 ] 	Batch(339/480) done. Loss: 3.2065  lr:0.100000  network_time: 0.0119
[ Fri May 12 19:11:55 2023 ] 	Batch(439/480) done. Loss: 2.2550  lr:0.100000  network_time: 0.0110
[ Fri May 12 19:12:15 2023 ] 	Training Accuracy: 13.88%
[ Fri May 12 19:12:15 2023 ] Eval epoch: 3
[ Fri May 12 19:12:31 2023 ] 	Mean test loss of 120 batches: 3.8346633911132812.
[ Fri May 12 19:12:31 2023 ] 	Top1: 16.50%
[ Fri May 12 19:12:31 2023 ] 	Top5: 55.00%
[ Fri May 12 19:12:31 2023 ] Training epoch: 4
[ Fri May 12 19:13:01 2023 ] 	Batch(59/480) done. Loss: 2.5053  lr:0.100000  network_time: 0.0114
[ Fri May 12 19:13:49 2023 ] 	Batch(159/480) done. Loss: 2.3451  lr:0.100000  network_time: 0.0116
[ Fri May 12 19:14:38 2023 ] 	Batch(259/480) done. Loss: 2.5221  lr:0.100000  network_time: 0.0117
[ Fri May 12 19:15:27 2023 ] 	Batch(359/480) done. Loss: 1.9512  lr:0.100000  network_time: 0.0115
[ Fri May 12 19:16:15 2023 ] 	Batch(459/480) done. Loss: 2.9187  lr:0.100000  network_time: 0.0113
[ Fri May 12 19:16:25 2023 ] 	Training Accuracy: 20.21%
[ Fri May 12 19:16:25 2023 ] Eval epoch: 4
[ Fri May 12 19:16:42 2023 ] 	Mean test loss of 120 batches: 4.817964553833008.
[ Fri May 12 19:16:42 2023 ] 	Top1: 18.50%
[ Fri May 12 19:16:42 2023 ] 	Top5: 62.33%
[ Fri May 12 19:16:42 2023 ] Training epoch: 5
[ Fri May 12 19:17:21 2023 ] 	Batch(79/480) done. Loss: 2.1806  lr:0.100000  network_time: 0.0118
[ Fri May 12 19:18:09 2023 ] 	Batch(179/480) done. Loss: 1.8821  lr:0.100000  network_time: 0.0113
[ Fri May 12 19:18:58 2023 ] 	Batch(279/480) done. Loss: 1.9228  lr:0.100000  network_time: 0.0118
[ Fri May 12 19:19:47 2023 ] 	Batch(379/480) done. Loss: 2.4033  lr:0.100000  network_time: 0.0113
[ Fri May 12 19:20:35 2023 ] 	Batch(479/480) done. Loss: 1.5703  lr:0.100000  network_time: 0.0114
[ Fri May 12 19:20:35 2023 ] 	Training Accuracy: 28.83%
[ Fri May 12 19:20:35 2023 ] Eval epoch: 5
[ Fri May 12 19:20:52 2023 ] 	Mean test loss of 120 batches: 7.650877475738525.
[ Fri May 12 19:20:52 2023 ] 	Top1: 31.17%
[ Fri May 12 19:20:52 2023 ] 	Top5: 72.33%
[ Fri May 12 19:20:52 2023 ] Training epoch: 6
[ Fri May 12 19:21:41 2023 ] 	Batch(99/480) done. Loss: 3.4324  lr:0.100000  network_time: 0.0111
[ Fri May 12 19:22:29 2023 ] 	Batch(199/480) done. Loss: 2.0041  lr:0.100000  network_time: 0.0111
[ Fri May 12 19:23:18 2023 ] 	Batch(299/480) done. Loss: 1.7074  lr:0.100000  network_time: 0.0115
[ Fri May 12 19:24:07 2023 ] 	Batch(399/480) done. Loss: 2.6804  lr:0.100000  network_time: 0.0112
[ Fri May 12 19:24:46 2023 ] 	Training Accuracy: 36.25%
[ Fri May 12 19:24:46 2023 ] Eval epoch: 6
[ Fri May 12 19:25:02 2023 ] 	Mean test loss of 120 batches: 3.00445556640625.
[ Fri May 12 19:25:02 2023 ] 	Top1: 35.17%
[ Fri May 12 19:25:02 2023 ] 	Top5: 78.67%
[ Fri May 12 19:25:02 2023 ] Training epoch: 7
[ Fri May 12 19:25:12 2023 ] 	Batch(19/480) done. Loss: 1.5202  lr:0.100000  network_time: 0.0115
[ Fri May 12 19:26:01 2023 ] 	Batch(119/480) done. Loss: 1.6293  lr:0.100000  network_time: 0.0123
[ Fri May 12 19:26:50 2023 ] 	Batch(219/480) done. Loss: 1.6008  lr:0.100000  network_time: 0.0114
[ Fri May 12 19:27:38 2023 ] 	Batch(319/480) done. Loss: 0.7446  lr:0.100000  network_time: 0.0113
[ Fri May 12 19:28:27 2023 ] 	Batch(419/480) done. Loss: 1.7441  lr:0.100000  network_time: 0.0111
[ Fri May 12 19:28:56 2023 ] 	Training Accuracy: 44.67%
[ Fri May 12 19:28:56 2023 ] Eval epoch: 7
[ Fri May 12 19:29:13 2023 ] 	Mean test loss of 120 batches: 1.9202574491500854.
[ Fri May 12 19:29:13 2023 ] 	Top1: 47.67%
[ Fri May 12 19:29:13 2023 ] 	Top5: 86.83%
[ Fri May 12 19:29:13 2023 ] Training epoch: 8
[ Fri May 12 19:29:32 2023 ] 	Batch(39/480) done. Loss: 1.5406  lr:0.100000  network_time: 0.0110
[ Fri May 12 19:30:21 2023 ] 	Batch(139/480) done. Loss: 1.9718  lr:0.100000  network_time: 0.0115
[ Fri May 12 19:31:10 2023 ] 	Batch(239/480) done. Loss: 2.2942  lr:0.100000  network_time: 0.0110
[ Fri May 12 19:31:58 2023 ] 	Batch(339/480) done. Loss: 1.8735  lr:0.100000  network_time: 0.0110
[ Fri May 12 19:32:47 2023 ] 	Batch(439/480) done. Loss: 0.9170  lr:0.100000  network_time: 0.0112
[ Fri May 12 19:33:06 2023 ] 	Training Accuracy: 53.67%
[ Fri May 12 19:33:06 2023 ] Eval epoch: 8
[ Fri May 12 19:33:23 2023 ] 	Mean test loss of 120 batches: 1.346471905708313.
[ Fri May 12 19:33:23 2023 ] 	Top1: 57.83%
[ Fri May 12 19:33:23 2023 ] 	Top5: 93.17%
[ Fri May 12 19:33:23 2023 ] Training epoch: 9
[ Fri May 12 19:33:52 2023 ] 	Batch(59/480) done. Loss: 1.8378  lr:0.100000  network_time: 0.0114
[ Fri May 12 19:34:41 2023 ] 	Batch(159/480) done. Loss: 1.2158  lr:0.100000  network_time: 0.0113
[ Fri May 12 19:35:30 2023 ] 	Batch(259/480) done. Loss: 1.4952  lr:0.100000  network_time: 0.0111
[ Fri May 12 19:36:18 2023 ] 	Batch(359/480) done. Loss: 1.7337  lr:0.100000  network_time: 0.0112
[ Fri May 12 19:37:07 2023 ] 	Batch(459/480) done. Loss: 0.7775  lr:0.100000  network_time: 0.0117
[ Fri May 12 19:37:17 2023 ] 	Training Accuracy: 62.08%
[ Fri May 12 19:37:17 2023 ] Eval epoch: 9
[ Fri May 12 19:37:33 2023 ] 	Mean test loss of 120 batches: 1.6826187372207642.
[ Fri May 12 19:37:33 2023 ] 	Top1: 52.50%
[ Fri May 12 19:37:33 2023 ] 	Top5: 88.50%
[ Fri May 12 19:37:33 2023 ] Training epoch: 10
[ Fri May 12 19:38:12 2023 ] 	Batch(79/480) done. Loss: 1.8859  lr:0.100000  network_time: 0.0108
[ Fri May 12 19:39:01 2023 ] 	Batch(179/480) done. Loss: 0.6254  lr:0.100000  network_time: 0.0112
[ Fri May 12 19:39:50 2023 ] 	Batch(279/480) done. Loss: 0.7017  lr:0.100000  network_time: 0.0113
[ Fri May 12 19:40:38 2023 ] 	Batch(379/480) done. Loss: 1.4926  lr:0.100000  network_time: 0.0111
[ Fri May 12 19:41:27 2023 ] 	Batch(479/480) done. Loss: 1.0345  lr:0.100000  network_time: 0.0110
[ Fri May 12 19:41:27 2023 ] 	Training Accuracy: 66.83%
[ Fri May 12 19:41:27 2023 ] Eval epoch: 10
[ Fri May 12 19:41:44 2023 ] 	Mean test loss of 120 batches: 0.8440603017807007.
[ Fri May 12 19:41:44 2023 ] 	Top1: 73.67%
[ Fri May 12 19:41:44 2023 ] 	Top5: 96.33%
[ Fri May 12 19:41:44 2023 ] Training epoch: 11
[ Fri May 12 19:42:33 2023 ] 	Batch(99/480) done. Loss: 1.0857  lr:0.100000  network_time: 0.0107
[ Fri May 12 19:43:21 2023 ] 	Batch(199/480) done. Loss: 0.4959  lr:0.100000  network_time: 0.0111
[ Fri May 12 19:44:10 2023 ] 	Batch(299/480) done. Loss: 0.4552  lr:0.100000  network_time: 0.0109
[ Fri May 12 19:44:59 2023 ] 	Batch(399/480) done. Loss: 1.6799  lr:0.100000  network_time: 0.0112
[ Fri May 12 19:45:37 2023 ] 	Training Accuracy: 71.71%
[ Fri May 12 19:45:38 2023 ] Eval epoch: 11
[ Fri May 12 19:45:54 2023 ] 	Mean test loss of 120 batches: 0.8927267789840698.
[ Fri May 12 19:45:54 2023 ] 	Top1: 70.67%
[ Fri May 12 19:45:54 2023 ] 	Top5: 97.83%
[ Fri May 12 19:45:54 2023 ] Training epoch: 12
[ Fri May 12 19:46:04 2023 ] 	Batch(19/480) done. Loss: 0.6658  lr:0.100000  network_time: 0.0107
[ Fri May 12 19:46:53 2023 ] 	Batch(119/480) done. Loss: 0.3996  lr:0.100000  network_time: 0.0109
[ Fri May 12 19:47:41 2023 ] 	Batch(219/480) done. Loss: 0.0501  lr:0.100000  network_time: 0.0109
[ Fri May 12 19:48:30 2023 ] 	Batch(319/480) done. Loss: 0.4474  lr:0.100000  network_time: 0.0111
[ Fri May 12 19:49:19 2023 ] 	Batch(419/480) done. Loss: 0.5267  lr:0.100000  network_time: 0.0112
[ Fri May 12 19:49:48 2023 ] 	Training Accuracy: 75.42%
[ Fri May 12 19:49:48 2023 ] Eval epoch: 12
[ Fri May 12 19:50:05 2023 ] 	Mean test loss of 120 batches: 0.7204999327659607.
[ Fri May 12 19:50:05 2023 ] 	Top1: 76.17%
[ Fri May 12 19:50:05 2023 ] 	Top5: 97.50%
[ Fri May 12 19:50:05 2023 ] Training epoch: 13
[ Fri May 12 19:50:24 2023 ] 	Batch(39/480) done. Loss: 0.4630  lr:0.100000  network_time: 0.0111
[ Fri May 12 19:51:13 2023 ] 	Batch(139/480) done. Loss: 0.9191  lr:0.100000  network_time: 0.0113
[ Fri May 12 19:52:02 2023 ] 	Batch(239/480) done. Loss: 0.4645  lr:0.100000  network_time: 0.0112
[ Fri May 12 19:52:50 2023 ] 	Batch(339/480) done. Loss: 0.6246  lr:0.100000  network_time: 0.0112
[ Fri May 12 19:53:39 2023 ] 	Batch(439/480) done. Loss: 0.2502  lr:0.100000  network_time: 0.0125
[ Fri May 12 19:53:58 2023 ] 	Training Accuracy: 79.38%
[ Fri May 12 19:53:58 2023 ] Eval epoch: 13
[ Fri May 12 19:54:15 2023 ] 	Mean test loss of 120 batches: 0.6612776517868042.
[ Fri May 12 19:54:15 2023 ] 	Top1: 83.67%
[ Fri May 12 19:54:15 2023 ] 	Top5: 98.83%
[ Fri May 12 19:54:15 2023 ] Training epoch: 14
[ Fri May 12 19:54:44 2023 ] 	Batch(59/480) done. Loss: 0.6488  lr:0.100000  network_time: 0.0111
[ Fri May 12 19:55:33 2023 ] 	Batch(159/480) done. Loss: 0.9802  lr:0.100000  network_time: 0.0116
[ Fri May 12 19:56:22 2023 ] 	Batch(259/480) done. Loss: 0.7304  lr:0.100000  network_time: 0.0113
[ Fri May 12 19:57:10 2023 ] 	Batch(359/480) done. Loss: 0.3769  lr:0.100000  network_time: 0.0111
[ Fri May 12 19:57:59 2023 ] 	Batch(459/480) done. Loss: 0.1323  lr:0.100000  network_time: 0.0111
[ Fri May 12 19:58:09 2023 ] 	Training Accuracy: 83.04%
[ Fri May 12 19:58:09 2023 ] Eval epoch: 14
[ Fri May 12 19:58:26 2023 ] 	Mean test loss of 120 batches: 0.3051029443740845.
[ Fri May 12 19:58:26 2023 ] 	Top1: 90.83%
[ Fri May 12 19:58:26 2023 ] 	Top5: 99.67%
[ Fri May 12 19:58:26 2023 ] Training epoch: 15
[ Fri May 12 19:59:05 2023 ] 	Batch(79/480) done. Loss: 0.5490  lr:0.100000  network_time: 0.0113
[ Fri May 12 19:59:53 2023 ] 	Batch(179/480) done. Loss: 0.0378  lr:0.100000  network_time: 0.0115
[ Fri May 12 20:00:42 2023 ] 	Batch(279/480) done. Loss: 0.3919  lr:0.100000  network_time: 0.0116
[ Fri May 12 20:01:31 2023 ] 	Batch(379/480) done. Loss: 0.2887  lr:0.100000  network_time: 0.0111
[ Fri May 12 20:02:19 2023 ] 	Batch(479/480) done. Loss: 0.0263  lr:0.100000  network_time: 0.0110
[ Fri May 12 20:02:19 2023 ] 	Training Accuracy: 85.21%
[ Fri May 12 20:02:19 2023 ] Eval epoch: 15
[ Fri May 12 20:02:36 2023 ] 	Mean test loss of 120 batches: 0.9167239665985107.
[ Fri May 12 20:02:36 2023 ] 	Top1: 76.50%
[ Fri May 12 20:02:36 2023 ] 	Top5: 98.00%
[ Fri May 12 20:02:36 2023 ] Training epoch: 16
[ Fri May 12 20:03:25 2023 ] 	Batch(99/480) done. Loss: 0.8376  lr:0.100000  network_time: 0.0109
[ Fri May 12 20:04:14 2023 ] 	Batch(199/480) done. Loss: 0.2727  lr:0.100000  network_time: 0.0114
[ Fri May 12 20:05:02 2023 ] 	Batch(299/480) done. Loss: 1.0693  lr:0.100000  network_time: 0.0111
[ Fri May 12 20:05:51 2023 ] 	Batch(399/480) done. Loss: 0.0758  lr:0.100000  network_time: 0.0116
[ Fri May 12 20:06:30 2023 ] 	Training Accuracy: 85.46%
[ Fri May 12 20:06:30 2023 ] Eval epoch: 16
[ Fri May 12 20:06:47 2023 ] 	Mean test loss of 120 batches: 2.2208166122436523.
[ Fri May 12 20:06:47 2023 ] 	Top1: 60.33%
[ Fri May 12 20:06:47 2023 ] 	Top5: 84.83%
[ Fri May 12 20:06:47 2023 ] Training epoch: 17
[ Fri May 12 20:06:56 2023 ] 	Batch(19/480) done. Loss: 0.9448  lr:0.100000  network_time: 0.0109
[ Fri May 12 20:07:45 2023 ] 	Batch(119/480) done. Loss: 0.9472  lr:0.100000  network_time: 0.0111
[ Fri May 12 20:08:34 2023 ] 	Batch(219/480) done. Loss: 0.1970  lr:0.100000  network_time: 0.0110
[ Fri May 12 20:09:22 2023 ] 	Batch(319/480) done. Loss: 0.1997  lr:0.100000  network_time: 0.0111
[ Fri May 12 20:10:11 2023 ] 	Batch(419/480) done. Loss: 0.4501  lr:0.100000  network_time: 0.0108
[ Fri May 12 20:10:40 2023 ] 	Training Accuracy: 83.38%
[ Fri May 12 20:10:40 2023 ] Eval epoch: 17
[ Fri May 12 20:10:57 2023 ] 	Mean test loss of 120 batches: 0.22623750567436218.
[ Fri May 12 20:10:57 2023 ] 	Top1: 91.17%
[ Fri May 12 20:10:57 2023 ] 	Top5: 100.00%
[ Fri May 12 20:10:57 2023 ] Training epoch: 18
[ Fri May 12 20:11:16 2023 ] 	Batch(39/480) done. Loss: 0.4051  lr:0.100000  network_time: 0.0112
[ Fri May 12 20:12:05 2023 ] 	Batch(139/480) done. Loss: 0.5393  lr:0.100000  network_time: 0.0110
[ Fri May 12 20:12:54 2023 ] 	Batch(239/480) done. Loss: 0.0954  lr:0.100000  network_time: 0.0112
[ Fri May 12 20:13:43 2023 ] 	Batch(339/480) done. Loss: 0.0749  lr:0.100000  network_time: 0.0115
[ Fri May 12 20:14:31 2023 ] 	Batch(439/480) done. Loss: 0.1514  lr:0.100000  network_time: 0.0116
[ Fri May 12 20:14:51 2023 ] 	Training Accuracy: 88.46%
[ Fri May 12 20:14:51 2023 ] Eval epoch: 18
[ Fri May 12 20:15:07 2023 ] 	Mean test loss of 120 batches: 0.3782652020454407.
[ Fri May 12 20:15:07 2023 ] 	Top1: 87.67%
[ Fri May 12 20:15:07 2023 ] 	Top5: 99.67%
[ Fri May 12 20:15:08 2023 ] Training epoch: 19
[ Fri May 12 20:15:37 2023 ] 	Batch(59/480) done. Loss: 0.0180  lr:0.100000  network_time: 0.0107
[ Fri May 12 20:16:25 2023 ] 	Batch(159/480) done. Loss: 0.3452  lr:0.100000  network_time: 0.0114
[ Fri May 12 20:17:14 2023 ] 	Batch(259/480) done. Loss: 0.4840  lr:0.100000  network_time: 0.0113
[ Fri May 12 20:18:03 2023 ] 	Batch(359/480) done. Loss: 0.8401  lr:0.100000  network_time: 0.0108
[ Fri May 12 20:18:51 2023 ] 	Batch(459/480) done. Loss: 0.5103  lr:0.100000  network_time: 0.0113
[ Fri May 12 20:19:01 2023 ] 	Training Accuracy: 89.00%
[ Fri May 12 20:19:01 2023 ] Eval epoch: 19
[ Fri May 12 20:19:18 2023 ] 	Mean test loss of 120 batches: 0.542591392993927.
[ Fri May 12 20:19:18 2023 ] 	Top1: 86.50%
[ Fri May 12 20:19:18 2023 ] 	Top5: 99.67%
[ Fri May 12 20:19:18 2023 ] Training epoch: 20
[ Fri May 12 20:19:57 2023 ] 	Batch(79/480) done. Loss: 0.4985  lr:0.100000  network_time: 0.0110
[ Fri May 12 20:20:46 2023 ] 	Batch(179/480) done. Loss: 0.9616  lr:0.100000  network_time: 0.0109
[ Fri May 12 20:21:34 2023 ] 	Batch(279/480) done. Loss: 0.5682  lr:0.100000  network_time: 0.0118
[ Fri May 12 20:22:23 2023 ] 	Batch(379/480) done. Loss: 0.0686  lr:0.100000  network_time: 0.0113
[ Fri May 12 20:23:11 2023 ] 	Batch(479/480) done. Loss: 0.0976  lr:0.100000  network_time: 0.0112
[ Fri May 12 20:23:11 2023 ] 	Training Accuracy: 89.29%
[ Fri May 12 20:23:12 2023 ] Eval epoch: 20
[ Fri May 12 20:23:28 2023 ] 	Mean test loss of 120 batches: 0.2207651138305664.
[ Fri May 12 20:23:28 2023 ] 	Top1: 93.50%
[ Fri May 12 20:23:28 2023 ] 	Top5: 100.00%
[ Fri May 12 20:23:28 2023 ] Training epoch: 21
[ Fri May 12 20:24:17 2023 ] 	Batch(99/480) done. Loss: 0.4610  lr:0.010000  network_time: 0.0108
[ Fri May 12 20:25:06 2023 ] 	Batch(199/480) done. Loss: 0.1361  lr:0.010000  network_time: 0.0114
[ Fri May 12 20:25:54 2023 ] 	Batch(299/480) done. Loss: 0.0212  lr:0.010000  network_time: 0.0111
[ Fri May 12 20:26:43 2023 ] 	Batch(399/480) done. Loss: 0.0337  lr:0.010000  network_time: 0.0112
[ Fri May 12 20:27:22 2023 ] 	Training Accuracy: 97.08%
[ Fri May 12 20:27:22 2023 ] Eval epoch: 21
[ Fri May 12 20:27:39 2023 ] 	Mean test loss of 120 batches: 0.03681318834424019.
[ Fri May 12 20:27:39 2023 ] 	Top1: 98.67%
[ Fri May 12 20:27:39 2023 ] 	Top5: 100.00%
[ Fri May 12 20:27:39 2023 ] Training epoch: 22
[ Fri May 12 20:27:48 2023 ] 	Batch(19/480) done. Loss: 0.0402  lr:0.010000  network_time: 0.0112
[ Fri May 12 20:28:37 2023 ] 	Batch(119/480) done. Loss: 0.0210  lr:0.010000  network_time: 0.0111
[ Fri May 12 20:29:26 2023 ] 	Batch(219/480) done. Loss: 0.0053  lr:0.010000  network_time: 0.0113
[ Fri May 12 20:30:14 2023 ] 	Batch(319/480) done. Loss: 0.0242  lr:0.010000  network_time: 0.0109
[ Fri May 12 20:31:03 2023 ] 	Batch(419/480) done. Loss: 0.0240  lr:0.010000  network_time: 0.0116
[ Fri May 12 20:31:32 2023 ] 	Training Accuracy: 98.50%
[ Fri May 12 20:31:32 2023 ] Eval epoch: 22
[ Fri May 12 20:31:49 2023 ] 	Mean test loss of 120 batches: 0.029705187305808067.
[ Fri May 12 20:31:49 2023 ] 	Top1: 99.00%
[ Fri May 12 20:31:49 2023 ] 	Top5: 100.00%
[ Fri May 12 20:31:49 2023 ] Training epoch: 23
[ Fri May 12 20:32:09 2023 ] 	Batch(39/480) done. Loss: 0.0860  lr:0.010000  network_time: 0.0110
[ Fri May 12 20:32:57 2023 ] 	Batch(139/480) done. Loss: 0.0388  lr:0.010000  network_time: 0.0114
[ Fri May 12 20:33:46 2023 ] 	Batch(239/480) done. Loss: 0.0193  lr:0.010000  network_time: 0.0114
[ Fri May 12 20:34:35 2023 ] 	Batch(339/480) done. Loss: 0.0328  lr:0.010000  network_time: 0.0112
[ Fri May 12 20:35:23 2023 ] 	Batch(439/480) done. Loss: 0.0491  lr:0.010000  network_time: 0.0110
[ Fri May 12 20:35:43 2023 ] 	Training Accuracy: 99.33%
[ Fri May 12 20:35:43 2023 ] Eval epoch: 23
[ Fri May 12 20:36:00 2023 ] 	Mean test loss of 120 batches: 0.02622341923415661.
[ Fri May 12 20:36:00 2023 ] 	Top1: 98.83%
[ Fri May 12 20:36:00 2023 ] 	Top5: 100.00%
[ Fri May 12 20:36:00 2023 ] Training epoch: 24
[ Fri May 12 20:36:29 2023 ] 	Batch(59/480) done. Loss: 0.0231  lr:0.010000  network_time: 0.0115
[ Fri May 12 20:37:17 2023 ] 	Batch(159/480) done. Loss: 0.0101  lr:0.010000  network_time: 0.0116
[ Fri May 12 20:38:06 2023 ] 	Batch(259/480) done. Loss: 0.0084  lr:0.010000  network_time: 0.0119
[ Fri May 12 20:38:55 2023 ] 	Batch(359/480) done. Loss: 0.0166  lr:0.010000  network_time: 0.0116
[ Fri May 12 20:39:43 2023 ] 	Batch(459/480) done. Loss: 0.0026  lr:0.010000  network_time: 0.0115
[ Fri May 12 20:39:53 2023 ] 	Training Accuracy: 99.21%
[ Fri May 12 20:39:53 2023 ] Eval epoch: 24
[ Fri May 12 20:40:10 2023 ] 	Mean test loss of 120 batches: 0.015290397219359875.
[ Fri May 12 20:40:10 2023 ] 	Top1: 99.50%
[ Fri May 12 20:40:10 2023 ] 	Top5: 100.00%
[ Fri May 12 20:40:10 2023 ] Training epoch: 25
[ Fri May 12 20:40:49 2023 ] 	Batch(79/480) done. Loss: 0.0134  lr:0.010000  network_time: 0.0109
[ Fri May 12 20:41:38 2023 ] 	Batch(179/480) done. Loss: 0.0044  lr:0.010000  network_time: 0.0112
[ Fri May 12 20:42:26 2023 ] 	Batch(279/480) done. Loss: 0.0241  lr:0.010000  network_time: 0.0112
[ Fri May 12 20:43:15 2023 ] 	Batch(379/480) done. Loss: 0.0036  lr:0.010000  network_time: 0.0109
[ Fri May 12 20:44:04 2023 ] 	Batch(479/480) done. Loss: 0.1018  lr:0.010000  network_time: 0.0108
[ Fri May 12 20:44:04 2023 ] 	Training Accuracy: 99.08%
[ Fri May 12 20:44:04 2023 ] Eval epoch: 25
[ Fri May 12 20:44:20 2023 ] 	Mean test loss of 120 batches: 0.0074627152644097805.
[ Fri May 12 20:44:20 2023 ] 	Top1: 99.83%
[ Fri May 12 20:44:20 2023 ] 	Top5: 100.00%
[ Fri May 12 20:44:20 2023 ] Training epoch: 26
[ Fri May 12 20:45:09 2023 ] 	Batch(99/480) done. Loss: 0.0632  lr:0.001000  network_time: 0.0110
[ Fri May 12 20:45:58 2023 ] 	Batch(199/480) done. Loss: 0.1031  lr:0.001000  network_time: 0.0115
[ Fri May 12 20:46:47 2023 ] 	Batch(299/480) done. Loss: 0.0120  lr:0.001000  network_time: 0.0111
[ Fri May 12 20:47:35 2023 ] 	Batch(399/480) done. Loss: 0.0778  lr:0.001000  network_time: 0.0117
[ Fri May 12 20:48:14 2023 ] 	Training Accuracy: 99.75%
[ Fri May 12 20:48:14 2023 ] Eval epoch: 26
[ Fri May 12 20:48:31 2023 ] 	Mean test loss of 120 batches: 0.011012387461960316.
[ Fri May 12 20:48:31 2023 ] 	Top1: 99.67%
[ Fri May 12 20:48:31 2023 ] 	Top5: 100.00%
[ Fri May 12 20:48:31 2023 ] Training epoch: 27
[ Fri May 12 20:48:41 2023 ] 	Batch(19/480) done. Loss: 0.0078  lr:0.001000  network_time: 0.0112
[ Fri May 12 20:49:29 2023 ] 	Batch(119/480) done. Loss: 0.0091  lr:0.001000  network_time: 0.0115
[ Fri May 12 20:50:18 2023 ] 	Batch(219/480) done. Loss: 0.0583  lr:0.001000  network_time: 0.0112
[ Fri May 12 20:51:07 2023 ] 	Batch(319/480) done. Loss: 0.0156  lr:0.001000  network_time: 0.0109
[ Fri May 12 20:51:55 2023 ] 	Batch(419/480) done. Loss: 0.0014  lr:0.001000  network_time: 0.0116
[ Fri May 12 20:52:25 2023 ] 	Training Accuracy: 99.62%
[ Fri May 12 20:52:25 2023 ] Eval epoch: 27
[ Fri May 12 20:52:41 2023 ] 	Mean test loss of 120 batches: 0.008642279542982578.
[ Fri May 12 20:52:41 2023 ] 	Top1: 99.83%
[ Fri May 12 20:52:41 2023 ] 	Top5: 100.00%
[ Fri May 12 20:52:41 2023 ] Training epoch: 28
[ Fri May 12 20:53:01 2023 ] 	Batch(39/480) done. Loss: 0.0113  lr:0.001000  network_time: 0.0109
[ Fri May 12 20:53:50 2023 ] 	Batch(139/480) done. Loss: 0.0323  lr:0.001000  network_time: 0.0109
[ Fri May 12 20:54:38 2023 ] 	Batch(239/480) done. Loss: 0.0724  lr:0.001000  network_time: 0.0110
[ Fri May 12 20:55:27 2023 ] 	Batch(339/480) done. Loss: 0.0299  lr:0.001000  network_time: 0.0110
[ Fri May 12 20:56:16 2023 ] 	Batch(439/480) done. Loss: 0.0210  lr:0.001000  network_time: 0.0110
[ Fri May 12 20:56:35 2023 ] 	Training Accuracy: 99.42%
[ Fri May 12 20:56:35 2023 ] Eval epoch: 28
[ Fri May 12 20:56:52 2023 ] 	Mean test loss of 120 batches: 0.011329347267746925.
[ Fri May 12 20:56:52 2023 ] 	Top1: 99.67%
[ Fri May 12 20:56:52 2023 ] 	Top5: 100.00%
[ Fri May 12 20:56:52 2023 ] Training epoch: 29
[ Fri May 12 20:57:21 2023 ] 	Batch(59/480) done. Loss: 0.0040  lr:0.001000  network_time: 0.0115
[ Fri May 12 20:58:10 2023 ] 	Batch(159/480) done. Loss: 0.0369  lr:0.001000  network_time: 0.0112
[ Fri May 12 20:58:58 2023 ] 	Batch(259/480) done. Loss: 0.0489  lr:0.001000  network_time: 0.0114
[ Fri May 12 20:59:47 2023 ] 	Batch(359/480) done. Loss: 0.0157  lr:0.001000  network_time: 0.0109
[ Fri May 12 21:00:36 2023 ] 	Batch(459/480) done. Loss: 0.0468  lr:0.001000  network_time: 0.0112
[ Fri May 12 21:00:45 2023 ] 	Training Accuracy: 99.62%
[ Fri May 12 21:00:46 2023 ] Eval epoch: 29
[ Fri May 12 21:01:02 2023 ] 	Mean test loss of 120 batches: 0.004677059128880501.
[ Fri May 12 21:01:02 2023 ] 	Top1: 100.00%
[ Fri May 12 21:01:02 2023 ] 	Top5: 100.00%
[ Fri May 12 21:01:02 2023 ] Training epoch: 30
[ Fri May 12 21:01:41 2023 ] 	Batch(79/480) done. Loss: 0.0627  lr:0.001000  network_time: 0.0113
[ Fri May 12 21:02:30 2023 ] 	Batch(179/480) done. Loss: 0.0043  lr:0.001000  network_time: 0.0111
[ Fri May 12 21:03:19 2023 ] 	Batch(279/480) done. Loss: 0.0279  lr:0.001000  network_time: 0.0112
[ Fri May 12 21:04:07 2023 ] 	Batch(379/480) done. Loss: 0.0577  lr:0.001000  network_time: 0.0115
[ Fri May 12 21:04:56 2023 ] 	Batch(479/480) done. Loss: 0.0041  lr:0.001000  network_time: 0.0114
[ Fri May 12 21:04:56 2023 ] 	Training Accuracy: 99.33%
[ Fri May 12 21:04:56 2023 ] Eval epoch: 30
[ Fri May 12 21:05:13 2023 ] 	Mean test loss of 120 batches: 0.0074476758018136024.
[ Fri May 12 21:05:13 2023 ] 	Top1: 99.83%
[ Fri May 12 21:05:13 2023 ] 	Top5: 100.00%
