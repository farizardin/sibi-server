[ Fri May 12 23:05:51 2023 ] NUM WORKER: 1
[ Fri May 12 23:06:42 2023 ] Parameters:
{'work_dir': './work_dir/sibi_individual_inner_group_ShiftGCN_mod_3_joint_n_5_kfold_fold_5', 'model_saved_name': './save_models/sibi_individual_inner_group_ShiftGCN_mod_3_joint_n_5_kfold_fold_5', 'Experiment_name': 'sibi_individual_inner_group_ShiftGCN_mod_3_joint_n_5_kfold', 'config': './config/recalculated/train_sibi_with_mouth_augmented_individual_inner_group_shift_joint_mod_3.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 2, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'n_splits': 5, 'feeder': 'feeders.feeder_hsd.Feeder', 'num_worker': 1, 'train_feeder_args': {'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': -1, 'normalization': False}, 'test_feeder_args': None, 'data_path': './data/augmented_recalculate_normalized', 'model': 'model.shift_gcn.Model', 'model_args': {'num_class': 50, 'num_person': 1, 'num_point': 115, 'graph_group': [[0, 39], [40, 60], [61, 81], [82, 114]], 'method': 'grouped.inner', 'weight': 3, 'graph': 'graph.skeleton_with_mouth.SkeletonWithMouth', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [20, 25], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 5, 'test_batch_size': 5, 'start_epoch': 0, 'num_epoch': 30, 'folds_range': [2, 5], 'weight_decay': 0.0001, 'only_train_part': True, 'only_train_epoch': 1, 'warm_up_epoch': 0}

[ Fri May 12 23:06:42 2023 ] Training epoch: 1
[ Fri May 12 23:07:32 2023 ] 	Batch(99/480) done. Loss: 4.3378  lr:0.100000  network_time: 0.0109
[ Fri May 12 23:08:20 2023 ] 	Batch(199/480) done. Loss: 3.8715  lr:0.100000  network_time: 0.0109
[ Fri May 12 23:09:09 2023 ] 	Batch(299/480) done. Loss: 3.2523  lr:0.100000  network_time: 0.0108
[ Fri May 12 23:09:57 2023 ] 	Batch(399/480) done. Loss: 3.5431  lr:0.100000  network_time: 0.0113
[ Fri May 12 23:10:36 2023 ] 	Training Accuracy: 5.42%
[ Fri May 12 23:10:36 2023 ] Eval epoch: 1
[ Fri May 12 23:10:53 2023 ] 	Mean test loss of 120 batches: 3.754573345184326.
[ Fri May 12 23:10:53 2023 ] 	Top1: 10.83%
[ Fri May 12 23:10:53 2023 ] 	Top5: 40.50%
[ Fri May 12 23:10:53 2023 ] Training epoch: 2
[ Fri May 12 23:11:03 2023 ] 	Batch(19/480) done. Loss: 2.8710  lr:0.100000  network_time: 0.0107
[ Fri May 12 23:11:52 2023 ] 	Batch(119/480) done. Loss: 3.5167  lr:0.100000  network_time: 0.0129
[ Fri May 12 23:12:40 2023 ] 	Batch(219/480) done. Loss: 2.9928  lr:0.100000  network_time: 0.0112
[ Fri May 12 23:13:29 2023 ] 	Batch(319/480) done. Loss: 2.1205  lr:0.100000  network_time: 0.0113
[ Fri May 12 23:14:18 2023 ] 	Batch(419/480) done. Loss: 3.3543  lr:0.100000  network_time: 0.0139
[ Fri May 12 23:14:47 2023 ] 	Training Accuracy: 10.17%
[ Fri May 12 23:14:47 2023 ] Eval epoch: 2
[ Fri May 12 23:15:04 2023 ] 	Mean test loss of 120 batches: 2.838888645172119.
[ Fri May 12 23:15:04 2023 ] 	Top1: 14.50%
[ Fri May 12 23:15:04 2023 ] 	Top5: 57.83%
[ Fri May 12 23:15:04 2023 ] Training epoch: 3
[ Fri May 12 23:15:23 2023 ] 	Batch(39/480) done. Loss: 3.8187  lr:0.100000  network_time: 0.0134
[ Fri May 12 23:16:12 2023 ] 	Batch(139/480) done. Loss: 3.7686  lr:0.100000  network_time: 0.0111
[ Fri May 12 23:17:01 2023 ] 	Batch(239/480) done. Loss: 3.3774  lr:0.100000  network_time: 0.0134
[ Fri May 12 23:17:49 2023 ] 	Batch(339/480) done. Loss: 2.4052  lr:0.100000  network_time: 0.0108
[ Fri May 12 23:18:38 2023 ] 	Batch(439/480) done. Loss: 2.7110  lr:0.100000  network_time: 0.0110
[ Fri May 12 23:18:57 2023 ] 	Training Accuracy: 17.21%
[ Fri May 12 23:18:57 2023 ] Eval epoch: 3
[ Fri May 12 23:19:14 2023 ] 	Mean test loss of 120 batches: 3.3201308250427246.
[ Fri May 12 23:19:14 2023 ] 	Top1: 22.50%
[ Fri May 12 23:19:14 2023 ] 	Top5: 63.83%
[ Fri May 12 23:19:14 2023 ] Training epoch: 4
[ Fri May 12 23:19:44 2023 ] 	Batch(59/480) done. Loss: 2.9026  lr:0.100000  network_time: 0.0108
[ Fri May 12 23:20:32 2023 ] 	Batch(159/480) done. Loss: 3.5278  lr:0.100000  network_time: 0.0134
[ Fri May 12 23:21:21 2023 ] 	Batch(259/480) done. Loss: 2.2920  lr:0.100000  network_time: 0.0106
[ Fri May 12 23:22:10 2023 ] 	Batch(359/480) done. Loss: 2.5479  lr:0.100000  network_time: 0.0135
[ Fri May 12 23:22:58 2023 ] 	Batch(459/480) done. Loss: 2.2898  lr:0.100000  network_time: 0.0114
[ Fri May 12 23:23:08 2023 ] 	Training Accuracy: 23.79%
[ Fri May 12 23:23:08 2023 ] Eval epoch: 4
[ Fri May 12 23:23:25 2023 ] 	Mean test loss of 120 batches: 2.3194518089294434.
[ Fri May 12 23:23:25 2023 ] 	Top1: 35.17%
[ Fri May 12 23:23:25 2023 ] 	Top5: 77.67%
[ Fri May 12 23:23:25 2023 ] Training epoch: 5
[ Fri May 12 23:24:04 2023 ] 	Batch(79/480) done. Loss: 2.9511  lr:0.100000  network_time: 0.0113
[ Fri May 12 23:24:53 2023 ] 	Batch(179/480) done. Loss: 1.8492  lr:0.100000  network_time: 0.0108
[ Fri May 12 23:25:41 2023 ] 	Batch(279/480) done. Loss: 2.4058  lr:0.100000  network_time: 0.0109
[ Fri May 12 23:26:30 2023 ] 	Batch(379/480) done. Loss: 2.2007  lr:0.100000  network_time: 0.0138
[ Fri May 12 23:27:19 2023 ] 	Batch(479/480) done. Loss: 1.8095  lr:0.100000  network_time: 0.0109
[ Fri May 12 23:27:19 2023 ] 	Training Accuracy: 30.50%
[ Fri May 12 23:27:19 2023 ] Eval epoch: 5
[ Fri May 12 23:27:36 2023 ] 	Mean test loss of 120 batches: 2.5327346324920654.
[ Fri May 12 23:27:36 2023 ] 	Top1: 36.50%
[ Fri May 12 23:27:36 2023 ] 	Top5: 83.83%
[ Fri May 12 23:27:36 2023 ] Training epoch: 6
[ Fri May 12 23:28:25 2023 ] 	Batch(99/480) done. Loss: 1.6745  lr:0.100000  network_time: 0.0113
[ Fri May 12 23:29:13 2023 ] 	Batch(199/480) done. Loss: 2.3764  lr:0.100000  network_time: 0.0111
[ Fri May 12 23:30:02 2023 ] 	Batch(299/480) done. Loss: 0.9956  lr:0.100000  network_time: 0.0110
[ Fri May 12 23:30:51 2023 ] 	Batch(399/480) done. Loss: 1.2606  lr:0.100000  network_time: 0.0108
[ Fri May 12 23:31:29 2023 ] 	Training Accuracy: 40.75%
[ Fri May 12 23:31:30 2023 ] Eval epoch: 6
[ Fri May 12 23:31:47 2023 ] 	Mean test loss of 120 batches: 4.940072536468506.
[ Fri May 12 23:31:47 2023 ] 	Top1: 18.83%
[ Fri May 12 23:31:47 2023 ] 	Top5: 50.83%
[ Fri May 12 23:31:47 2023 ] Training epoch: 7
[ Fri May 12 23:31:56 2023 ] 	Batch(19/480) done. Loss: 0.6182  lr:0.100000  network_time: 0.0113
[ Fri May 12 23:32:45 2023 ] 	Batch(119/480) done. Loss: 1.3051  lr:0.100000  network_time: 0.0111
[ Fri May 12 23:33:34 2023 ] 	Batch(219/480) done. Loss: 1.6121  lr:0.100000  network_time: 0.0108
[ Fri May 12 23:34:22 2023 ] 	Batch(319/480) done. Loss: 2.5106  lr:0.100000  network_time: 0.0108
[ Fri May 12 23:35:11 2023 ] 	Batch(419/480) done. Loss: 2.4713  lr:0.100000  network_time: 0.0110
[ Fri May 12 23:35:40 2023 ] 	Training Accuracy: 48.50%
[ Fri May 12 23:35:40 2023 ] Eval epoch: 7
[ Fri May 12 23:35:57 2023 ] 	Mean test loss of 120 batches: 1.2564330101013184.
[ Fri May 12 23:35:57 2023 ] 	Top1: 59.17%
[ Fri May 12 23:35:57 2023 ] 	Top5: 94.67%
[ Fri May 12 23:35:57 2023 ] Training epoch: 8
[ Fri May 12 23:36:17 2023 ] 	Batch(39/480) done. Loss: 1.6840  lr:0.100000  network_time: 0.0133
[ Fri May 12 23:37:06 2023 ] 	Batch(139/480) done. Loss: 0.9796  lr:0.100000  network_time: 0.0109
[ Fri May 12 23:37:54 2023 ] 	Batch(239/480) done. Loss: 1.2594  lr:0.100000  network_time: 0.0109
[ Fri May 12 23:38:43 2023 ] 	Batch(339/480) done. Loss: 2.2961  lr:0.100000  network_time: 0.0111
[ Fri May 12 23:39:32 2023 ] 	Batch(439/480) done. Loss: 0.6448  lr:0.100000  network_time: 0.0111
[ Fri May 12 23:39:51 2023 ] 	Training Accuracy: 55.62%
[ Fri May 12 23:39:51 2023 ] Eval epoch: 8
[ Fri May 12 23:40:08 2023 ] 	Mean test loss of 120 batches: 1.0702000856399536.
[ Fri May 12 23:40:08 2023 ] 	Top1: 65.17%
[ Fri May 12 23:40:08 2023 ] 	Top5: 95.83%
[ Fri May 12 23:40:08 2023 ] Training epoch: 9
[ Fri May 12 23:40:38 2023 ] 	Batch(59/480) done. Loss: 1.3983  lr:0.100000  network_time: 0.0110
[ Fri May 12 23:41:26 2023 ] 	Batch(159/480) done. Loss: 1.3601  lr:0.100000  network_time: 0.0111
[ Fri May 12 23:42:15 2023 ] 	Batch(259/480) done. Loss: 0.5456  lr:0.100000  network_time: 0.0116
[ Fri May 12 23:43:04 2023 ] 	Batch(359/480) done. Loss: 1.3665  lr:0.100000  network_time: 0.0108
[ Fri May 12 23:43:52 2023 ] 	Batch(459/480) done. Loss: 0.9100  lr:0.100000  network_time: 0.0108
[ Fri May 12 23:44:02 2023 ] 	Training Accuracy: 61.58%
[ Fri May 12 23:44:02 2023 ] Eval epoch: 9
[ Fri May 12 23:44:19 2023 ] 	Mean test loss of 120 batches: 1.3510417938232422.
[ Fri May 12 23:44:19 2023 ] 	Top1: 62.83%
[ Fri May 12 23:44:19 2023 ] 	Top5: 92.67%
[ Fri May 12 23:44:19 2023 ] Training epoch: 10
[ Fri May 12 23:44:58 2023 ] 	Batch(79/480) done. Loss: 1.0532  lr:0.100000  network_time: 0.0109
[ Fri May 12 23:45:47 2023 ] 	Batch(179/480) done. Loss: 1.6571  lr:0.100000  network_time: 0.0112
[ Fri May 12 23:46:36 2023 ] 	Batch(279/480) done. Loss: 0.7526  lr:0.100000  network_time: 0.0134
[ Fri May 12 23:47:24 2023 ] 	Batch(379/480) done. Loss: 1.4058  lr:0.100000  network_time: 0.0110
[ Fri May 12 23:48:13 2023 ] 	Batch(479/480) done. Loss: 1.3554  lr:0.100000  network_time: 0.0109
[ Fri May 12 23:48:13 2023 ] 	Training Accuracy: 67.83%
[ Fri May 12 23:48:13 2023 ] Eval epoch: 10
[ Fri May 12 23:48:30 2023 ] 	Mean test loss of 120 batches: 1.2254585027694702.
[ Fri May 12 23:48:30 2023 ] 	Top1: 59.83%
[ Fri May 12 23:48:30 2023 ] 	Top5: 91.50%
[ Fri May 12 23:48:30 2023 ] Training epoch: 11
[ Fri May 12 23:49:19 2023 ] 	Batch(99/480) done. Loss: 0.8671  lr:0.100000  network_time: 0.0133
[ Fri May 12 23:50:07 2023 ] 	Batch(199/480) done. Loss: 0.8325  lr:0.100000  network_time: 0.0107
[ Fri May 12 23:50:56 2023 ] 	Batch(299/480) done. Loss: 0.5207  lr:0.100000  network_time: 0.0131
[ Fri May 12 23:51:45 2023 ] 	Batch(399/480) done. Loss: 1.2764  lr:0.100000  network_time: 0.0132
[ Fri May 12 23:52:24 2023 ] 	Training Accuracy: 72.88%
[ Fri May 12 23:52:24 2023 ] Eval epoch: 11
[ Fri May 12 23:52:41 2023 ] 	Mean test loss of 120 batches: 13.183849334716797.
[ Fri May 12 23:52:41 2023 ] 	Top1: 12.67%
[ Fri May 12 23:52:41 2023 ] 	Top5: 51.83%
[ Fri May 12 23:52:41 2023 ] Training epoch: 12
[ Fri May 12 23:52:51 2023 ] 	Batch(19/480) done. Loss: 0.5460  lr:0.100000  network_time: 0.0106
[ Fri May 12 23:53:40 2023 ] 	Batch(119/480) done. Loss: 0.3353  lr:0.100000  network_time: 0.0108
[ Fri May 12 23:54:28 2023 ] 	Batch(219/480) done. Loss: 0.1572  lr:0.100000  network_time: 0.0130
[ Fri May 12 23:55:17 2023 ] 	Batch(319/480) done. Loss: 0.4637  lr:0.100000  network_time: 0.0113
[ Fri May 12 23:56:06 2023 ] 	Batch(419/480) done. Loss: 0.8394  lr:0.100000  network_time: 0.0123
[ Fri May 12 23:56:35 2023 ] 	Training Accuracy: 77.83%
[ Fri May 12 23:56:35 2023 ] Eval epoch: 12
[ Fri May 12 23:56:52 2023 ] 	Mean test loss of 120 batches: 0.5061317086219788.
[ Fri May 12 23:56:52 2023 ] 	Top1: 82.00%
[ Fri May 12 23:56:52 2023 ] 	Top5: 99.83%
[ Fri May 12 23:56:52 2023 ] Training epoch: 13
[ Fri May 12 23:57:12 2023 ] 	Batch(39/480) done. Loss: 0.2502  lr:0.100000  network_time: 0.0119
[ Fri May 12 23:58:00 2023 ] 	Batch(139/480) done. Loss: 0.7320  lr:0.100000  network_time: 0.0152
[ Fri May 12 23:58:49 2023 ] 	Batch(239/480) done. Loss: 0.1163  lr:0.100000  network_time: 0.0111
[ Fri May 12 23:59:38 2023 ] 	Batch(339/480) done. Loss: 0.4287  lr:0.100000  network_time: 0.0134
[ Sat May 13 00:00:27 2023 ] 	Batch(439/480) done. Loss: 0.6296  lr:0.100000  network_time: 0.0106
[ Sat May 13 00:00:46 2023 ] 	Training Accuracy: 76.83%
[ Sat May 13 00:00:46 2023 ] Eval epoch: 13
[ Sat May 13 00:01:03 2023 ] 	Mean test loss of 120 batches: 0.6399956941604614.
[ Sat May 13 00:01:03 2023 ] 	Top1: 80.33%
[ Sat May 13 00:01:03 2023 ] 	Top5: 99.00%
[ Sat May 13 00:01:03 2023 ] Training epoch: 14
[ Sat May 13 00:01:33 2023 ] 	Batch(59/480) done. Loss: 0.3696  lr:0.100000  network_time: 0.0108
[ Sat May 13 00:02:21 2023 ] 	Batch(159/480) done. Loss: 0.6363  lr:0.100000  network_time: 0.0108
[ Sat May 13 00:03:10 2023 ] 	Batch(259/480) done. Loss: 0.6854  lr:0.100000  network_time: 0.0125
[ Sat May 13 00:03:59 2023 ] 	Batch(359/480) done. Loss: 0.3423  lr:0.100000  network_time: 0.0116
[ Sat May 13 00:04:47 2023 ] 	Batch(459/480) done. Loss: 0.2099  lr:0.100000  network_time: 0.0107
[ Sat May 13 00:04:57 2023 ] 	Training Accuracy: 80.42%
[ Sat May 13 00:04:57 2023 ] Eval epoch: 14
[ Sat May 13 00:05:14 2023 ] 	Mean test loss of 120 batches: 1.095981240272522.
[ Sat May 13 00:05:14 2023 ] 	Top1: 75.00%
[ Sat May 13 00:05:14 2023 ] 	Top5: 97.00%
[ Sat May 13 00:05:14 2023 ] Training epoch: 15
[ Sat May 13 00:05:53 2023 ] 	Batch(79/480) done. Loss: 0.2954  lr:0.100000  network_time: 0.0134
[ Sat May 13 00:06:42 2023 ] 	Batch(179/480) done. Loss: 0.3004  lr:0.100000  network_time: 0.0118
[ Sat May 13 00:07:31 2023 ] 	Batch(279/480) done. Loss: 0.8202  lr:0.100000  network_time: 0.0107
[ Sat May 13 00:08:19 2023 ] 	Batch(379/480) done. Loss: 0.1864  lr:0.100000  network_time: 0.0139
[ Sat May 13 00:09:08 2023 ] 	Batch(479/480) done. Loss: 0.5499  lr:0.100000  network_time: 0.0109
[ Sat May 13 00:09:08 2023 ] 	Training Accuracy: 81.63%
[ Sat May 13 00:09:08 2023 ] Eval epoch: 15
[ Sat May 13 00:09:25 2023 ] 	Mean test loss of 120 batches: 0.4260532259941101.
[ Sat May 13 00:09:25 2023 ] 	Top1: 86.83%
[ Sat May 13 00:09:25 2023 ] 	Top5: 99.67%
[ Sat May 13 00:09:25 2023 ] Training epoch: 16
[ Sat May 13 00:10:14 2023 ] 	Batch(99/480) done. Loss: 0.0811  lr:0.100000  network_time: 0.0133
[ Sat May 13 00:11:03 2023 ] 	Batch(199/480) done. Loss: 0.4096  lr:0.100000  network_time: 0.0115
[ Sat May 13 00:11:51 2023 ] 	Batch(299/480) done. Loss: 1.3775  lr:0.100000  network_time: 0.0109
[ Sat May 13 00:12:40 2023 ] 	Batch(399/480) done. Loss: 0.7058  lr:0.100000  network_time: 0.0110
[ Sat May 13 00:13:19 2023 ] 	Training Accuracy: 84.67%
[ Sat May 13 00:13:19 2023 ] Eval epoch: 16
[ Sat May 13 00:13:36 2023 ] 	Mean test loss of 120 batches: 0.5370281338691711.
[ Sat May 13 00:13:36 2023 ] 	Top1: 81.83%
[ Sat May 13 00:13:36 2023 ] 	Top5: 99.50%
[ Sat May 13 00:13:36 2023 ] Training epoch: 17
[ Sat May 13 00:13:46 2023 ] 	Batch(19/480) done. Loss: 0.6702  lr:0.100000  network_time: 0.0107
[ Sat May 13 00:14:35 2023 ] 	Batch(119/480) done. Loss: 1.0387  lr:0.100000  network_time: 0.0110
[ Sat May 13 00:15:23 2023 ] 	Batch(219/480) done. Loss: 0.4512  lr:0.100000  network_time: 0.0107
[ Sat May 13 00:16:12 2023 ] 	Batch(319/480) done. Loss: 0.0577  lr:0.100000  network_time: 0.0110
[ Sat May 13 00:17:01 2023 ] 	Batch(419/480) done. Loss: 1.4727  lr:0.100000  network_time: 0.0107
[ Sat May 13 00:17:30 2023 ] 	Training Accuracy: 83.83%
[ Sat May 13 00:17:30 2023 ] Eval epoch: 17
[ Sat May 13 00:17:47 2023 ] 	Mean test loss of 120 batches: 0.4988804757595062.
[ Sat May 13 00:17:47 2023 ] 	Top1: 83.83%
[ Sat May 13 00:17:47 2023 ] 	Top5: 99.33%
[ Sat May 13 00:17:47 2023 ] Training epoch: 18
[ Sat May 13 00:18:07 2023 ] 	Batch(39/480) done. Loss: 1.2415  lr:0.100000  network_time: 0.0106
[ Sat May 13 00:18:55 2023 ] 	Batch(139/480) done. Loss: 0.0332  lr:0.100000  network_time: 0.0131
[ Sat May 13 00:19:44 2023 ] 	Batch(239/480) done. Loss: 0.1619  lr:0.100000  network_time: 0.0117
[ Sat May 13 00:20:33 2023 ] 	Batch(339/480) done. Loss: 0.2468  lr:0.100000  network_time: 0.0133
[ Sat May 13 00:21:22 2023 ] 	Batch(439/480) done. Loss: 0.3354  lr:0.100000  network_time: 0.0117
[ Sat May 13 00:21:41 2023 ] 	Training Accuracy: 87.17%
[ Sat May 13 00:21:41 2023 ] Eval epoch: 18
[ Sat May 13 00:21:58 2023 ] 	Mean test loss of 120 batches: 0.32412558794021606.
[ Sat May 13 00:21:58 2023 ] 	Top1: 89.50%
[ Sat May 13 00:21:58 2023 ] 	Top5: 99.50%
[ Sat May 13 00:21:58 2023 ] Training epoch: 19
[ Sat May 13 00:22:27 2023 ] 	Batch(59/480) done. Loss: 1.5775  lr:0.100000  network_time: 0.0106
[ Sat May 13 00:23:16 2023 ] 	Batch(159/480) done. Loss: 0.6773  lr:0.100000  network_time: 0.0109
[ Sat May 13 00:24:05 2023 ] 	Batch(259/480) done. Loss: 0.9403  lr:0.100000  network_time: 0.0117
[ Sat May 13 00:24:53 2023 ] 	Batch(359/480) done. Loss: 0.0489  lr:0.100000  network_time: 0.0108
[ Sat May 13 00:25:42 2023 ] 	Batch(459/480) done. Loss: 0.1708  lr:0.100000  network_time: 0.0111
[ Sat May 13 00:25:52 2023 ] 	Training Accuracy: 86.17%
[ Sat May 13 00:25:52 2023 ] Eval epoch: 19
[ Sat May 13 00:26:09 2023 ] 	Mean test loss of 120 batches: 0.44535574316978455.
[ Sat May 13 00:26:09 2023 ] 	Top1: 84.33%
[ Sat May 13 00:26:09 2023 ] 	Top5: 99.50%
[ Sat May 13 00:26:09 2023 ] Training epoch: 20
[ Sat May 13 00:26:48 2023 ] 	Batch(79/480) done. Loss: 0.1233  lr:0.100000  network_time: 0.0132
[ Sat May 13 00:27:37 2023 ] 	Batch(179/480) done. Loss: 0.0350  lr:0.100000  network_time: 0.0111
[ Sat May 13 00:28:26 2023 ] 	Batch(279/480) done. Loss: 0.8532  lr:0.100000  network_time: 0.0134
[ Sat May 13 00:29:14 2023 ] 	Batch(379/480) done. Loss: 0.0807  lr:0.100000  network_time: 0.0136
[ Sat May 13 00:30:03 2023 ] 	Batch(479/480) done. Loss: 0.8035  lr:0.100000  network_time: 0.0129
[ Sat May 13 00:30:03 2023 ] 	Training Accuracy: 87.12%
[ Sat May 13 00:30:03 2023 ] Eval epoch: 20
[ Sat May 13 00:30:20 2023 ] 	Mean test loss of 120 batches: 0.2518075108528137.
[ Sat May 13 00:30:20 2023 ] 	Top1: 91.00%
[ Sat May 13 00:30:20 2023 ] 	Top5: 100.00%
[ Sat May 13 00:30:20 2023 ] Training epoch: 21
[ Sat May 13 00:31:09 2023 ] 	Batch(99/480) done. Loss: 0.5039  lr:0.010000  network_time: 0.0131
[ Sat May 13 00:31:58 2023 ] 	Batch(199/480) done. Loss: 0.8849  lr:0.010000  network_time: 0.0109
[ Sat May 13 00:32:46 2023 ] 	Batch(299/480) done. Loss: 0.2941  lr:0.010000  network_time: 0.0109
[ Sat May 13 00:33:35 2023 ] 	Batch(399/480) done. Loss: 0.0631  lr:0.010000  network_time: 0.0139
[ Sat May 13 00:34:14 2023 ] 	Training Accuracy: 95.50%
[ Sat May 13 00:34:14 2023 ] Eval epoch: 21
[ Sat May 13 00:34:31 2023 ] 	Mean test loss of 120 batches: 0.032563794404268265.
[ Sat May 13 00:34:31 2023 ] 	Top1: 99.50%
[ Sat May 13 00:34:31 2023 ] 	Top5: 100.00%
[ Sat May 13 00:34:31 2023 ] Training epoch: 22
[ Sat May 13 00:34:41 2023 ] 	Batch(19/480) done. Loss: 0.2295  lr:0.010000  network_time: 0.0132
[ Sat May 13 00:35:30 2023 ] 	Batch(119/480) done. Loss: 0.7814  lr:0.010000  network_time: 0.0108
[ Sat May 13 00:36:19 2023 ] 	Batch(219/480) done. Loss: 0.2325  lr:0.010000  network_time: 0.0110
[ Sat May 13 00:37:07 2023 ] 	Batch(319/480) done. Loss: 0.2032  lr:0.010000  network_time: 0.0111
[ Sat May 13 00:37:56 2023 ] 	Batch(419/480) done. Loss: 0.0735  lr:0.010000  network_time: 0.0115
[ Sat May 13 00:38:26 2023 ] 	Training Accuracy: 97.75%
[ Sat May 13 00:38:26 2023 ] Eval epoch: 22
[ Sat May 13 00:38:43 2023 ] 	Mean test loss of 120 batches: 0.027779677882790565.
[ Sat May 13 00:38:43 2023 ] 	Top1: 99.83%
[ Sat May 13 00:38:43 2023 ] 	Top5: 100.00%
[ Sat May 13 00:38:43 2023 ] Training epoch: 23
[ Sat May 13 00:39:02 2023 ] 	Batch(39/480) done. Loss: 0.0727  lr:0.010000  network_time: 0.0131
[ Sat May 13 00:39:51 2023 ] 	Batch(139/480) done. Loss: 0.0081  lr:0.010000  network_time: 0.0108
[ Sat May 13 00:40:40 2023 ] 	Batch(239/480) done. Loss: 0.0453  lr:0.010000  network_time: 0.0109
[ Sat May 13 00:41:28 2023 ] 	Batch(339/480) done. Loss: 0.4760  lr:0.010000  network_time: 0.0107
[ Sat May 13 00:42:17 2023 ] 	Batch(439/480) done. Loss: 0.0157  lr:0.010000  network_time: 0.0133
[ Sat May 13 00:42:37 2023 ] 	Training Accuracy: 98.42%
[ Sat May 13 00:42:37 2023 ] Eval epoch: 23
[ Sat May 13 00:42:54 2023 ] 	Mean test loss of 120 batches: 0.02035173960030079.
[ Sat May 13 00:42:54 2023 ] 	Top1: 99.83%
[ Sat May 13 00:42:54 2023 ] 	Top5: 100.00%
[ Sat May 13 00:42:54 2023 ] Training epoch: 24
[ Sat May 13 00:43:23 2023 ] 	Batch(59/480) done. Loss: 0.2554  lr:0.010000  network_time: 0.0107
[ Sat May 13 00:44:12 2023 ] 	Batch(159/480) done. Loss: 0.0227  lr:0.010000  network_time: 0.0113
[ Sat May 13 00:45:00 2023 ] 	Batch(259/480) done. Loss: 0.0372  lr:0.010000  network_time: 0.0121
[ Sat May 13 00:45:49 2023 ] 	Batch(359/480) done. Loss: 0.1270  lr:0.010000  network_time: 0.0111
[ Sat May 13 00:46:38 2023 ] 	Batch(459/480) done. Loss: 0.1426  lr:0.010000  network_time: 0.0111
[ Sat May 13 00:46:48 2023 ] 	Training Accuracy: 99.17%
[ Sat May 13 00:46:48 2023 ] Eval epoch: 24
[ Sat May 13 00:47:05 2023 ] 	Mean test loss of 120 batches: 0.023584824055433273.
[ Sat May 13 00:47:05 2023 ] 	Top1: 99.33%
[ Sat May 13 00:47:05 2023 ] 	Top5: 100.00%
[ Sat May 13 00:47:05 2023 ] Training epoch: 25
[ Sat May 13 00:47:44 2023 ] 	Batch(79/480) done. Loss: 0.1548  lr:0.010000  network_time: 0.0108
[ Sat May 13 00:48:32 2023 ] 	Batch(179/480) done. Loss: 0.0298  lr:0.010000  network_time: 0.0108
[ Sat May 13 00:49:21 2023 ] 	Batch(279/480) done. Loss: 0.0423  lr:0.010000  network_time: 0.0107
[ Sat May 13 00:50:10 2023 ] 	Batch(379/480) done. Loss: 0.0402  lr:0.010000  network_time: 0.0112
[ Sat May 13 00:50:59 2023 ] 	Batch(479/480) done. Loss: 0.0411  lr:0.010000  network_time: 0.0108
[ Sat May 13 00:50:59 2023 ] 	Training Accuracy: 98.71%
[ Sat May 13 00:50:59 2023 ] Eval epoch: 25
[ Sat May 13 00:51:16 2023 ] 	Mean test loss of 120 batches: 0.019672362133860588.
[ Sat May 13 00:51:16 2023 ] 	Top1: 99.83%
[ Sat May 13 00:51:16 2023 ] 	Top5: 100.00%
[ Sat May 13 00:51:16 2023 ] Training epoch: 26
[ Sat May 13 00:52:05 2023 ] 	Batch(99/480) done. Loss: 0.0384  lr:0.001000  network_time: 0.0134
[ Sat May 13 00:52:53 2023 ] 	Batch(199/480) done. Loss: 0.0583  lr:0.001000  network_time: 0.0113
[ Sat May 13 00:53:42 2023 ] 	Batch(299/480) done. Loss: 0.0878  lr:0.001000  network_time: 0.0136
[ Sat May 13 00:54:31 2023 ] 	Batch(399/480) done. Loss: 0.0725  lr:0.001000  network_time: 0.0111
[ Sat May 13 00:55:10 2023 ] 	Training Accuracy: 99.42%
[ Sat May 13 00:55:10 2023 ] Eval epoch: 26
[ Sat May 13 00:55:27 2023 ] 	Mean test loss of 120 batches: 0.01771029643714428.
[ Sat May 13 00:55:27 2023 ] 	Top1: 100.00%
[ Sat May 13 00:55:27 2023 ] 	Top5: 100.00%
[ Sat May 13 00:55:27 2023 ] Training epoch: 27
[ Sat May 13 00:55:37 2023 ] 	Batch(19/480) done. Loss: 0.0052  lr:0.001000  network_time: 0.0110
[ Sat May 13 00:56:26 2023 ] 	Batch(119/480) done. Loss: 0.1633  lr:0.001000  network_time: 0.0110
[ Sat May 13 00:57:14 2023 ] 	Batch(219/480) done. Loss: 0.0099  lr:0.001000  network_time: 0.0109
[ Sat May 13 00:58:03 2023 ] 	Batch(319/480) done. Loss: 0.0314  lr:0.001000  network_time: 0.0111
[ Sat May 13 00:58:52 2023 ] 	Batch(419/480) done. Loss: 0.0288  lr:0.001000  network_time: 0.0132
[ Sat May 13 00:59:21 2023 ] 	Training Accuracy: 99.12%
[ Sat May 13 00:59:21 2023 ] Eval epoch: 27
[ Sat May 13 00:59:38 2023 ] 	Mean test loss of 120 batches: 0.016033293679356575.
[ Sat May 13 00:59:38 2023 ] 	Top1: 99.83%
[ Sat May 13 00:59:38 2023 ] 	Top5: 100.00%
[ Sat May 13 00:59:38 2023 ] Training epoch: 28
[ Sat May 13 00:59:58 2023 ] 	Batch(39/480) done. Loss: 0.2514  lr:0.001000  network_time: 0.0106
[ Sat May 13 01:00:46 2023 ] 	Batch(139/480) done. Loss: 0.0696  lr:0.001000  network_time: 0.0108
[ Sat May 13 01:01:35 2023 ] 	Batch(239/480) done. Loss: 0.0550  lr:0.001000  network_time: 0.0110
[ Sat May 13 01:02:24 2023 ] 	Batch(339/480) done. Loss: 0.0633  lr:0.001000  network_time: 0.0107
[ Sat May 13 01:03:13 2023 ] 	Batch(439/480) done. Loss: 0.0150  lr:0.001000  network_time: 0.0114
[ Sat May 13 01:03:32 2023 ] 	Training Accuracy: 99.17%
[ Sat May 13 01:03:32 2023 ] Eval epoch: 28
[ Sat May 13 01:03:49 2023 ] 	Mean test loss of 120 batches: 0.01434648223221302.
[ Sat May 13 01:03:49 2023 ] 	Top1: 100.00%
[ Sat May 13 01:03:49 2023 ] 	Top5: 100.00%
[ Sat May 13 01:03:49 2023 ] Training epoch: 29
[ Sat May 13 01:04:19 2023 ] 	Batch(59/480) done. Loss: 0.0208  lr:0.001000  network_time: 0.0110
[ Sat May 13 01:05:07 2023 ] 	Batch(159/480) done. Loss: 1.1619  lr:0.001000  network_time: 0.0135
[ Sat May 13 01:05:56 2023 ] 	Batch(259/480) done. Loss: 0.0815  lr:0.001000  network_time: 0.0117
[ Sat May 13 01:06:45 2023 ] 	Batch(359/480) done. Loss: 0.0112  lr:0.001000  network_time: 0.0141
[ Sat May 13 01:07:34 2023 ] 	Batch(459/480) done. Loss: 0.0140  lr:0.001000  network_time: 0.0107
[ Sat May 13 01:07:44 2023 ] 	Training Accuracy: 99.00%
[ Sat May 13 01:07:44 2023 ] Eval epoch: 29
[ Sat May 13 01:08:01 2023 ] 	Mean test loss of 120 batches: 0.01634487323462963.
[ Sat May 13 01:08:01 2023 ] 	Top1: 99.83%
[ Sat May 13 01:08:01 2023 ] 	Top5: 100.00%
[ Sat May 13 01:08:01 2023 ] Training epoch: 30
[ Sat May 13 01:08:40 2023 ] 	Batch(79/480) done. Loss: 0.0535  lr:0.001000  network_time: 0.0109
[ Sat May 13 01:09:28 2023 ] 	Batch(179/480) done. Loss: 0.0363  lr:0.001000  network_time: 0.0107
[ Sat May 13 01:10:17 2023 ] 	Batch(279/480) done. Loss: 0.0476  lr:0.001000  network_time: 0.0111
[ Sat May 13 01:11:06 2023 ] 	Batch(379/480) done. Loss: 0.0072  lr:0.001000  network_time: 0.0133
[ Sat May 13 01:11:55 2023 ] 	Batch(479/480) done. Loss: 0.0724  lr:0.001000  network_time: 0.0107
[ Sat May 13 01:11:55 2023 ] 	Training Accuracy: 99.08%
[ Sat May 13 01:11:55 2023 ] Eval epoch: 30
[ Sat May 13 01:12:12 2023 ] 	Mean test loss of 120 batches: 0.017323873937129974.
[ Sat May 13 01:12:12 2023 ] 	Top1: 99.50%
[ Sat May 13 01:12:12 2023 ] 	Top5: 100.00%
