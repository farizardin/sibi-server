[ Tue May 16 11:04:40 2023 ] NUM WORKER: 1
[ Tue May 16 11:05:37 2023 ] Parameters:
{'work_dir': './work_dir/sibi_merged_inner_group_ShiftGCN_mod_4_joint_n_5_kfold_fold_5', 'model_saved_name': './save_models/sibi_merged_inner_group_ShiftGCN_mod_4_joint_n_5_kfold_fold_5', 'Experiment_name': 'sibi_merged_inner_group_ShiftGCN_mod_4_joint_n_5_kfold', 'config': './config/recalculated/train_sibi_with_mouth_augmented_merged_inner_group_shift_joint_mod_4.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 2, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'n_splits': 5, 'feeder': 'feeders.feeder_hsd.Feeder', 'num_worker': 1, 'train_feeder_args': {'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': -1, 'normalization': False}, 'test_feeder_args': None, 'data_path': './data/augmented_recalculate_normalized', 'model': 'model.shift_gcn.Model', 'model_args': {'num_class': 50, 'num_person': 1, 'num_point': 115, 'graph_group': [[0, 81], [82, 114]], 'method': 'grouped.inner', 'weight': 4, 'graph': 'graph.skeleton_with_mouth.SkeletonWithMouth', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [20, 25], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 5, 'test_batch_size': 5, 'start_epoch': 0, 'num_epoch': 30, 'folds_range': [2, 5], 'weight_decay': 0.0001, 'only_train_part': True, 'only_train_epoch': 1, 'warm_up_epoch': 0}

[ Tue May 16 11:05:37 2023 ] Training epoch: 1
[ Tue May 16 11:06:25 2023 ] 	Batch(99/480) done. Loss: 3.3420  lr:0.100000  network_time: 0.0110
[ Tue May 16 11:07:14 2023 ] 	Batch(199/480) done. Loss: 3.7359  lr:0.100000  network_time: 0.0112
[ Tue May 16 11:08:02 2023 ] 	Batch(299/480) done. Loss: 3.1683  lr:0.100000  network_time: 0.0117
[ Tue May 16 11:08:51 2023 ] 	Batch(399/480) done. Loss: 2.9007  lr:0.100000  network_time: 0.0111
[ Tue May 16 11:09:30 2023 ] 	Training Accuracy: 6.33%
[ Tue May 16 11:09:30 2023 ] Eval epoch: 1
[ Tue May 16 11:09:47 2023 ] 	Mean test loss of 120 batches: 2.8097503185272217.
[ Tue May 16 11:09:47 2023 ] 	Top1: 16.00%
[ Tue May 16 11:09:47 2023 ] 	Top5: 55.17%
[ Tue May 16 11:09:47 2023 ] Training epoch: 2
[ Tue May 16 11:09:57 2023 ] 	Batch(19/480) done. Loss: 3.2177  lr:0.100000  network_time: 0.0110
[ Tue May 16 11:10:45 2023 ] 	Batch(119/480) done. Loss: 2.9421  lr:0.100000  network_time: 0.0119
[ Tue May 16 11:11:34 2023 ] 	Batch(219/480) done. Loss: 3.1236  lr:0.100000  network_time: 0.0112
[ Tue May 16 11:12:23 2023 ] 	Batch(319/480) done. Loss: 1.7775  lr:0.100000  network_time: 0.0113
[ Tue May 16 11:13:12 2023 ] 	Batch(419/480) done. Loss: 3.6243  lr:0.100000  network_time: 0.0113
[ Tue May 16 11:13:41 2023 ] 	Training Accuracy: 16.33%
[ Tue May 16 11:13:41 2023 ] Eval epoch: 2
[ Tue May 16 11:13:58 2023 ] 	Mean test loss of 120 batches: 2.581651210784912.
[ Tue May 16 11:13:58 2023 ] 	Top1: 22.33%
[ Tue May 16 11:13:58 2023 ] 	Top5: 69.17%
[ Tue May 16 11:13:58 2023 ] Training epoch: 3
[ Tue May 16 11:14:17 2023 ] 	Batch(39/480) done. Loss: 2.4065  lr:0.100000  network_time: 0.0111
[ Tue May 16 11:15:06 2023 ] 	Batch(139/480) done. Loss: 2.8751  lr:0.100000  network_time: 0.0114
[ Tue May 16 11:15:55 2023 ] 	Batch(239/480) done. Loss: 2.5568  lr:0.100000  network_time: 0.0112
[ Tue May 16 11:16:44 2023 ] 	Batch(339/480) done. Loss: 2.6441  lr:0.100000  network_time: 0.0121
[ Tue May 16 11:17:33 2023 ] 	Batch(439/480) done. Loss: 1.6943  lr:0.100000  network_time: 0.0118
[ Tue May 16 11:17:52 2023 ] 	Training Accuracy: 27.29%
[ Tue May 16 11:17:52 2023 ] Eval epoch: 3
[ Tue May 16 11:18:09 2023 ] 	Mean test loss of 120 batches: 1.9573771953582764.
[ Tue May 16 11:18:09 2023 ] 	Top1: 38.67%
[ Tue May 16 11:18:09 2023 ] 	Top5: 86.33%
[ Tue May 16 11:18:09 2023 ] Training epoch: 4
[ Tue May 16 11:18:38 2023 ] 	Batch(59/480) done. Loss: 1.5915  lr:0.100000  network_time: 0.0114
[ Tue May 16 11:19:27 2023 ] 	Batch(159/480) done. Loss: 3.3248  lr:0.100000  network_time: 0.0114
[ Tue May 16 11:20:16 2023 ] 	Batch(259/480) done. Loss: 1.2129  lr:0.100000  network_time: 0.0128
[ Tue May 16 11:21:05 2023 ] 	Batch(359/480) done. Loss: 3.3108  lr:0.100000  network_time: 0.0114
[ Tue May 16 11:21:54 2023 ] 	Batch(459/480) done. Loss: 1.8971  lr:0.100000  network_time: 0.0109
[ Tue May 16 11:22:03 2023 ] 	Training Accuracy: 42.33%
[ Tue May 16 11:22:03 2023 ] Eval epoch: 4
[ Tue May 16 11:22:20 2023 ] 	Mean test loss of 120 batches: 1.4825547933578491.
[ Tue May 16 11:22:20 2023 ] 	Top1: 53.67%
[ Tue May 16 11:22:20 2023 ] 	Top5: 92.33%
[ Tue May 16 11:22:20 2023 ] Training epoch: 5
[ Tue May 16 11:22:59 2023 ] 	Batch(79/480) done. Loss: 1.2444  lr:0.100000  network_time: 0.0116
[ Tue May 16 11:23:48 2023 ] 	Batch(179/480) done. Loss: 0.5432  lr:0.100000  network_time: 0.0122
[ Tue May 16 11:24:37 2023 ] 	Batch(279/480) done. Loss: 1.5041  lr:0.100000  network_time: 0.0117
[ Tue May 16 11:25:26 2023 ] 	Batch(379/480) done. Loss: 0.4304  lr:0.100000  network_time: 0.0111
[ Tue May 16 11:26:14 2023 ] 	Batch(479/480) done. Loss: 0.7192  lr:0.100000  network_time: 0.0116
[ Tue May 16 11:26:14 2023 ] 	Training Accuracy: 56.42%
[ Tue May 16 11:26:14 2023 ] Eval epoch: 5
[ Tue May 16 11:26:31 2023 ] 	Mean test loss of 120 batches: 0.8695553541183472.
[ Tue May 16 11:26:31 2023 ] 	Top1: 71.17%
[ Tue May 16 11:26:31 2023 ] 	Top5: 97.83%
[ Tue May 16 11:26:31 2023 ] Training epoch: 6
[ Tue May 16 11:27:20 2023 ] 	Batch(99/480) done. Loss: 0.4996  lr:0.100000  network_time: 0.0126
[ Tue May 16 11:28:09 2023 ] 	Batch(199/480) done. Loss: 0.9441  lr:0.100000  network_time: 0.0121
[ Tue May 16 11:28:58 2023 ] 	Batch(299/480) done. Loss: 1.0098  lr:0.100000  network_time: 0.0115
[ Tue May 16 11:29:46 2023 ] 	Batch(399/480) done. Loss: 1.0166  lr:0.100000  network_time: 0.0110
[ Tue May 16 11:30:25 2023 ] 	Training Accuracy: 66.46%
[ Tue May 16 11:30:26 2023 ] Eval epoch: 6
[ Tue May 16 11:30:42 2023 ] 	Mean test loss of 120 batches: 0.6058543920516968.
[ Tue May 16 11:30:42 2023 ] 	Top1: 79.17%
[ Tue May 16 11:30:42 2023 ] 	Top5: 98.83%
[ Tue May 16 11:30:42 2023 ] Training epoch: 7
[ Tue May 16 11:30:52 2023 ] 	Batch(19/480) done. Loss: 0.1787  lr:0.100000  network_time: 0.0113
[ Tue May 16 11:31:41 2023 ] 	Batch(119/480) done. Loss: 0.8816  lr:0.100000  network_time: 0.0116
[ Tue May 16 11:32:30 2023 ] 	Batch(219/480) done. Loss: 0.8235  lr:0.100000  network_time: 0.0115
[ Tue May 16 11:33:19 2023 ] 	Batch(319/480) done. Loss: 0.8796  lr:0.100000  network_time: 0.0116
[ Tue May 16 11:34:07 2023 ] 	Batch(419/480) done. Loss: 2.2036  lr:0.100000  network_time: 0.0111
[ Tue May 16 11:34:37 2023 ] 	Training Accuracy: 71.50%
[ Tue May 16 11:34:37 2023 ] Eval epoch: 7
[ Tue May 16 11:34:53 2023 ] 	Mean test loss of 120 batches: 0.7477720975875854.
[ Tue May 16 11:34:53 2023 ] 	Top1: 74.67%
[ Tue May 16 11:34:53 2023 ] 	Top5: 98.17%
[ Tue May 16 11:34:53 2023 ] Training epoch: 8
[ Tue May 16 11:35:13 2023 ] 	Batch(39/480) done. Loss: 0.4182  lr:0.100000  network_time: 0.0118
[ Tue May 16 11:36:02 2023 ] 	Batch(139/480) done. Loss: 0.3606  lr:0.100000  network_time: 0.0115
[ Tue May 16 11:36:51 2023 ] 	Batch(239/480) done. Loss: 0.5830  lr:0.100000  network_time: 0.0115
[ Tue May 16 11:37:39 2023 ] 	Batch(339/480) done. Loss: 0.6949  lr:0.100000  network_time: 0.0114
[ Tue May 16 11:38:28 2023 ] 	Batch(439/480) done. Loss: 0.4779  lr:0.100000  network_time: 0.0111
[ Tue May 16 11:38:48 2023 ] 	Training Accuracy: 75.71%
[ Tue May 16 11:38:48 2023 ] Eval epoch: 8
[ Tue May 16 11:39:04 2023 ] 	Mean test loss of 120 batches: 0.8396726250648499.
[ Tue May 16 11:39:04 2023 ] 	Top1: 77.00%
[ Tue May 16 11:39:04 2023 ] 	Top5: 98.33%
[ Tue May 16 11:39:04 2023 ] Training epoch: 9
[ Tue May 16 11:39:34 2023 ] 	Batch(59/480) done. Loss: 0.6697  lr:0.100000  network_time: 0.0118
[ Tue May 16 11:40:23 2023 ] 	Batch(159/480) done. Loss: 0.8654  lr:0.100000  network_time: 0.0114
[ Tue May 16 11:41:12 2023 ] 	Batch(259/480) done. Loss: 0.6652  lr:0.100000  network_time: 0.0110
[ Tue May 16 11:42:00 2023 ] 	Batch(359/480) done. Loss: 1.4361  lr:0.100000  network_time: 0.0112
[ Tue May 16 11:42:49 2023 ] 	Batch(459/480) done. Loss: 0.4966  lr:0.100000  network_time: 0.0112
[ Tue May 16 11:42:59 2023 ] 	Training Accuracy: 78.42%
[ Tue May 16 11:42:59 2023 ] Eval epoch: 9
[ Tue May 16 11:43:16 2023 ] 	Mean test loss of 120 batches: 0.2617466151714325.
[ Tue May 16 11:43:16 2023 ] 	Top1: 91.50%
[ Tue May 16 11:43:16 2023 ] 	Top5: 99.83%
[ Tue May 16 11:43:16 2023 ] Training epoch: 10
[ Tue May 16 11:43:55 2023 ] 	Batch(79/480) done. Loss: 0.8694  lr:0.100000  network_time: 0.0114
[ Tue May 16 11:44:44 2023 ] 	Batch(179/480) done. Loss: 0.8393  lr:0.100000  network_time: 0.0115
[ Tue May 16 11:45:32 2023 ] 	Batch(279/480) done. Loss: 0.2316  lr:0.100000  network_time: 0.0112
[ Tue May 16 11:46:21 2023 ] 	Batch(379/480) done. Loss: 0.0693  lr:0.100000  network_time: 0.0114
[ Tue May 16 11:47:10 2023 ] 	Batch(479/480) done. Loss: 0.5733  lr:0.100000  network_time: 0.0118
[ Tue May 16 11:47:10 2023 ] 	Training Accuracy: 82.08%
[ Tue May 16 11:47:10 2023 ] Eval epoch: 10
[ Tue May 16 11:47:27 2023 ] 	Mean test loss of 120 batches: 0.1833553910255432.
[ Tue May 16 11:47:27 2023 ] 	Top1: 95.33%
[ Tue May 16 11:47:27 2023 ] 	Top5: 99.83%
[ Tue May 16 11:47:27 2023 ] Training epoch: 11
[ Tue May 16 11:48:16 2023 ] 	Batch(99/480) done. Loss: 0.2004  lr:0.100000  network_time: 0.0112
[ Tue May 16 11:49:05 2023 ] 	Batch(199/480) done. Loss: 0.0373  lr:0.100000  network_time: 0.0116
[ Tue May 16 11:49:53 2023 ] 	Batch(299/480) done. Loss: 0.5847  lr:0.100000  network_time: 0.0114
[ Tue May 16 11:50:42 2023 ] 	Batch(399/480) done. Loss: 1.0338  lr:0.100000  network_time: 0.0114
[ Tue May 16 11:51:21 2023 ] 	Training Accuracy: 83.46%
[ Tue May 16 11:51:21 2023 ] Eval epoch: 11
[ Tue May 16 11:51:38 2023 ] 	Mean test loss of 120 batches: 0.3908887803554535.
[ Tue May 16 11:51:38 2023 ] 	Top1: 86.67%
[ Tue May 16 11:51:38 2023 ] 	Top5: 100.00%
[ Tue May 16 11:51:38 2023 ] Training epoch: 12
[ Tue May 16 11:51:48 2023 ] 	Batch(19/480) done. Loss: 0.0803  lr:0.100000  network_time: 0.0115
[ Tue May 16 11:52:37 2023 ] 	Batch(119/480) done. Loss: 0.2354  lr:0.100000  network_time: 0.0113
[ Tue May 16 11:53:25 2023 ] 	Batch(219/480) done. Loss: 0.6515  lr:0.100000  network_time: 0.0112
[ Tue May 16 11:54:14 2023 ] 	Batch(319/480) done. Loss: 0.4458  lr:0.100000  network_time: 0.0115
[ Tue May 16 11:55:03 2023 ] 	Batch(419/480) done. Loss: 0.5566  lr:0.100000  network_time: 0.0111
[ Tue May 16 11:55:32 2023 ] 	Training Accuracy: 88.17%
[ Tue May 16 11:55:33 2023 ] Eval epoch: 12
[ Tue May 16 11:55:49 2023 ] 	Mean test loss of 120 batches: 0.36753252148628235.
[ Tue May 16 11:55:49 2023 ] 	Top1: 88.17%
[ Tue May 16 11:55:49 2023 ] 	Top5: 99.67%
[ Tue May 16 11:55:49 2023 ] Training epoch: 13
[ Tue May 16 11:56:09 2023 ] 	Batch(39/480) done. Loss: 0.0444  lr:0.100000  network_time: 0.0114
[ Tue May 16 11:56:58 2023 ] 	Batch(139/480) done. Loss: 0.1968  lr:0.100000  network_time: 0.0113
[ Tue May 16 11:57:46 2023 ] 	Batch(239/480) done. Loss: 0.1973  lr:0.100000  network_time: 0.0121
[ Tue May 16 11:58:35 2023 ] 	Batch(339/480) done. Loss: 0.1309  lr:0.100000  network_time: 0.0115
[ Tue May 16 11:59:24 2023 ] 	Batch(439/480) done. Loss: 1.4154  lr:0.100000  network_time: 0.0114
[ Tue May 16 11:59:44 2023 ] 	Training Accuracy: 88.33%
[ Tue May 16 11:59:44 2023 ] Eval epoch: 13
[ Tue May 16 12:00:00 2023 ] 	Mean test loss of 120 batches: 0.27697017788887024.
[ Tue May 16 12:00:00 2023 ] 	Top1: 91.67%
[ Tue May 16 12:00:00 2023 ] 	Top5: 99.83%
[ Tue May 16 12:00:00 2023 ] Training epoch: 14
[ Tue May 16 12:00:30 2023 ] 	Batch(59/480) done. Loss: 1.1783  lr:0.100000  network_time: 0.0112
[ Tue May 16 12:01:19 2023 ] 	Batch(159/480) done. Loss: 0.1704  lr:0.100000  network_time: 0.0110
[ Tue May 16 12:02:08 2023 ] 	Batch(259/480) done. Loss: 0.0869  lr:0.100000  network_time: 0.0111
[ Tue May 16 12:02:56 2023 ] 	Batch(359/480) done. Loss: 0.2515  lr:0.100000  network_time: 0.0110
[ Tue May 16 12:03:45 2023 ] 	Batch(459/480) done. Loss: 0.6568  lr:0.100000  network_time: 0.0112
[ Tue May 16 12:03:55 2023 ] 	Training Accuracy: 87.00%
[ Tue May 16 12:03:55 2023 ] Eval epoch: 14
[ Tue May 16 12:04:12 2023 ] 	Mean test loss of 120 batches: 0.4689052700996399.
[ Tue May 16 12:04:12 2023 ] 	Top1: 86.17%
[ Tue May 16 12:04:12 2023 ] 	Top5: 99.50%
[ Tue May 16 12:04:12 2023 ] Training epoch: 15
[ Tue May 16 12:04:51 2023 ] 	Batch(79/480) done. Loss: 0.3931  lr:0.100000  network_time: 0.0111
[ Tue May 16 12:05:40 2023 ] 	Batch(179/480) done. Loss: 0.1085  lr:0.100000  network_time: 0.0111
[ Tue May 16 12:06:29 2023 ] 	Batch(279/480) done. Loss: 0.1212  lr:0.100000  network_time: 0.0110
[ Tue May 16 12:07:17 2023 ] 	Batch(379/480) done. Loss: 0.1642  lr:0.100000  network_time: 0.0111
[ Tue May 16 12:08:06 2023 ] 	Batch(479/480) done. Loss: 0.0668  lr:0.100000  network_time: 0.0111
[ Tue May 16 12:08:06 2023 ] 	Training Accuracy: 90.46%
[ Tue May 16 12:08:06 2023 ] Eval epoch: 15
[ Tue May 16 12:08:23 2023 ] 	Mean test loss of 120 batches: 0.17656847834587097.
[ Tue May 16 12:08:23 2023 ] 	Top1: 95.17%
[ Tue May 16 12:08:23 2023 ] 	Top5: 100.00%
[ Tue May 16 12:08:23 2023 ] Training epoch: 16
[ Tue May 16 12:09:12 2023 ] 	Batch(99/480) done. Loss: 0.2452  lr:0.100000  network_time: 0.0115
[ Tue May 16 12:10:01 2023 ] 	Batch(199/480) done. Loss: 0.0545  lr:0.100000  network_time: 0.0113
[ Tue May 16 12:10:50 2023 ] 	Batch(299/480) done. Loss: 0.0684  lr:0.100000  network_time: 0.0115
[ Tue May 16 12:11:38 2023 ] 	Batch(399/480) done. Loss: 0.7299  lr:0.100000  network_time: 0.0110
[ Tue May 16 12:12:17 2023 ] 	Training Accuracy: 89.92%
[ Tue May 16 12:12:18 2023 ] Eval epoch: 16
[ Tue May 16 12:12:34 2023 ] 	Mean test loss of 120 batches: 0.27996551990509033.
[ Tue May 16 12:12:34 2023 ] 	Top1: 91.83%
[ Tue May 16 12:12:34 2023 ] 	Top5: 99.50%
[ Tue May 16 12:12:34 2023 ] Training epoch: 17
[ Tue May 16 12:12:44 2023 ] 	Batch(19/480) done. Loss: 0.0365  lr:0.100000  network_time: 0.0113
[ Tue May 16 12:13:33 2023 ] 	Batch(119/480) done. Loss: 0.0090  lr:0.100000  network_time: 0.0111
[ Tue May 16 12:14:22 2023 ] 	Batch(219/480) done. Loss: 0.0246  lr:0.100000  network_time: 0.0108
[ Tue May 16 12:15:10 2023 ] 	Batch(319/480) done. Loss: 0.0363  lr:0.100000  network_time: 0.0114
[ Tue May 16 12:15:59 2023 ] 	Batch(419/480) done. Loss: 0.8357  lr:0.100000  network_time: 0.0117
[ Tue May 16 12:16:29 2023 ] 	Training Accuracy: 91.25%
[ Tue May 16 12:16:29 2023 ] Eval epoch: 17
[ Tue May 16 12:16:45 2023 ] 	Mean test loss of 120 batches: 0.18197894096374512.
[ Tue May 16 12:16:45 2023 ] 	Top1: 94.83%
[ Tue May 16 12:16:45 2023 ] 	Top5: 100.00%
[ Tue May 16 12:16:45 2023 ] Training epoch: 18
[ Tue May 16 12:17:05 2023 ] 	Batch(39/480) done. Loss: 0.7146  lr:0.100000  network_time: 0.0111
[ Tue May 16 12:17:54 2023 ] 	Batch(139/480) done. Loss: 0.2566  lr:0.100000  network_time: 0.0117
[ Tue May 16 12:18:43 2023 ] 	Batch(239/480) done. Loss: 0.0113  lr:0.100000  network_time: 0.0114
[ Tue May 16 12:19:32 2023 ] 	Batch(339/480) done. Loss: 0.0347  lr:0.100000  network_time: 0.0112
[ Tue May 16 12:20:21 2023 ] 	Batch(439/480) done. Loss: 0.1225  lr:0.100000  network_time: 0.0122
[ Tue May 16 12:20:40 2023 ] 	Training Accuracy: 89.83%
[ Tue May 16 12:20:40 2023 ] Eval epoch: 18
[ Tue May 16 12:20:57 2023 ] 	Mean test loss of 120 batches: 1.5844247341156006.
[ Tue May 16 12:20:57 2023 ] 	Top1: 72.33%
[ Tue May 16 12:20:57 2023 ] 	Top5: 94.33%
[ Tue May 16 12:20:57 2023 ] Training epoch: 19
[ Tue May 16 12:21:26 2023 ] 	Batch(59/480) done. Loss: 0.0224  lr:0.100000  network_time: 0.0115
[ Tue May 16 12:22:15 2023 ] 	Batch(159/480) done. Loss: 0.8150  lr:0.100000  network_time: 0.0110
[ Tue May 16 12:23:04 2023 ] 	Batch(259/480) done. Loss: 0.0166  lr:0.100000  network_time: 0.0120
[ Tue May 16 12:23:53 2023 ] 	Batch(359/480) done. Loss: 0.0650  lr:0.100000  network_time: 0.0112
[ Tue May 16 12:24:42 2023 ] 	Batch(459/480) done. Loss: 0.0082  lr:0.100000  network_time: 0.0112
[ Tue May 16 12:24:51 2023 ] 	Training Accuracy: 91.92%
[ Tue May 16 12:24:51 2023 ] Eval epoch: 19
[ Tue May 16 12:25:08 2023 ] 	Mean test loss of 120 batches: 0.2644357681274414.
[ Tue May 16 12:25:08 2023 ] 	Top1: 91.50%
[ Tue May 16 12:25:08 2023 ] 	Top5: 100.00%
[ Tue May 16 12:25:08 2023 ] Training epoch: 20
[ Tue May 16 12:25:47 2023 ] 	Batch(79/480) done. Loss: 0.0053  lr:0.100000  network_time: 0.0111
[ Tue May 16 12:26:36 2023 ] 	Batch(179/480) done. Loss: 0.0318  lr:0.100000  network_time: 0.0120
[ Tue May 16 12:27:25 2023 ] 	Batch(279/480) done. Loss: 0.9640  lr:0.100000  network_time: 0.0110
[ Tue May 16 12:28:14 2023 ] 	Batch(379/480) done. Loss: 0.0245  lr:0.100000  network_time: 0.0109
[ Tue May 16 12:29:03 2023 ] 	Batch(479/480) done. Loss: 0.3713  lr:0.100000  network_time: 0.0112
[ Tue May 16 12:29:03 2023 ] 	Training Accuracy: 91.04%
[ Tue May 16 12:29:03 2023 ] Eval epoch: 20
[ Tue May 16 12:29:19 2023 ] 	Mean test loss of 120 batches: 0.421641081571579.
[ Tue May 16 12:29:19 2023 ] 	Top1: 86.00%
[ Tue May 16 12:29:19 2023 ] 	Top5: 99.67%
[ Tue May 16 12:29:19 2023 ] Training epoch: 21
[ Tue May 16 12:30:08 2023 ] 	Batch(99/480) done. Loss: 0.2775  lr:0.010000  network_time: 0.0113
[ Tue May 16 12:30:57 2023 ] 	Batch(199/480) done. Loss: 0.1216  lr:0.010000  network_time: 0.0111
[ Tue May 16 12:31:46 2023 ] 	Batch(299/480) done. Loss: 0.0361  lr:0.010000  network_time: 0.0113
[ Tue May 16 12:32:35 2023 ] 	Batch(399/480) done. Loss: 0.0238  lr:0.010000  network_time: 0.0119
[ Tue May 16 12:33:14 2023 ] 	Training Accuracy: 97.46%
[ Tue May 16 12:33:14 2023 ] Eval epoch: 21
[ Tue May 16 12:33:31 2023 ] 	Mean test loss of 120 batches: 0.051453765481710434.
[ Tue May 16 12:33:31 2023 ] 	Top1: 98.83%
[ Tue May 16 12:33:31 2023 ] 	Top5: 100.00%
[ Tue May 16 12:33:31 2023 ] Training epoch: 22
[ Tue May 16 12:33:41 2023 ] 	Batch(19/480) done. Loss: 0.0134  lr:0.010000  network_time: 0.0113
[ Tue May 16 12:34:29 2023 ] 	Batch(119/480) done. Loss: 0.1199  lr:0.010000  network_time: 0.0113
[ Tue May 16 12:35:18 2023 ] 	Batch(219/480) done. Loss: 0.2463  lr:0.010000  network_time: 0.0116
[ Tue May 16 12:36:07 2023 ] 	Batch(319/480) done. Loss: 0.0773  lr:0.010000  network_time: 0.0113
[ Tue May 16 12:36:56 2023 ] 	Batch(419/480) done. Loss: 0.0063  lr:0.010000  network_time: 0.0116
[ Tue May 16 12:37:25 2023 ] 	Training Accuracy: 99.12%
[ Tue May 16 12:37:25 2023 ] Eval epoch: 22
[ Tue May 16 12:37:42 2023 ] 	Mean test loss of 120 batches: 0.04368441551923752.
[ Tue May 16 12:37:42 2023 ] 	Top1: 98.83%
[ Tue May 16 12:37:42 2023 ] 	Top5: 100.00%
[ Tue May 16 12:37:42 2023 ] Training epoch: 23
[ Tue May 16 12:38:02 2023 ] 	Batch(39/480) done. Loss: 0.0587  lr:0.010000  network_time: 0.0116
[ Tue May 16 12:38:51 2023 ] 	Batch(139/480) done. Loss: 0.0033  lr:0.010000  network_time: 0.0113
[ Tue May 16 12:39:39 2023 ] 	Batch(239/480) done. Loss: 0.0116  lr:0.010000  network_time: 0.0124
[ Tue May 16 12:40:28 2023 ] 	Batch(339/480) done. Loss: 0.0040  lr:0.010000  network_time: 0.0111
[ Tue May 16 12:41:17 2023 ] 	Batch(439/480) done. Loss: 0.0035  lr:0.010000  network_time: 0.0109
[ Tue May 16 12:41:37 2023 ] 	Training Accuracy: 99.33%
[ Tue May 16 12:41:37 2023 ] Eval epoch: 23
[ Tue May 16 12:41:53 2023 ] 	Mean test loss of 120 batches: 0.02766300179064274.
[ Tue May 16 12:41:53 2023 ] 	Top1: 99.17%
[ Tue May 16 12:41:53 2023 ] 	Top5: 100.00%
[ Tue May 16 12:41:53 2023 ] Training epoch: 24
[ Tue May 16 12:42:23 2023 ] 	Batch(59/480) done. Loss: 0.0602  lr:0.010000  network_time: 0.0112
[ Tue May 16 12:43:12 2023 ] 	Batch(159/480) done. Loss: 0.0045  lr:0.010000  network_time: 0.0110
[ Tue May 16 12:44:00 2023 ] 	Batch(259/480) done. Loss: 0.0280  lr:0.010000  network_time: 0.0114
[ Tue May 16 12:44:49 2023 ] 	Batch(359/480) done. Loss: 0.0173  lr:0.010000  network_time: 0.0110
[ Tue May 16 12:45:38 2023 ] 	Batch(459/480) done. Loss: 0.0464  lr:0.010000  network_time: 0.0113
[ Tue May 16 12:45:48 2023 ] 	Training Accuracy: 99.54%
[ Tue May 16 12:45:48 2023 ] Eval epoch: 24
[ Tue May 16 12:46:05 2023 ] 	Mean test loss of 120 batches: 0.01724674552679062.
[ Tue May 16 12:46:05 2023 ] 	Top1: 99.50%
[ Tue May 16 12:46:05 2023 ] 	Top5: 100.00%
[ Tue May 16 12:46:05 2023 ] Training epoch: 25
[ Tue May 16 12:46:44 2023 ] 	Batch(79/480) done. Loss: 0.0159  lr:0.010000  network_time: 0.0113
[ Tue May 16 12:47:33 2023 ] 	Batch(179/480) done. Loss: 0.0084  lr:0.010000  network_time: 0.0111
[ Tue May 16 12:48:21 2023 ] 	Batch(279/480) done. Loss: 0.0021  lr:0.010000  network_time: 0.0111
[ Tue May 16 12:49:10 2023 ] 	Batch(379/480) done. Loss: 0.0113  lr:0.010000  network_time: 0.0115
[ Tue May 16 12:49:59 2023 ] 	Batch(479/480) done. Loss: 0.0353  lr:0.010000  network_time: 0.0114
[ Tue May 16 12:49:59 2023 ] 	Training Accuracy: 99.54%
[ Tue May 16 12:49:59 2023 ] Eval epoch: 25
[ Tue May 16 12:50:16 2023 ] 	Mean test loss of 120 batches: 0.01680011674761772.
[ Tue May 16 12:50:16 2023 ] 	Top1: 99.83%
[ Tue May 16 12:50:16 2023 ] 	Top5: 100.00%
[ Tue May 16 12:50:16 2023 ] Training epoch: 26
[ Tue May 16 12:51:05 2023 ] 	Batch(99/480) done. Loss: 0.1100  lr:0.001000  network_time: 0.0115
[ Tue May 16 12:51:53 2023 ] 	Batch(199/480) done. Loss: 0.0023  lr:0.001000  network_time: 0.0114
[ Tue May 16 12:52:42 2023 ] 	Batch(299/480) done. Loss: 0.0170  lr:0.001000  network_time: 0.0113
[ Tue May 16 12:53:31 2023 ] 	Batch(399/480) done. Loss: 0.0031  lr:0.001000  network_time: 0.0114
[ Tue May 16 12:54:10 2023 ] 	Training Accuracy: 99.83%
[ Tue May 16 12:54:10 2023 ] Eval epoch: 26
[ Tue May 16 12:54:27 2023 ] 	Mean test loss of 120 batches: 0.004988909233361483.
[ Tue May 16 12:54:27 2023 ] 	Top1: 100.00%
[ Tue May 16 12:54:27 2023 ] 	Top5: 100.00%
[ Tue May 16 12:54:27 2023 ] Training epoch: 27
[ Tue May 16 12:54:37 2023 ] 	Batch(19/480) done. Loss: 0.0187  lr:0.001000  network_time: 0.0111
[ Tue May 16 12:55:26 2023 ] 	Batch(119/480) done. Loss: 0.0066  lr:0.001000  network_time: 0.0113
[ Tue May 16 12:56:15 2023 ] 	Batch(219/480) done. Loss: 0.0030  lr:0.001000  network_time: 0.0115
[ Tue May 16 12:57:03 2023 ] 	Batch(319/480) done. Loss: 0.0173  lr:0.001000  network_time: 0.0126
[ Tue May 16 12:57:52 2023 ] 	Batch(419/480) done. Loss: 0.0044  lr:0.001000  network_time: 0.0113
[ Tue May 16 12:58:22 2023 ] 	Training Accuracy: 99.67%
[ Tue May 16 12:58:22 2023 ] Eval epoch: 27
[ Tue May 16 12:58:38 2023 ] 	Mean test loss of 120 batches: 0.010284101590514183.
[ Tue May 16 12:58:38 2023 ] 	Top1: 99.67%
[ Tue May 16 12:58:38 2023 ] 	Top5: 100.00%
[ Tue May 16 12:58:38 2023 ] Training epoch: 28
[ Tue May 16 12:58:58 2023 ] 	Batch(39/480) done. Loss: 0.0256  lr:0.001000  network_time: 0.0125
[ Tue May 16 12:59:47 2023 ] 	Batch(139/480) done. Loss: 0.0490  lr:0.001000  network_time: 0.0115
[ Tue May 16 13:00:36 2023 ] 	Batch(239/480) done. Loss: 0.2982  lr:0.001000  network_time: 0.0116
[ Tue May 16 13:01:25 2023 ] 	Batch(339/480) done. Loss: 0.0175  lr:0.001000  network_time: 0.0116
[ Tue May 16 13:02:14 2023 ] 	Batch(439/480) done. Loss: 0.0085  lr:0.001000  network_time: 0.0114
[ Tue May 16 13:02:33 2023 ] 	Training Accuracy: 99.71%
[ Tue May 16 13:02:33 2023 ] Eval epoch: 28
[ Tue May 16 13:02:50 2023 ] 	Mean test loss of 120 batches: 0.004719533491879702.
[ Tue May 16 13:02:50 2023 ] 	Top1: 100.00%
[ Tue May 16 13:02:50 2023 ] 	Top5: 100.00%
[ Tue May 16 13:02:50 2023 ] Training epoch: 29
[ Tue May 16 13:03:19 2023 ] 	Batch(59/480) done. Loss: 0.0170  lr:0.001000  network_time: 0.0112
[ Tue May 16 13:04:08 2023 ] 	Batch(159/480) done. Loss: 0.3770  lr:0.001000  network_time: 0.0116
[ Tue May 16 13:04:57 2023 ] 	Batch(259/480) done. Loss: 0.0558  lr:0.001000  network_time: 0.0114
[ Tue May 16 13:05:46 2023 ] 	Batch(359/480) done. Loss: 0.0149  lr:0.001000  network_time: 0.0122
[ Tue May 16 13:06:35 2023 ] 	Batch(459/480) done. Loss: 0.0250  lr:0.001000  network_time: 0.0115
[ Tue May 16 13:06:44 2023 ] 	Training Accuracy: 99.75%
[ Tue May 16 13:06:45 2023 ] Eval epoch: 29
[ Tue May 16 13:07:01 2023 ] 	Mean test loss of 120 batches: 0.012088662944734097.
[ Tue May 16 13:07:01 2023 ] 	Top1: 99.83%
[ Tue May 16 13:07:01 2023 ] 	Top5: 100.00%
[ Tue May 16 13:07:01 2023 ] Training epoch: 30
[ Tue May 16 13:07:40 2023 ] 	Batch(79/480) done. Loss: 0.0154  lr:0.001000  network_time: 0.0113
[ Tue May 16 13:08:29 2023 ] 	Batch(179/480) done. Loss: 0.0022  lr:0.001000  network_time: 0.0119
[ Tue May 16 13:09:18 2023 ] 	Batch(279/480) done. Loss: 0.0027  lr:0.001000  network_time: 0.0114
[ Tue May 16 13:10:07 2023 ] 	Batch(379/480) done. Loss: 0.0316  lr:0.001000  network_time: 0.0118
[ Tue May 16 13:10:56 2023 ] 	Batch(479/480) done. Loss: 0.0781  lr:0.001000  network_time: 0.0111
[ Tue May 16 13:10:56 2023 ] 	Training Accuracy: 99.58%
[ Tue May 16 13:10:56 2023 ] Eval epoch: 30
[ Tue May 16 13:11:12 2023 ] 	Mean test loss of 120 batches: 0.0037587620317935944.
[ Tue May 16 13:11:12 2023 ] 	Top1: 100.00%
[ Tue May 16 13:11:12 2023 ] 	Top5: 100.00%
