[ Thu May 18 14:19:15 2023 ] NUM WORKER: 1
[ Thu May 18 14:20:12 2023 ] Parameters:
{'work_dir': './work_dir/sibi_nonlocal_ShiftGCN_joint_n_5_kfold_fold_3', 'model_saved_name': './save_models/sibi_nonlocal_ShiftGCN_joint_n_5_kfold_fold_3', 'Experiment_name': 'sibi_nonlocal_ShiftGCN_joint_n_5_kfold', 'config': './config/recalculated/train_sibi_with_mouth_augmented_non_local.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 2, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'n_splits': 5, 'feeder': 'feeders.feeder_hsd.Feeder', 'num_worker': 1, 'train_feeder_args': {'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': -1, 'normalization': False}, 'test_feeder_args': None, 'data_path': './data/augmented_recalculate_normalized', 'model': 'model.shift_gcn.Model', 'model_args': {'num_class': 50, 'num_person': 1, 'num_point': 115, 'method': 'nonlocal', 'graph': 'graph.skeleton_with_mouth.SkeletonWithMouth', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [20, 25], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 5, 'test_batch_size': 5, 'start_epoch': 0, 'num_epoch': 30, 'folds_range': [0, 5], 'weight_decay': 0.0001, 'only_train_part': True, 'only_train_epoch': 1, 'warm_up_epoch': 0}

[ Thu May 18 14:20:12 2023 ] Training epoch: 1
[ Thu May 18 14:20:55 2023 ] 	Batch(99/480) done. Loss: 3.4701  lr:0.100000  network_time: 0.0112
[ Thu May 18 14:21:39 2023 ] 	Batch(199/480) done. Loss: 3.7696  lr:0.100000  network_time: 0.0111
[ Thu May 18 14:22:22 2023 ] 	Batch(299/480) done. Loss: 3.5888  lr:0.100000  network_time: 0.0116
[ Thu May 18 14:23:06 2023 ] 	Batch(399/480) done. Loss: 3.2658  lr:0.100000  network_time: 0.0113
[ Thu May 18 14:23:40 2023 ] 	Training Accuracy: 6.00%
[ Thu May 18 14:23:40 2023 ] Eval epoch: 1
[ Thu May 18 14:23:56 2023 ] 	Mean test loss of 120 batches: 3.9955146312713623.
[ Thu May 18 14:23:56 2023 ] 	Top1: 12.83%
[ Thu May 18 14:23:56 2023 ] 	Top5: 49.00%
[ Thu May 18 14:23:56 2023 ] Training epoch: 2
[ Thu May 18 14:24:05 2023 ] 	Batch(19/480) done. Loss: 2.9867  lr:0.100000  network_time: 0.0112
[ Thu May 18 14:24:49 2023 ] 	Batch(119/480) done. Loss: 3.2165  lr:0.100000  network_time: 0.0112
[ Thu May 18 14:25:32 2023 ] 	Batch(219/480) done. Loss: 3.0191  lr:0.100000  network_time: 0.0114
[ Thu May 18 14:26:16 2023 ] 	Batch(319/480) done. Loss: 1.6499  lr:0.100000  network_time: 0.0115
[ Thu May 18 14:26:59 2023 ] 	Batch(419/480) done. Loss: 3.7688  lr:0.100000  network_time: 0.0111
[ Thu May 18 14:27:25 2023 ] 	Training Accuracy: 16.04%
[ Thu May 18 14:27:25 2023 ] Eval epoch: 2
[ Thu May 18 14:27:41 2023 ] 	Mean test loss of 120 batches: 5.379229545593262.
[ Thu May 18 14:27:41 2023 ] 	Top1: 16.00%
[ Thu May 18 14:27:41 2023 ] 	Top5: 62.17%
[ Thu May 18 14:27:41 2023 ] Training epoch: 3
[ Thu May 18 14:27:59 2023 ] 	Batch(39/480) done. Loss: 2.5760  lr:0.100000  network_time: 0.0111
[ Thu May 18 14:28:42 2023 ] 	Batch(139/480) done. Loss: 2.8478  lr:0.100000  network_time: 0.0113
[ Thu May 18 14:29:26 2023 ] 	Batch(239/480) done. Loss: 2.4004  lr:0.100000  network_time: 0.0113
[ Thu May 18 14:30:09 2023 ] 	Batch(339/480) done. Loss: 2.2775  lr:0.100000  network_time: 0.0111
[ Thu May 18 14:30:53 2023 ] 	Batch(439/480) done. Loss: 2.1648  lr:0.100000  network_time: 0.0120
[ Thu May 18 14:31:10 2023 ] 	Training Accuracy: 26.25%
[ Thu May 18 14:31:10 2023 ] Eval epoch: 3
[ Thu May 18 14:31:26 2023 ] 	Mean test loss of 120 batches: 2.831965684890747.
[ Thu May 18 14:31:26 2023 ] 	Top1: 30.67%
[ Thu May 18 14:31:26 2023 ] 	Top5: 81.67%
[ Thu May 18 14:31:26 2023 ] Training epoch: 4
[ Thu May 18 14:31:52 2023 ] 	Batch(59/480) done. Loss: 1.5053  lr:0.100000  network_time: 0.0120
[ Thu May 18 14:32:36 2023 ] 	Batch(159/480) done. Loss: 3.8333  lr:0.100000  network_time: 0.0119
[ Thu May 18 14:33:19 2023 ] 	Batch(259/480) done. Loss: 1.7654  lr:0.100000  network_time: 0.0114
[ Thu May 18 14:34:03 2023 ] 	Batch(359/480) done. Loss: 1.2342  lr:0.100000  network_time: 0.0114
[ Thu May 18 14:34:47 2023 ] 	Batch(459/480) done. Loss: 1.9432  lr:0.100000  network_time: 0.0114
[ Thu May 18 14:34:55 2023 ] 	Training Accuracy: 38.00%
[ Thu May 18 14:34:55 2023 ] Eval epoch: 4
[ Thu May 18 14:35:11 2023 ] 	Mean test loss of 120 batches: 3.0146048069000244.
[ Thu May 18 14:35:11 2023 ] 	Top1: 45.67%
[ Thu May 18 14:35:11 2023 ] 	Top5: 85.83%
[ Thu May 18 14:35:11 2023 ] Training epoch: 5
[ Thu May 18 14:35:46 2023 ] 	Batch(79/480) done. Loss: 1.4918  lr:0.100000  network_time: 0.0116
[ Thu May 18 14:36:30 2023 ] 	Batch(179/480) done. Loss: 2.1793  lr:0.100000  network_time: 0.0115
[ Thu May 18 14:37:13 2023 ] 	Batch(279/480) done. Loss: 1.4495  lr:0.100000  network_time: 0.0117
[ Thu May 18 14:37:57 2023 ] 	Batch(379/480) done. Loss: 0.4895  lr:0.100000  network_time: 0.0113
[ Thu May 18 14:38:40 2023 ] 	Batch(479/480) done. Loss: 0.9102  lr:0.100000  network_time: 0.0117
[ Thu May 18 14:38:41 2023 ] 	Training Accuracy: 48.04%
[ Thu May 18 14:38:41 2023 ] Eval epoch: 5
[ Thu May 18 14:38:56 2023 ] 	Mean test loss of 120 batches: 1.9712938070297241.
[ Thu May 18 14:38:56 2023 ] 	Top1: 52.00%
[ Thu May 18 14:38:56 2023 ] 	Top5: 93.00%
[ Thu May 18 14:38:56 2023 ] Training epoch: 6
[ Thu May 18 14:39:40 2023 ] 	Batch(99/480) done. Loss: 2.1030  lr:0.100000  network_time: 0.0112
[ Thu May 18 14:40:24 2023 ] 	Batch(199/480) done. Loss: 1.4624  lr:0.100000  network_time: 0.0112
[ Thu May 18 14:41:07 2023 ] 	Batch(299/480) done. Loss: 1.0671  lr:0.100000  network_time: 0.0112
[ Thu May 18 14:41:51 2023 ] 	Batch(399/480) done. Loss: 0.9567  lr:0.100000  network_time: 0.0117
[ Thu May 18 14:42:26 2023 ] 	Training Accuracy: 56.71%
[ Thu May 18 14:42:26 2023 ] Eval epoch: 6
[ Thu May 18 14:42:42 2023 ] 	Mean test loss of 120 batches: 1.0144412517547607.
[ Thu May 18 14:42:42 2023 ] 	Top1: 65.83%
[ Thu May 18 14:42:42 2023 ] 	Top5: 97.50%
[ Thu May 18 14:42:42 2023 ] Training epoch: 7
[ Thu May 18 14:42:50 2023 ] 	Batch(19/480) done. Loss: 0.4203  lr:0.100000  network_time: 0.0116
[ Thu May 18 14:43:34 2023 ] 	Batch(119/480) done. Loss: 0.9839  lr:0.100000  network_time: 0.0160
[ Thu May 18 14:44:17 2023 ] 	Batch(219/480) done. Loss: 0.6210  lr:0.100000  network_time: 0.0116
[ Thu May 18 14:45:01 2023 ] 	Batch(319/480) done. Loss: 1.0530  lr:0.100000  network_time: 0.0114
[ Thu May 18 14:45:45 2023 ] 	Batch(419/480) done. Loss: 2.3107  lr:0.100000  network_time: 0.0114
[ Thu May 18 14:46:11 2023 ] 	Training Accuracy: 63.29%
[ Thu May 18 14:46:11 2023 ] Eval epoch: 7
[ Thu May 18 14:46:27 2023 ] 	Mean test loss of 120 batches: 1.6010279655456543.
[ Thu May 18 14:46:27 2023 ] 	Top1: 67.00%
[ Thu May 18 14:46:27 2023 ] 	Top5: 94.67%
[ Thu May 18 14:46:27 2023 ] Training epoch: 8
[ Thu May 18 14:46:44 2023 ] 	Batch(39/480) done. Loss: 1.6736  lr:0.100000  network_time: 0.0116
[ Thu May 18 14:47:28 2023 ] 	Batch(139/480) done. Loss: 0.7397  lr:0.100000  network_time: 0.0110
[ Thu May 18 14:48:11 2023 ] 	Batch(239/480) done. Loss: 1.2548  lr:0.100000  network_time: 0.0112
[ Thu May 18 14:48:55 2023 ] 	Batch(339/480) done. Loss: 0.6510  lr:0.100000  network_time: 0.0113
[ Thu May 18 14:49:38 2023 ] 	Batch(439/480) done. Loss: 1.1025  lr:0.100000  network_time: 0.0111
[ Thu May 18 14:49:56 2023 ] 	Training Accuracy: 68.88%
[ Thu May 18 14:49:56 2023 ] Eval epoch: 8
[ Thu May 18 14:50:12 2023 ] 	Mean test loss of 120 batches: 3.4280924797058105.
[ Thu May 18 14:50:12 2023 ] 	Top1: 42.83%
[ Thu May 18 14:50:12 2023 ] 	Top5: 80.33%
[ Thu May 18 14:50:12 2023 ] Training epoch: 9
[ Thu May 18 14:50:38 2023 ] 	Batch(59/480) done. Loss: 1.2874  lr:0.100000  network_time: 0.0116
[ Thu May 18 14:51:22 2023 ] 	Batch(159/480) done. Loss: 0.4677  lr:0.100000  network_time: 0.0116
[ Thu May 18 14:52:05 2023 ] 	Batch(259/480) done. Loss: 0.7246  lr:0.100000  network_time: 0.0113
[ Thu May 18 14:52:49 2023 ] 	Batch(359/480) done. Loss: 0.7416  lr:0.100000  network_time: 0.0119
[ Thu May 18 14:53:32 2023 ] 	Batch(459/480) done. Loss: 0.6861  lr:0.100000  network_time: 0.0124
[ Thu May 18 14:53:41 2023 ] 	Training Accuracy: 74.00%
[ Thu May 18 14:53:41 2023 ] Eval epoch: 9
[ Thu May 18 14:53:57 2023 ] 	Mean test loss of 120 batches: 1.1286530494689941.
[ Thu May 18 14:53:57 2023 ] 	Top1: 73.17%
[ Thu May 18 14:53:57 2023 ] 	Top5: 95.50%
[ Thu May 18 14:53:57 2023 ] Training epoch: 10
[ Thu May 18 14:54:32 2023 ] 	Batch(79/480) done. Loss: 0.2367  lr:0.100000  network_time: 0.0113
[ Thu May 18 14:55:16 2023 ] 	Batch(179/480) done. Loss: 0.2095  lr:0.100000  network_time: 0.0112
[ Thu May 18 14:55:59 2023 ] 	Batch(279/480) done. Loss: 0.3656  lr:0.100000  network_time: 0.0113
[ Thu May 18 14:56:43 2023 ] 	Batch(379/480) done. Loss: 0.3959  lr:0.100000  network_time: 0.0115
[ Thu May 18 14:57:26 2023 ] 	Batch(479/480) done. Loss: 0.4167  lr:0.100000  network_time: 0.0113
[ Thu May 18 14:57:26 2023 ] 	Training Accuracy: 77.92%
[ Thu May 18 14:57:26 2023 ] Eval epoch: 10
[ Thu May 18 14:57:42 2023 ] 	Mean test loss of 120 batches: 0.6020983457565308.
[ Thu May 18 14:57:42 2023 ] 	Top1: 81.17%
[ Thu May 18 14:57:42 2023 ] 	Top5: 98.67%
[ Thu May 18 14:57:42 2023 ] Training epoch: 11
[ Thu May 18 14:58:26 2023 ] 	Batch(99/480) done. Loss: 0.4785  lr:0.100000  network_time: 0.0113
[ Thu May 18 14:59:09 2023 ] 	Batch(199/480) done. Loss: 1.1602  lr:0.100000  network_time: 0.0113
[ Thu May 18 14:59:53 2023 ] 	Batch(299/480) done. Loss: 0.1085  lr:0.100000  network_time: 0.0120
[ Thu May 18 15:00:37 2023 ] 	Batch(399/480) done. Loss: 0.3801  lr:0.100000  network_time: 0.0114
[ Thu May 18 15:01:12 2023 ] 	Training Accuracy: 79.17%
[ Thu May 18 15:01:12 2023 ] Eval epoch: 11
[ Thu May 18 15:01:27 2023 ] 	Mean test loss of 120 batches: 0.35325077176094055.
[ Thu May 18 15:01:27 2023 ] 	Top1: 88.83%
[ Thu May 18 15:01:27 2023 ] 	Top5: 99.17%
[ Thu May 18 15:01:27 2023 ] Training epoch: 12
[ Thu May 18 15:01:36 2023 ] 	Batch(19/480) done. Loss: 0.2761  lr:0.100000  network_time: 0.0120
[ Thu May 18 15:02:20 2023 ] 	Batch(119/480) done. Loss: 0.2725  lr:0.100000  network_time: 0.0123
[ Thu May 18 15:03:03 2023 ] 	Batch(219/480) done. Loss: 0.9933  lr:0.100000  network_time: 0.0115
[ Thu May 18 15:03:47 2023 ] 	Batch(319/480) done. Loss: 0.3759  lr:0.100000  network_time: 0.0116
[ Thu May 18 15:04:30 2023 ] 	Batch(419/480) done. Loss: 0.1632  lr:0.100000  network_time: 0.0118
[ Thu May 18 15:04:57 2023 ] 	Training Accuracy: 84.04%
[ Thu May 18 15:04:57 2023 ] Eval epoch: 12
[ Thu May 18 15:05:13 2023 ] 	Mean test loss of 120 batches: 0.5261842012405396.
[ Thu May 18 15:05:13 2023 ] 	Top1: 84.67%
[ Thu May 18 15:05:13 2023 ] 	Top5: 99.33%
[ Thu May 18 15:05:13 2023 ] Training epoch: 13
[ Thu May 18 15:05:30 2023 ] 	Batch(39/480) done. Loss: 0.4226  lr:0.100000  network_time: 0.0115
[ Thu May 18 15:06:14 2023 ] 	Batch(139/480) done. Loss: 0.0147  lr:0.100000  network_time: 0.0116
[ Thu May 18 15:06:57 2023 ] 	Batch(239/480) done. Loss: 0.0902  lr:0.100000  network_time: 0.0112
[ Thu May 18 15:07:41 2023 ] 	Batch(339/480) done. Loss: 0.2819  lr:0.100000  network_time: 0.0115
[ Thu May 18 15:08:25 2023 ] 	Batch(439/480) done. Loss: 0.3296  lr:0.100000  network_time: 0.0112
[ Thu May 18 15:08:42 2023 ] 	Training Accuracy: 84.13%
[ Thu May 18 15:08:42 2023 ] Eval epoch: 13
[ Thu May 18 15:08:58 2023 ] 	Mean test loss of 120 batches: 0.34357738494873047.
[ Thu May 18 15:08:58 2023 ] 	Top1: 88.33%
[ Thu May 18 15:08:58 2023 ] 	Top5: 99.83%
[ Thu May 18 15:08:58 2023 ] Training epoch: 14
[ Thu May 18 15:09:24 2023 ] 	Batch(59/480) done. Loss: 0.0275  lr:0.100000  network_time: 0.0121
[ Thu May 18 15:10:08 2023 ] 	Batch(159/480) done. Loss: 1.8022  lr:0.100000  network_time: 0.0118
[ Thu May 18 15:10:51 2023 ] 	Batch(259/480) done. Loss: 0.6719  lr:0.100000  network_time: 0.0113
[ Thu May 18 15:11:35 2023 ] 	Batch(359/480) done. Loss: 0.7913  lr:0.100000  network_time: 0.0116
[ Thu May 18 15:12:18 2023 ] 	Batch(459/480) done. Loss: 0.0925  lr:0.100000  network_time: 0.0114
[ Thu May 18 15:12:27 2023 ] 	Training Accuracy: 84.67%
[ Thu May 18 15:12:27 2023 ] Eval epoch: 14
[ Thu May 18 15:12:43 2023 ] 	Mean test loss of 120 batches: 0.4045574963092804.
[ Thu May 18 15:12:43 2023 ] 	Top1: 89.00%
[ Thu May 18 15:12:43 2023 ] 	Top5: 99.00%
[ Thu May 18 15:12:43 2023 ] Training epoch: 15
[ Thu May 18 15:13:18 2023 ] 	Batch(79/480) done. Loss: 0.4868  lr:0.100000  network_time: 0.0116
[ Thu May 18 15:14:01 2023 ] 	Batch(179/480) done. Loss: 0.1825  lr:0.100000  network_time: 0.0113
[ Thu May 18 15:14:45 2023 ] 	Batch(279/480) done. Loss: 2.0303  lr:0.100000  network_time: 0.0109
[ Thu May 18 15:15:29 2023 ] 	Batch(379/480) done. Loss: 0.3211  lr:0.100000  network_time: 0.0124
[ Thu May 18 15:16:12 2023 ] 	Batch(479/480) done. Loss: 0.1778  lr:0.100000  network_time: 0.0117
[ Thu May 18 15:16:12 2023 ] 	Training Accuracy: 85.33%
[ Thu May 18 15:16:12 2023 ] Eval epoch: 15
[ Thu May 18 15:16:28 2023 ] 	Mean test loss of 120 batches: 0.24789901077747345.
[ Thu May 18 15:16:28 2023 ] 	Top1: 92.50%
[ Thu May 18 15:16:28 2023 ] 	Top5: 100.00%
[ Thu May 18 15:16:28 2023 ] Training epoch: 16
[ Thu May 18 15:17:12 2023 ] 	Batch(99/480) done. Loss: 0.0168  lr:0.100000  network_time: 0.0113
[ Thu May 18 15:17:55 2023 ] 	Batch(199/480) done. Loss: 0.1240  lr:0.100000  network_time: 0.0113
[ Thu May 18 15:18:39 2023 ] 	Batch(299/480) done. Loss: 0.4167  lr:0.100000  network_time: 0.0112
[ Thu May 18 15:19:23 2023 ] 	Batch(399/480) done. Loss: 0.9264  lr:0.100000  network_time: 0.0113
[ Thu May 18 15:19:57 2023 ] 	Training Accuracy: 88.54%
[ Thu May 18 15:19:58 2023 ] Eval epoch: 16
[ Thu May 18 15:20:13 2023 ] 	Mean test loss of 120 batches: 0.4619714319705963.
[ Thu May 18 15:20:13 2023 ] 	Top1: 84.33%
[ Thu May 18 15:20:13 2023 ] 	Top5: 99.00%
[ Thu May 18 15:20:13 2023 ] Training epoch: 17
[ Thu May 18 15:20:22 2023 ] 	Batch(19/480) done. Loss: 0.0331  lr:0.100000  network_time: 0.0112
[ Thu May 18 15:21:06 2023 ] 	Batch(119/480) done. Loss: 1.9829  lr:0.100000  network_time: 0.0111
[ Thu May 18 15:21:49 2023 ] 	Batch(219/480) done. Loss: 0.0418  lr:0.100000  network_time: 0.0117
[ Thu May 18 15:22:33 2023 ] 	Batch(319/480) done. Loss: 0.2514  lr:0.100000  network_time: 0.0112
[ Thu May 18 15:23:16 2023 ] 	Batch(419/480) done. Loss: 0.1455  lr:0.100000  network_time: 0.0141
[ Thu May 18 15:23:43 2023 ] 	Training Accuracy: 87.50%
[ Thu May 18 15:23:43 2023 ] Eval epoch: 17
[ Thu May 18 15:23:59 2023 ] 	Mean test loss of 120 batches: 0.29769909381866455.
[ Thu May 18 15:23:59 2023 ] 	Top1: 91.00%
[ Thu May 18 15:23:59 2023 ] 	Top5: 99.83%
[ Thu May 18 15:23:59 2023 ] Training epoch: 18
[ Thu May 18 15:24:16 2023 ] 	Batch(39/480) done. Loss: 0.6416  lr:0.100000  network_time: 0.0112
[ Thu May 18 15:25:00 2023 ] 	Batch(139/480) done. Loss: 0.0717  lr:0.100000  network_time: 0.0111
[ Thu May 18 15:25:43 2023 ] 	Batch(239/480) done. Loss: 0.0110  lr:0.100000  network_time: 0.0114
[ Thu May 18 15:26:27 2023 ] 	Batch(339/480) done. Loss: 0.1055  lr:0.100000  network_time: 0.0114
[ Thu May 18 15:27:10 2023 ] 	Batch(439/480) done. Loss: 0.3307  lr:0.100000  network_time: 0.0111
[ Thu May 18 15:27:28 2023 ] 	Training Accuracy: 88.17%
[ Thu May 18 15:27:28 2023 ] Eval epoch: 18
[ Thu May 18 15:27:44 2023 ] 	Mean test loss of 120 batches: 0.49055543541908264.
[ Thu May 18 15:27:44 2023 ] 	Top1: 88.50%
[ Thu May 18 15:27:44 2023 ] 	Top5: 99.00%
[ Thu May 18 15:27:44 2023 ] Training epoch: 19
[ Thu May 18 15:28:10 2023 ] 	Batch(59/480) done. Loss: 0.0181  lr:0.100000  network_time: 0.0110
[ Thu May 18 15:28:53 2023 ] 	Batch(159/480) done. Loss: 0.1204  lr:0.100000  network_time: 0.0113
[ Thu May 18 15:29:37 2023 ] 	Batch(259/480) done. Loss: 0.9884  lr:0.100000  network_time: 0.0110
[ Thu May 18 15:30:21 2023 ] 	Batch(359/480) done. Loss: 0.5566  lr:0.100000  network_time: 0.0118
[ Thu May 18 15:31:04 2023 ] 	Batch(459/480) done. Loss: 0.3448  lr:0.100000  network_time: 0.0113
[ Thu May 18 15:31:13 2023 ] 	Training Accuracy: 92.42%
[ Thu May 18 15:31:13 2023 ] Eval epoch: 19
[ Thu May 18 15:31:29 2023 ] 	Mean test loss of 120 batches: 0.22206377983093262.
[ Thu May 18 15:31:29 2023 ] 	Top1: 93.00%
[ Thu May 18 15:31:29 2023 ] 	Top5: 99.67%
[ Thu May 18 15:31:29 2023 ] Training epoch: 20
[ Thu May 18 15:32:04 2023 ] 	Batch(79/480) done. Loss: 0.7768  lr:0.100000  network_time: 0.0115
[ Thu May 18 15:32:47 2023 ] 	Batch(179/480) done. Loss: 0.4250  lr:0.100000  network_time: 0.0118
[ Thu May 18 15:33:31 2023 ] 	Batch(279/480) done. Loss: 0.7572  lr:0.100000  network_time: 0.0124
[ Thu May 18 15:34:14 2023 ] 	Batch(379/480) done. Loss: 0.0455  lr:0.100000  network_time: 0.0114
[ Thu May 18 15:34:58 2023 ] 	Batch(479/480) done. Loss: 0.4895  lr:0.100000  network_time: 0.0119
[ Thu May 18 15:34:58 2023 ] 	Training Accuracy: 90.17%
[ Thu May 18 15:34:58 2023 ] Eval epoch: 20
[ Thu May 18 15:35:14 2023 ] 	Mean test loss of 120 batches: 0.4325052797794342.
[ Thu May 18 15:35:14 2023 ] 	Top1: 92.67%
[ Thu May 18 15:35:14 2023 ] 	Top5: 99.17%
[ Thu May 18 15:35:14 2023 ] Training epoch: 21
[ Thu May 18 15:35:58 2023 ] 	Batch(99/480) done. Loss: 0.2243  lr:0.010000  network_time: 0.0122
[ Thu May 18 15:36:41 2023 ] 	Batch(199/480) done. Loss: 0.0273  lr:0.010000  network_time: 0.0110
[ Thu May 18 15:37:25 2023 ] 	Batch(299/480) done. Loss: 0.0048  lr:0.010000  network_time: 0.0118
[ Thu May 18 15:38:08 2023 ] 	Batch(399/480) done. Loss: 0.1028  lr:0.010000  network_time: 0.0111
[ Thu May 18 15:38:43 2023 ] 	Training Accuracy: 97.83%
[ Thu May 18 15:38:43 2023 ] Eval epoch: 21
[ Thu May 18 15:38:59 2023 ] 	Mean test loss of 120 batches: 0.04514942318201065.
[ Thu May 18 15:38:59 2023 ] 	Top1: 98.50%
[ Thu May 18 15:38:59 2023 ] 	Top5: 100.00%
[ Thu May 18 15:38:59 2023 ] Training epoch: 22
[ Thu May 18 15:39:08 2023 ] 	Batch(19/480) done. Loss: 0.0939  lr:0.010000  network_time: 0.0112
[ Thu May 18 15:39:52 2023 ] 	Batch(119/480) done. Loss: 0.1371  lr:0.010000  network_time: 0.0112
[ Thu May 18 15:40:35 2023 ] 	Batch(219/480) done. Loss: 0.5293  lr:0.010000  network_time: 0.0116
[ Thu May 18 15:41:19 2023 ] 	Batch(319/480) done. Loss: 0.0072  lr:0.010000  network_time: 0.0118
[ Thu May 18 15:42:02 2023 ] 	Batch(419/480) done. Loss: 0.0176  lr:0.010000  network_time: 0.0115
[ Thu May 18 15:42:28 2023 ] 	Training Accuracy: 98.83%
[ Thu May 18 15:42:28 2023 ] Eval epoch: 22
[ Thu May 18 15:42:44 2023 ] 	Mean test loss of 120 batches: 0.011209245771169662.
[ Thu May 18 15:42:44 2023 ] 	Top1: 99.83%
[ Thu May 18 15:42:44 2023 ] 	Top5: 100.00%
[ Thu May 18 15:42:44 2023 ] Training epoch: 23
[ Thu May 18 15:43:02 2023 ] 	Batch(39/480) done. Loss: 0.0050  lr:0.010000  network_time: 0.0113
[ Thu May 18 15:43:45 2023 ] 	Batch(139/480) done. Loss: 0.0043  lr:0.010000  network_time: 0.0123
[ Thu May 18 15:44:29 2023 ] 	Batch(239/480) done. Loss: 0.0028  lr:0.010000  network_time: 0.0112
[ Thu May 18 15:45:13 2023 ] 	Batch(339/480) done. Loss: 0.0032  lr:0.010000  network_time: 0.0113
[ Thu May 18 15:45:56 2023 ] 	Batch(439/480) done. Loss: 0.0080  lr:0.010000  network_time: 0.0115
[ Thu May 18 15:46:14 2023 ] 	Training Accuracy: 99.33%
[ Thu May 18 15:46:14 2023 ] Eval epoch: 23
[ Thu May 18 15:46:30 2023 ] 	Mean test loss of 120 batches: 0.01235094852745533.
[ Thu May 18 15:46:30 2023 ] 	Top1: 100.00%
[ Thu May 18 15:46:30 2023 ] 	Top5: 100.00%
[ Thu May 18 15:46:30 2023 ] Training epoch: 24
[ Thu May 18 15:46:56 2023 ] 	Batch(59/480) done. Loss: 0.0273  lr:0.010000  network_time: 0.0109
[ Thu May 18 15:47:39 2023 ] 	Batch(159/480) done. Loss: 0.0085  lr:0.010000  network_time: 0.0118
[ Thu May 18 15:48:23 2023 ] 	Batch(259/480) done. Loss: 0.0066  lr:0.010000  network_time: 0.0113
[ Thu May 18 15:49:07 2023 ] 	Batch(359/480) done. Loss: 0.0154  lr:0.010000  network_time: 0.0113
[ Thu May 18 15:49:50 2023 ] 	Batch(459/480) done. Loss: 0.0480  lr:0.010000  network_time: 0.0114
[ Thu May 18 15:49:59 2023 ] 	Training Accuracy: 99.46%
[ Thu May 18 15:49:59 2023 ] Eval epoch: 24
[ Thu May 18 15:50:15 2023 ] 	Mean test loss of 120 batches: 0.006800500676035881.
[ Thu May 18 15:50:15 2023 ] 	Top1: 99.83%
[ Thu May 18 15:50:15 2023 ] 	Top5: 100.00%
[ Thu May 18 15:50:15 2023 ] Training epoch: 25
[ Thu May 18 15:50:50 2023 ] 	Batch(79/480) done. Loss: 0.0111  lr:0.010000  network_time: 0.0113
[ Thu May 18 15:51:33 2023 ] 	Batch(179/480) done. Loss: 0.0032  lr:0.010000  network_time: 0.0111
[ Thu May 18 15:52:17 2023 ] 	Batch(279/480) done. Loss: 0.0046  lr:0.010000  network_time: 0.0112
[ Thu May 18 15:53:00 2023 ] 	Batch(379/480) done. Loss: 0.0439  lr:0.010000  network_time: 0.0115
[ Thu May 18 15:53:44 2023 ] 	Batch(479/480) done. Loss: 0.0648  lr:0.010000  network_time: 0.0112
[ Thu May 18 15:53:44 2023 ] 	Training Accuracy: 99.46%
[ Thu May 18 15:53:44 2023 ] Eval epoch: 25
[ Thu May 18 15:54:00 2023 ] 	Mean test loss of 120 batches: 0.0050697629339993.
[ Thu May 18 15:54:00 2023 ] 	Top1: 100.00%
[ Thu May 18 15:54:00 2023 ] 	Top5: 100.00%
[ Thu May 18 15:54:00 2023 ] Training epoch: 26
[ Thu May 18 15:54:44 2023 ] 	Batch(99/480) done. Loss: 0.0134  lr:0.001000  network_time: 0.0117
[ Thu May 18 15:55:27 2023 ] 	Batch(199/480) done. Loss: 0.0049  lr:0.001000  network_time: 0.0110
[ Thu May 18 15:56:11 2023 ] 	Batch(299/480) done. Loss: 0.0117  lr:0.001000  network_time: 0.0117
[ Thu May 18 15:56:54 2023 ] 	Batch(399/480) done. Loss: 0.0041  lr:0.001000  network_time: 0.0120
[ Thu May 18 15:57:29 2023 ] 	Training Accuracy: 99.62%
[ Thu May 18 15:57:29 2023 ] Eval epoch: 26
[ Thu May 18 15:57:45 2023 ] 	Mean test loss of 120 batches: 0.005673304665833712.
[ Thu May 18 15:57:45 2023 ] 	Top1: 100.00%
[ Thu May 18 15:57:45 2023 ] 	Top5: 100.00%
[ Thu May 18 15:57:45 2023 ] Training epoch: 27
[ Thu May 18 15:57:54 2023 ] 	Batch(19/480) done. Loss: 0.0064  lr:0.001000  network_time: 0.0126
[ Thu May 18 15:58:37 2023 ] 	Batch(119/480) done. Loss: 0.0023  lr:0.001000  network_time: 0.0115
[ Thu May 18 15:59:21 2023 ] 	Batch(219/480) done. Loss: 0.0055  lr:0.001000  network_time: 0.0115
[ Thu May 18 16:00:05 2023 ] 	Batch(319/480) done. Loss: 0.5551  lr:0.001000  network_time: 0.0126
[ Thu May 18 16:00:48 2023 ] 	Batch(419/480) done. Loss: 0.0041  lr:0.001000  network_time: 0.0112
[ Thu May 18 16:01:14 2023 ] 	Training Accuracy: 99.62%
[ Thu May 18 16:01:14 2023 ] Eval epoch: 27
[ Thu May 18 16:01:30 2023 ] 	Mean test loss of 120 batches: 0.004336856305599213.
[ Thu May 18 16:01:30 2023 ] 	Top1: 100.00%
[ Thu May 18 16:01:30 2023 ] 	Top5: 100.00%
[ Thu May 18 16:01:30 2023 ] Training epoch: 28
[ Thu May 18 16:01:48 2023 ] 	Batch(39/480) done. Loss: 0.0033  lr:0.001000  network_time: 0.0111
[ Thu May 18 16:02:31 2023 ] 	Batch(139/480) done. Loss: 0.0267  lr:0.001000  network_time: 0.0114
[ Thu May 18 16:03:15 2023 ] 	Batch(239/480) done. Loss: 0.0054  lr:0.001000  network_time: 0.0114
[ Thu May 18 16:03:59 2023 ] 	Batch(339/480) done. Loss: 0.0023  lr:0.001000  network_time: 0.0113
[ Thu May 18 16:04:42 2023 ] 	Batch(439/480) done. Loss: 0.0871  lr:0.001000  network_time: 0.0117
[ Thu May 18 16:05:00 2023 ] 	Training Accuracy: 99.75%
[ Thu May 18 16:05:00 2023 ] Eval epoch: 28
[ Thu May 18 16:05:16 2023 ] 	Mean test loss of 120 batches: 0.005502848885953426.
[ Thu May 18 16:05:16 2023 ] 	Top1: 100.00%
[ Thu May 18 16:05:16 2023 ] 	Top5: 100.00%
[ Thu May 18 16:05:16 2023 ] Training epoch: 29
[ Thu May 18 16:05:42 2023 ] 	Batch(59/480) done. Loss: 0.0005  lr:0.001000  network_time: 0.0123
[ Thu May 18 16:06:25 2023 ] 	Batch(159/480) done. Loss: 0.0476  lr:0.001000  network_time: 0.0118
[ Thu May 18 16:07:09 2023 ] 	Batch(259/480) done. Loss: 0.0131  lr:0.001000  network_time: 0.0114
[ Thu May 18 16:07:52 2023 ] 	Batch(359/480) done. Loss: 0.0014  lr:0.001000  network_time: 0.0110
[ Thu May 18 16:08:36 2023 ] 	Batch(459/480) done. Loss: 0.0152  lr:0.001000  network_time: 0.0117
[ Thu May 18 16:08:45 2023 ] 	Training Accuracy: 99.75%
[ Thu May 18 16:08:45 2023 ] Eval epoch: 29
[ Thu May 18 16:09:01 2023 ] 	Mean test loss of 120 batches: 0.0040801772847771645.
[ Thu May 18 16:09:01 2023 ] 	Top1: 100.00%
[ Thu May 18 16:09:01 2023 ] 	Top5: 100.00%
[ Thu May 18 16:09:01 2023 ] Training epoch: 30
[ Thu May 18 16:09:36 2023 ] 	Batch(79/480) done. Loss: 0.0673  lr:0.001000  network_time: 0.0113
[ Thu May 18 16:10:19 2023 ] 	Batch(179/480) done. Loss: 0.0144  lr:0.001000  network_time: 0.0111
[ Thu May 18 16:11:03 2023 ] 	Batch(279/480) done. Loss: 0.0148  lr:0.001000  network_time: 0.0118
[ Thu May 18 16:11:46 2023 ] 	Batch(379/480) done. Loss: 0.0091  lr:0.001000  network_time: 0.0110
[ Thu May 18 16:12:30 2023 ] 	Batch(479/480) done. Loss: 0.0053  lr:0.001000  network_time: 0.0116
[ Thu May 18 16:12:30 2023 ] 	Training Accuracy: 99.75%
[ Thu May 18 16:12:30 2023 ] Eval epoch: 30
[ Thu May 18 16:12:46 2023 ] 	Mean test loss of 120 batches: 0.0039330096915364265.
[ Thu May 18 16:12:46 2023 ] 	Top1: 100.00%
[ Thu May 18 16:12:46 2023 ] 	Top5: 100.00%
