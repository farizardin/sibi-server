[ Thu May 18 10:35:28 2023 ] NUM WORKER: 1
[ Thu May 18 10:36:21 2023 ] Parameters:
{'work_dir': './work_dir/sibi_modified_ShiftGCN_mod_4_joint_n_5_kfold_fold_5', 'model_saved_name': './save_models/sibi_modified_ShiftGCN_mod_4_joint_n_5_kfold_fold_5', 'Experiment_name': 'sibi_modified_ShiftGCN_mod_4_joint_n_5_kfold', 'config': './config/recalculated/train_sibi_with_mouth_augmented_modified_shift_joint_mod_4.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 2, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'n_splits': 5, 'feeder': 'feeders.feeder_hsd.Feeder', 'num_worker': 1, 'train_feeder_args': {'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': -1, 'normalization': False}, 'test_feeder_args': None, 'data_path': './data/augmented_recalculate_normalized', 'model': 'model.shift_gcn.Model', 'model_args': {'num_class': 50, 'num_person': 1, 'num_point': 115, 'method': 'modified', 'weight': 4, 'graph': 'graph.skeleton_with_mouth.SkeletonWithMouth', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [20, 25], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 5, 'test_batch_size': 5, 'start_epoch': 0, 'num_epoch': 30, 'folds_range': [3, 5], 'weight_decay': 0.0001, 'only_train_part': True, 'only_train_epoch': 1, 'warm_up_epoch': 0}

[ Thu May 18 10:36:21 2023 ] Training epoch: 1
[ Thu May 18 10:37:11 2023 ] 	Batch(99/480) done. Loss: 3.8370  lr:0.100000  network_time: 0.0107
[ Thu May 18 10:38:01 2023 ] 	Batch(199/480) done. Loss: 3.4772  lr:0.100000  network_time: 0.0118
[ Thu May 18 10:38:51 2023 ] 	Batch(299/480) done. Loss: 3.2724  lr:0.100000  network_time: 0.0107
[ Thu May 18 10:39:42 2023 ] 	Batch(399/480) done. Loss: 3.0394  lr:0.100000  network_time: 0.0109
[ Thu May 18 10:40:22 2023 ] 	Training Accuracy: 6.62%
[ Thu May 18 10:40:22 2023 ] Eval epoch: 1
[ Thu May 18 10:40:40 2023 ] 	Mean test loss of 120 batches: 4.6775641441345215.
[ Thu May 18 10:40:40 2023 ] 	Top1: 8.50%
[ Thu May 18 10:40:40 2023 ] 	Top5: 43.00%
[ Thu May 18 10:40:40 2023 ] Training epoch: 2
[ Thu May 18 10:40:50 2023 ] 	Batch(19/480) done. Loss: 3.4413  lr:0.100000  network_time: 0.0108
[ Thu May 18 10:41:40 2023 ] 	Batch(119/480) done. Loss: 3.5609  lr:0.100000  network_time: 0.0110
[ Thu May 18 10:42:31 2023 ] 	Batch(219/480) done. Loss: 2.6903  lr:0.100000  network_time: 0.0109
[ Thu May 18 10:43:22 2023 ] 	Batch(319/480) done. Loss: 3.9602  lr:0.100000  network_time: 0.0111
[ Thu May 18 10:44:13 2023 ] 	Batch(419/480) done. Loss: 2.1706  lr:0.100000  network_time: 0.0119
[ Thu May 18 10:44:43 2023 ] 	Training Accuracy: 14.46%
[ Thu May 18 10:44:43 2023 ] Eval epoch: 2
[ Thu May 18 10:45:00 2023 ] 	Mean test loss of 120 batches: 2.9608187675476074.
[ Thu May 18 10:45:00 2023 ] 	Top1: 16.83%
[ Thu May 18 10:45:00 2023 ] 	Top5: 55.50%
[ Thu May 18 10:45:00 2023 ] Training epoch: 3
[ Thu May 18 10:45:20 2023 ] 	Batch(39/480) done. Loss: 2.3312  lr:0.100000  network_time: 0.0107
[ Thu May 18 10:46:11 2023 ] 	Batch(139/480) done. Loss: 3.1935  lr:0.100000  network_time: 0.0116
[ Thu May 18 10:47:02 2023 ] 	Batch(239/480) done. Loss: 2.5473  lr:0.100000  network_time: 0.0111
[ Thu May 18 10:47:52 2023 ] 	Batch(339/480) done. Loss: 3.0477  lr:0.100000  network_time: 0.0110
[ Thu May 18 10:48:43 2023 ] 	Batch(439/480) done. Loss: 2.9668  lr:0.100000  network_time: 0.0110
[ Thu May 18 10:49:03 2023 ] 	Training Accuracy: 22.79%
[ Thu May 18 10:49:03 2023 ] Eval epoch: 3
[ Thu May 18 10:49:21 2023 ] 	Mean test loss of 120 batches: 2.421741008758545.
[ Thu May 18 10:49:21 2023 ] 	Top1: 25.17%
[ Thu May 18 10:49:21 2023 ] 	Top5: 72.33%
[ Thu May 18 10:49:21 2023 ] Training epoch: 4
[ Thu May 18 10:49:51 2023 ] 	Batch(59/480) done. Loss: 1.7011  lr:0.100000  network_time: 0.0108
[ Thu May 18 10:50:42 2023 ] 	Batch(159/480) done. Loss: 2.0747  lr:0.100000  network_time: 0.0114
[ Thu May 18 10:51:32 2023 ] 	Batch(259/480) done. Loss: 1.9181  lr:0.100000  network_time: 0.0111
[ Thu May 18 10:52:23 2023 ] 	Batch(359/480) done. Loss: 1.7102  lr:0.100000  network_time: 0.0111
[ Thu May 18 10:53:14 2023 ] 	Batch(459/480) done. Loss: 2.5905  lr:0.100000  network_time: 0.0110
[ Thu May 18 10:53:24 2023 ] 	Training Accuracy: 30.71%
[ Thu May 18 10:53:24 2023 ] Eval epoch: 4
[ Thu May 18 10:53:41 2023 ] 	Mean test loss of 120 batches: 2.4034719467163086.
[ Thu May 18 10:53:41 2023 ] 	Top1: 31.00%
[ Thu May 18 10:53:41 2023 ] 	Top5: 80.00%
[ Thu May 18 10:53:41 2023 ] Training epoch: 5
[ Thu May 18 10:54:22 2023 ] 	Batch(79/480) done. Loss: 2.0089  lr:0.100000  network_time: 0.0119
[ Thu May 18 10:55:13 2023 ] 	Batch(179/480) done. Loss: 1.4863  lr:0.100000  network_time: 0.0116
[ Thu May 18 10:56:03 2023 ] 	Batch(279/480) done. Loss: 0.8559  lr:0.100000  network_time: 0.0112
[ Thu May 18 10:56:54 2023 ] 	Batch(379/480) done. Loss: 2.4745  lr:0.100000  network_time: 0.0121
[ Thu May 18 10:57:45 2023 ] 	Batch(479/480) done. Loss: 1.7623  lr:0.100000  network_time: 0.0109
[ Thu May 18 10:57:45 2023 ] 	Training Accuracy: 42.71%
[ Thu May 18 10:57:45 2023 ] Eval epoch: 5
[ Thu May 18 10:58:02 2023 ] 	Mean test loss of 120 batches: 1.4564610719680786.
[ Thu May 18 10:58:02 2023 ] 	Top1: 52.67%
[ Thu May 18 10:58:02 2023 ] 	Top5: 90.17%
[ Thu May 18 10:58:02 2023 ] Training epoch: 6
[ Thu May 18 10:58:53 2023 ] 	Batch(99/480) done. Loss: 1.8809  lr:0.100000  network_time: 0.0114
[ Thu May 18 10:59:44 2023 ] 	Batch(199/480) done. Loss: 1.0714  lr:0.100000  network_time: 0.0113
[ Thu May 18 11:00:34 2023 ] 	Batch(299/480) done. Loss: 1.9144  lr:0.100000  network_time: 0.0110
[ Thu May 18 11:01:25 2023 ] 	Batch(399/480) done. Loss: 1.1388  lr:0.100000  network_time: 0.0113
[ Thu May 18 11:02:05 2023 ] 	Training Accuracy: 53.17%
[ Thu May 18 11:02:06 2023 ] Eval epoch: 6
[ Thu May 18 11:02:23 2023 ] 	Mean test loss of 120 batches: 1.1144909858703613.
[ Thu May 18 11:02:23 2023 ] 	Top1: 63.83%
[ Thu May 18 11:02:23 2023 ] 	Top5: 95.33%
[ Thu May 18 11:02:23 2023 ] Training epoch: 7
[ Thu May 18 11:02:33 2023 ] 	Batch(19/480) done. Loss: 2.2742  lr:0.100000  network_time: 0.0110
[ Thu May 18 11:03:24 2023 ] 	Batch(119/480) done. Loss: 1.3490  lr:0.100000  network_time: 0.0113
[ Thu May 18 11:04:14 2023 ] 	Batch(219/480) done. Loss: 1.1954  lr:0.100000  network_time: 0.0110
[ Thu May 18 11:05:05 2023 ] 	Batch(319/480) done. Loss: 0.6720  lr:0.100000  network_time: 0.0116
[ Thu May 18 11:05:56 2023 ] 	Batch(419/480) done. Loss: 3.0721  lr:0.100000  network_time: 0.0112
[ Thu May 18 11:06:26 2023 ] 	Training Accuracy: 58.75%
[ Thu May 18 11:06:26 2023 ] Eval epoch: 7
[ Thu May 18 11:06:43 2023 ] 	Mean test loss of 120 batches: 2.250396251678467.
[ Thu May 18 11:06:43 2023 ] 	Top1: 42.83%
[ Thu May 18 11:06:43 2023 ] 	Top5: 90.50%
[ Thu May 18 11:06:43 2023 ] Training epoch: 8
[ Thu May 18 11:07:03 2023 ] 	Batch(39/480) done. Loss: 0.5821  lr:0.100000  network_time: 0.0111
[ Thu May 18 11:07:54 2023 ] 	Batch(139/480) done. Loss: 1.6082  lr:0.100000  network_time: 0.0114
[ Thu May 18 11:08:45 2023 ] 	Batch(239/480) done. Loss: 0.6584  lr:0.100000  network_time: 0.0111
[ Thu May 18 11:09:36 2023 ] 	Batch(339/480) done. Loss: 0.6328  lr:0.100000  network_time: 0.0110
[ Thu May 18 11:10:26 2023 ] 	Batch(439/480) done. Loss: 1.1152  lr:0.100000  network_time: 0.0112
[ Thu May 18 11:10:47 2023 ] 	Training Accuracy: 61.50%
[ Thu May 18 11:10:47 2023 ] Eval epoch: 8
[ Thu May 18 11:11:04 2023 ] 	Mean test loss of 120 batches: 0.8480402827262878.
[ Thu May 18 11:11:04 2023 ] 	Top1: 74.50%
[ Thu May 18 11:11:04 2023 ] 	Top5: 98.50%
[ Thu May 18 11:11:04 2023 ] Training epoch: 9
[ Thu May 18 11:11:34 2023 ] 	Batch(59/480) done. Loss: 0.6748  lr:0.100000  network_time: 0.0109
[ Thu May 18 11:12:25 2023 ] 	Batch(159/480) done. Loss: 1.3107  lr:0.100000  network_time: 0.0111
[ Thu May 18 11:13:16 2023 ] 	Batch(259/480) done. Loss: 0.5663  lr:0.100000  network_time: 0.0108
[ Thu May 18 11:14:06 2023 ] 	Batch(359/480) done. Loss: 0.5522  lr:0.100000  network_time: 0.0114
[ Thu May 18 11:14:57 2023 ] 	Batch(459/480) done. Loss: 1.3797  lr:0.100000  network_time: 0.0115
[ Thu May 18 11:15:07 2023 ] 	Training Accuracy: 70.29%
[ Thu May 18 11:15:07 2023 ] Eval epoch: 9
[ Thu May 18 11:15:24 2023 ] 	Mean test loss of 120 batches: 0.8315401673316956.
[ Thu May 18 11:15:24 2023 ] 	Top1: 74.00%
[ Thu May 18 11:15:24 2023 ] 	Top5: 98.50%
[ Thu May 18 11:15:24 2023 ] Training epoch: 10
[ Thu May 18 11:16:05 2023 ] 	Batch(79/480) done. Loss: 1.3646  lr:0.100000  network_time: 0.0117
[ Thu May 18 11:16:56 2023 ] 	Batch(179/480) done. Loss: 1.6084  lr:0.100000  network_time: 0.0110
[ Thu May 18 11:17:46 2023 ] 	Batch(279/480) done. Loss: 2.1606  lr:0.100000  network_time: 0.0108
[ Thu May 18 11:18:37 2023 ] 	Batch(379/480) done. Loss: 0.5454  lr:0.100000  network_time: 0.0113
[ Thu May 18 11:19:28 2023 ] 	Batch(479/480) done. Loss: 1.2170  lr:0.100000  network_time: 0.0110
[ Thu May 18 11:19:28 2023 ] 	Training Accuracy: 74.46%
[ Thu May 18 11:19:28 2023 ] Eval epoch: 10
[ Thu May 18 11:19:45 2023 ] 	Mean test loss of 120 batches: 0.7021758556365967.
[ Thu May 18 11:19:45 2023 ] 	Top1: 77.83%
[ Thu May 18 11:19:45 2023 ] 	Top5: 98.50%
[ Thu May 18 11:19:45 2023 ] Training epoch: 11
[ Thu May 18 11:20:36 2023 ] 	Batch(99/480) done. Loss: 0.7945  lr:0.100000  network_time: 0.0111
[ Thu May 18 11:21:26 2023 ] 	Batch(199/480) done. Loss: 0.3853  lr:0.100000  network_time: 0.0116
[ Thu May 18 11:22:17 2023 ] 	Batch(299/480) done. Loss: 0.2344  lr:0.100000  network_time: 0.0112
[ Thu May 18 11:23:08 2023 ] 	Batch(399/480) done. Loss: 0.3509  lr:0.100000  network_time: 0.0123
[ Thu May 18 11:23:48 2023 ] 	Training Accuracy: 76.04%
[ Thu May 18 11:23:48 2023 ] Eval epoch: 11
[ Thu May 18 11:24:06 2023 ] 	Mean test loss of 120 batches: 0.5956489443778992.
[ Thu May 18 11:24:06 2023 ] 	Top1: 81.17%
[ Thu May 18 11:24:06 2023 ] 	Top5: 98.17%
[ Thu May 18 11:24:06 2023 ] Training epoch: 12
[ Thu May 18 11:24:16 2023 ] 	Batch(19/480) done. Loss: 0.1933  lr:0.100000  network_time: 0.0110
[ Thu May 18 11:25:07 2023 ] 	Batch(119/480) done. Loss: 0.0808  lr:0.100000  network_time: 0.0114
[ Thu May 18 11:25:57 2023 ] 	Batch(219/480) done. Loss: 2.7592  lr:0.100000  network_time: 0.0114
[ Thu May 18 11:26:48 2023 ] 	Batch(319/480) done. Loss: 0.3149  lr:0.100000  network_time: 0.0110
[ Thu May 18 11:27:39 2023 ] 	Batch(419/480) done. Loss: 0.4128  lr:0.100000  network_time: 0.0110
[ Thu May 18 11:28:09 2023 ] 	Training Accuracy: 79.54%
[ Thu May 18 11:28:09 2023 ] Eval epoch: 12
[ Thu May 18 11:28:26 2023 ] 	Mean test loss of 120 batches: 1.1489734649658203.
[ Thu May 18 11:28:26 2023 ] 	Top1: 70.33%
[ Thu May 18 11:28:26 2023 ] 	Top5: 97.33%
[ Thu May 18 11:28:26 2023 ] Training epoch: 13
[ Thu May 18 11:28:47 2023 ] 	Batch(39/480) done. Loss: 0.4825  lr:0.100000  network_time: 0.0108
[ Thu May 18 11:29:37 2023 ] 	Batch(139/480) done. Loss: 0.3768  lr:0.100000  network_time: 0.0116
[ Thu May 18 11:30:28 2023 ] 	Batch(239/480) done. Loss: 0.3956  lr:0.100000  network_time: 0.0112
[ Thu May 18 11:31:19 2023 ] 	Batch(339/480) done. Loss: 0.3031  lr:0.100000  network_time: 0.0111
[ Thu May 18 11:32:09 2023 ] 	Batch(439/480) done. Loss: 1.1120  lr:0.100000  network_time: 0.0110
[ Thu May 18 11:32:30 2023 ] 	Training Accuracy: 77.54%
[ Thu May 18 11:32:30 2023 ] Eval epoch: 13
[ Thu May 18 11:32:47 2023 ] 	Mean test loss of 120 batches: 0.46521028876304626.
[ Thu May 18 11:32:47 2023 ] 	Top1: 85.50%
[ Thu May 18 11:32:47 2023 ] 	Top5: 98.83%
[ Thu May 18 11:32:47 2023 ] Training epoch: 14
[ Thu May 18 11:33:17 2023 ] 	Batch(59/480) done. Loss: 0.0857  lr:0.100000  network_time: 0.0107
[ Thu May 18 11:34:08 2023 ] 	Batch(159/480) done. Loss: 0.4055  lr:0.100000  network_time: 0.0117
[ Thu May 18 11:34:59 2023 ] 	Batch(259/480) done. Loss: 0.2694  lr:0.100000  network_time: 0.0112
[ Thu May 18 11:35:50 2023 ] 	Batch(359/480) done. Loss: 0.9671  lr:0.100000  network_time: 0.0117
[ Thu May 18 11:36:40 2023 ] 	Batch(459/480) done. Loss: 0.4246  lr:0.100000  network_time: 0.0123
[ Thu May 18 11:36:50 2023 ] 	Training Accuracy: 83.38%
[ Thu May 18 11:36:51 2023 ] Eval epoch: 14
[ Thu May 18 11:37:08 2023 ] 	Mean test loss of 120 batches: 0.4248902201652527.
[ Thu May 18 11:37:08 2023 ] 	Top1: 86.00%
[ Thu May 18 11:37:08 2023 ] 	Top5: 99.00%
[ Thu May 18 11:37:08 2023 ] Training epoch: 15
[ Thu May 18 11:37:48 2023 ] 	Batch(79/480) done. Loss: 1.7265  lr:0.100000  network_time: 0.0115
[ Thu May 18 11:38:39 2023 ] 	Batch(179/480) done. Loss: 0.3669  lr:0.100000  network_time: 0.0126
[ Thu May 18 11:39:30 2023 ] 	Batch(279/480) done. Loss: 0.0874  lr:0.100000  network_time: 0.0130
[ Thu May 18 11:40:20 2023 ] 	Batch(379/480) done. Loss: 0.0691  lr:0.100000  network_time: 0.0113
[ Thu May 18 11:41:11 2023 ] 	Batch(479/480) done. Loss: 0.4164  lr:0.100000  network_time: 0.0118
[ Thu May 18 11:41:11 2023 ] 	Training Accuracy: 82.92%
[ Thu May 18 11:41:11 2023 ] Eval epoch: 15
[ Thu May 18 11:41:28 2023 ] 	Mean test loss of 120 batches: 0.485387921333313.
[ Thu May 18 11:41:28 2023 ] 	Top1: 86.00%
[ Thu May 18 11:41:28 2023 ] 	Top5: 99.67%
[ Thu May 18 11:41:28 2023 ] Training epoch: 16
[ Thu May 18 11:42:19 2023 ] 	Batch(99/480) done. Loss: 0.0871  lr:0.100000  network_time: 0.0112
[ Thu May 18 11:43:10 2023 ] 	Batch(199/480) done. Loss: 0.0431  lr:0.100000  network_time: 0.0117
[ Thu May 18 11:44:01 2023 ] 	Batch(299/480) done. Loss: 0.4861  lr:0.100000  network_time: 0.0111
[ Thu May 18 11:44:51 2023 ] 	Batch(399/480) done. Loss: 0.9049  lr:0.100000  network_time: 0.0115
[ Thu May 18 11:45:32 2023 ] 	Training Accuracy: 85.42%
[ Thu May 18 11:45:32 2023 ] Eval epoch: 16
[ Thu May 18 11:45:49 2023 ] 	Mean test loss of 120 batches: 0.3275316059589386.
[ Thu May 18 11:45:49 2023 ] 	Top1: 89.17%
[ Thu May 18 11:45:49 2023 ] 	Top5: 100.00%
[ Thu May 18 11:45:49 2023 ] Training epoch: 17
[ Thu May 18 11:45:59 2023 ] 	Batch(19/480) done. Loss: 0.0668  lr:0.100000  network_time: 0.0111
[ Thu May 18 11:46:50 2023 ] 	Batch(119/480) done. Loss: 0.1352  lr:0.100000  network_time: 0.0121
[ Thu May 18 11:47:41 2023 ] 	Batch(219/480) done. Loss: 0.2515  lr:0.100000  network_time: 0.0118
[ Thu May 18 11:48:31 2023 ] 	Batch(319/480) done. Loss: 0.4907  lr:0.100000  network_time: 0.0113
[ Thu May 18 11:49:22 2023 ] 	Batch(419/480) done. Loss: 0.1540  lr:0.100000  network_time: 0.0112
[ Thu May 18 11:49:52 2023 ] 	Training Accuracy: 85.96%
[ Thu May 18 11:49:53 2023 ] Eval epoch: 17
[ Thu May 18 11:50:10 2023 ] 	Mean test loss of 120 batches: 0.6316602826118469.
[ Thu May 18 11:50:10 2023 ] 	Top1: 82.33%
[ Thu May 18 11:50:10 2023 ] 	Top5: 98.83%
[ Thu May 18 11:50:10 2023 ] Training epoch: 18
[ Thu May 18 11:50:30 2023 ] 	Batch(39/480) done. Loss: 0.6067  lr:0.100000  network_time: 0.0112
[ Thu May 18 11:51:21 2023 ] 	Batch(139/480) done. Loss: 0.5082  lr:0.100000  network_time: 0.0114
[ Thu May 18 11:52:11 2023 ] 	Batch(239/480) done. Loss: 1.2618  lr:0.100000  network_time: 0.0114
[ Thu May 18 11:53:02 2023 ] 	Batch(339/480) done. Loss: 0.1819  lr:0.100000  network_time: 0.0113
[ Thu May 18 11:53:53 2023 ] 	Batch(439/480) done. Loss: 0.7504  lr:0.100000  network_time: 0.0113
[ Thu May 18 11:54:13 2023 ] 	Training Accuracy: 86.17%
[ Thu May 18 11:54:13 2023 ] Eval epoch: 18
[ Thu May 18 11:54:30 2023 ] 	Mean test loss of 120 batches: 0.4112899899482727.
[ Thu May 18 11:54:30 2023 ] 	Top1: 86.50%
[ Thu May 18 11:54:30 2023 ] 	Top5: 100.00%
[ Thu May 18 11:54:30 2023 ] Training epoch: 19
[ Thu May 18 11:55:01 2023 ] 	Batch(59/480) done. Loss: 0.0285  lr:0.100000  network_time: 0.0111
[ Thu May 18 11:55:51 2023 ] 	Batch(159/480) done. Loss: 0.2452  lr:0.100000  network_time: 0.0115
[ Thu May 18 11:56:42 2023 ] 	Batch(259/480) done. Loss: 0.6966  lr:0.100000  network_time: 0.0118
[ Thu May 18 11:57:33 2023 ] 	Batch(359/480) done. Loss: 0.9014  lr:0.100000  network_time: 0.0112
[ Thu May 18 11:58:24 2023 ] 	Batch(459/480) done. Loss: 0.3151  lr:0.100000  network_time: 0.0109
[ Thu May 18 11:58:34 2023 ] 	Training Accuracy: 86.04%
[ Thu May 18 11:58:34 2023 ] Eval epoch: 19
[ Thu May 18 11:58:51 2023 ] 	Mean test loss of 120 batches: 0.3775549530982971.
[ Thu May 18 11:58:51 2023 ] 	Top1: 89.17%
[ Thu May 18 11:58:51 2023 ] 	Top5: 100.00%
[ Thu May 18 11:58:51 2023 ] Training epoch: 20
[ Thu May 18 11:59:32 2023 ] 	Batch(79/480) done. Loss: 0.4764  lr:0.100000  network_time: 0.0109
[ Thu May 18 12:00:22 2023 ] 	Batch(179/480) done. Loss: 0.1928  lr:0.100000  network_time: 0.0120
[ Thu May 18 12:01:13 2023 ] 	Batch(279/480) done. Loss: 1.6120  lr:0.100000  network_time: 0.0110
[ Thu May 18 12:02:04 2023 ] 	Batch(379/480) done. Loss: 0.0844  lr:0.100000  network_time: 0.0115
[ Thu May 18 12:02:55 2023 ] 	Batch(479/480) done. Loss: 0.1175  lr:0.100000  network_time: 0.0112
[ Thu May 18 12:02:55 2023 ] 	Training Accuracy: 88.67%
[ Thu May 18 12:02:55 2023 ] Eval epoch: 20
[ Thu May 18 12:03:12 2023 ] 	Mean test loss of 120 batches: 0.3661479949951172.
[ Thu May 18 12:03:12 2023 ] 	Top1: 88.33%
[ Thu May 18 12:03:12 2023 ] 	Top5: 99.00%
[ Thu May 18 12:03:12 2023 ] Training epoch: 21
[ Thu May 18 12:04:03 2023 ] 	Batch(99/480) done. Loss: 0.0540  lr:0.010000  network_time: 0.0109
[ Thu May 18 12:04:53 2023 ] 	Batch(199/480) done. Loss: 0.0457  lr:0.010000  network_time: 0.0113
[ Thu May 18 12:05:44 2023 ] 	Batch(299/480) done. Loss: 0.4065  lr:0.010000  network_time: 0.0110
[ Thu May 18 12:06:35 2023 ] 	Batch(399/480) done. Loss: 0.4517  lr:0.010000  network_time: 0.0110
[ Thu May 18 12:07:15 2023 ] 	Training Accuracy: 96.50%
[ Thu May 18 12:07:15 2023 ] Eval epoch: 21
[ Thu May 18 12:07:33 2023 ] 	Mean test loss of 120 batches: 0.0477360337972641.
[ Thu May 18 12:07:33 2023 ] 	Top1: 98.83%
[ Thu May 18 12:07:33 2023 ] 	Top5: 100.00%
[ Thu May 18 12:07:33 2023 ] Training epoch: 22
[ Thu May 18 12:07:43 2023 ] 	Batch(19/480) done. Loss: 0.0820  lr:0.010000  network_time: 0.0113
[ Thu May 18 12:08:33 2023 ] 	Batch(119/480) done. Loss: 0.1036  lr:0.010000  network_time: 0.0117
[ Thu May 18 12:09:24 2023 ] 	Batch(219/480) done. Loss: 0.0425  lr:0.010000  network_time: 0.0109
[ Thu May 18 12:10:15 2023 ] 	Batch(319/480) done. Loss: 0.2028  lr:0.010000  network_time: 0.0112
[ Thu May 18 12:11:05 2023 ] 	Batch(419/480) done. Loss: 0.3304  lr:0.010000  network_time: 0.0112
[ Thu May 18 12:11:36 2023 ] 	Training Accuracy: 98.21%
[ Thu May 18 12:11:36 2023 ] Eval epoch: 22
[ Thu May 18 12:11:53 2023 ] 	Mean test loss of 120 batches: 0.032506708055734634.
[ Thu May 18 12:11:53 2023 ] 	Top1: 99.33%
[ Thu May 18 12:11:53 2023 ] 	Top5: 100.00%
[ Thu May 18 12:11:53 2023 ] Training epoch: 23
[ Thu May 18 12:12:13 2023 ] 	Batch(39/480) done. Loss: 0.0181  lr:0.010000  network_time: 0.0119
[ Thu May 18 12:13:04 2023 ] 	Batch(139/480) done. Loss: 0.0445  lr:0.010000  network_time: 0.0114
[ Thu May 18 12:13:55 2023 ] 	Batch(239/480) done. Loss: 0.0064  lr:0.010000  network_time: 0.0114
[ Thu May 18 12:14:46 2023 ] 	Batch(339/480) done. Loss: 0.0150  lr:0.010000  network_time: 0.0108
[ Thu May 18 12:15:36 2023 ] 	Batch(439/480) done. Loss: 0.0217  lr:0.010000  network_time: 0.0110
[ Thu May 18 12:15:56 2023 ] 	Training Accuracy: 98.17%
[ Thu May 18 12:15:57 2023 ] Eval epoch: 23
[ Thu May 18 12:16:14 2023 ] 	Mean test loss of 120 batches: 0.02749866247177124.
[ Thu May 18 12:16:14 2023 ] 	Top1: 99.67%
[ Thu May 18 12:16:14 2023 ] 	Top5: 100.00%
[ Thu May 18 12:16:14 2023 ] Training epoch: 24
[ Thu May 18 12:16:44 2023 ] 	Batch(59/480) done. Loss: 0.0309  lr:0.010000  network_time: 0.0110
[ Thu May 18 12:17:35 2023 ] 	Batch(159/480) done. Loss: 0.0064  lr:0.010000  network_time: 0.0109
[ Thu May 18 12:18:26 2023 ] 	Batch(259/480) done. Loss: 0.0107  lr:0.010000  network_time: 0.0116
[ Thu May 18 12:19:16 2023 ] 	Batch(359/480) done. Loss: 0.0599  lr:0.010000  network_time: 0.0112
[ Thu May 18 12:20:07 2023 ] 	Batch(459/480) done. Loss: 0.0440  lr:0.010000  network_time: 0.0109
[ Thu May 18 12:20:17 2023 ] 	Training Accuracy: 99.00%
[ Thu May 18 12:20:17 2023 ] Eval epoch: 24
[ Thu May 18 12:20:34 2023 ] 	Mean test loss of 120 batches: 0.02104559913277626.
[ Thu May 18 12:20:34 2023 ] 	Top1: 99.67%
[ Thu May 18 12:20:34 2023 ] 	Top5: 100.00%
[ Thu May 18 12:20:34 2023 ] Training epoch: 25
[ Thu May 18 12:21:15 2023 ] 	Batch(79/480) done. Loss: 0.0075  lr:0.010000  network_time: 0.0112
[ Thu May 18 12:22:06 2023 ] 	Batch(179/480) done. Loss: 0.0376  lr:0.010000  network_time: 0.0113
[ Thu May 18 12:22:56 2023 ] 	Batch(279/480) done. Loss: 0.0057  lr:0.010000  network_time: 0.0111
[ Thu May 18 12:23:47 2023 ] 	Batch(379/480) done. Loss: 0.0154  lr:0.010000  network_time: 0.0114
[ Thu May 18 12:24:38 2023 ] 	Batch(479/480) done. Loss: 0.0184  lr:0.010000  network_time: 0.0113
[ Thu May 18 12:24:38 2023 ] 	Training Accuracy: 99.25%
[ Thu May 18 12:24:38 2023 ] Eval epoch: 25
[ Thu May 18 12:24:55 2023 ] 	Mean test loss of 120 batches: 0.03330245986580849.
[ Thu May 18 12:24:55 2023 ] 	Top1: 99.17%
[ Thu May 18 12:24:55 2023 ] 	Top5: 100.00%
[ Thu May 18 12:24:55 2023 ] Training epoch: 26
[ Thu May 18 12:25:46 2023 ] 	Batch(99/480) done. Loss: 0.0056  lr:0.001000  network_time: 0.0110
[ Thu May 18 12:26:37 2023 ] 	Batch(199/480) done. Loss: 0.1892  lr:0.001000  network_time: 0.0125
[ Thu May 18 12:27:27 2023 ] 	Batch(299/480) done. Loss: 0.0016  lr:0.001000  network_time: 0.0113
[ Thu May 18 12:28:18 2023 ] 	Batch(399/480) done. Loss: 0.0083  lr:0.001000  network_time: 0.0109
[ Thu May 18 12:28:59 2023 ] 	Training Accuracy: 99.21%
[ Thu May 18 12:28:59 2023 ] Eval epoch: 26
[ Thu May 18 12:29:16 2023 ] 	Mean test loss of 120 batches: 0.02265145257115364.
[ Thu May 18 12:29:16 2023 ] 	Top1: 99.50%
[ Thu May 18 12:29:16 2023 ] 	Top5: 100.00%
[ Thu May 18 12:29:16 2023 ] Training epoch: 27
[ Thu May 18 12:29:26 2023 ] 	Batch(19/480) done. Loss: 0.0109  lr:0.001000  network_time: 0.0110
[ Thu May 18 12:30:17 2023 ] 	Batch(119/480) done. Loss: 0.0329  lr:0.001000  network_time: 0.0112
[ Thu May 18 12:31:07 2023 ] 	Batch(219/480) done. Loss: 0.2128  lr:0.001000  network_time: 0.0112
[ Thu May 18 12:31:58 2023 ] 	Batch(319/480) done. Loss: 0.0129  lr:0.001000  network_time: 0.0110
[ Thu May 18 12:32:49 2023 ] 	Batch(419/480) done. Loss: 0.0306  lr:0.001000  network_time: 0.0111
[ Thu May 18 12:33:19 2023 ] 	Training Accuracy: 99.46%
[ Thu May 18 12:33:19 2023 ] Eval epoch: 27
[ Thu May 18 12:33:36 2023 ] 	Mean test loss of 120 batches: 0.021271010860800743.
[ Thu May 18 12:33:36 2023 ] 	Top1: 99.50%
[ Thu May 18 12:33:36 2023 ] 	Top5: 100.00%
[ Thu May 18 12:33:36 2023 ] Training epoch: 28
[ Thu May 18 12:33:57 2023 ] 	Batch(39/480) done. Loss: 0.0750  lr:0.001000  network_time: 0.0111
[ Thu May 18 12:34:47 2023 ] 	Batch(139/480) done. Loss: 0.0167  lr:0.001000  network_time: 0.0109
[ Thu May 18 12:35:38 2023 ] 	Batch(239/480) done. Loss: 0.0176  lr:0.001000  network_time: 0.0112
[ Thu May 18 12:36:29 2023 ] 	Batch(339/480) done. Loss: 0.0378  lr:0.001000  network_time: 0.0108
[ Thu May 18 12:37:20 2023 ] 	Batch(439/480) done. Loss: 0.0549  lr:0.001000  network_time: 0.0116
[ Thu May 18 12:37:40 2023 ] 	Training Accuracy: 99.17%
[ Thu May 18 12:37:40 2023 ] Eval epoch: 28
[ Thu May 18 12:37:57 2023 ] 	Mean test loss of 120 batches: 0.017497364431619644.
[ Thu May 18 12:37:57 2023 ] 	Top1: 99.67%
[ Thu May 18 12:37:57 2023 ] 	Top5: 100.00%
[ Thu May 18 12:37:57 2023 ] Training epoch: 29
[ Thu May 18 12:38:28 2023 ] 	Batch(59/480) done. Loss: 0.1693  lr:0.001000  network_time: 0.0108
[ Thu May 18 12:39:18 2023 ] 	Batch(159/480) done. Loss: 0.0192  lr:0.001000  network_time: 0.0107
[ Thu May 18 12:40:09 2023 ] 	Batch(259/480) done. Loss: 0.1122  lr:0.001000  network_time: 0.0112
[ Thu May 18 12:41:00 2023 ] 	Batch(359/480) done. Loss: 0.0121  lr:0.001000  network_time: 0.0113
[ Thu May 18 12:41:51 2023 ] 	Batch(459/480) done. Loss: 0.0640  lr:0.001000  network_time: 0.0110
[ Thu May 18 12:42:01 2023 ] 	Training Accuracy: 99.33%
[ Thu May 18 12:42:01 2023 ] Eval epoch: 29
[ Thu May 18 12:42:18 2023 ] 	Mean test loss of 120 batches: 0.02052602730691433.
[ Thu May 18 12:42:18 2023 ] 	Top1: 99.33%
[ Thu May 18 12:42:18 2023 ] 	Top5: 100.00%
[ Thu May 18 12:42:18 2023 ] Training epoch: 30
[ Thu May 18 12:42:59 2023 ] 	Batch(79/480) done. Loss: 0.0029  lr:0.001000  network_time: 0.0109
[ Thu May 18 12:43:49 2023 ] 	Batch(179/480) done. Loss: 0.0043  lr:0.001000  network_time: 0.0109
[ Thu May 18 12:44:40 2023 ] 	Batch(279/480) done. Loss: 0.0106  lr:0.001000  network_time: 0.0111
[ Thu May 18 12:45:31 2023 ] 	Batch(379/480) done. Loss: 0.0246  lr:0.001000  network_time: 0.0109
[ Thu May 18 12:46:22 2023 ] 	Batch(479/480) done. Loss: 0.0230  lr:0.001000  network_time: 0.0113
[ Thu May 18 12:46:22 2023 ] 	Training Accuracy: 99.29%
[ Thu May 18 12:46:22 2023 ] Eval epoch: 30
[ Thu May 18 12:46:39 2023 ] 	Mean test loss of 120 batches: 0.01665376126766205.
[ Thu May 18 12:46:39 2023 ] 	Top1: 99.67%
[ Thu May 18 12:46:39 2023 ] 	Top5: 100.00%
