[ Tue May 16 01:33:52 2023 ] NUM WORKER: 1
[ Tue May 16 01:34:44 2023 ] Parameters:
{'work_dir': './work_dir/sibi_merged_inner_group_ShiftGCN_mod_4_joint_n_5_kfold_fold_2', 'model_saved_name': './save_models/sibi_merged_inner_group_ShiftGCN_mod_4_joint_n_5_kfold_fold_2', 'Experiment_name': 'sibi_merged_inner_group_ShiftGCN_mod_4_joint_n_5_kfold', 'config': './config/recalculated/train_sibi_with_mouth_augmented_merged_inner_group_shift_joint_mod_4.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 2, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'n_splits': 5, 'feeder': 'feeders.feeder_hsd.Feeder', 'num_worker': 1, 'train_feeder_args': {'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': -1, 'normalization': False}, 'test_feeder_args': None, 'data_path': './data/augmented_recalculate_normalized', 'model': 'model.shift_gcn.Model', 'model_args': {'num_class': 50, 'num_person': 1, 'num_point': 115, 'graph_group': [[0, 81], [82, 114]], 'method': 'grouped.inner', 'weight': 4, 'graph': 'graph.skeleton_with_mouth.SkeletonWithMouth', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [20, 25], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 5, 'test_batch_size': 5, 'start_epoch': 0, 'num_epoch': 30, 'folds_range': [0, 5], 'weight_decay': 0.0001, 'only_train_part': True, 'only_train_epoch': 1, 'warm_up_epoch': 0}

[ Tue May 16 01:34:44 2023 ] Training epoch: 1
[ Tue May 16 01:35:35 2023 ] 	Batch(99/480) done. Loss: 3.7440  lr:0.100000  network_time: 0.0110
[ Tue May 16 01:36:25 2023 ] 	Batch(199/480) done. Loss: 3.7705  lr:0.100000  network_time: 0.0110
[ Tue May 16 01:37:16 2023 ] 	Batch(299/480) done. Loss: 3.2800  lr:0.100000  network_time: 0.0132
[ Tue May 16 01:38:06 2023 ] 	Batch(399/480) done. Loss: 3.6514  lr:0.100000  network_time: 0.0107
[ Tue May 16 01:38:47 2023 ] 	Training Accuracy: 5.96%
[ Tue May 16 01:38:47 2023 ] Eval epoch: 1
[ Tue May 16 01:39:04 2023 ] 	Mean test loss of 120 batches: 3.010951519012451.
[ Tue May 16 01:39:04 2023 ] 	Top1: 10.50%
[ Tue May 16 01:39:04 2023 ] 	Top5: 49.50%
[ Tue May 16 01:39:04 2023 ] Training epoch: 2
[ Tue May 16 01:39:14 2023 ] 	Batch(19/480) done. Loss: 3.1650  lr:0.100000  network_time: 0.0107
[ Tue May 16 01:40:04 2023 ] 	Batch(119/480) done. Loss: 3.4918  lr:0.100000  network_time: 0.0108
[ Tue May 16 01:40:55 2023 ] 	Batch(219/480) done. Loss: 2.4742  lr:0.100000  network_time: 0.0131
[ Tue May 16 01:41:45 2023 ] 	Batch(319/480) done. Loss: 3.6696  lr:0.100000  network_time: 0.0107
[ Tue May 16 01:42:36 2023 ] 	Batch(419/480) done. Loss: 2.4676  lr:0.100000  network_time: 0.0108
[ Tue May 16 01:43:06 2023 ] 	Training Accuracy: 16.04%
[ Tue May 16 01:43:06 2023 ] Eval epoch: 2
[ Tue May 16 01:43:23 2023 ] 	Mean test loss of 120 batches: 2.575990915298462.
[ Tue May 16 01:43:23 2023 ] 	Top1: 23.83%
[ Tue May 16 01:43:23 2023 ] 	Top5: 67.67%
[ Tue May 16 01:43:23 2023 ] Training epoch: 3
[ Tue May 16 01:43:43 2023 ] 	Batch(39/480) done. Loss: 2.4334  lr:0.100000  network_time: 0.0110
[ Tue May 16 01:44:33 2023 ] 	Batch(139/480) done. Loss: 2.0260  lr:0.100000  network_time: 0.0109
[ Tue May 16 01:45:24 2023 ] 	Batch(239/480) done. Loss: 2.2454  lr:0.100000  network_time: 0.0107
[ Tue May 16 01:46:14 2023 ] 	Batch(339/480) done. Loss: 3.0226  lr:0.100000  network_time: 0.0133
[ Tue May 16 01:47:05 2023 ] 	Batch(439/480) done. Loss: 1.8686  lr:0.100000  network_time: 0.0109
[ Tue May 16 01:47:25 2023 ] 	Training Accuracy: 26.50%
[ Tue May 16 01:47:25 2023 ] Eval epoch: 3
[ Tue May 16 01:47:42 2023 ] 	Mean test loss of 120 batches: 2.306368112564087.
[ Tue May 16 01:47:42 2023 ] 	Top1: 34.17%
[ Tue May 16 01:47:42 2023 ] 	Top5: 77.50%
[ Tue May 16 01:47:42 2023 ] Training epoch: 4
[ Tue May 16 01:48:12 2023 ] 	Batch(59/480) done. Loss: 1.7309  lr:0.100000  network_time: 0.0107
[ Tue May 16 01:49:03 2023 ] 	Batch(159/480) done. Loss: 2.0694  lr:0.100000  network_time: 0.0111
[ Tue May 16 01:49:53 2023 ] 	Batch(259/480) done. Loss: 1.4558  lr:0.100000  network_time: 0.0109
[ Tue May 16 01:50:44 2023 ] 	Batch(359/480) done. Loss: 1.7325  lr:0.100000  network_time: 0.0107
[ Tue May 16 01:51:34 2023 ] 	Batch(459/480) done. Loss: 1.4124  lr:0.100000  network_time: 0.0109
[ Tue May 16 01:51:44 2023 ] 	Training Accuracy: 38.88%
[ Tue May 16 01:51:44 2023 ] Eval epoch: 4
[ Tue May 16 01:52:01 2023 ] 	Mean test loss of 120 batches: 1.8130574226379395.
[ Tue May 16 01:52:01 2023 ] 	Top1: 45.83%
[ Tue May 16 01:52:01 2023 ] 	Top5: 83.50%
[ Tue May 16 01:52:01 2023 ] Training epoch: 5
[ Tue May 16 01:52:41 2023 ] 	Batch(79/480) done. Loss: 2.2694  lr:0.100000  network_time: 0.0108
[ Tue May 16 01:53:32 2023 ] 	Batch(179/480) done. Loss: 0.9995  lr:0.100000  network_time: 0.0108
[ Tue May 16 01:54:22 2023 ] 	Batch(279/480) done. Loss: 1.8664  lr:0.100000  network_time: 0.0108
[ Tue May 16 01:55:13 2023 ] 	Batch(379/480) done. Loss: 2.3609  lr:0.100000  network_time: 0.0133
[ Tue May 16 01:56:03 2023 ] 	Batch(479/480) done. Loss: 0.8587  lr:0.100000  network_time: 0.0108
[ Tue May 16 01:56:03 2023 ] 	Training Accuracy: 47.83%
[ Tue May 16 01:56:03 2023 ] Eval epoch: 5
[ Tue May 16 01:56:20 2023 ] 	Mean test loss of 120 batches: 2.1994547843933105.
[ Tue May 16 01:56:20 2023 ] 	Top1: 45.17%
[ Tue May 16 01:56:20 2023 ] 	Top5: 79.33%
[ Tue May 16 01:56:20 2023 ] Training epoch: 6
[ Tue May 16 01:57:11 2023 ] 	Batch(99/480) done. Loss: 1.9382  lr:0.100000  network_time: 0.0109
[ Tue May 16 01:58:01 2023 ] 	Batch(199/480) done. Loss: 1.4148  lr:0.100000  network_time: 0.0115
[ Tue May 16 01:58:52 2023 ] 	Batch(299/480) done. Loss: 0.6254  lr:0.100000  network_time: 0.0108
[ Tue May 16 01:59:42 2023 ] 	Batch(399/480) done. Loss: 2.8336  lr:0.100000  network_time: 0.0107
[ Tue May 16 02:00:22 2023 ] 	Training Accuracy: 54.00%
[ Tue May 16 02:00:22 2023 ] Eval epoch: 6
[ Tue May 16 02:00:39 2023 ] 	Mean test loss of 120 batches: 0.8504438996315002.
[ Tue May 16 02:00:39 2023 ] 	Top1: 73.17%
[ Tue May 16 02:00:39 2023 ] 	Top5: 97.50%
[ Tue May 16 02:00:39 2023 ] Training epoch: 7
[ Tue May 16 02:00:49 2023 ] 	Batch(19/480) done. Loss: 2.0437  lr:0.100000  network_time: 0.0112
[ Tue May 16 02:01:40 2023 ] 	Batch(119/480) done. Loss: 1.0262  lr:0.100000  network_time: 0.0108
[ Tue May 16 02:02:30 2023 ] 	Batch(219/480) done. Loss: 1.1622  lr:0.100000  network_time: 0.0108
[ Tue May 16 02:03:21 2023 ] 	Batch(319/480) done. Loss: 0.6249  lr:0.100000  network_time: 0.0108
[ Tue May 16 02:04:11 2023 ] 	Batch(419/480) done. Loss: 1.8464  lr:0.100000  network_time: 0.0114
[ Tue May 16 02:04:41 2023 ] 	Training Accuracy: 61.46%
[ Tue May 16 02:04:41 2023 ] Eval epoch: 7
[ Tue May 16 02:04:59 2023 ] 	Mean test loss of 120 batches: 1.063611388206482.
[ Tue May 16 02:04:59 2023 ] 	Top1: 65.00%
[ Tue May 16 02:04:59 2023 ] 	Top5: 95.67%
[ Tue May 16 02:04:59 2023 ] Training epoch: 8
[ Tue May 16 02:05:19 2023 ] 	Batch(39/480) done. Loss: 0.6064  lr:0.100000  network_time: 0.0132
[ Tue May 16 02:06:09 2023 ] 	Batch(139/480) done. Loss: 0.7398  lr:0.100000  network_time: 0.0137
[ Tue May 16 02:07:00 2023 ] 	Batch(239/480) done. Loss: 0.6858  lr:0.100000  network_time: 0.0108
[ Tue May 16 02:07:50 2023 ] 	Batch(339/480) done. Loss: 0.9564  lr:0.100000  network_time: 0.0132
[ Tue May 16 02:08:41 2023 ] 	Batch(439/480) done. Loss: 1.0320  lr:0.100000  network_time: 0.0130
[ Tue May 16 02:09:01 2023 ] 	Training Accuracy: 66.25%
[ Tue May 16 02:09:01 2023 ] Eval epoch: 8
[ Tue May 16 02:09:18 2023 ] 	Mean test loss of 120 batches: 0.9591563940048218.
[ Tue May 16 02:09:18 2023 ] 	Top1: 69.67%
[ Tue May 16 02:09:18 2023 ] 	Top5: 97.67%
[ Tue May 16 02:09:18 2023 ] Training epoch: 9
[ Tue May 16 02:09:49 2023 ] 	Batch(59/480) done. Loss: 0.6024  lr:0.100000  network_time: 0.0110
[ Tue May 16 02:10:39 2023 ] 	Batch(159/480) done. Loss: 1.2576  lr:0.100000  network_time: 0.0108
[ Tue May 16 02:11:30 2023 ] 	Batch(259/480) done. Loss: 2.4552  lr:0.100000  network_time: 0.0118
[ Tue May 16 02:12:20 2023 ] 	Batch(359/480) done. Loss: 0.4654  lr:0.100000  network_time: 0.0111
[ Tue May 16 02:13:11 2023 ] 	Batch(459/480) done. Loss: 0.4965  lr:0.100000  network_time: 0.0135
[ Tue May 16 02:13:21 2023 ] 	Training Accuracy: 72.83%
[ Tue May 16 02:13:21 2023 ] Eval epoch: 9
[ Tue May 16 02:13:38 2023 ] 	Mean test loss of 120 batches: 1.0082852840423584.
[ Tue May 16 02:13:38 2023 ] 	Top1: 71.33%
[ Tue May 16 02:13:38 2023 ] 	Top5: 98.50%
[ Tue May 16 02:13:38 2023 ] Training epoch: 10
[ Tue May 16 02:14:18 2023 ] 	Batch(79/480) done. Loss: 1.7460  lr:0.100000  network_time: 0.0140
[ Tue May 16 02:15:09 2023 ] 	Batch(179/480) done. Loss: 1.4135  lr:0.100000  network_time: 0.0113
[ Tue May 16 02:15:59 2023 ] 	Batch(279/480) done. Loss: 0.7058  lr:0.100000  network_time: 0.0109
[ Tue May 16 02:16:50 2023 ] 	Batch(379/480) done. Loss: 0.7684  lr:0.100000  network_time: 0.0136
[ Tue May 16 02:17:40 2023 ] 	Batch(479/480) done. Loss: 1.2844  lr:0.100000  network_time: 0.0109
[ Tue May 16 02:17:40 2023 ] 	Training Accuracy: 74.21%
[ Tue May 16 02:17:40 2023 ] Eval epoch: 10
[ Tue May 16 02:17:57 2023 ] 	Mean test loss of 120 batches: 0.6247251629829407.
[ Tue May 16 02:17:57 2023 ] 	Top1: 79.83%
[ Tue May 16 02:17:57 2023 ] 	Top5: 99.67%
[ Tue May 16 02:17:58 2023 ] Training epoch: 11
[ Tue May 16 02:18:48 2023 ] 	Batch(99/480) done. Loss: 0.9481  lr:0.100000  network_time: 0.0107
[ Tue May 16 02:19:38 2023 ] 	Batch(199/480) done. Loss: 1.1979  lr:0.100000  network_time: 0.0134
[ Tue May 16 02:20:29 2023 ] 	Batch(299/480) done. Loss: 1.0247  lr:0.100000  network_time: 0.0132
[ Tue May 16 02:21:19 2023 ] 	Batch(399/480) done. Loss: 0.4228  lr:0.100000  network_time: 0.0109
[ Tue May 16 02:22:00 2023 ] 	Training Accuracy: 77.25%
[ Tue May 16 02:22:00 2023 ] Eval epoch: 11
[ Tue May 16 02:22:17 2023 ] 	Mean test loss of 120 batches: 0.5841054320335388.
[ Tue May 16 02:22:17 2023 ] 	Top1: 80.50%
[ Tue May 16 02:22:17 2023 ] 	Top5: 99.83%
[ Tue May 16 02:22:17 2023 ] Training epoch: 12
[ Tue May 16 02:22:27 2023 ] 	Batch(19/480) done. Loss: 0.0948  lr:0.100000  network_time: 0.0134
[ Tue May 16 02:23:18 2023 ] 	Batch(119/480) done. Loss: 0.2246  lr:0.100000  network_time: 0.0111
[ Tue May 16 02:24:08 2023 ] 	Batch(219/480) done. Loss: 0.3621  lr:0.100000  network_time: 0.0116
[ Tue May 16 02:24:58 2023 ] 	Batch(319/480) done. Loss: 0.6398  lr:0.100000  network_time: 0.0110
[ Tue May 16 02:25:49 2023 ] 	Batch(419/480) done. Loss: 0.9489  lr:0.100000  network_time: 0.0133
[ Tue May 16 02:26:19 2023 ] 	Training Accuracy: 80.42%
[ Tue May 16 02:26:19 2023 ] Eval epoch: 12
[ Tue May 16 02:26:36 2023 ] 	Mean test loss of 120 batches: 0.7435724139213562.
[ Tue May 16 02:26:36 2023 ] 	Top1: 76.33%
[ Tue May 16 02:26:36 2023 ] 	Top5: 98.50%
[ Tue May 16 02:26:36 2023 ] Training epoch: 13
[ Tue May 16 02:26:56 2023 ] 	Batch(39/480) done. Loss: 0.5425  lr:0.100000  network_time: 0.0113
[ Tue May 16 02:27:47 2023 ] 	Batch(139/480) done. Loss: 0.2482  lr:0.100000  network_time: 0.0139
[ Tue May 16 02:28:37 2023 ] 	Batch(239/480) done. Loss: 0.1938  lr:0.100000  network_time: 0.0132
[ Tue May 16 02:29:28 2023 ] 	Batch(339/480) done. Loss: 1.0401  lr:0.100000  network_time: 0.0106
[ Tue May 16 02:30:18 2023 ] 	Batch(439/480) done. Loss: 0.9269  lr:0.100000  network_time: 0.0110
[ Tue May 16 02:30:38 2023 ] 	Training Accuracy: 82.04%
[ Tue May 16 02:30:38 2023 ] Eval epoch: 13
[ Tue May 16 02:30:56 2023 ] 	Mean test loss of 120 batches: 0.4188120663166046.
[ Tue May 16 02:30:56 2023 ] 	Top1: 89.00%
[ Tue May 16 02:30:56 2023 ] 	Top5: 99.67%
[ Tue May 16 02:30:56 2023 ] Training epoch: 14
[ Tue May 16 02:31:26 2023 ] 	Batch(59/480) done. Loss: 0.2262  lr:0.100000  network_time: 0.0109
[ Tue May 16 02:32:16 2023 ] 	Batch(159/480) done. Loss: 0.1882  lr:0.100000  network_time: 0.0113
[ Tue May 16 02:33:07 2023 ] 	Batch(259/480) done. Loss: 0.5234  lr:0.100000  network_time: 0.0109
[ Tue May 16 02:33:57 2023 ] 	Batch(359/480) done. Loss: 0.3306  lr:0.100000  network_time: 0.0108
[ Tue May 16 02:34:48 2023 ] 	Batch(459/480) done. Loss: 0.3649  lr:0.100000  network_time: 0.0112
[ Tue May 16 02:34:58 2023 ] 	Training Accuracy: 84.71%
[ Tue May 16 02:34:58 2023 ] Eval epoch: 14
[ Tue May 16 02:35:15 2023 ] 	Mean test loss of 120 batches: 0.5513787865638733.
[ Tue May 16 02:35:15 2023 ] 	Top1: 83.33%
[ Tue May 16 02:35:15 2023 ] 	Top5: 99.33%
[ Tue May 16 02:35:15 2023 ] Training epoch: 15
[ Tue May 16 02:35:56 2023 ] 	Batch(79/480) done. Loss: 1.2469  lr:0.100000  network_time: 0.0113
[ Tue May 16 02:36:46 2023 ] 	Batch(179/480) done. Loss: 0.8392  lr:0.100000  network_time: 0.0137
[ Tue May 16 02:37:36 2023 ] 	Batch(279/480) done. Loss: 0.0589  lr:0.100000  network_time: 0.0111
[ Tue May 16 02:38:27 2023 ] 	Batch(379/480) done. Loss: 0.3261  lr:0.100000  network_time: 0.0142
[ Tue May 16 02:39:17 2023 ] 	Batch(479/480) done. Loss: 0.2534  lr:0.100000  network_time: 0.0136
[ Tue May 16 02:39:17 2023 ] 	Training Accuracy: 85.79%
[ Tue May 16 02:39:17 2023 ] Eval epoch: 15
[ Tue May 16 02:39:35 2023 ] 	Mean test loss of 120 batches: 0.4220021367073059.
[ Tue May 16 02:39:35 2023 ] 	Top1: 88.33%
[ Tue May 16 02:39:35 2023 ] 	Top5: 99.67%
[ Tue May 16 02:39:35 2023 ] Training epoch: 16
[ Tue May 16 02:40:25 2023 ] 	Batch(99/480) done. Loss: 0.1249  lr:0.100000  network_time: 0.0134
[ Tue May 16 02:41:16 2023 ] 	Batch(199/480) done. Loss: 0.1396  lr:0.100000  network_time: 0.0109
[ Tue May 16 02:42:06 2023 ] 	Batch(299/480) done. Loss: 0.3152  lr:0.100000  network_time: 0.0109
[ Tue May 16 02:42:57 2023 ] 	Batch(399/480) done. Loss: 1.5436  lr:0.100000  network_time: 0.0110
[ Tue May 16 02:43:37 2023 ] 	Training Accuracy: 84.67%
[ Tue May 16 02:43:37 2023 ] Eval epoch: 16
[ Tue May 16 02:43:54 2023 ] 	Mean test loss of 120 batches: 0.8180888891220093.
[ Tue May 16 02:43:54 2023 ] 	Top1: 81.83%
[ Tue May 16 02:43:54 2023 ] 	Top5: 99.00%
[ Tue May 16 02:43:54 2023 ] Training epoch: 17
[ Tue May 16 02:44:04 2023 ] 	Batch(19/480) done. Loss: 0.2461  lr:0.100000  network_time: 0.0110
[ Tue May 16 02:44:55 2023 ] 	Batch(119/480) done. Loss: 0.0738  lr:0.100000  network_time: 0.0140
[ Tue May 16 02:45:45 2023 ] 	Batch(219/480) done. Loss: 0.0418  lr:0.100000  network_time: 0.0127
[ Tue May 16 02:46:36 2023 ] 	Batch(319/480) done. Loss: 0.1228  lr:0.100000  network_time: 0.0134
[ Tue May 16 02:47:26 2023 ] 	Batch(419/480) done. Loss: 0.0684  lr:0.100000  network_time: 0.0136
[ Tue May 16 02:47:56 2023 ] 	Training Accuracy: 86.75%
[ Tue May 16 02:47:56 2023 ] Eval epoch: 17
[ Tue May 16 02:48:14 2023 ] 	Mean test loss of 120 batches: 0.4777825176715851.
[ Tue May 16 02:48:14 2023 ] 	Top1: 84.83%
[ Tue May 16 02:48:14 2023 ] 	Top5: 99.00%
[ Tue May 16 02:48:14 2023 ] Training epoch: 18
[ Tue May 16 02:48:34 2023 ] 	Batch(39/480) done. Loss: 0.9099  lr:0.100000  network_time: 0.0106
[ Tue May 16 02:49:24 2023 ] 	Batch(139/480) done. Loss: 1.1951  lr:0.100000  network_time: 0.0111
[ Tue May 16 02:50:15 2023 ] 	Batch(239/480) done. Loss: 0.0312  lr:0.100000  network_time: 0.0139
[ Tue May 16 02:51:05 2023 ] 	Batch(339/480) done. Loss: 0.1434  lr:0.100000  network_time: 0.0110
[ Tue May 16 02:51:56 2023 ] 	Batch(439/480) done. Loss: 0.5632  lr:0.100000  network_time: 0.0123
[ Tue May 16 02:52:16 2023 ] 	Training Accuracy: 86.13%
[ Tue May 16 02:52:16 2023 ] Eval epoch: 18
[ Tue May 16 02:52:33 2023 ] 	Mean test loss of 120 batches: 0.2738139033317566.
[ Tue May 16 02:52:33 2023 ] 	Top1: 92.67%
[ Tue May 16 02:52:33 2023 ] 	Top5: 99.83%
[ Tue May 16 02:52:33 2023 ] Training epoch: 19
[ Tue May 16 02:53:03 2023 ] 	Batch(59/480) done. Loss: 0.2896  lr:0.100000  network_time: 0.0112
[ Tue May 16 02:53:54 2023 ] 	Batch(159/480) done. Loss: 0.1079  lr:0.100000  network_time: 0.0139
[ Tue May 16 02:54:44 2023 ] 	Batch(259/480) done. Loss: 0.4816  lr:0.100000  network_time: 0.0138
[ Tue May 16 02:55:35 2023 ] 	Batch(359/480) done. Loss: 0.0490  lr:0.100000  network_time: 0.0134
[ Tue May 16 02:56:25 2023 ] 	Batch(459/480) done. Loss: 0.4109  lr:0.100000  network_time: 0.0109
[ Tue May 16 02:56:35 2023 ] 	Training Accuracy: 88.88%
[ Tue May 16 02:56:35 2023 ] Eval epoch: 19
[ Tue May 16 02:56:52 2023 ] 	Mean test loss of 120 batches: 0.49791499972343445.
[ Tue May 16 02:56:52 2023 ] 	Top1: 88.17%
[ Tue May 16 02:56:52 2023 ] 	Top5: 99.50%
[ Tue May 16 02:56:52 2023 ] Training epoch: 20
[ Tue May 16 02:57:33 2023 ] 	Batch(79/480) done. Loss: 0.5661  lr:0.100000  network_time: 0.0109
[ Tue May 16 02:58:23 2023 ] 	Batch(179/480) done. Loss: 0.8956  lr:0.100000  network_time: 0.0132
[ Tue May 16 02:59:14 2023 ] 	Batch(279/480) done. Loss: 0.1803  lr:0.100000  network_time: 0.0106
[ Tue May 16 03:00:04 2023 ] 	Batch(379/480) done. Loss: 0.1165  lr:0.100000  network_time: 0.0137
[ Tue May 16 03:00:55 2023 ] 	Batch(479/480) done. Loss: 0.0961  lr:0.100000  network_time: 0.0110
[ Tue May 16 03:00:55 2023 ] 	Training Accuracy: 89.00%
[ Tue May 16 03:00:55 2023 ] Eval epoch: 20
[ Tue May 16 03:01:12 2023 ] 	Mean test loss of 120 batches: 0.28716832399368286.
[ Tue May 16 03:01:12 2023 ] 	Top1: 90.50%
[ Tue May 16 03:01:12 2023 ] 	Top5: 100.00%
[ Tue May 16 03:01:12 2023 ] Training epoch: 21
[ Tue May 16 03:02:03 2023 ] 	Batch(99/480) done. Loss: 0.0425  lr:0.010000  network_time: 0.0113
[ Tue May 16 03:02:53 2023 ] 	Batch(199/480) done. Loss: 0.1519  lr:0.010000  network_time: 0.0109
[ Tue May 16 03:03:44 2023 ] 	Batch(299/480) done. Loss: 0.7627  lr:0.010000  network_time: 0.0109
[ Tue May 16 03:04:34 2023 ] 	Batch(399/480) done. Loss: 0.1548  lr:0.010000  network_time: 0.0110
[ Tue May 16 03:05:14 2023 ] 	Training Accuracy: 96.33%
[ Tue May 16 03:05:14 2023 ] Eval epoch: 21
[ Tue May 16 03:05:32 2023 ] 	Mean test loss of 120 batches: 0.0407395102083683.
[ Tue May 16 03:05:32 2023 ] 	Top1: 99.17%
[ Tue May 16 03:05:32 2023 ] 	Top5: 100.00%
[ Tue May 16 03:05:32 2023 ] Training epoch: 22
[ Tue May 16 03:05:42 2023 ] 	Batch(19/480) done. Loss: 0.0463  lr:0.010000  network_time: 0.0123
[ Tue May 16 03:06:32 2023 ] 	Batch(119/480) done. Loss: 0.0075  lr:0.010000  network_time: 0.0109
[ Tue May 16 03:07:23 2023 ] 	Batch(219/480) done. Loss: 0.0315  lr:0.010000  network_time: 0.0135
[ Tue May 16 03:08:13 2023 ] 	Batch(319/480) done. Loss: 0.0386  lr:0.010000  network_time: 0.0135
[ Tue May 16 03:09:04 2023 ] 	Batch(419/480) done. Loss: 0.0323  lr:0.010000  network_time: 0.0133
[ Tue May 16 03:09:34 2023 ] 	Training Accuracy: 98.04%
[ Tue May 16 03:09:34 2023 ] Eval epoch: 22
[ Tue May 16 03:09:51 2023 ] 	Mean test loss of 120 batches: 0.024779094383120537.
[ Tue May 16 03:09:51 2023 ] 	Top1: 99.33%
[ Tue May 16 03:09:51 2023 ] 	Top5: 100.00%
[ Tue May 16 03:09:51 2023 ] Training epoch: 23
[ Tue May 16 03:10:11 2023 ] 	Batch(39/480) done. Loss: 0.0367  lr:0.010000  network_time: 0.0113
[ Tue May 16 03:11:02 2023 ] 	Batch(139/480) done. Loss: 0.0194  lr:0.010000  network_time: 0.0112
[ Tue May 16 03:11:52 2023 ] 	Batch(239/480) done. Loss: 0.0031  lr:0.010000  network_time: 0.0109
[ Tue May 16 03:12:43 2023 ] 	Batch(339/480) done. Loss: 0.0236  lr:0.010000  network_time: 0.0110
[ Tue May 16 03:13:33 2023 ] 	Batch(439/480) done. Loss: 0.0451  lr:0.010000  network_time: 0.0107
[ Tue May 16 03:13:53 2023 ] 	Training Accuracy: 98.83%
[ Tue May 16 03:13:53 2023 ] Eval epoch: 23
[ Tue May 16 03:14:11 2023 ] 	Mean test loss of 120 batches: 0.018205886706709862.
[ Tue May 16 03:14:11 2023 ] 	Top1: 100.00%
[ Tue May 16 03:14:11 2023 ] 	Top5: 100.00%
[ Tue May 16 03:14:11 2023 ] Training epoch: 24
[ Tue May 16 03:14:41 2023 ] 	Batch(59/480) done. Loss: 0.0749  lr:0.010000  network_time: 0.0133
[ Tue May 16 03:15:31 2023 ] 	Batch(159/480) done. Loss: 0.0311  lr:0.010000  network_time: 0.0107
[ Tue May 16 03:16:22 2023 ] 	Batch(259/480) done. Loss: 0.0770  lr:0.010000  network_time: 0.0109
[ Tue May 16 03:17:12 2023 ] 	Batch(359/480) done. Loss: 0.0401  lr:0.010000  network_time: 0.0112
[ Tue May 16 03:18:03 2023 ] 	Batch(459/480) done. Loss: 0.0207  lr:0.010000  network_time: 0.0111
[ Tue May 16 03:18:13 2023 ] 	Training Accuracy: 99.12%
[ Tue May 16 03:18:13 2023 ] Eval epoch: 24
[ Tue May 16 03:18:30 2023 ] 	Mean test loss of 120 batches: 0.016843128949403763.
[ Tue May 16 03:18:30 2023 ] 	Top1: 99.33%
[ Tue May 16 03:18:30 2023 ] 	Top5: 100.00%
[ Tue May 16 03:18:30 2023 ] Training epoch: 25
[ Tue May 16 03:19:11 2023 ] 	Batch(79/480) done. Loss: 0.0087  lr:0.010000  network_time: 0.0125
[ Tue May 16 03:20:01 2023 ] 	Batch(179/480) done. Loss: 0.0160  lr:0.010000  network_time: 0.0108
[ Tue May 16 03:20:52 2023 ] 	Batch(279/480) done. Loss: 0.0047  lr:0.010000  network_time: 0.0134
[ Tue May 16 03:21:42 2023 ] 	Batch(379/480) done. Loss: 0.0097  lr:0.010000  network_time: 0.0111
[ Tue May 16 03:22:33 2023 ] 	Batch(479/480) done. Loss: 0.0063  lr:0.010000  network_time: 0.0108
[ Tue May 16 03:22:33 2023 ] 	Training Accuracy: 99.25%
[ Tue May 16 03:22:33 2023 ] Eval epoch: 25
[ Tue May 16 03:22:50 2023 ] 	Mean test loss of 120 batches: 0.013502825982868671.
[ Tue May 16 03:22:50 2023 ] 	Top1: 99.83%
[ Tue May 16 03:22:50 2023 ] 	Top5: 100.00%
[ Tue May 16 03:22:50 2023 ] Training epoch: 26
[ Tue May 16 03:23:40 2023 ] 	Batch(99/480) done. Loss: 0.0209  lr:0.001000  network_time: 0.0112
[ Tue May 16 03:24:31 2023 ] 	Batch(199/480) done. Loss: 0.0054  lr:0.001000  network_time: 0.0110
[ Tue May 16 03:25:22 2023 ] 	Batch(299/480) done. Loss: 0.0014  lr:0.001000  network_time: 0.0109
[ Tue May 16 03:26:12 2023 ] 	Batch(399/480) done. Loss: 0.0120  lr:0.001000  network_time: 0.0108
[ Tue May 16 03:26:52 2023 ] 	Training Accuracy: 99.29%
[ Tue May 16 03:26:52 2023 ] Eval epoch: 26
[ Tue May 16 03:27:10 2023 ] 	Mean test loss of 120 batches: 0.014187809079885483.
[ Tue May 16 03:27:10 2023 ] 	Top1: 99.83%
[ Tue May 16 03:27:10 2023 ] 	Top5: 100.00%
[ Tue May 16 03:27:10 2023 ] Training epoch: 27
[ Tue May 16 03:27:20 2023 ] 	Batch(19/480) done. Loss: 0.0057  lr:0.001000  network_time: 0.0133
[ Tue May 16 03:28:10 2023 ] 	Batch(119/480) done. Loss: 0.0905  lr:0.001000  network_time: 0.0136
[ Tue May 16 03:29:01 2023 ] 	Batch(219/480) done. Loss: 0.0105  lr:0.001000  network_time: 0.0133
[ Tue May 16 03:29:51 2023 ] 	Batch(319/480) done. Loss: 0.0131  lr:0.001000  network_time: 0.0141
[ Tue May 16 03:30:42 2023 ] 	Batch(419/480) done. Loss: 0.0621  lr:0.001000  network_time: 0.0108
[ Tue May 16 03:31:12 2023 ] 	Training Accuracy: 99.33%
[ Tue May 16 03:31:12 2023 ] Eval epoch: 27
[ Tue May 16 03:31:29 2023 ] 	Mean test loss of 120 batches: 0.014584476128220558.
[ Tue May 16 03:31:29 2023 ] 	Top1: 99.50%
[ Tue May 16 03:31:29 2023 ] 	Top5: 100.00%
[ Tue May 16 03:31:29 2023 ] Training epoch: 28
[ Tue May 16 03:31:49 2023 ] 	Batch(39/480) done. Loss: 0.0315  lr:0.001000  network_time: 0.0109
[ Tue May 16 03:32:40 2023 ] 	Batch(139/480) done. Loss: 0.0060  lr:0.001000  network_time: 0.0106
[ Tue May 16 03:33:30 2023 ] 	Batch(239/480) done. Loss: 0.0356  lr:0.001000  network_time: 0.0141
[ Tue May 16 03:34:21 2023 ] 	Batch(339/480) done. Loss: 0.0641  lr:0.001000  network_time: 0.0135
[ Tue May 16 03:35:11 2023 ] 	Batch(439/480) done. Loss: 0.0164  lr:0.001000  network_time: 0.0137
[ Tue May 16 03:35:31 2023 ] 	Training Accuracy: 99.46%
[ Tue May 16 03:35:31 2023 ] Eval epoch: 28
[ Tue May 16 03:35:48 2023 ] 	Mean test loss of 120 batches: 0.010533091612160206.
[ Tue May 16 03:35:48 2023 ] 	Top1: 100.00%
[ Tue May 16 03:35:48 2023 ] 	Top5: 100.00%
[ Tue May 16 03:35:48 2023 ] Training epoch: 29
[ Tue May 16 03:36:19 2023 ] 	Batch(59/480) done. Loss: 0.0669  lr:0.001000  network_time: 0.0113
[ Tue May 16 03:37:09 2023 ] 	Batch(159/480) done. Loss: 0.0110  lr:0.001000  network_time: 0.0135
[ Tue May 16 03:38:00 2023 ] 	Batch(259/480) done. Loss: 0.0299  lr:0.001000  network_time: 0.0111
[ Tue May 16 03:38:50 2023 ] 	Batch(359/480) done. Loss: 0.0354  lr:0.001000  network_time: 0.0114
[ Tue May 16 03:39:41 2023 ] 	Batch(459/480) done. Loss: 0.0370  lr:0.001000  network_time: 0.0110
[ Tue May 16 03:39:51 2023 ] 	Training Accuracy: 99.42%
[ Tue May 16 03:39:51 2023 ] Eval epoch: 29
[ Tue May 16 03:40:08 2023 ] 	Mean test loss of 120 batches: 0.012219009920954704.
[ Tue May 16 03:40:08 2023 ] 	Top1: 99.83%
[ Tue May 16 03:40:08 2023 ] 	Top5: 100.00%
[ Tue May 16 03:40:08 2023 ] Training epoch: 30
[ Tue May 16 03:40:48 2023 ] 	Batch(79/480) done. Loss: 0.0089  lr:0.001000  network_time: 0.0108
[ Tue May 16 03:41:39 2023 ] 	Batch(179/480) done. Loss: 0.0167  lr:0.001000  network_time: 0.0110
[ Tue May 16 03:42:30 2023 ] 	Batch(279/480) done. Loss: 0.0051  lr:0.001000  network_time: 0.0107
[ Tue May 16 03:43:20 2023 ] 	Batch(379/480) done. Loss: 0.0044  lr:0.001000  network_time: 0.0110
[ Tue May 16 03:44:10 2023 ] 	Batch(479/480) done. Loss: 0.0039  lr:0.001000  network_time: 0.0108
[ Tue May 16 03:44:10 2023 ] 	Training Accuracy: 99.54%
[ Tue May 16 03:44:10 2023 ] Eval epoch: 30
[ Tue May 16 03:44:28 2023 ] 	Mean test loss of 120 batches: 0.010084535926580429.
[ Tue May 16 03:44:28 2023 ] 	Top1: 99.83%
[ Tue May 16 03:44:28 2023 ] 	Top5: 100.00%
