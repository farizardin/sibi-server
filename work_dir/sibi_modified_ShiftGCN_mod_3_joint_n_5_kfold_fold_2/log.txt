[ Wed May 17 20:52:17 2023 ] NUM WORKER: 1
[ Wed May 17 20:53:13 2023 ] Parameters:
{'work_dir': './work_dir/sibi_modified_ShiftGCN_mod_3_joint_n_5_kfold_fold_2', 'model_saved_name': './save_models/sibi_modified_ShiftGCN_mod_3_joint_n_5_kfold_fold_2', 'Experiment_name': 'sibi_modified_ShiftGCN_mod_3_joint_n_5_kfold', 'config': './config/recalculated/train_sibi_with_mouth_augmented_modified_shift_joint_mod_3.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 2, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'n_splits': 5, 'feeder': 'feeders.feeder_hsd.Feeder', 'num_worker': 1, 'train_feeder_args': {'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': -1, 'normalization': False}, 'test_feeder_args': None, 'data_path': './data/augmented_recalculate_normalized', 'model': 'model.shift_gcn.Model', 'model_args': {'num_class': 50, 'num_person': 1, 'num_point': 115, 'method': 'modified', 'weight': 3, 'graph': 'graph.skeleton_with_mouth.SkeletonWithMouth', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [20, 25], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 5, 'test_batch_size': 5, 'start_epoch': 0, 'num_epoch': 30, 'folds_range': [0, 5], 'weight_decay': 0.0001, 'only_train_part': True, 'only_train_epoch': 1, 'warm_up_epoch': 0}

[ Wed May 17 20:53:13 2023 ] Training epoch: 1
[ Wed May 17 20:54:02 2023 ] 	Batch(99/480) done. Loss: 3.8676  lr:0.100000  network_time: 0.0123
[ Wed May 17 20:54:50 2023 ] 	Batch(199/480) done. Loss: 3.7696  lr:0.100000  network_time: 0.0110
[ Wed May 17 20:55:39 2023 ] 	Batch(299/480) done. Loss: 3.4242  lr:0.100000  network_time: 0.0113
[ Wed May 17 20:56:27 2023 ] 	Batch(399/480) done. Loss: 3.4411  lr:0.100000  network_time: 0.0112
[ Wed May 17 20:57:06 2023 ] 	Training Accuracy: 5.21%
[ Wed May 17 20:57:06 2023 ] Eval epoch: 1
[ Wed May 17 20:57:22 2023 ] 	Mean test loss of 120 batches: 3.955059289932251.
[ Wed May 17 20:57:22 2023 ] 	Top1: 9.50%
[ Wed May 17 20:57:22 2023 ] 	Top5: 36.67%
[ Wed May 17 20:57:22 2023 ] Training epoch: 2
[ Wed May 17 20:57:32 2023 ] 	Batch(19/480) done. Loss: 3.2426  lr:0.100000  network_time: 0.0113
[ Wed May 17 20:58:20 2023 ] 	Batch(119/480) done. Loss: 3.5789  lr:0.100000  network_time: 0.0118
[ Wed May 17 20:59:09 2023 ] 	Batch(219/480) done. Loss: 2.9072  lr:0.100000  network_time: 0.0116
[ Wed May 17 20:59:57 2023 ] 	Batch(319/480) done. Loss: 3.2613  lr:0.100000  network_time: 0.0113
[ Wed May 17 21:00:46 2023 ] 	Batch(419/480) done. Loss: 2.7432  lr:0.100000  network_time: 0.0115
[ Wed May 17 21:01:15 2023 ] 	Training Accuracy: 13.75%
[ Wed May 17 21:01:15 2023 ] Eval epoch: 2
[ Wed May 17 21:01:31 2023 ] 	Mean test loss of 120 batches: 3.1222763061523438.
[ Wed May 17 21:01:31 2023 ] 	Top1: 18.67%
[ Wed May 17 21:01:31 2023 ] 	Top5: 52.50%
[ Wed May 17 21:01:31 2023 ] Training epoch: 3
[ Wed May 17 21:01:51 2023 ] 	Batch(39/480) done. Loss: 2.9352  lr:0.100000  network_time: 0.0114
[ Wed May 17 21:02:39 2023 ] 	Batch(139/480) done. Loss: 1.9900  lr:0.100000  network_time: 0.0115
[ Wed May 17 21:03:27 2023 ] 	Batch(239/480) done. Loss: 2.5882  lr:0.100000  network_time: 0.0115
[ Wed May 17 21:04:16 2023 ] 	Batch(339/480) done. Loss: 2.8764  lr:0.100000  network_time: 0.0116
[ Wed May 17 21:05:04 2023 ] 	Batch(439/480) done. Loss: 3.3217  lr:0.100000  network_time: 0.0117
[ Wed May 17 21:05:24 2023 ] 	Training Accuracy: 19.38%
[ Wed May 17 21:05:24 2023 ] Eval epoch: 3
[ Wed May 17 21:05:40 2023 ] 	Mean test loss of 120 batches: 2.385009765625.
[ Wed May 17 21:05:40 2023 ] 	Top1: 27.17%
[ Wed May 17 21:05:40 2023 ] 	Top5: 70.67%
[ Wed May 17 21:05:40 2023 ] Training epoch: 4
[ Wed May 17 21:06:09 2023 ] 	Batch(59/480) done. Loss: 2.3624  lr:0.100000  network_time: 0.0113
[ Wed May 17 21:06:58 2023 ] 	Batch(159/480) done. Loss: 2.5417  lr:0.100000  network_time: 0.0113
[ Wed May 17 21:07:46 2023 ] 	Batch(259/480) done. Loss: 1.5767  lr:0.100000  network_time: 0.0113
[ Wed May 17 21:08:35 2023 ] 	Batch(359/480) done. Loss: 2.0422  lr:0.100000  network_time: 0.0116
[ Wed May 17 21:09:23 2023 ] 	Batch(459/480) done. Loss: 3.0553  lr:0.100000  network_time: 0.0122
[ Wed May 17 21:09:33 2023 ] 	Training Accuracy: 27.58%
[ Wed May 17 21:09:33 2023 ] Eval epoch: 4
[ Wed May 17 21:09:49 2023 ] 	Mean test loss of 120 batches: 3.489713430404663.
[ Wed May 17 21:09:49 2023 ] 	Top1: 14.67%
[ Wed May 17 21:09:49 2023 ] 	Top5: 47.17%
[ Wed May 17 21:09:49 2023 ] Training epoch: 5
[ Wed May 17 21:10:28 2023 ] 	Batch(79/480) done. Loss: 3.3379  lr:0.100000  network_time: 0.0115
[ Wed May 17 21:11:16 2023 ] 	Batch(179/480) done. Loss: 2.4146  lr:0.100000  network_time: 0.0116
[ Wed May 17 21:12:05 2023 ] 	Batch(279/480) done. Loss: 1.8085  lr:0.100000  network_time: 0.0116
[ Wed May 17 21:12:53 2023 ] 	Batch(379/480) done. Loss: 2.4894  lr:0.100000  network_time: 0.0116
[ Wed May 17 21:13:42 2023 ] 	Batch(479/480) done. Loss: 1.2203  lr:0.100000  network_time: 0.0113
[ Wed May 17 21:13:42 2023 ] 	Training Accuracy: 34.88%
[ Wed May 17 21:13:42 2023 ] Eval epoch: 5
[ Wed May 17 21:13:58 2023 ] 	Mean test loss of 120 batches: 1.9574629068374634.
[ Wed May 17 21:13:58 2023 ] 	Top1: 35.83%
[ Wed May 17 21:13:58 2023 ] 	Top5: 86.67%
[ Wed May 17 21:13:58 2023 ] Training epoch: 6
[ Wed May 17 21:14:46 2023 ] 	Batch(99/480) done. Loss: 1.4070  lr:0.100000  network_time: 0.0122
[ Wed May 17 21:15:35 2023 ] 	Batch(199/480) done. Loss: 2.0821  lr:0.100000  network_time: 0.0113
[ Wed May 17 21:16:23 2023 ] 	Batch(299/480) done. Loss: 1.6411  lr:0.100000  network_time: 0.0115
[ Wed May 17 21:17:12 2023 ] 	Batch(399/480) done. Loss: 2.1605  lr:0.100000  network_time: 0.0113
[ Wed May 17 21:17:51 2023 ] 	Training Accuracy: 44.79%
[ Wed May 17 21:17:51 2023 ] Eval epoch: 6
[ Wed May 17 21:18:07 2023 ] 	Mean test loss of 120 batches: 1.5234543085098267.
[ Wed May 17 21:18:07 2023 ] 	Top1: 54.00%
[ Wed May 17 21:18:07 2023 ] 	Top5: 89.83%
[ Wed May 17 21:18:07 2023 ] Training epoch: 7
[ Wed May 17 21:18:17 2023 ] 	Batch(19/480) done. Loss: 2.4482  lr:0.100000  network_time: 0.0112
[ Wed May 17 21:19:05 2023 ] 	Batch(119/480) done. Loss: 1.3548  lr:0.100000  network_time: 0.0112
[ Wed May 17 21:19:53 2023 ] 	Batch(219/480) done. Loss: 1.2993  lr:0.100000  network_time: 0.0123
[ Wed May 17 21:20:42 2023 ] 	Batch(319/480) done. Loss: 1.1802  lr:0.100000  network_time: 0.0116
[ Wed May 17 21:21:30 2023 ] 	Batch(419/480) done. Loss: 1.7492  lr:0.100000  network_time: 0.0120
[ Wed May 17 21:21:59 2023 ] 	Training Accuracy: 53.62%
[ Wed May 17 21:22:00 2023 ] Eval epoch: 7
[ Wed May 17 21:22:16 2023 ] 	Mean test loss of 120 batches: 7.41506814956665.
[ Wed May 17 21:22:16 2023 ] 	Top1: 12.50%
[ Wed May 17 21:22:16 2023 ] 	Top5: 47.83%
[ Wed May 17 21:22:16 2023 ] Training epoch: 8
[ Wed May 17 21:22:35 2023 ] 	Batch(39/480) done. Loss: 0.5649  lr:0.100000  network_time: 0.0113
[ Wed May 17 21:23:24 2023 ] 	Batch(139/480) done. Loss: 1.2498  lr:0.100000  network_time: 0.0122
[ Wed May 17 21:24:12 2023 ] 	Batch(239/480) done. Loss: 1.0107  lr:0.100000  network_time: 0.0123
[ Wed May 17 21:25:01 2023 ] 	Batch(339/480) done. Loss: 1.3998  lr:0.100000  network_time: 0.0119
[ Wed May 17 21:25:49 2023 ] 	Batch(439/480) done. Loss: 1.1031  lr:0.100000  network_time: 0.0111
[ Wed May 17 21:26:08 2023 ] 	Training Accuracy: 61.42%
[ Wed May 17 21:26:09 2023 ] Eval epoch: 8
[ Wed May 17 21:26:25 2023 ] 	Mean test loss of 120 batches: 1.5681740045547485.
[ Wed May 17 21:26:25 2023 ] 	Top1: 58.67%
[ Wed May 17 21:26:25 2023 ] 	Top5: 97.00%
[ Wed May 17 21:26:25 2023 ] Training epoch: 9
[ Wed May 17 21:26:54 2023 ] 	Batch(59/480) done. Loss: 0.1913  lr:0.100000  network_time: 0.0114
[ Wed May 17 21:27:42 2023 ] 	Batch(159/480) done. Loss: 1.3621  lr:0.100000  network_time: 0.0112
[ Wed May 17 21:28:31 2023 ] 	Batch(259/480) done. Loss: 1.5043  lr:0.100000  network_time: 0.0113
[ Wed May 17 21:29:19 2023 ] 	Batch(359/480) done. Loss: 0.6585  lr:0.100000  network_time: 0.0114
[ Wed May 17 21:30:08 2023 ] 	Batch(459/480) done. Loss: 0.4818  lr:0.100000  network_time: 0.0114
[ Wed May 17 21:30:17 2023 ] 	Training Accuracy: 66.79%
[ Wed May 17 21:30:17 2023 ] Eval epoch: 9
[ Wed May 17 21:30:34 2023 ] 	Mean test loss of 120 batches: 0.9663788676261902.
[ Wed May 17 21:30:34 2023 ] 	Top1: 69.17%
[ Wed May 17 21:30:34 2023 ] 	Top5: 95.83%
[ Wed May 17 21:30:34 2023 ] Training epoch: 10
[ Wed May 17 21:31:13 2023 ] 	Batch(79/480) done. Loss: 2.8456  lr:0.100000  network_time: 0.0120
[ Wed May 17 21:32:01 2023 ] 	Batch(179/480) done. Loss: 1.5507  lr:0.100000  network_time: 0.0112
[ Wed May 17 21:32:50 2023 ] 	Batch(279/480) done. Loss: 1.1573  lr:0.100000  network_time: 0.0112
[ Wed May 17 21:33:38 2023 ] 	Batch(379/480) done. Loss: 1.7175  lr:0.100000  network_time: 0.0116
[ Wed May 17 21:34:26 2023 ] 	Batch(479/480) done. Loss: 1.1152  lr:0.100000  network_time: 0.0118
[ Wed May 17 21:34:27 2023 ] 	Training Accuracy: 68.83%
[ Wed May 17 21:34:27 2023 ] Eval epoch: 10
[ Wed May 17 21:34:43 2023 ] 	Mean test loss of 120 batches: 2.1032979488372803.
[ Wed May 17 21:34:43 2023 ] 	Top1: 48.67%
[ Wed May 17 21:34:43 2023 ] 	Top5: 87.00%
[ Wed May 17 21:34:43 2023 ] Training epoch: 11
[ Wed May 17 21:35:31 2023 ] 	Batch(99/480) done. Loss: 0.3482  lr:0.100000  network_time: 0.0112
[ Wed May 17 21:36:20 2023 ] 	Batch(199/480) done. Loss: 0.9361  lr:0.100000  network_time: 0.0109
[ Wed May 17 21:37:08 2023 ] 	Batch(299/480) done. Loss: 0.6025  lr:0.100000  network_time: 0.0111
[ Wed May 17 21:37:57 2023 ] 	Batch(399/480) done. Loss: 0.5178  lr:0.100000  network_time: 0.0114
[ Wed May 17 21:38:35 2023 ] 	Training Accuracy: 73.38%
[ Wed May 17 21:38:36 2023 ] Eval epoch: 11
[ Wed May 17 21:38:52 2023 ] 	Mean test loss of 120 batches: 0.5823628306388855.
[ Wed May 17 21:38:52 2023 ] 	Top1: 81.17%
[ Wed May 17 21:38:52 2023 ] 	Top5: 99.33%
[ Wed May 17 21:38:52 2023 ] Training epoch: 12
[ Wed May 17 21:39:02 2023 ] 	Batch(19/480) done. Loss: 0.4940  lr:0.100000  network_time: 0.0113
[ Wed May 17 21:39:50 2023 ] 	Batch(119/480) done. Loss: 0.2274  lr:0.100000  network_time: 0.0113
[ Wed May 17 21:40:39 2023 ] 	Batch(219/480) done. Loss: 0.9583  lr:0.100000  network_time: 0.0111
[ Wed May 17 21:41:27 2023 ] 	Batch(319/480) done. Loss: 0.2431  lr:0.100000  network_time: 0.0112
[ Wed May 17 21:42:15 2023 ] 	Batch(419/480) done. Loss: 0.7321  lr:0.100000  network_time: 0.0125
[ Wed May 17 21:42:45 2023 ] 	Training Accuracy: 79.58%
[ Wed May 17 21:42:45 2023 ] Eval epoch: 12
[ Wed May 17 21:43:01 2023 ] 	Mean test loss of 120 batches: 1.1245635747909546.
[ Wed May 17 21:43:01 2023 ] 	Top1: 71.67%
[ Wed May 17 21:43:01 2023 ] 	Top5: 96.33%
[ Wed May 17 21:43:01 2023 ] Training epoch: 13
[ Wed May 17 21:43:20 2023 ] 	Batch(39/480) done. Loss: 1.1152  lr:0.100000  network_time: 0.0119
[ Wed May 17 21:44:09 2023 ] 	Batch(139/480) done. Loss: 0.2810  lr:0.100000  network_time: 0.0115
[ Wed May 17 21:44:57 2023 ] 	Batch(239/480) done. Loss: 0.2057  lr:0.100000  network_time: 0.0119
[ Wed May 17 21:45:46 2023 ] 	Batch(339/480) done. Loss: 1.8604  lr:0.100000  network_time: 0.0131
[ Wed May 17 21:46:34 2023 ] 	Batch(439/480) done. Loss: 1.4288  lr:0.100000  network_time: 0.0114
[ Wed May 17 21:46:54 2023 ] 	Training Accuracy: 79.33%
[ Wed May 17 21:46:54 2023 ] Eval epoch: 13
[ Wed May 17 21:47:10 2023 ] 	Mean test loss of 120 batches: 0.7407605051994324.
[ Wed May 17 21:47:10 2023 ] 	Top1: 77.17%
[ Wed May 17 21:47:10 2023 ] 	Top5: 98.50%
[ Wed May 17 21:47:10 2023 ] Training epoch: 14
[ Wed May 17 21:47:39 2023 ] 	Batch(59/480) done. Loss: 0.4023  lr:0.100000  network_time: 0.0110
[ Wed May 17 21:48:28 2023 ] 	Batch(159/480) done. Loss: 0.3600  lr:0.100000  network_time: 0.0111
[ Wed May 17 21:49:16 2023 ] 	Batch(259/480) done. Loss: 1.4091  lr:0.100000  network_time: 0.0113
[ Wed May 17 21:50:04 2023 ] 	Batch(359/480) done. Loss: 0.7354  lr:0.100000  network_time: 0.0115
[ Wed May 17 21:50:53 2023 ] 	Batch(459/480) done. Loss: 0.4181  lr:0.100000  network_time: 0.0120
[ Wed May 17 21:51:03 2023 ] 	Training Accuracy: 81.88%
[ Wed May 17 21:51:03 2023 ] Eval epoch: 14
[ Wed May 17 21:51:19 2023 ] 	Mean test loss of 120 batches: 0.5118926763534546.
[ Wed May 17 21:51:19 2023 ] 	Top1: 84.83%
[ Wed May 17 21:51:19 2023 ] 	Top5: 98.83%
[ Wed May 17 21:51:19 2023 ] Training epoch: 15
[ Wed May 17 21:51:58 2023 ] 	Batch(79/480) done. Loss: 0.4342  lr:0.100000  network_time: 0.0123
[ Wed May 17 21:52:46 2023 ] 	Batch(179/480) done. Loss: 0.2501  lr:0.100000  network_time: 0.0120
[ Wed May 17 21:53:35 2023 ] 	Batch(279/480) done. Loss: 0.0540  lr:0.100000  network_time: 0.0113
[ Wed May 17 21:54:23 2023 ] 	Batch(379/480) done. Loss: 0.0448  lr:0.100000  network_time: 0.0117
[ Wed May 17 21:55:12 2023 ] 	Batch(479/480) done. Loss: 0.4341  lr:0.100000  network_time: 0.0119
[ Wed May 17 21:55:12 2023 ] 	Training Accuracy: 84.04%
[ Wed May 17 21:55:12 2023 ] Eval epoch: 15
[ Wed May 17 21:55:28 2023 ] 	Mean test loss of 120 batches: 0.43978849053382874.
[ Wed May 17 21:55:28 2023 ] 	Top1: 85.17%
[ Wed May 17 21:55:28 2023 ] 	Top5: 99.67%
[ Wed May 17 21:55:28 2023 ] Training epoch: 16
[ Wed May 17 21:56:17 2023 ] 	Batch(99/480) done. Loss: 0.5119  lr:0.100000  network_time: 0.0114
[ Wed May 17 21:57:05 2023 ] 	Batch(199/480) done. Loss: 0.0497  lr:0.100000  network_time: 0.0116
[ Wed May 17 21:57:54 2023 ] 	Batch(299/480) done. Loss: 1.4602  lr:0.100000  network_time: 0.0118
[ Wed May 17 21:58:42 2023 ] 	Batch(399/480) done. Loss: 1.1429  lr:0.100000  network_time: 0.0114
[ Wed May 17 21:59:21 2023 ] 	Training Accuracy: 84.42%
[ Wed May 17 21:59:21 2023 ] Eval epoch: 16
[ Wed May 17 21:59:37 2023 ] 	Mean test loss of 120 batches: 0.49948838353157043.
[ Wed May 17 21:59:37 2023 ] 	Top1: 81.00%
[ Wed May 17 21:59:37 2023 ] 	Top5: 99.83%
[ Wed May 17 21:59:37 2023 ] Training epoch: 17
[ Wed May 17 21:59:47 2023 ] 	Batch(19/480) done. Loss: 0.0855  lr:0.100000  network_time: 0.0113
[ Wed May 17 22:00:35 2023 ] 	Batch(119/480) done. Loss: 0.2940  lr:0.100000  network_time: 0.0111
[ Wed May 17 22:01:24 2023 ] 	Batch(219/480) done. Loss: 0.1829  lr:0.100000  network_time: 0.0111
[ Wed May 17 22:02:12 2023 ] 	Batch(319/480) done. Loss: 0.1519  lr:0.100000  network_time: 0.0119
[ Wed May 17 22:03:01 2023 ] 	Batch(419/480) done. Loss: 0.1600  lr:0.100000  network_time: 0.0114
[ Wed May 17 22:03:30 2023 ] 	Training Accuracy: 85.33%
[ Wed May 17 22:03:30 2023 ] Eval epoch: 17
[ Wed May 17 22:03:46 2023 ] 	Mean test loss of 120 batches: 1.7463605403900146.
[ Wed May 17 22:03:46 2023 ] 	Top1: 60.17%
[ Wed May 17 22:03:46 2023 ] 	Top5: 94.83%
[ Wed May 17 22:03:46 2023 ] Training epoch: 18
[ Wed May 17 22:04:06 2023 ] 	Batch(39/480) done. Loss: 3.0744  lr:0.100000  network_time: 0.0113
[ Wed May 17 22:04:54 2023 ] 	Batch(139/480) done. Loss: 0.9119  lr:0.100000  network_time: 0.0114
[ Wed May 17 22:05:43 2023 ] 	Batch(239/480) done. Loss: 0.1752  lr:0.100000  network_time: 0.0113
[ Wed May 17 22:06:31 2023 ] 	Batch(339/480) done. Loss: 0.1697  lr:0.100000  network_time: 0.0121
[ Wed May 17 22:07:19 2023 ] 	Batch(439/480) done. Loss: 1.0696  lr:0.100000  network_time: 0.0114
[ Wed May 17 22:07:39 2023 ] 	Training Accuracy: 87.13%
[ Wed May 17 22:07:39 2023 ] Eval epoch: 18
[ Wed May 17 22:07:55 2023 ] 	Mean test loss of 120 batches: 0.4032091796398163.
[ Wed May 17 22:07:55 2023 ] 	Top1: 87.83%
[ Wed May 17 22:07:55 2023 ] 	Top5: 99.33%
[ Wed May 17 22:07:55 2023 ] Training epoch: 19
[ Wed May 17 22:08:24 2023 ] 	Batch(59/480) done. Loss: 0.2393  lr:0.100000  network_time: 0.0114
[ Wed May 17 22:09:13 2023 ] 	Batch(159/480) done. Loss: 0.3056  lr:0.100000  network_time: 0.0112
[ Wed May 17 22:10:01 2023 ] 	Batch(259/480) done. Loss: 0.3312  lr:0.100000  network_time: 0.0116
[ Wed May 17 22:10:50 2023 ] 	Batch(359/480) done. Loss: 0.0629  lr:0.100000  network_time: 0.0109
[ Wed May 17 22:11:38 2023 ] 	Batch(459/480) done. Loss: 0.8598  lr:0.100000  network_time: 0.0125
[ Wed May 17 22:11:48 2023 ] 	Training Accuracy: 87.79%
[ Wed May 17 22:11:48 2023 ] Eval epoch: 19
[ Wed May 17 22:12:04 2023 ] 	Mean test loss of 120 batches: 0.37275588512420654.
[ Wed May 17 22:12:04 2023 ] 	Top1: 87.00%
[ Wed May 17 22:12:04 2023 ] 	Top5: 99.67%
[ Wed May 17 22:12:04 2023 ] Training epoch: 20
[ Wed May 17 22:12:43 2023 ] 	Batch(79/480) done. Loss: 0.8652  lr:0.100000  network_time: 0.0117
[ Wed May 17 22:13:32 2023 ] 	Batch(179/480) done. Loss: 0.3929  lr:0.100000  network_time: 0.0121
[ Wed May 17 22:14:20 2023 ] 	Batch(279/480) done. Loss: 0.3205  lr:0.100000  network_time: 0.0109
[ Wed May 17 22:15:08 2023 ] 	Batch(379/480) done. Loss: 0.4359  lr:0.100000  network_time: 0.0113
[ Wed May 17 22:15:57 2023 ] 	Batch(479/480) done. Loss: 0.1782  lr:0.100000  network_time: 0.0117
[ Wed May 17 22:15:57 2023 ] 	Training Accuracy: 87.83%
[ Wed May 17 22:15:57 2023 ] Eval epoch: 20
[ Wed May 17 22:16:13 2023 ] 	Mean test loss of 120 batches: 0.4270491302013397.
[ Wed May 17 22:16:13 2023 ] 	Top1: 90.67%
[ Wed May 17 22:16:13 2023 ] 	Top5: 99.50%
[ Wed May 17 22:16:13 2023 ] Training epoch: 21
[ Wed May 17 22:17:02 2023 ] 	Batch(99/480) done. Loss: 0.0492  lr:0.010000  network_time: 0.0120
[ Wed May 17 22:17:50 2023 ] 	Batch(199/480) done. Loss: 0.2302  lr:0.010000  network_time: 0.0121
[ Wed May 17 22:18:39 2023 ] 	Batch(299/480) done. Loss: 0.4448  lr:0.010000  network_time: 0.0115
[ Wed May 17 22:19:27 2023 ] 	Batch(399/480) done. Loss: 0.0513  lr:0.010000  network_time: 0.0111
[ Wed May 17 22:20:06 2023 ] 	Training Accuracy: 95.46%
[ Wed May 17 22:20:06 2023 ] Eval epoch: 21
[ Wed May 17 22:20:22 2023 ] 	Mean test loss of 120 batches: 0.07199966162443161.
[ Wed May 17 22:20:22 2023 ] 	Top1: 98.33%
[ Wed May 17 22:20:22 2023 ] 	Top5: 100.00%
[ Wed May 17 22:20:22 2023 ] Training epoch: 22
[ Wed May 17 22:20:32 2023 ] 	Batch(19/480) done. Loss: 0.0320  lr:0.010000  network_time: 0.0114
[ Wed May 17 22:21:21 2023 ] 	Batch(119/480) done. Loss: 0.0105  lr:0.010000  network_time: 0.0115
[ Wed May 17 22:22:09 2023 ] 	Batch(219/480) done. Loss: 0.0024  lr:0.010000  network_time: 0.0112
[ Wed May 17 22:22:58 2023 ] 	Batch(319/480) done. Loss: 0.0136  lr:0.010000  network_time: 0.0114
[ Wed May 17 22:23:46 2023 ] 	Batch(419/480) done. Loss: 0.0192  lr:0.010000  network_time: 0.0117
[ Wed May 17 22:24:15 2023 ] 	Training Accuracy: 98.75%
[ Wed May 17 22:24:15 2023 ] Eval epoch: 22
[ Wed May 17 22:24:32 2023 ] 	Mean test loss of 120 batches: 0.038837313652038574.
[ Wed May 17 22:24:32 2023 ] 	Top1: 99.00%
[ Wed May 17 22:24:32 2023 ] 	Top5: 100.00%
[ Wed May 17 22:24:32 2023 ] Training epoch: 23
[ Wed May 17 22:24:51 2023 ] 	Batch(39/480) done. Loss: 0.0206  lr:0.010000  network_time: 0.0137
[ Wed May 17 22:25:39 2023 ] 	Batch(139/480) done. Loss: 0.0198  lr:0.010000  network_time: 0.0114
[ Wed May 17 22:26:28 2023 ] 	Batch(239/480) done. Loss: 0.0324  lr:0.010000  network_time: 0.0118
[ Wed May 17 22:27:16 2023 ] 	Batch(339/480) done. Loss: 0.0070  lr:0.010000  network_time: 0.0112
[ Wed May 17 22:28:05 2023 ] 	Batch(439/480) done. Loss: 0.0093  lr:0.010000  network_time: 0.0115
[ Wed May 17 22:28:24 2023 ] 	Training Accuracy: 98.75%
[ Wed May 17 22:28:24 2023 ] Eval epoch: 23
[ Wed May 17 22:28:41 2023 ] 	Mean test loss of 120 batches: 0.0248873271048069.
[ Wed May 17 22:28:41 2023 ] 	Top1: 99.50%
[ Wed May 17 22:28:41 2023 ] 	Top5: 100.00%
[ Wed May 17 22:28:41 2023 ] Training epoch: 24
[ Wed May 17 22:29:10 2023 ] 	Batch(59/480) done. Loss: 0.2020  lr:0.010000  network_time: 0.0112
[ Wed May 17 22:29:58 2023 ] 	Batch(159/480) done. Loss: 0.0100  lr:0.010000  network_time: 0.0121
[ Wed May 17 22:30:47 2023 ] 	Batch(259/480) done. Loss: 0.0118  lr:0.010000  network_time: 0.0116
[ Wed May 17 22:31:35 2023 ] 	Batch(359/480) done. Loss: 0.1413  lr:0.010000  network_time: 0.0119
[ Wed May 17 22:32:24 2023 ] 	Batch(459/480) done. Loss: 0.0546  lr:0.010000  network_time: 0.0113
[ Wed May 17 22:32:33 2023 ] 	Training Accuracy: 99.21%
[ Wed May 17 22:32:33 2023 ] Eval epoch: 24
[ Wed May 17 22:32:50 2023 ] 	Mean test loss of 120 batches: 0.020769832655787468.
[ Wed May 17 22:32:50 2023 ] 	Top1: 99.83%
[ Wed May 17 22:32:50 2023 ] 	Top5: 100.00%
[ Wed May 17 22:32:50 2023 ] Training epoch: 25
[ Wed May 17 22:33:28 2023 ] 	Batch(79/480) done. Loss: 0.0130  lr:0.010000  network_time: 0.0114
[ Wed May 17 22:34:17 2023 ] 	Batch(179/480) done. Loss: 0.0078  lr:0.010000  network_time: 0.0114
[ Wed May 17 22:35:05 2023 ] 	Batch(279/480) done. Loss: 0.0028  lr:0.010000  network_time: 0.0117
[ Wed May 17 22:35:54 2023 ] 	Batch(379/480) done. Loss: 0.0187  lr:0.010000  network_time: 0.0114
[ Wed May 17 22:36:42 2023 ] 	Batch(479/480) done. Loss: 0.0358  lr:0.010000  network_time: 0.0113
[ Wed May 17 22:36:43 2023 ] 	Training Accuracy: 99.17%
[ Wed May 17 22:36:43 2023 ] Eval epoch: 25
[ Wed May 17 22:36:59 2023 ] 	Mean test loss of 120 batches: 0.023734109476208687.
[ Wed May 17 22:36:59 2023 ] 	Top1: 99.50%
[ Wed May 17 22:36:59 2023 ] 	Top5: 100.00%
[ Wed May 17 22:36:59 2023 ] Training epoch: 26
[ Wed May 17 22:37:47 2023 ] 	Batch(99/480) done. Loss: 0.0124  lr:0.001000  network_time: 0.0117
[ Wed May 17 22:38:36 2023 ] 	Batch(199/480) done. Loss: 0.0568  lr:0.001000  network_time: 0.0121
[ Wed May 17 22:39:24 2023 ] 	Batch(299/480) done. Loss: 0.0016  lr:0.001000  network_time: 0.0124
[ Wed May 17 22:40:13 2023 ] 	Batch(399/480) done. Loss: 0.0049  lr:0.001000  network_time: 0.0117
[ Wed May 17 22:40:52 2023 ] 	Training Accuracy: 99.21%
[ Wed May 17 22:40:52 2023 ] Eval epoch: 26
[ Wed May 17 22:41:08 2023 ] 	Mean test loss of 120 batches: 0.028958046808838844.
[ Wed May 17 22:41:08 2023 ] 	Top1: 99.67%
[ Wed May 17 22:41:08 2023 ] 	Top5: 100.00%
[ Wed May 17 22:41:08 2023 ] Training epoch: 27
[ Wed May 17 22:41:18 2023 ] 	Batch(19/480) done. Loss: 0.0060  lr:0.001000  network_time: 0.0109
[ Wed May 17 22:42:06 2023 ] 	Batch(119/480) done. Loss: 0.0222  lr:0.001000  network_time: 0.0116
[ Wed May 17 22:42:55 2023 ] 	Batch(219/480) done. Loss: 0.0144  lr:0.001000  network_time: 0.0114
[ Wed May 17 22:43:43 2023 ] 	Batch(319/480) done. Loss: 0.0096  lr:0.001000  network_time: 0.0119
[ Wed May 17 22:44:32 2023 ] 	Batch(419/480) done. Loss: 0.0373  lr:0.001000  network_time: 0.0115
[ Wed May 17 22:45:01 2023 ] 	Training Accuracy: 99.54%
[ Wed May 17 22:45:01 2023 ] Eval epoch: 27
[ Wed May 17 22:45:17 2023 ] 	Mean test loss of 120 batches: 0.02172013185918331.
[ Wed May 17 22:45:17 2023 ] 	Top1: 99.83%
[ Wed May 17 22:45:17 2023 ] 	Top5: 100.00%
[ Wed May 17 22:45:17 2023 ] Training epoch: 28
[ Wed May 17 22:45:36 2023 ] 	Batch(39/480) done. Loss: 0.0152  lr:0.001000  network_time: 0.0118
[ Wed May 17 22:46:25 2023 ] 	Batch(139/480) done. Loss: 0.0046  lr:0.001000  network_time: 0.0113
[ Wed May 17 22:47:13 2023 ] 	Batch(239/480) done. Loss: 0.0115  lr:0.001000  network_time: 0.0117
[ Wed May 17 22:48:02 2023 ] 	Batch(339/480) done. Loss: 0.0270  lr:0.001000  network_time: 0.0110
[ Wed May 17 22:48:51 2023 ] 	Batch(439/480) done. Loss: 0.0160  lr:0.001000  network_time: 0.0119
[ Wed May 17 22:49:10 2023 ] 	Training Accuracy: 99.50%
[ Wed May 17 22:49:10 2023 ] Eval epoch: 28
[ Wed May 17 22:49:26 2023 ] 	Mean test loss of 120 batches: 0.016662590205669403.
[ Wed May 17 22:49:26 2023 ] 	Top1: 99.83%
[ Wed May 17 22:49:26 2023 ] 	Top5: 100.00%
[ Wed May 17 22:49:26 2023 ] Training epoch: 29
[ Wed May 17 22:49:55 2023 ] 	Batch(59/480) done. Loss: 0.0466  lr:0.001000  network_time: 0.0114
[ Wed May 17 22:50:44 2023 ] 	Batch(159/480) done. Loss: 0.0233  lr:0.001000  network_time: 0.0110
[ Wed May 17 22:51:32 2023 ] 	Batch(259/480) done. Loss: 0.0521  lr:0.001000  network_time: 0.0114
[ Wed May 17 22:52:21 2023 ] 	Batch(359/480) done. Loss: 0.0175  lr:0.001000  network_time: 0.0114
[ Wed May 17 22:53:09 2023 ] 	Batch(459/480) done. Loss: 0.0401  lr:0.001000  network_time: 0.0122
[ Wed May 17 22:53:19 2023 ] 	Training Accuracy: 99.58%
[ Wed May 17 22:53:19 2023 ] Eval epoch: 29
[ Wed May 17 22:53:35 2023 ] 	Mean test loss of 120 batches: 0.025200847536325455.
[ Wed May 17 22:53:35 2023 ] 	Top1: 99.83%
[ Wed May 17 22:53:35 2023 ] 	Top5: 100.00%
[ Wed May 17 22:53:35 2023 ] Training epoch: 30
[ Wed May 17 22:54:14 2023 ] 	Batch(79/480) done. Loss: 0.0159  lr:0.001000  network_time: 0.0111
[ Wed May 17 22:55:03 2023 ] 	Batch(179/480) done. Loss: 0.0064  lr:0.001000  network_time: 0.0117
[ Wed May 17 22:55:51 2023 ] 	Batch(279/480) done. Loss: 0.0144  lr:0.001000  network_time: 0.0112
[ Wed May 17 22:56:40 2023 ] 	Batch(379/480) done. Loss: 0.0105  lr:0.001000  network_time: 0.0113
[ Wed May 17 22:57:28 2023 ] 	Batch(479/480) done. Loss: 0.0012  lr:0.001000  network_time: 0.0111
[ Wed May 17 22:57:28 2023 ] 	Training Accuracy: 99.54%
[ Wed May 17 22:57:28 2023 ] Eval epoch: 30
[ Wed May 17 22:57:45 2023 ] 	Mean test loss of 120 batches: 0.018746111541986465.
[ Wed May 17 22:57:45 2023 ] 	Top1: 99.83%
[ Wed May 17 22:57:45 2023 ] 	Top5: 100.00%
