[ Thu May 11 16:44:36 2023 ] NUM WORKER: 1
[ Thu May 11 16:45:30 2023 ] Parameters:
{'work_dir': './work_dir/sibi_individual_inner_group_ShiftGCN_mod_4_joint_n_5_kfold_fold_3', 'model_saved_name': './save_models/sibi_individual_inner_group_ShiftGCN_mod_4_joint_n_5_kfold_fold_3', 'Experiment_name': 'sibi_individual_inner_group_ShiftGCN_mod_4_joint_n_5_kfold', 'config': './config/recalculated/train_sibi_with_mouth_augmented_individual_inner_group_shift_joint_mod_4.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 2, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'n_splits': 5, 'feeder': 'feeders.feeder_hsd.Feeder', 'num_worker': 1, 'train_feeder_args': {'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': -1, 'normalization': False}, 'test_feeder_args': None, 'data_path': './data/augmented_recalculate_normalized', 'model': 'model.shift_gcn.Model', 'model_args': {'num_class': 50, 'num_person': 1, 'num_point': 115, 'graph_group': [[0, 39], [40, 60], [61, 81], [82, 114]], 'method': 'grouped.inner', 'weight': 4, 'graph': 'graph.skeleton_with_mouth.SkeletonWithMouth', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [20, 25], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 5, 'test_batch_size': 5, 'start_epoch': 0, 'num_epoch': 30, 'folds_range': [0, 5], 'weight_decay': 0.0001, 'only_train_part': True, 'only_train_epoch': 1, 'warm_up_epoch': 0}

[ Thu May 11 16:45:30 2023 ] Training epoch: 1
[ Thu May 11 16:46:17 2023 ] 	Batch(99/480) done. Loss: 3.4695  lr:0.100000  network_time: 0.0110
[ Thu May 11 16:47:04 2023 ] 	Batch(199/480) done. Loss: 3.5970  lr:0.100000  network_time: 0.0114
[ Thu May 11 16:47:51 2023 ] 	Batch(299/480) done. Loss: 3.1822  lr:0.100000  network_time: 0.0114
[ Thu May 11 16:48:38 2023 ] 	Batch(399/480) done. Loss: 3.1034  lr:0.100000  network_time: 0.0111
[ Thu May 11 16:49:16 2023 ] 	Training Accuracy: 5.88%
[ Thu May 11 16:49:16 2023 ] Eval epoch: 1
[ Thu May 11 16:49:32 2023 ] 	Mean test loss of 120 batches: 3.919480323791504.
[ Thu May 11 16:49:32 2023 ] 	Top1: 12.50%
[ Thu May 11 16:49:32 2023 ] 	Top5: 52.50%
[ Thu May 11 16:49:32 2023 ] Training epoch: 2
[ Thu May 11 16:49:41 2023 ] 	Batch(19/480) done. Loss: 3.0448  lr:0.100000  network_time: 0.0109
[ Thu May 11 16:50:29 2023 ] 	Batch(119/480) done. Loss: 2.9218  lr:0.100000  network_time: 0.0110
[ Thu May 11 16:51:16 2023 ] 	Batch(219/480) done. Loss: 2.8665  lr:0.100000  network_time: 0.0112
[ Thu May 11 16:52:03 2023 ] 	Batch(319/480) done. Loss: 2.5708  lr:0.100000  network_time: 0.0109
[ Thu May 11 16:52:50 2023 ] 	Batch(419/480) done. Loss: 4.9237  lr:0.100000  network_time: 0.0111
[ Thu May 11 16:53:18 2023 ] 	Training Accuracy: 12.12%
[ Thu May 11 16:53:18 2023 ] Eval epoch: 2
[ Thu May 11 16:53:34 2023 ] 	Mean test loss of 120 batches: 2.754373073577881.
[ Thu May 11 16:53:34 2023 ] 	Top1: 20.17%
[ Thu May 11 16:53:34 2023 ] 	Top5: 60.17%
[ Thu May 11 16:53:34 2023 ] Training epoch: 3
[ Thu May 11 16:53:53 2023 ] 	Batch(39/480) done. Loss: 2.3782  lr:0.100000  network_time: 0.0110
[ Thu May 11 16:54:40 2023 ] 	Batch(139/480) done. Loss: 3.0087  lr:0.100000  network_time: 0.0116
[ Thu May 11 16:55:27 2023 ] 	Batch(239/480) done. Loss: 2.7116  lr:0.100000  network_time: 0.0119
[ Thu May 11 16:56:14 2023 ] 	Batch(339/480) done. Loss: 2.7077  lr:0.100000  network_time: 0.0111
[ Thu May 11 16:57:01 2023 ] 	Batch(439/480) done. Loss: 2.7084  lr:0.100000  network_time: 0.0119
[ Thu May 11 16:57:20 2023 ] 	Training Accuracy: 20.50%
[ Thu May 11 16:57:20 2023 ] Eval epoch: 3
[ Thu May 11 16:57:36 2023 ] 	Mean test loss of 120 batches: 3.1794309616088867.
[ Thu May 11 16:57:36 2023 ] 	Top1: 29.17%
[ Thu May 11 16:57:36 2023 ] 	Top5: 73.00%
[ Thu May 11 16:57:36 2023 ] Training epoch: 4
[ Thu May 11 16:58:05 2023 ] 	Batch(59/480) done. Loss: 2.5378  lr:0.100000  network_time: 0.0110
[ Thu May 11 16:58:52 2023 ] 	Batch(159/480) done. Loss: 2.6028  lr:0.100000  network_time: 0.0111
[ Thu May 11 16:59:39 2023 ] 	Batch(259/480) done. Loss: 1.9820  lr:0.100000  network_time: 0.0117
[ Thu May 11 17:00:26 2023 ] 	Batch(359/480) done. Loss: 2.6776  lr:0.100000  network_time: 0.0115
[ Thu May 11 17:01:13 2023 ] 	Batch(459/480) done. Loss: 2.2040  lr:0.100000  network_time: 0.0109
[ Thu May 11 17:01:22 2023 ] 	Training Accuracy: 28.04%
[ Thu May 11 17:01:22 2023 ] Eval epoch: 4
[ Thu May 11 17:01:39 2023 ] 	Mean test loss of 120 batches: 1.8056389093399048.
[ Thu May 11 17:01:39 2023 ] 	Top1: 43.67%
[ Thu May 11 17:01:39 2023 ] 	Top5: 84.83%
[ Thu May 11 17:01:39 2023 ] Training epoch: 5
[ Thu May 11 17:02:16 2023 ] 	Batch(79/480) done. Loss: 2.6872  lr:0.100000  network_time: 0.0116
[ Thu May 11 17:03:04 2023 ] 	Batch(179/480) done. Loss: 1.3561  lr:0.100000  network_time: 0.0115
[ Thu May 11 17:03:51 2023 ] 	Batch(279/480) done. Loss: 1.9764  lr:0.100000  network_time: 0.0114
[ Thu May 11 17:04:38 2023 ] 	Batch(379/480) done. Loss: 1.4736  lr:0.100000  network_time: 0.0112
[ Thu May 11 17:05:25 2023 ] 	Batch(479/480) done. Loss: 0.9643  lr:0.100000  network_time: 0.0121
[ Thu May 11 17:05:25 2023 ] 	Training Accuracy: 38.21%
[ Thu May 11 17:05:25 2023 ] Eval epoch: 5
[ Thu May 11 17:05:41 2023 ] 	Mean test loss of 120 batches: 1.7843645811080933.
[ Thu May 11 17:05:41 2023 ] 	Top1: 44.83%
[ Thu May 11 17:05:41 2023 ] 	Top5: 91.67%
[ Thu May 11 17:05:41 2023 ] Training epoch: 6
[ Thu May 11 17:06:28 2023 ] 	Batch(99/480) done. Loss: 1.2079  lr:0.100000  network_time: 0.0115
[ Thu May 11 17:07:16 2023 ] 	Batch(199/480) done. Loss: 1.1787  lr:0.100000  network_time: 0.0116
[ Thu May 11 17:08:03 2023 ] 	Batch(299/480) done. Loss: 1.1699  lr:0.100000  network_time: 0.0117
[ Thu May 11 17:08:50 2023 ] 	Batch(399/480) done. Loss: 0.9566  lr:0.100000  network_time: 0.0114
[ Thu May 11 17:09:27 2023 ] 	Training Accuracy: 50.17%
[ Thu May 11 17:09:28 2023 ] Eval epoch: 6
[ Thu May 11 17:09:44 2023 ] 	Mean test loss of 120 batches: 1.8153071403503418.
[ Thu May 11 17:09:44 2023 ] 	Top1: 45.67%
[ Thu May 11 17:09:44 2023 ] 	Top5: 88.67%
[ Thu May 11 17:09:44 2023 ] Training epoch: 7
[ Thu May 11 17:09:53 2023 ] 	Batch(19/480) done. Loss: 0.8593  lr:0.100000  network_time: 0.0111
[ Thu May 11 17:10:40 2023 ] 	Batch(119/480) done. Loss: 0.8294  lr:0.100000  network_time: 0.0108
[ Thu May 11 17:11:28 2023 ] 	Batch(219/480) done. Loss: 1.1635  lr:0.100000  network_time: 0.0117
[ Thu May 11 17:12:15 2023 ] 	Batch(319/480) done. Loss: 2.5169  lr:0.100000  network_time: 0.0112
[ Thu May 11 17:13:02 2023 ] 	Batch(419/480) done. Loss: 2.3715  lr:0.100000  network_time: 0.0117
[ Thu May 11 17:13:30 2023 ] 	Training Accuracy: 58.33%
[ Thu May 11 17:13:30 2023 ] Eval epoch: 7
[ Thu May 11 17:13:46 2023 ] 	Mean test loss of 120 batches: 1.2757407426834106.
[ Thu May 11 17:13:46 2023 ] 	Top1: 68.67%
[ Thu May 11 17:13:46 2023 ] 	Top5: 96.33%
[ Thu May 11 17:13:46 2023 ] Training epoch: 8
[ Thu May 11 17:14:05 2023 ] 	Batch(39/480) done. Loss: 1.1675  lr:0.100000  network_time: 0.0113
[ Thu May 11 17:14:52 2023 ] 	Batch(139/480) done. Loss: 0.9073  lr:0.100000  network_time: 0.0115
[ Thu May 11 17:15:39 2023 ] 	Batch(239/480) done. Loss: 1.0077  lr:0.100000  network_time: 0.0113
[ Thu May 11 17:16:27 2023 ] 	Batch(339/480) done. Loss: 1.0574  lr:0.100000  network_time: 0.0114
[ Thu May 11 17:17:14 2023 ] 	Batch(439/480) done. Loss: 0.9006  lr:0.100000  network_time: 0.0116
[ Thu May 11 17:17:33 2023 ] 	Training Accuracy: 64.12%
[ Thu May 11 17:17:33 2023 ] Eval epoch: 8
[ Thu May 11 17:17:49 2023 ] 	Mean test loss of 120 batches: 1.740234136581421.
[ Thu May 11 17:17:49 2023 ] 	Top1: 63.50%
[ Thu May 11 17:17:49 2023 ] 	Top5: 96.50%
[ Thu May 11 17:17:49 2023 ] Training epoch: 9
[ Thu May 11 17:18:17 2023 ] 	Batch(59/480) done. Loss: 1.3798  lr:0.100000  network_time: 0.0114
[ Thu May 11 17:19:04 2023 ] 	Batch(159/480) done. Loss: 0.8530  lr:0.100000  network_time: 0.0117
[ Thu May 11 17:19:51 2023 ] 	Batch(259/480) done. Loss: 0.4689  lr:0.100000  network_time: 0.0118
[ Thu May 11 17:20:39 2023 ] 	Batch(359/480) done. Loss: 1.4845  lr:0.100000  network_time: 0.0111
[ Thu May 11 17:21:26 2023 ] 	Batch(459/480) done. Loss: 0.8015  lr:0.100000  network_time: 0.0120
[ Thu May 11 17:21:35 2023 ] 	Training Accuracy: 70.08%
[ Thu May 11 17:21:35 2023 ] Eval epoch: 9
[ Thu May 11 17:21:52 2023 ] 	Mean test loss of 120 batches: 1.2814557552337646.
[ Thu May 11 17:21:52 2023 ] 	Top1: 72.50%
[ Thu May 11 17:21:52 2023 ] 	Top5: 95.67%
[ Thu May 11 17:21:52 2023 ] Training epoch: 10
[ Thu May 11 17:22:29 2023 ] 	Batch(79/480) done. Loss: 0.4006  lr:0.100000  network_time: 0.0109
[ Thu May 11 17:23:16 2023 ] 	Batch(179/480) done. Loss: 1.5807  lr:0.100000  network_time: 0.0110
[ Thu May 11 17:24:04 2023 ] 	Batch(279/480) done. Loss: 0.8132  lr:0.100000  network_time: 0.0109
[ Thu May 11 17:24:51 2023 ] 	Batch(379/480) done. Loss: 0.5903  lr:0.100000  network_time: 0.0127
[ Thu May 11 17:25:38 2023 ] 	Batch(479/480) done. Loss: 0.6880  lr:0.100000  network_time: 0.0112
[ Thu May 11 17:25:38 2023 ] 	Training Accuracy: 75.12%
[ Thu May 11 17:25:38 2023 ] Eval epoch: 10
[ Thu May 11 17:25:54 2023 ] 	Mean test loss of 120 batches: 0.8147604465484619.
[ Thu May 11 17:25:54 2023 ] 	Top1: 75.50%
[ Thu May 11 17:25:54 2023 ] 	Top5: 98.83%
[ Thu May 11 17:25:54 2023 ] Training epoch: 11
[ Thu May 11 17:26:41 2023 ] 	Batch(99/480) done. Loss: 1.1469  lr:0.100000  network_time: 0.0111
[ Thu May 11 17:27:28 2023 ] 	Batch(199/480) done. Loss: 0.9143  lr:0.100000  network_time: 0.0108
[ Thu May 11 17:28:16 2023 ] 	Batch(299/480) done. Loss: 0.2610  lr:0.100000  network_time: 0.0108
[ Thu May 11 17:29:03 2023 ] 	Batch(399/480) done. Loss: 1.1491  lr:0.100000  network_time: 0.0110
[ Thu May 11 17:29:41 2023 ] 	Training Accuracy: 77.25%
[ Thu May 11 17:29:41 2023 ] Eval epoch: 11
[ Thu May 11 17:29:57 2023 ] 	Mean test loss of 120 batches: 0.7656015753746033.
[ Thu May 11 17:29:57 2023 ] 	Top1: 81.67%
[ Thu May 11 17:29:57 2023 ] 	Top5: 98.50%
[ Thu May 11 17:29:57 2023 ] Training epoch: 12
[ Thu May 11 17:30:06 2023 ] 	Batch(19/480) done. Loss: 0.4340  lr:0.100000  network_time: 0.0110
[ Thu May 11 17:30:53 2023 ] 	Batch(119/480) done. Loss: 0.3192  lr:0.100000  network_time: 0.0116
[ Thu May 11 17:31:41 2023 ] 	Batch(219/480) done. Loss: 0.5368  lr:0.100000  network_time: 0.0112
[ Thu May 11 17:32:28 2023 ] 	Batch(319/480) done. Loss: 0.6367  lr:0.100000  network_time: 0.0106
[ Thu May 11 17:33:15 2023 ] 	Batch(419/480) done. Loss: 0.3406  lr:0.100000  network_time: 0.0112
[ Thu May 11 17:33:43 2023 ] 	Training Accuracy: 80.46%
[ Thu May 11 17:33:43 2023 ] Eval epoch: 12
[ Thu May 11 17:33:59 2023 ] 	Mean test loss of 120 batches: 0.43216976523399353.
[ Thu May 11 17:33:59 2023 ] 	Top1: 85.50%
[ Thu May 11 17:33:59 2023 ] 	Top5: 99.17%
[ Thu May 11 17:33:59 2023 ] Training epoch: 13
[ Thu May 11 17:34:18 2023 ] 	Batch(39/480) done. Loss: 0.0625  lr:0.100000  network_time: 0.0117
[ Thu May 11 17:35:05 2023 ] 	Batch(139/480) done. Loss: 0.6759  lr:0.100000  network_time: 0.0120
[ Thu May 11 17:35:52 2023 ] 	Batch(239/480) done. Loss: 0.3174  lr:0.100000  network_time: 0.0120
[ Thu May 11 17:36:40 2023 ] 	Batch(339/480) done. Loss: 0.5831  lr:0.100000  network_time: 0.0113
[ Thu May 11 17:37:27 2023 ] 	Batch(439/480) done. Loss: 0.4174  lr:0.100000  network_time: 0.0113
[ Thu May 11 17:37:46 2023 ] 	Training Accuracy: 79.54%
[ Thu May 11 17:37:46 2023 ] Eval epoch: 13
[ Thu May 11 17:38:02 2023 ] 	Mean test loss of 120 batches: 0.4356796443462372.
[ Thu May 11 17:38:02 2023 ] 	Top1: 85.67%
[ Thu May 11 17:38:02 2023 ] 	Top5: 98.83%
[ Thu May 11 17:38:02 2023 ] Training epoch: 14
[ Thu May 11 17:38:30 2023 ] 	Batch(59/480) done. Loss: 0.5168  lr:0.100000  network_time: 0.0112
[ Thu May 11 17:39:18 2023 ] 	Batch(159/480) done. Loss: 0.4609  lr:0.100000  network_time: 0.0110
[ Thu May 11 17:40:05 2023 ] 	Batch(259/480) done. Loss: 0.1753  lr:0.100000  network_time: 0.0123
[ Thu May 11 17:40:52 2023 ] 	Batch(359/480) done. Loss: 0.3096  lr:0.100000  network_time: 0.0106
[ Thu May 11 17:41:39 2023 ] 	Batch(459/480) done. Loss: 0.1317  lr:0.100000  network_time: 0.0110
[ Thu May 11 17:41:48 2023 ] 	Training Accuracy: 82.79%
[ Thu May 11 17:41:48 2023 ] Eval epoch: 14
[ Thu May 11 17:42:05 2023 ] 	Mean test loss of 120 batches: 0.3751276731491089.
[ Thu May 11 17:42:05 2023 ] 	Top1: 86.00%
[ Thu May 11 17:42:05 2023 ] 	Top5: 99.00%
[ Thu May 11 17:42:05 2023 ] Training epoch: 15
[ Thu May 11 17:42:42 2023 ] 	Batch(79/480) done. Loss: 0.6536  lr:0.100000  network_time: 0.0107
[ Thu May 11 17:43:30 2023 ] 	Batch(179/480) done. Loss: 0.5580  lr:0.100000  network_time: 0.0113
[ Thu May 11 17:44:17 2023 ] 	Batch(279/480) done. Loss: 1.0848  lr:0.100000  network_time: 0.0108
[ Thu May 11 17:45:04 2023 ] 	Batch(379/480) done. Loss: 0.3007  lr:0.100000  network_time: 0.0111
[ Thu May 11 17:45:51 2023 ] 	Batch(479/480) done. Loss: 0.0839  lr:0.100000  network_time: 0.0113
[ Thu May 11 17:45:51 2023 ] 	Training Accuracy: 85.42%
[ Thu May 11 17:45:51 2023 ] Eval epoch: 15
[ Thu May 11 17:46:07 2023 ] 	Mean test loss of 120 batches: 0.2262386977672577.
[ Thu May 11 17:46:07 2023 ] 	Top1: 93.17%
[ Thu May 11 17:46:07 2023 ] 	Top5: 99.67%
[ Thu May 11 17:46:07 2023 ] Training epoch: 16
[ Thu May 11 17:46:55 2023 ] 	Batch(99/480) done. Loss: 0.0720  lr:0.100000  network_time: 0.0108
[ Thu May 11 17:47:42 2023 ] 	Batch(199/480) done. Loss: 0.5132  lr:0.100000  network_time: 0.0107
[ Thu May 11 17:48:29 2023 ] 	Batch(299/480) done. Loss: 1.1285  lr:0.100000  network_time: 0.0106
[ Thu May 11 17:49:16 2023 ] 	Batch(399/480) done. Loss: 0.8252  lr:0.100000  network_time: 0.0110
[ Thu May 11 17:49:54 2023 ] 	Training Accuracy: 84.71%
[ Thu May 11 17:49:54 2023 ] Eval epoch: 16
[ Thu May 11 17:50:10 2023 ] 	Mean test loss of 120 batches: 0.7539742588996887.
[ Thu May 11 17:50:10 2023 ] 	Top1: 79.83%
[ Thu May 11 17:50:10 2023 ] 	Top5: 99.33%
[ Thu May 11 17:50:10 2023 ] Training epoch: 17
[ Thu May 11 17:50:20 2023 ] 	Batch(19/480) done. Loss: 0.2902  lr:0.100000  network_time: 0.0108
[ Thu May 11 17:51:07 2023 ] 	Batch(119/480) done. Loss: 1.0017  lr:0.100000  network_time: 0.0113
[ Thu May 11 17:51:54 2023 ] 	Batch(219/480) done. Loss: 0.3725  lr:0.100000  network_time: 0.0109
[ Thu May 11 17:52:41 2023 ] 	Batch(319/480) done. Loss: 0.4335  lr:0.100000  network_time: 0.0115
[ Thu May 11 17:53:28 2023 ] 	Batch(419/480) done. Loss: 0.5250  lr:0.100000  network_time: 0.0109
[ Thu May 11 17:53:57 2023 ] 	Training Accuracy: 84.83%
[ Thu May 11 17:53:57 2023 ] Eval epoch: 17
[ Thu May 11 17:54:13 2023 ] 	Mean test loss of 120 batches: 0.5663872957229614.
[ Thu May 11 17:54:13 2023 ] 	Top1: 87.33%
[ Thu May 11 17:54:13 2023 ] 	Top5: 99.33%
[ Thu May 11 17:54:13 2023 ] Training epoch: 18
[ Thu May 11 17:54:32 2023 ] 	Batch(39/480) done. Loss: 0.3996  lr:0.100000  network_time: 0.0111
[ Thu May 11 17:55:19 2023 ] 	Batch(139/480) done. Loss: 0.2398  lr:0.100000  network_time: 0.0108
[ Thu May 11 17:56:06 2023 ] 	Batch(239/480) done. Loss: 0.1556  lr:0.100000  network_time: 0.0109
[ Thu May 11 17:56:53 2023 ] 	Batch(339/480) done. Loss: 0.2822  lr:0.100000  network_time: 0.0104
[ Thu May 11 17:57:40 2023 ] 	Batch(439/480) done. Loss: 0.6996  lr:0.100000  network_time: 0.0108
[ Thu May 11 17:57:59 2023 ] 	Training Accuracy: 87.54%
[ Thu May 11 17:57:59 2023 ] Eval epoch: 18
[ Thu May 11 17:58:16 2023 ] 	Mean test loss of 120 batches: 0.4773421883583069.
[ Thu May 11 17:58:16 2023 ] 	Top1: 88.00%
[ Thu May 11 17:58:16 2023 ] 	Top5: 99.50%
[ Thu May 11 17:58:16 2023 ] Training epoch: 19
[ Thu May 11 17:58:44 2023 ] 	Batch(59/480) done. Loss: 0.0252  lr:0.100000  network_time: 0.0110
[ Thu May 11 17:59:31 2023 ] 	Batch(159/480) done. Loss: 0.2573  lr:0.100000  network_time: 0.0107
[ Thu May 11 18:00:18 2023 ] 	Batch(259/480) done. Loss: 0.5119  lr:0.100000  network_time: 0.0108
[ Thu May 11 18:01:05 2023 ] 	Batch(359/480) done. Loss: 1.1556  lr:0.100000  network_time: 0.0109
[ Thu May 11 18:01:53 2023 ] 	Batch(459/480) done. Loss: 0.0261  lr:0.100000  network_time: 0.0110
[ Thu May 11 18:02:02 2023 ] 	Training Accuracy: 87.13%
[ Thu May 11 18:02:02 2023 ] Eval epoch: 19
[ Thu May 11 18:02:18 2023 ] 	Mean test loss of 120 batches: 0.5193018913269043.
[ Thu May 11 18:02:18 2023 ] 	Top1: 87.33%
[ Thu May 11 18:02:18 2023 ] 	Top5: 98.50%
[ Thu May 11 18:02:18 2023 ] Training epoch: 20
[ Thu May 11 18:02:56 2023 ] 	Batch(79/480) done. Loss: 0.5848  lr:0.100000  network_time: 0.0119
[ Thu May 11 18:03:43 2023 ] 	Batch(179/480) done. Loss: 0.0892  lr:0.100000  network_time: 0.0122
[ Thu May 11 18:04:31 2023 ] 	Batch(279/480) done. Loss: 0.5080  lr:0.100000  network_time: 0.0117
[ Thu May 11 18:05:18 2023 ] 	Batch(379/480) done. Loss: 0.2264  lr:0.100000  network_time: 0.0112
[ Thu May 11 18:06:05 2023 ] 	Batch(479/480) done. Loss: 0.3206  lr:0.100000  network_time: 0.0121
[ Thu May 11 18:06:05 2023 ] 	Training Accuracy: 88.88%
[ Thu May 11 18:06:05 2023 ] Eval epoch: 20
[ Thu May 11 18:06:21 2023 ] 	Mean test loss of 120 batches: 0.43213939666748047.
[ Thu May 11 18:06:21 2023 ] 	Top1: 88.83%
[ Thu May 11 18:06:21 2023 ] 	Top5: 99.33%
[ Thu May 11 18:06:21 2023 ] Training epoch: 21
[ Thu May 11 18:07:09 2023 ] 	Batch(99/480) done. Loss: 0.5407  lr:0.010000  network_time: 0.0118
[ Thu May 11 18:07:56 2023 ] 	Batch(199/480) done. Loss: 0.3855  lr:0.010000  network_time: 0.0111
[ Thu May 11 18:08:43 2023 ] 	Batch(299/480) done. Loss: 0.0733  lr:0.010000  network_time: 0.0107
[ Thu May 11 18:09:30 2023 ] 	Batch(399/480) done. Loss: 0.2074  lr:0.010000  network_time: 0.0110
[ Thu May 11 18:10:08 2023 ] 	Training Accuracy: 97.12%
[ Thu May 11 18:10:08 2023 ] Eval epoch: 21
[ Thu May 11 18:10:24 2023 ] 	Mean test loss of 120 batches: 0.06353196501731873.
[ Thu May 11 18:10:24 2023 ] 	Top1: 98.67%
[ Thu May 11 18:10:24 2023 ] 	Top5: 100.00%
[ Thu May 11 18:10:24 2023 ] Training epoch: 22
[ Thu May 11 18:10:34 2023 ] 	Batch(19/480) done. Loss: 0.0453  lr:0.010000  network_time: 0.0106
[ Thu May 11 18:11:21 2023 ] 	Batch(119/480) done. Loss: 0.1725  lr:0.010000  network_time: 0.0113
[ Thu May 11 18:12:08 2023 ] 	Batch(219/480) done. Loss: 0.4005  lr:0.010000  network_time: 0.0109
[ Thu May 11 18:12:55 2023 ] 	Batch(319/480) done. Loss: 0.0230  lr:0.010000  network_time: 0.0109
[ Thu May 11 18:13:42 2023 ] 	Batch(419/480) done. Loss: 0.0215  lr:0.010000  network_time: 0.0107
[ Thu May 11 18:14:11 2023 ] 	Training Accuracy: 98.21%
[ Thu May 11 18:14:11 2023 ] Eval epoch: 22
[ Thu May 11 18:14:27 2023 ] 	Mean test loss of 120 batches: 0.22099503874778748.
[ Thu May 11 18:14:27 2023 ] 	Top1: 98.33%
[ Thu May 11 18:14:27 2023 ] 	Top5: 99.83%
[ Thu May 11 18:14:27 2023 ] Training epoch: 23
[ Thu May 11 18:14:46 2023 ] 	Batch(39/480) done. Loss: 0.0228  lr:0.010000  network_time: 0.0115
[ Thu May 11 18:15:33 2023 ] 	Batch(139/480) done. Loss: 0.0059  lr:0.010000  network_time: 0.0115
[ Thu May 11 18:16:20 2023 ] 	Batch(239/480) done. Loss: 0.0027  lr:0.010000  network_time: 0.0108
[ Thu May 11 18:17:08 2023 ] 	Batch(339/480) done. Loss: 0.0176  lr:0.010000  network_time: 0.0109
[ Thu May 11 18:17:55 2023 ] 	Batch(439/480) done. Loss: 0.0026  lr:0.010000  network_time: 0.0117
[ Thu May 11 18:18:14 2023 ] 	Training Accuracy: 98.79%
[ Thu May 11 18:18:14 2023 ] Eval epoch: 23
[ Thu May 11 18:18:30 2023 ] 	Mean test loss of 120 batches: 0.03019467554986477.
[ Thu May 11 18:18:30 2023 ] 	Top1: 99.67%
[ Thu May 11 18:18:30 2023 ] 	Top5: 100.00%
[ Thu May 11 18:18:30 2023 ] Training epoch: 24
[ Thu May 11 18:18:58 2023 ] 	Batch(59/480) done. Loss: 0.0474  lr:0.010000  network_time: 0.0109
[ Thu May 11 18:19:46 2023 ] 	Batch(159/480) done. Loss: 0.0181  lr:0.010000  network_time: 0.0113
[ Thu May 11 18:20:33 2023 ] 	Batch(259/480) done. Loss: 0.0162  lr:0.010000  network_time: 0.0106
[ Thu May 11 18:21:20 2023 ] 	Batch(359/480) done. Loss: 0.1092  lr:0.010000  network_time: 0.0109
[ Thu May 11 18:22:07 2023 ] 	Batch(459/480) done. Loss: 0.0168  lr:0.010000  network_time: 0.0107
[ Thu May 11 18:22:16 2023 ] 	Training Accuracy: 99.29%
[ Thu May 11 18:22:17 2023 ] Eval epoch: 24
[ Thu May 11 18:22:33 2023 ] 	Mean test loss of 120 batches: 0.030109073966741562.
[ Thu May 11 18:22:33 2023 ] 	Top1: 99.33%
[ Thu May 11 18:22:33 2023 ] 	Top5: 100.00%
[ Thu May 11 18:22:33 2023 ] Training epoch: 25
[ Thu May 11 18:23:11 2023 ] 	Batch(79/480) done. Loss: 0.0221  lr:0.010000  network_time: 0.0108
[ Thu May 11 18:23:58 2023 ] 	Batch(179/480) done. Loss: 0.0190  lr:0.010000  network_time: 0.0106
[ Thu May 11 18:24:45 2023 ] 	Batch(279/480) done. Loss: 0.0047  lr:0.010000  network_time: 0.0108
[ Thu May 11 18:25:32 2023 ] 	Batch(379/480) done. Loss: 0.0108  lr:0.010000  network_time: 0.0109
[ Thu May 11 18:26:19 2023 ] 	Batch(479/480) done. Loss: 0.1150  lr:0.010000  network_time: 0.0109
[ Thu May 11 18:26:19 2023 ] 	Training Accuracy: 99.17%
[ Thu May 11 18:26:19 2023 ] Eval epoch: 25
[ Thu May 11 18:26:36 2023 ] 	Mean test loss of 120 batches: 0.02346223220229149.
[ Thu May 11 18:26:36 2023 ] 	Top1: 99.50%
[ Thu May 11 18:26:36 2023 ] 	Top5: 100.00%
[ Thu May 11 18:26:36 2023 ] Training epoch: 26
[ Thu May 11 18:27:23 2023 ] 	Batch(99/480) done. Loss: 0.0170  lr:0.001000  network_time: 0.0113
[ Thu May 11 18:28:10 2023 ] 	Batch(199/480) done. Loss: 0.0172  lr:0.001000  network_time: 0.0109
[ Thu May 11 18:28:57 2023 ] 	Batch(299/480) done. Loss: 0.0118  lr:0.001000  network_time: 0.0118
[ Thu May 11 18:29:44 2023 ] 	Batch(399/480) done. Loss: 0.0749  lr:0.001000  network_time: 0.0108
[ Thu May 11 18:30:22 2023 ] 	Training Accuracy: 99.21%
[ Thu May 11 18:30:22 2023 ] Eval epoch: 26
[ Thu May 11 18:30:39 2023 ] 	Mean test loss of 120 batches: 0.03117603063583374.
[ Thu May 11 18:30:39 2023 ] 	Top1: 99.33%
[ Thu May 11 18:30:39 2023 ] 	Top5: 100.00%
[ Thu May 11 18:30:39 2023 ] Training epoch: 27
[ Thu May 11 18:30:48 2023 ] 	Batch(19/480) done. Loss: 0.0133  lr:0.001000  network_time: 0.0109
[ Thu May 11 18:31:35 2023 ] 	Batch(119/480) done. Loss: 0.0213  lr:0.001000  network_time: 0.0110
[ Thu May 11 18:32:22 2023 ] 	Batch(219/480) done. Loss: 0.0050  lr:0.001000  network_time: 0.0109
[ Thu May 11 18:33:10 2023 ] 	Batch(319/480) done. Loss: 0.1009  lr:0.001000  network_time: 0.0115
[ Thu May 11 18:33:57 2023 ] 	Batch(419/480) done. Loss: 0.0111  lr:0.001000  network_time: 0.0115
[ Thu May 11 18:34:25 2023 ] 	Training Accuracy: 99.62%
[ Thu May 11 18:34:25 2023 ] Eval epoch: 27
[ Thu May 11 18:34:42 2023 ] 	Mean test loss of 120 batches: 0.015848906710743904.
[ Thu May 11 18:34:42 2023 ] 	Top1: 99.83%
[ Thu May 11 18:34:42 2023 ] 	Top5: 100.00%
[ Thu May 11 18:34:42 2023 ] Training epoch: 28
[ Thu May 11 18:35:00 2023 ] 	Batch(39/480) done. Loss: 0.0272  lr:0.001000  network_time: 0.0109
[ Thu May 11 18:35:48 2023 ] 	Batch(139/480) done. Loss: 0.0072  lr:0.001000  network_time: 0.0109
[ Thu May 11 18:36:35 2023 ] 	Batch(239/480) done. Loss: 0.0156  lr:0.001000  network_time: 0.0112
[ Thu May 11 18:37:22 2023 ] 	Batch(339/480) done. Loss: 0.0818  lr:0.001000  network_time: 0.0110
[ Thu May 11 18:38:09 2023 ] 	Batch(439/480) done. Loss: 0.0459  lr:0.001000  network_time: 0.0108
[ Thu May 11 18:38:28 2023 ] 	Training Accuracy: 99.38%
[ Thu May 11 18:38:28 2023 ] Eval epoch: 28
[ Thu May 11 18:38:44 2023 ] 	Mean test loss of 120 batches: 0.053345147520303726.
[ Thu May 11 18:38:44 2023 ] 	Top1: 98.83%
[ Thu May 11 18:38:44 2023 ] 	Top5: 100.00%
[ Thu May 11 18:38:44 2023 ] Training epoch: 29
[ Thu May 11 18:39:13 2023 ] 	Batch(59/480) done. Loss: 0.0509  lr:0.001000  network_time: 0.0109
[ Thu May 11 18:40:00 2023 ] 	Batch(159/480) done. Loss: 0.1175  lr:0.001000  network_time: 0.0111
[ Thu May 11 18:40:47 2023 ] 	Batch(259/480) done. Loss: 0.0836  lr:0.001000  network_time: 0.0111
[ Thu May 11 18:41:34 2023 ] 	Batch(359/480) done. Loss: 0.0092  lr:0.001000  network_time: 0.0110
[ Thu May 11 18:42:21 2023 ] 	Batch(459/480) done. Loss: 0.0074  lr:0.001000  network_time: 0.0110
[ Thu May 11 18:42:31 2023 ] 	Training Accuracy: 99.37%
[ Thu May 11 18:42:31 2023 ] Eval epoch: 29
[ Thu May 11 18:42:47 2023 ] 	Mean test loss of 120 batches: 0.020858410745859146.
[ Thu May 11 18:42:47 2023 ] 	Top1: 99.67%
[ Thu May 11 18:42:47 2023 ] 	Top5: 100.00%
[ Thu May 11 18:42:47 2023 ] Training epoch: 30
[ Thu May 11 18:43:25 2023 ] 	Batch(79/480) done. Loss: 0.0147  lr:0.001000  network_time: 0.0113
[ Thu May 11 18:44:12 2023 ] 	Batch(179/480) done. Loss: 0.0734  lr:0.001000  network_time: 0.0116
[ Thu May 11 18:44:59 2023 ] 	Batch(279/480) done. Loss: 0.0642  lr:0.001000  network_time: 0.0115
[ Thu May 11 18:45:46 2023 ] 	Batch(379/480) done. Loss: 0.0906  lr:0.001000  network_time: 0.0110
[ Thu May 11 18:46:33 2023 ] 	Batch(479/480) done. Loss: 0.0262  lr:0.001000  network_time: 0.0112
[ Thu May 11 18:46:33 2023 ] 	Training Accuracy: 99.21%
[ Thu May 11 18:46:34 2023 ] Eval epoch: 30
[ Thu May 11 18:46:50 2023 ] 	Mean test loss of 120 batches: 0.019281361252069473.
[ Thu May 11 18:46:50 2023 ] 	Top1: 99.50%
[ Thu May 11 18:46:50 2023 ] 	Top5: 100.00%
