[ Mon May 15 08:42:20 2023 ] NUM WORKER: 1
[ Mon May 15 08:43:13 2023 ] Parameters:
{'work_dir': './work_dir/sibi_merged_inner_group_ShiftGCN_mod_3_joint_n_5_kfold_fold_1', 'model_saved_name': './save_models/sibi_merged_inner_group_ShiftGCN_mod_3_joint_n_5_kfold_fold_1', 'Experiment_name': 'sibi_merged_inner_group_ShiftGCN_mod_3_joint_n_5_kfold', 'config': './config/recalculated/train_sibi_with_mouth_augmented_merged_inner_group_shift_joint_mod_3.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 2, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'n_splits': 5, 'feeder': 'feeders.feeder_hsd.Feeder', 'num_worker': 1, 'train_feeder_args': {'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': -1, 'normalization': False}, 'test_feeder_args': None, 'data_path': './data/augmented_recalculate_normalized', 'model': 'model.shift_gcn.Model', 'model_args': {'num_class': 50, 'num_person': 1, 'num_point': 115, 'graph_group': [[0, 81], [82, 114]], 'method': 'grouped.inner', 'weight': 3, 'graph': 'graph.skeleton_with_mouth.SkeletonWithMouth', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [20, 25], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 5, 'test_batch_size': 5, 'start_epoch': 0, 'num_epoch': 30, 'folds_range': [0, 5], 'weight_decay': 0.0001, 'only_train_part': True, 'only_train_epoch': 1, 'warm_up_epoch': 0}

[ Mon May 15 08:43:13 2023 ] Training epoch: 1
[ Mon May 15 08:44:04 2023 ] 	Batch(99/480) done. Loss: 3.8329  lr:0.100000  network_time: 0.0110
[ Mon May 15 08:44:53 2023 ] 	Batch(199/480) done. Loss: 3.4488  lr:0.100000  network_time: 0.0110
[ Mon May 15 08:45:43 2023 ] 	Batch(299/480) done. Loss: 3.4235  lr:0.100000  network_time: 0.0122
[ Mon May 15 08:46:32 2023 ] 	Batch(399/480) done. Loss: 4.0381  lr:0.100000  network_time: 0.0106
[ Mon May 15 08:47:12 2023 ] 	Training Accuracy: 5.00%
[ Mon May 15 08:47:12 2023 ] Eval epoch: 1
[ Mon May 15 08:47:29 2023 ] 	Mean test loss of 120 batches: 3.519169569015503.
[ Mon May 15 08:47:29 2023 ] 	Top1: 7.00%
[ Mon May 15 08:47:29 2023 ] 	Top5: 31.33%
[ Mon May 15 08:47:29 2023 ] Training epoch: 2
[ Mon May 15 08:47:39 2023 ] 	Batch(19/480) done. Loss: 3.2531  lr:0.100000  network_time: 0.0113
[ Mon May 15 08:48:28 2023 ] 	Batch(119/480) done. Loss: 3.7751  lr:0.100000  network_time: 0.0107
[ Mon May 15 08:49:18 2023 ] 	Batch(219/480) done. Loss: 3.0194  lr:0.100000  network_time: 0.0107
[ Mon May 15 08:50:07 2023 ] 	Batch(319/480) done. Loss: 3.2506  lr:0.100000  network_time: 0.0107
[ Mon May 15 08:50:57 2023 ] 	Batch(419/480) done. Loss: 2.9395  lr:0.100000  network_time: 0.0108
[ Mon May 15 08:51:27 2023 ] 	Training Accuracy: 9.63%
[ Mon May 15 08:51:27 2023 ] Eval epoch: 2
[ Mon May 15 08:51:44 2023 ] 	Mean test loss of 120 batches: 2.809180736541748.
[ Mon May 15 08:51:44 2023 ] 	Top1: 17.17%
[ Mon May 15 08:51:44 2023 ] 	Top5: 54.17%
[ Mon May 15 08:51:44 2023 ] Training epoch: 3
[ Mon May 15 08:52:04 2023 ] 	Batch(39/480) done. Loss: 2.6963  lr:0.100000  network_time: 0.0108
[ Mon May 15 08:52:53 2023 ] 	Batch(139/480) done. Loss: 3.3575  lr:0.100000  network_time: 0.0109
[ Mon May 15 08:53:43 2023 ] 	Batch(239/480) done. Loss: 2.5120  lr:0.100000  network_time: 0.0128
[ Mon May 15 08:54:32 2023 ] 	Batch(339/480) done. Loss: 3.0214  lr:0.100000  network_time: 0.0115
[ Mon May 15 08:55:22 2023 ] 	Batch(439/480) done. Loss: 2.8378  lr:0.100000  network_time: 0.0113
[ Mon May 15 08:55:42 2023 ] 	Training Accuracy: 15.67%
[ Mon May 15 08:55:42 2023 ] Eval epoch: 3
[ Mon May 15 08:55:59 2023 ] 	Mean test loss of 120 batches: 2.505073308944702.
[ Mon May 15 08:55:59 2023 ] 	Top1: 23.00%
[ Mon May 15 08:55:59 2023 ] 	Top5: 67.00%
[ Mon May 15 08:55:59 2023 ] Training epoch: 4
[ Mon May 15 08:56:28 2023 ] 	Batch(59/480) done. Loss: 2.2601  lr:0.100000  network_time: 0.0108
[ Mon May 15 08:57:18 2023 ] 	Batch(159/480) done. Loss: 2.5832  lr:0.100000  network_time: 0.0107
[ Mon May 15 08:58:08 2023 ] 	Batch(259/480) done. Loss: 2.6655  lr:0.100000  network_time: 0.0113
[ Mon May 15 08:58:57 2023 ] 	Batch(359/480) done. Loss: 2.4036  lr:0.100000  network_time: 0.0110
[ Mon May 15 08:59:47 2023 ] 	Batch(459/480) done. Loss: 2.8187  lr:0.100000  network_time: 0.0110
[ Mon May 15 08:59:57 2023 ] 	Training Accuracy: 22.50%
[ Mon May 15 08:59:57 2023 ] Eval epoch: 4
[ Mon May 15 09:00:14 2023 ] 	Mean test loss of 120 batches: 2.118063449859619.
[ Mon May 15 09:00:14 2023 ] 	Top1: 33.50%
[ Mon May 15 09:00:14 2023 ] 	Top5: 77.17%
[ Mon May 15 09:00:14 2023 ] Training epoch: 5
[ Mon May 15 09:00:54 2023 ] 	Batch(79/480) done. Loss: 2.2282  lr:0.100000  network_time: 0.0107
[ Mon May 15 09:01:43 2023 ] 	Batch(179/480) done. Loss: 2.7853  lr:0.100000  network_time: 0.0109
[ Mon May 15 09:02:33 2023 ] 	Batch(279/480) done. Loss: 2.4302  lr:0.100000  network_time: 0.0109
[ Mon May 15 09:03:22 2023 ] 	Batch(379/480) done. Loss: 2.5321  lr:0.100000  network_time: 0.0107
[ Mon May 15 09:04:12 2023 ] 	Batch(479/480) done. Loss: 2.0339  lr:0.100000  network_time: 0.0107
[ Mon May 15 09:04:12 2023 ] 	Training Accuracy: 26.75%
[ Mon May 15 09:04:12 2023 ] Eval epoch: 5
[ Mon May 15 09:04:29 2023 ] 	Mean test loss of 120 batches: 1.777639627456665.
[ Mon May 15 09:04:29 2023 ] 	Top1: 43.17%
[ Mon May 15 09:04:29 2023 ] 	Top5: 86.50%
[ Mon May 15 09:04:29 2023 ] Training epoch: 6
[ Mon May 15 09:05:19 2023 ] 	Batch(99/480) done. Loss: 1.4557  lr:0.100000  network_time: 0.0120
[ Mon May 15 09:06:08 2023 ] 	Batch(199/480) done. Loss: 3.1511  lr:0.100000  network_time: 0.0107
[ Mon May 15 09:06:58 2023 ] 	Batch(299/480) done. Loss: 1.4287  lr:0.100000  network_time: 0.0109
[ Mon May 15 09:07:47 2023 ] 	Batch(399/480) done. Loss: 2.0414  lr:0.100000  network_time: 0.0109
[ Mon May 15 09:08:27 2023 ] 	Training Accuracy: 35.42%
[ Mon May 15 09:08:27 2023 ] Eval epoch: 6
[ Mon May 15 09:08:44 2023 ] 	Mean test loss of 120 batches: 1.7801403999328613.
[ Mon May 15 09:08:44 2023 ] 	Top1: 44.50%
[ Mon May 15 09:08:44 2023 ] 	Top5: 85.33%
[ Mon May 15 09:08:44 2023 ] Training epoch: 7
[ Mon May 15 09:08:54 2023 ] 	Batch(19/480) done. Loss: 1.9750  lr:0.100000  network_time: 0.0108
[ Mon May 15 09:09:44 2023 ] 	Batch(119/480) done. Loss: 2.3589  lr:0.100000  network_time: 0.0107
[ Mon May 15 09:10:33 2023 ] 	Batch(219/480) done. Loss: 1.0881  lr:0.100000  network_time: 0.0110
[ Mon May 15 09:11:23 2023 ] 	Batch(319/480) done. Loss: 1.2896  lr:0.100000  network_time: 0.0115
[ Mon May 15 09:12:13 2023 ] 	Batch(419/480) done. Loss: 1.6415  lr:0.100000  network_time: 0.0112
[ Mon May 15 09:12:42 2023 ] 	Training Accuracy: 40.67%
[ Mon May 15 09:12:42 2023 ] Eval epoch: 7
[ Mon May 15 09:12:59 2023 ] 	Mean test loss of 120 batches: 1.7035490274429321.
[ Mon May 15 09:12:59 2023 ] 	Top1: 47.17%
[ Mon May 15 09:12:59 2023 ] 	Top5: 90.83%
[ Mon May 15 09:12:59 2023 ] Training epoch: 8
[ Mon May 15 09:13:19 2023 ] 	Batch(39/480) done. Loss: 0.9878  lr:0.100000  network_time: 0.0105
[ Mon May 15 09:14:09 2023 ] 	Batch(139/480) done. Loss: 1.7860  lr:0.100000  network_time: 0.0106
[ Mon May 15 09:14:58 2023 ] 	Batch(239/480) done. Loss: 3.5464  lr:0.100000  network_time: 0.0107
[ Mon May 15 09:15:48 2023 ] 	Batch(339/480) done. Loss: 1.5575  lr:0.100000  network_time: 0.0106
[ Mon May 15 09:16:38 2023 ] 	Batch(439/480) done. Loss: 0.5250  lr:0.100000  network_time: 0.0107
[ Mon May 15 09:16:57 2023 ] 	Training Accuracy: 49.13%
[ Mon May 15 09:16:58 2023 ] Eval epoch: 8
[ Mon May 15 09:17:14 2023 ] 	Mean test loss of 120 batches: 1.8567850589752197.
[ Mon May 15 09:17:14 2023 ] 	Top1: 44.00%
[ Mon May 15 09:17:14 2023 ] 	Top5: 85.17%
[ Mon May 15 09:17:14 2023 ] Training epoch: 9
[ Mon May 15 09:17:44 2023 ] 	Batch(59/480) done. Loss: 1.0209  lr:0.100000  network_time: 0.0108
[ Mon May 15 09:18:34 2023 ] 	Batch(159/480) done. Loss: 0.9565  lr:0.100000  network_time: 0.0106
[ Mon May 15 09:19:23 2023 ] 	Batch(259/480) done. Loss: 1.0262  lr:0.100000  network_time: 0.0107
[ Mon May 15 09:20:13 2023 ] 	Batch(359/480) done. Loss: 0.9347  lr:0.100000  network_time: 0.0106
[ Mon May 15 09:21:03 2023 ] 	Batch(459/480) done. Loss: 1.1310  lr:0.100000  network_time: 0.0116
[ Mon May 15 09:21:13 2023 ] 	Training Accuracy: 57.50%
[ Mon May 15 09:21:13 2023 ] Eval epoch: 9
[ Mon May 15 09:21:29 2023 ] 	Mean test loss of 120 batches: 1.1557786464691162.
[ Mon May 15 09:21:29 2023 ] 	Top1: 63.83%
[ Mon May 15 09:21:29 2023 ] 	Top5: 93.17%
[ Mon May 15 09:21:29 2023 ] Training epoch: 10
[ Mon May 15 09:22:09 2023 ] 	Batch(79/480) done. Loss: 1.0962  lr:0.100000  network_time: 0.0112
[ Mon May 15 09:22:59 2023 ] 	Batch(179/480) done. Loss: 1.3117  lr:0.100000  network_time: 0.0115
[ Mon May 15 09:23:48 2023 ] 	Batch(279/480) done. Loss: 1.1834  lr:0.100000  network_time: 0.0115
[ Mon May 15 09:24:38 2023 ] 	Batch(379/480) done. Loss: 1.5390  lr:0.100000  network_time: 0.0110
[ Mon May 15 09:25:28 2023 ] 	Batch(479/480) done. Loss: 0.6568  lr:0.100000  network_time: 0.0117
[ Mon May 15 09:25:28 2023 ] 	Training Accuracy: 59.79%
[ Mon May 15 09:25:28 2023 ] Eval epoch: 10
[ Mon May 15 09:25:45 2023 ] 	Mean test loss of 120 batches: 1.1202000379562378.
[ Mon May 15 09:25:45 2023 ] 	Top1: 68.83%
[ Mon May 15 09:25:45 2023 ] 	Top5: 98.00%
[ Mon May 15 09:25:45 2023 ] Training epoch: 11
[ Mon May 15 09:26:34 2023 ] 	Batch(99/480) done. Loss: 1.8532  lr:0.100000  network_time: 0.0109
[ Mon May 15 09:27:24 2023 ] 	Batch(199/480) done. Loss: 0.9832  lr:0.100000  network_time: 0.0106
[ Mon May 15 09:28:13 2023 ] 	Batch(299/480) done. Loss: 1.7593  lr:0.100000  network_time: 0.0112
[ Mon May 15 09:29:03 2023 ] 	Batch(399/480) done. Loss: 0.9278  lr:0.100000  network_time: 0.0106
[ Mon May 15 09:29:43 2023 ] 	Training Accuracy: 64.12%
[ Mon May 15 09:29:43 2023 ] Eval epoch: 11
[ Mon May 15 09:30:00 2023 ] 	Mean test loss of 120 batches: 1.140228509902954.
[ Mon May 15 09:30:00 2023 ] 	Top1: 65.67%
[ Mon May 15 09:30:00 2023 ] 	Top5: 97.50%
[ Mon May 15 09:30:00 2023 ] Training epoch: 12
[ Mon May 15 09:30:10 2023 ] 	Batch(19/480) done. Loss: 1.0282  lr:0.100000  network_time: 0.0105
[ Mon May 15 09:30:59 2023 ] 	Batch(119/480) done. Loss: 1.0860  lr:0.100000  network_time: 0.0110
[ Mon May 15 09:31:49 2023 ] 	Batch(219/480) done. Loss: 0.4234  lr:0.100000  network_time: 0.0105
[ Mon May 15 09:32:39 2023 ] 	Batch(319/480) done. Loss: 0.7335  lr:0.100000  network_time: 0.0107
[ Mon May 15 09:33:28 2023 ] 	Batch(419/480) done. Loss: 0.7879  lr:0.100000  network_time: 0.0107
[ Mon May 15 09:33:58 2023 ] 	Training Accuracy: 71.79%
[ Mon May 15 09:33:58 2023 ] Eval epoch: 12
[ Mon May 15 09:34:15 2023 ] 	Mean test loss of 120 batches: 0.5936939716339111.
[ Mon May 15 09:34:15 2023 ] 	Top1: 79.67%
[ Mon May 15 09:34:15 2023 ] 	Top5: 98.33%
[ Mon May 15 09:34:15 2023 ] Training epoch: 13
[ Mon May 15 09:34:35 2023 ] 	Batch(39/480) done. Loss: 1.2998  lr:0.100000  network_time: 0.0109
[ Mon May 15 09:35:24 2023 ] 	Batch(139/480) done. Loss: 1.1298  lr:0.100000  network_time: 0.0107
[ Mon May 15 09:36:14 2023 ] 	Batch(239/480) done. Loss: 0.5270  lr:0.100000  network_time: 0.0109
[ Mon May 15 09:37:04 2023 ] 	Batch(339/480) done. Loss: 0.2718  lr:0.100000  network_time: 0.0115
[ Mon May 15 09:37:53 2023 ] 	Batch(439/480) done. Loss: 1.5150  lr:0.100000  network_time: 0.0113
[ Mon May 15 09:38:13 2023 ] 	Training Accuracy: 70.54%
[ Mon May 15 09:38:13 2023 ] Eval epoch: 13
[ Mon May 15 09:38:30 2023 ] 	Mean test loss of 120 batches: 1.352687954902649.
[ Mon May 15 09:38:30 2023 ] 	Top1: 69.50%
[ Mon May 15 09:38:30 2023 ] 	Top5: 92.50%
[ Mon May 15 09:38:30 2023 ] Training epoch: 14
[ Mon May 15 09:39:00 2023 ] 	Batch(59/480) done. Loss: 0.6198  lr:0.100000  network_time: 0.0113
[ Mon May 15 09:39:49 2023 ] 	Batch(159/480) done. Loss: 0.9466  lr:0.100000  network_time: 0.0106
[ Mon May 15 09:40:39 2023 ] 	Batch(259/480) done. Loss: 0.4522  lr:0.100000  network_time: 0.0108
[ Mon May 15 09:41:29 2023 ] 	Batch(359/480) done. Loss: 0.8529  lr:0.100000  network_time: 0.0122
[ Mon May 15 09:42:18 2023 ] 	Batch(459/480) done. Loss: 0.3808  lr:0.100000  network_time: 0.0109
[ Mon May 15 09:42:28 2023 ] 	Training Accuracy: 75.50%
[ Mon May 15 09:42:28 2023 ] Eval epoch: 14
[ Mon May 15 09:42:45 2023 ] 	Mean test loss of 120 batches: 0.6277779936790466.
[ Mon May 15 09:42:45 2023 ] 	Top1: 81.83%
[ Mon May 15 09:42:45 2023 ] 	Top5: 99.17%
[ Mon May 15 09:42:45 2023 ] Training epoch: 15
[ Mon May 15 09:43:25 2023 ] 	Batch(79/480) done. Loss: 0.2684  lr:0.100000  network_time: 0.0107
[ Mon May 15 09:44:15 2023 ] 	Batch(179/480) done. Loss: 0.6417  lr:0.100000  network_time: 0.0109
[ Mon May 15 09:45:04 2023 ] 	Batch(279/480) done. Loss: 0.4188  lr:0.100000  network_time: 0.0108
[ Mon May 15 09:45:54 2023 ] 	Batch(379/480) done. Loss: 0.4485  lr:0.100000  network_time: 0.0105
[ Mon May 15 09:46:43 2023 ] 	Batch(479/480) done. Loss: 2.3190  lr:0.100000  network_time: 0.0111
[ Mon May 15 09:46:43 2023 ] 	Training Accuracy: 79.00%
[ Mon May 15 09:46:44 2023 ] Eval epoch: 15
[ Mon May 15 09:47:00 2023 ] 	Mean test loss of 120 batches: 0.5879777073860168.
[ Mon May 15 09:47:00 2023 ] 	Top1: 82.50%
[ Mon May 15 09:47:00 2023 ] 	Top5: 97.67%
[ Mon May 15 09:47:00 2023 ] Training epoch: 16
[ Mon May 15 09:47:50 2023 ] 	Batch(99/480) done. Loss: 0.4882  lr:0.100000  network_time: 0.0112
[ Mon May 15 09:48:40 2023 ] 	Batch(199/480) done. Loss: 0.6363  lr:0.100000  network_time: 0.0112
[ Mon May 15 09:49:29 2023 ] 	Batch(299/480) done. Loss: 2.4317  lr:0.100000  network_time: 0.0106
[ Mon May 15 09:50:19 2023 ] 	Batch(399/480) done. Loss: 0.3563  lr:0.100000  network_time: 0.0106
[ Mon May 15 09:50:59 2023 ] 	Training Accuracy: 82.46%
[ Mon May 15 09:50:59 2023 ] Eval epoch: 16
[ Mon May 15 09:51:15 2023 ] 	Mean test loss of 120 batches: 0.534887969493866.
[ Mon May 15 09:51:15 2023 ] 	Top1: 83.33%
[ Mon May 15 09:51:16 2023 ] 	Top5: 99.00%
[ Mon May 15 09:51:16 2023 ] Training epoch: 17
[ Mon May 15 09:51:25 2023 ] 	Batch(19/480) done. Loss: 0.5955  lr:0.100000  network_time: 0.0116
[ Mon May 15 09:52:15 2023 ] 	Batch(119/480) done. Loss: 0.1600  lr:0.100000  network_time: 0.0108
[ Mon May 15 09:53:05 2023 ] 	Batch(219/480) done. Loss: 0.2664  lr:0.100000  network_time: 0.0107
[ Mon May 15 09:53:54 2023 ] 	Batch(319/480) done. Loss: 0.4647  lr:0.100000  network_time: 0.0109
[ Mon May 15 09:54:44 2023 ] 	Batch(419/480) done. Loss: 0.6056  lr:0.100000  network_time: 0.0107
[ Mon May 15 09:55:14 2023 ] 	Training Accuracy: 82.38%
[ Mon May 15 09:55:14 2023 ] Eval epoch: 17
[ Mon May 15 09:55:31 2023 ] 	Mean test loss of 120 batches: 0.5226666331291199.
[ Mon May 15 09:55:31 2023 ] 	Top1: 82.50%
[ Mon May 15 09:55:31 2023 ] 	Top5: 99.33%
[ Mon May 15 09:55:31 2023 ] Training epoch: 18
[ Mon May 15 09:55:51 2023 ] 	Batch(39/480) done. Loss: 0.7498  lr:0.100000  network_time: 0.0105
[ Mon May 15 09:56:40 2023 ] 	Batch(139/480) done. Loss: 0.5950  lr:0.100000  network_time: 0.0112
[ Mon May 15 09:57:30 2023 ] 	Batch(239/480) done. Loss: 0.0978  lr:0.100000  network_time: 0.0106
[ Mon May 15 09:58:20 2023 ] 	Batch(339/480) done. Loss: 0.0874  lr:0.100000  network_time: 0.0112
[ Mon May 15 09:59:09 2023 ] 	Batch(439/480) done. Loss: 0.0732  lr:0.100000  network_time: 0.0110
[ Mon May 15 09:59:29 2023 ] 	Training Accuracy: 86.13%
[ Mon May 15 09:59:29 2023 ] Eval epoch: 18
[ Mon May 15 09:59:46 2023 ] 	Mean test loss of 120 batches: 0.54913330078125.
[ Mon May 15 09:59:46 2023 ] 	Top1: 83.33%
[ Mon May 15 09:59:46 2023 ] 	Top5: 98.33%
[ Mon May 15 09:59:46 2023 ] Training epoch: 19
[ Mon May 15 10:00:16 2023 ] 	Batch(59/480) done. Loss: 0.0421  lr:0.100000  network_time: 0.0109
[ Mon May 15 10:01:05 2023 ] 	Batch(159/480) done. Loss: 0.5256  lr:0.100000  network_time: 0.0108
[ Mon May 15 10:01:55 2023 ] 	Batch(259/480) done. Loss: 0.1762  lr:0.100000  network_time: 0.0107
[ Mon May 15 10:02:45 2023 ] 	Batch(359/480) done. Loss: 0.9424  lr:0.100000  network_time: 0.0107
[ Mon May 15 10:03:34 2023 ] 	Batch(459/480) done. Loss: 0.5332  lr:0.100000  network_time: 0.0106
[ Mon May 15 10:03:44 2023 ] 	Training Accuracy: 85.88%
[ Mon May 15 10:03:44 2023 ] Eval epoch: 19
[ Mon May 15 10:04:01 2023 ] 	Mean test loss of 120 batches: 0.22527053952217102.
[ Mon May 15 10:04:01 2023 ] 	Top1: 93.00%
[ Mon May 15 10:04:01 2023 ] 	Top5: 99.50%
[ Mon May 15 10:04:01 2023 ] Training epoch: 20
[ Mon May 15 10:04:41 2023 ] 	Batch(79/480) done. Loss: 0.1747  lr:0.100000  network_time: 0.0110
[ Mon May 15 10:05:31 2023 ] 	Batch(179/480) done. Loss: 0.5058  lr:0.100000  network_time: 0.0106
[ Mon May 15 10:06:20 2023 ] 	Batch(279/480) done. Loss: 1.1773  lr:0.100000  network_time: 0.0110
[ Mon May 15 10:07:10 2023 ] 	Batch(379/480) done. Loss: 0.4169  lr:0.100000  network_time: 0.0108
[ Mon May 15 10:07:59 2023 ] 	Batch(479/480) done. Loss: 0.2066  lr:0.100000  network_time: 0.0113
[ Mon May 15 10:08:00 2023 ] 	Training Accuracy: 84.62%
[ Mon May 15 10:08:00 2023 ] Eval epoch: 20
[ Mon May 15 10:08:16 2023 ] 	Mean test loss of 120 batches: 0.3390570282936096.
[ Mon May 15 10:08:16 2023 ] 	Top1: 87.50%
[ Mon May 15 10:08:16 2023 ] 	Top5: 99.67%
[ Mon May 15 10:08:16 2023 ] Training epoch: 21
[ Mon May 15 10:09:06 2023 ] 	Batch(99/480) done. Loss: 0.3714  lr:0.010000  network_time: 0.0109
[ Mon May 15 10:09:56 2023 ] 	Batch(199/480) done. Loss: 0.0486  lr:0.010000  network_time: 0.0110
[ Mon May 15 10:10:45 2023 ] 	Batch(299/480) done. Loss: 0.1156  lr:0.010000  network_time: 0.0109
[ Mon May 15 10:11:35 2023 ] 	Batch(399/480) done. Loss: 0.1782  lr:0.010000  network_time: 0.0108
[ Mon May 15 10:12:15 2023 ] 	Training Accuracy: 94.83%
[ Mon May 15 10:12:15 2023 ] Eval epoch: 21
[ Mon May 15 10:12:32 2023 ] 	Mean test loss of 120 batches: 0.08692208677530289.
[ Mon May 15 10:12:32 2023 ] 	Top1: 97.50%
[ Mon May 15 10:12:32 2023 ] 	Top5: 100.00%
[ Mon May 15 10:12:32 2023 ] Training epoch: 22
[ Mon May 15 10:12:42 2023 ] 	Batch(19/480) done. Loss: 0.0380  lr:0.010000  network_time: 0.0110
[ Mon May 15 10:13:31 2023 ] 	Batch(119/480) done. Loss: 0.0173  lr:0.010000  network_time: 0.0110
[ Mon May 15 10:14:21 2023 ] 	Batch(219/480) done. Loss: 0.1411  lr:0.010000  network_time: 0.0119
[ Mon May 15 10:15:10 2023 ] 	Batch(319/480) done. Loss: 0.0140  lr:0.010000  network_time: 0.0109
[ Mon May 15 10:16:00 2023 ] 	Batch(419/480) done. Loss: 0.0729  lr:0.010000  network_time: 0.0110
[ Mon May 15 10:16:30 2023 ] 	Training Accuracy: 97.83%
[ Mon May 15 10:16:30 2023 ] Eval epoch: 22
[ Mon May 15 10:16:47 2023 ] 	Mean test loss of 120 batches: 0.05466460436582565.
[ Mon May 15 10:16:47 2023 ] 	Top1: 99.17%
[ Mon May 15 10:16:47 2023 ] 	Top5: 100.00%
[ Mon May 15 10:16:47 2023 ] Training epoch: 23
[ Mon May 15 10:17:07 2023 ] 	Batch(39/480) done. Loss: 0.0565  lr:0.010000  network_time: 0.0104
[ Mon May 15 10:17:56 2023 ] 	Batch(139/480) done. Loss: 0.0142  lr:0.010000  network_time: 0.0106
[ Mon May 15 10:18:46 2023 ] 	Batch(239/480) done. Loss: 0.0347  lr:0.010000  network_time: 0.0109
[ Mon May 15 10:19:36 2023 ] 	Batch(339/480) done. Loss: 0.1957  lr:0.010000  network_time: 0.0109
[ Mon May 15 10:20:25 2023 ] 	Batch(439/480) done. Loss: 0.0047  lr:0.010000  network_time: 0.0107
[ Mon May 15 10:20:45 2023 ] 	Training Accuracy: 98.21%
[ Mon May 15 10:20:45 2023 ] Eval epoch: 23
[ Mon May 15 10:21:02 2023 ] 	Mean test loss of 120 batches: 0.04857733100652695.
[ Mon May 15 10:21:02 2023 ] 	Top1: 98.83%
[ Mon May 15 10:21:02 2023 ] 	Top5: 100.00%
[ Mon May 15 10:21:02 2023 ] Training epoch: 24
[ Mon May 15 10:21:32 2023 ] 	Batch(59/480) done. Loss: 0.1164  lr:0.010000  network_time: 0.0110
[ Mon May 15 10:22:22 2023 ] 	Batch(159/480) done. Loss: 0.1469  lr:0.010000  network_time: 0.0120
[ Mon May 15 10:23:11 2023 ] 	Batch(259/480) done. Loss: 0.0479  lr:0.010000  network_time: 0.0106
[ Mon May 15 10:24:01 2023 ] 	Batch(359/480) done. Loss: 0.0164  lr:0.010000  network_time: 0.0107
[ Mon May 15 10:24:51 2023 ] 	Batch(459/480) done. Loss: 0.0100  lr:0.010000  network_time: 0.0112
[ Mon May 15 10:25:00 2023 ] 	Training Accuracy: 98.29%
[ Mon May 15 10:25:00 2023 ] Eval epoch: 24
[ Mon May 15 10:25:17 2023 ] 	Mean test loss of 120 batches: 0.02342340163886547.
[ Mon May 15 10:25:17 2023 ] 	Top1: 100.00%
[ Mon May 15 10:25:17 2023 ] 	Top5: 100.00%
[ Mon May 15 10:25:17 2023 ] Training epoch: 25
[ Mon May 15 10:25:57 2023 ] 	Batch(79/480) done. Loss: 0.1259  lr:0.010000  network_time: 0.0114
[ Mon May 15 10:26:47 2023 ] 	Batch(179/480) done. Loss: 0.1307  lr:0.010000  network_time: 0.0109
[ Mon May 15 10:27:36 2023 ] 	Batch(279/480) done. Loss: 0.0396  lr:0.010000  network_time: 0.0109
[ Mon May 15 10:28:26 2023 ] 	Batch(379/480) done. Loss: 0.0094  lr:0.010000  network_time: 0.0110
[ Mon May 15 10:29:16 2023 ] 	Batch(479/480) done. Loss: 0.3270  lr:0.010000  network_time: 0.0112
[ Mon May 15 10:29:16 2023 ] 	Training Accuracy: 98.71%
[ Mon May 15 10:29:16 2023 ] Eval epoch: 25
[ Mon May 15 10:29:33 2023 ] 	Mean test loss of 120 batches: 0.020534396171569824.
[ Mon May 15 10:29:33 2023 ] 	Top1: 99.83%
[ Mon May 15 10:29:33 2023 ] 	Top5: 100.00%
[ Mon May 15 10:29:33 2023 ] Training epoch: 26
[ Mon May 15 10:30:22 2023 ] 	Batch(99/480) done. Loss: 0.0159  lr:0.001000  network_time: 0.0111
[ Mon May 15 10:31:12 2023 ] 	Batch(199/480) done. Loss: 0.2167  lr:0.001000  network_time: 0.0108
[ Mon May 15 10:32:01 2023 ] 	Batch(299/480) done. Loss: 0.0070  lr:0.001000  network_time: 0.0114
[ Mon May 15 10:32:51 2023 ] 	Batch(399/480) done. Loss: 0.0597  lr:0.001000  network_time: 0.0115
[ Mon May 15 10:33:31 2023 ] 	Training Accuracy: 98.79%
[ Mon May 15 10:33:31 2023 ] Eval epoch: 26
[ Mon May 15 10:33:48 2023 ] 	Mean test loss of 120 batches: 0.027057981118559837.
[ Mon May 15 10:33:48 2023 ] 	Top1: 99.67%
[ Mon May 15 10:33:48 2023 ] 	Top5: 100.00%
[ Mon May 15 10:33:48 2023 ] Training epoch: 27
[ Mon May 15 10:33:58 2023 ] 	Batch(19/480) done. Loss: 0.0241  lr:0.001000  network_time: 0.0108
[ Mon May 15 10:34:47 2023 ] 	Batch(119/480) done. Loss: 0.0088  lr:0.001000  network_time: 0.0111
[ Mon May 15 10:35:37 2023 ] 	Batch(219/480) done. Loss: 0.1035  lr:0.001000  network_time: 0.0109
[ Mon May 15 10:36:27 2023 ] 	Batch(319/480) done. Loss: 0.0059  lr:0.001000  network_time: 0.0105
[ Mon May 15 10:37:16 2023 ] 	Batch(419/480) done. Loss: 0.0181  lr:0.001000  network_time: 0.0108
[ Mon May 15 10:37:46 2023 ] 	Training Accuracy: 99.12%
[ Mon May 15 10:37:46 2023 ] Eval epoch: 27
[ Mon May 15 10:38:03 2023 ] 	Mean test loss of 120 batches: 0.020893963053822517.
[ Mon May 15 10:38:03 2023 ] 	Top1: 100.00%
[ Mon May 15 10:38:03 2023 ] 	Top5: 100.00%
[ Mon May 15 10:38:03 2023 ] Training epoch: 28
[ Mon May 15 10:38:23 2023 ] 	Batch(39/480) done. Loss: 0.1156  lr:0.001000  network_time: 0.0109
[ Mon May 15 10:39:13 2023 ] 	Batch(139/480) done. Loss: 0.4000  lr:0.001000  network_time: 0.0112
[ Mon May 15 10:40:02 2023 ] 	Batch(239/480) done. Loss: 0.0424  lr:0.001000  network_time: 0.0109
[ Mon May 15 10:40:52 2023 ] 	Batch(339/480) done. Loss: 0.1855  lr:0.001000  network_time: 0.0114
[ Mon May 15 10:41:41 2023 ] 	Batch(439/480) done. Loss: 0.4766  lr:0.001000  network_time: 0.0107
[ Mon May 15 10:42:01 2023 ] 	Training Accuracy: 98.75%
[ Mon May 15 10:42:01 2023 ] Eval epoch: 28
[ Mon May 15 10:42:18 2023 ] 	Mean test loss of 120 batches: 0.01644607074558735.
[ Mon May 15 10:42:18 2023 ] 	Top1: 100.00%
[ Mon May 15 10:42:18 2023 ] 	Top5: 100.00%
[ Mon May 15 10:42:18 2023 ] Training epoch: 29
[ Mon May 15 10:42:48 2023 ] 	Batch(59/480) done. Loss: 0.0338  lr:0.001000  network_time: 0.0107
[ Mon May 15 10:43:38 2023 ] 	Batch(159/480) done. Loss: 0.0663  lr:0.001000  network_time: 0.0108
[ Mon May 15 10:44:27 2023 ] 	Batch(259/480) done. Loss: 0.0500  lr:0.001000  network_time: 0.0111
[ Mon May 15 10:45:17 2023 ] 	Batch(359/480) done. Loss: 0.0068  lr:0.001000  network_time: 0.0113
[ Mon May 15 10:46:07 2023 ] 	Batch(459/480) done. Loss: 0.0959  lr:0.001000  network_time: 0.0112
[ Mon May 15 10:46:17 2023 ] 	Training Accuracy: 99.08%
[ Mon May 15 10:46:17 2023 ] Eval epoch: 29
[ Mon May 15 10:46:33 2023 ] 	Mean test loss of 120 batches: 0.018972914665937424.
[ Mon May 15 10:46:33 2023 ] 	Top1: 100.00%
[ Mon May 15 10:46:33 2023 ] 	Top5: 100.00%
[ Mon May 15 10:46:33 2023 ] Training epoch: 30
[ Mon May 15 10:47:13 2023 ] 	Batch(79/480) done. Loss: 0.0017  lr:0.001000  network_time: 0.0111
[ Mon May 15 10:48:03 2023 ] 	Batch(179/480) done. Loss: 0.0301  lr:0.001000  network_time: 0.0109
[ Mon May 15 10:48:52 2023 ] 	Batch(279/480) done. Loss: 0.0124  lr:0.001000  network_time: 0.0108
[ Mon May 15 10:49:42 2023 ] 	Batch(379/480) done. Loss: 0.0166  lr:0.001000  network_time: 0.0109
[ Mon May 15 10:50:32 2023 ] 	Batch(479/480) done. Loss: 0.0032  lr:0.001000  network_time: 0.0118
[ Mon May 15 10:50:32 2023 ] 	Training Accuracy: 98.83%
[ Mon May 15 10:50:32 2023 ] Eval epoch: 30
[ Mon May 15 10:50:49 2023 ] 	Mean test loss of 120 batches: 0.019664276391267776.
[ Mon May 15 10:50:49 2023 ] 	Top1: 99.83%
[ Mon May 15 10:50:49 2023 ] 	Top5: 100.00%
