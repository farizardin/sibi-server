[ Tue May 16 10:55:54 2023 ] NUM WORKER: 1
[ Tue May 16 10:56:45 2023 ] Parameters:
{'work_dir': './work_dir/sibi_modified_ShiftGCN_mod_2_joint_n_5_kfold_fold_1', 'model_saved_name': './save_models/sibi_modified_ShiftGCN_mod_2_joint_n_5_kfold_fold_1', 'Experiment_name': 'sibi_modified_ShiftGCN_mod_2_joint_n_5_kfold', 'config': './config/recalculated/train_sibi_with_mouth_augmented_modified_shift_joint_mod_2.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 2, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'n_splits': 5, 'feeder': 'feeders.feeder_hsd.Feeder', 'num_worker': 1, 'train_feeder_args': {'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': -1, 'normalization': False}, 'test_feeder_args': None, 'data_path': './data/augmented_recalculate_normalized', 'model': 'model.shift_gcn.Model', 'model_args': {'num_class': 50, 'num_person': 1, 'num_point': 115, 'method': 'modified', 'weight': 2, 'graph': 'graph.skeleton_with_mouth.SkeletonWithMouth', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [20, 25], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 5, 'test_batch_size': 5, 'start_epoch': 0, 'num_epoch': 30, 'folds_range': [0, 5], 'weight_decay': 0.0001, 'only_train_part': True, 'only_train_epoch': 1, 'warm_up_epoch': 0}

[ Tue May 16 10:56:45 2023 ] Training epoch: 1
[ Tue May 16 10:57:37 2023 ] 	Batch(99/480) done. Loss: 3.6055  lr:0.100000  network_time: 0.0135
[ Tue May 16 10:58:27 2023 ] 	Batch(199/480) done. Loss: 3.2036  lr:0.100000  network_time: 0.0107
[ Tue May 16 10:59:18 2023 ] 	Batch(299/480) done. Loss: 2.7576  lr:0.100000  network_time: 0.0107
[ Tue May 16 11:00:09 2023 ] 	Batch(399/480) done. Loss: 3.6558  lr:0.100000  network_time: 0.0138
[ Tue May 16 11:00:49 2023 ] 	Training Accuracy: 9.58%
[ Tue May 16 11:00:50 2023 ] Eval epoch: 1
[ Tue May 16 11:01:06 2023 ] 	Mean test loss of 120 batches: 2.98565411567688.
[ Tue May 16 11:01:06 2023 ] 	Top1: 19.67%
[ Tue May 16 11:01:07 2023 ] 	Top5: 56.50%
[ Tue May 16 11:01:07 2023 ] Training epoch: 2
[ Tue May 16 11:01:17 2023 ] 	Batch(19/480) done. Loss: 2.7346  lr:0.100000  network_time: 0.0106
[ Tue May 16 11:02:07 2023 ] 	Batch(119/480) done. Loss: 3.0990  lr:0.100000  network_time: 0.0129
[ Tue May 16 11:02:58 2023 ] 	Batch(219/480) done. Loss: 2.6235  lr:0.100000  network_time: 0.0134
[ Tue May 16 11:03:49 2023 ] 	Batch(319/480) done. Loss: 2.3786  lr:0.100000  network_time: 0.0108
[ Tue May 16 11:04:40 2023 ] 	Batch(419/480) done. Loss: 2.7186  lr:0.100000  network_time: 0.0108
[ Tue May 16 11:05:10 2023 ] 	Training Accuracy: 18.00%
[ Tue May 16 11:05:10 2023 ] Eval epoch: 2
[ Tue May 16 11:05:27 2023 ] 	Mean test loss of 120 batches: 3.679353952407837.
[ Tue May 16 11:05:27 2023 ] 	Top1: 16.00%
[ Tue May 16 11:05:27 2023 ] 	Top5: 56.17%
[ Tue May 16 11:05:27 2023 ] Training epoch: 3
[ Tue May 16 11:05:48 2023 ] 	Batch(39/480) done. Loss: 2.5870  lr:0.100000  network_time: 0.0106
[ Tue May 16 11:06:38 2023 ] 	Batch(139/480) done. Loss: 2.6356  lr:0.100000  network_time: 0.0109
[ Tue May 16 11:07:29 2023 ] 	Batch(239/480) done. Loss: 2.2180  lr:0.100000  network_time: 0.0109
[ Tue May 16 11:08:20 2023 ] 	Batch(339/480) done. Loss: 2.2682  lr:0.100000  network_time: 0.0133
[ Tue May 16 11:09:11 2023 ] 	Batch(439/480) done. Loss: 2.3170  lr:0.100000  network_time: 0.0109
[ Tue May 16 11:09:31 2023 ] 	Training Accuracy: 28.08%
[ Tue May 16 11:09:31 2023 ] Eval epoch: 3
[ Tue May 16 11:09:48 2023 ] 	Mean test loss of 120 batches: 2.155993700027466.
[ Tue May 16 11:09:48 2023 ] 	Top1: 32.50%
[ Tue May 16 11:09:48 2023 ] 	Top5: 78.67%
[ Tue May 16 11:09:48 2023 ] Training epoch: 4
[ Tue May 16 11:10:19 2023 ] 	Batch(59/480) done. Loss: 1.3610  lr:0.100000  network_time: 0.0109
[ Tue May 16 11:11:10 2023 ] 	Batch(159/480) done. Loss: 2.0949  lr:0.100000  network_time: 0.0130
[ Tue May 16 11:12:00 2023 ] 	Batch(259/480) done. Loss: 1.8483  lr:0.100000  network_time: 0.0110
[ Tue May 16 11:12:51 2023 ] 	Batch(359/480) done. Loss: 1.7319  lr:0.100000  network_time: 0.0108
[ Tue May 16 11:13:42 2023 ] 	Batch(459/480) done. Loss: 1.8132  lr:0.100000  network_time: 0.0108
[ Tue May 16 11:13:52 2023 ] 	Training Accuracy: 36.17%
[ Tue May 16 11:13:52 2023 ] Eval epoch: 4
[ Tue May 16 11:14:09 2023 ] 	Mean test loss of 120 batches: 2.209973096847534.
[ Tue May 16 11:14:09 2023 ] 	Top1: 43.33%
[ Tue May 16 11:14:09 2023 ] 	Top5: 81.17%
[ Tue May 16 11:14:09 2023 ] Training epoch: 5
[ Tue May 16 11:14:50 2023 ] 	Batch(79/480) done. Loss: 1.9958  lr:0.100000  network_time: 0.0108
[ Tue May 16 11:15:41 2023 ] 	Batch(179/480) done. Loss: 1.3396  lr:0.100000  network_time: 0.0131
[ Tue May 16 11:16:31 2023 ] 	Batch(279/480) done. Loss: 1.5861  lr:0.100000  network_time: 0.0107
[ Tue May 16 11:17:22 2023 ] 	Batch(379/480) done. Loss: 1.9552  lr:0.100000  network_time: 0.0110
[ Tue May 16 11:18:13 2023 ] 	Batch(479/480) done. Loss: 1.3974  lr:0.100000  network_time: 0.0110
[ Tue May 16 11:18:13 2023 ] 	Training Accuracy: 46.21%
[ Tue May 16 11:18:13 2023 ] Eval epoch: 5
[ Tue May 16 11:18:30 2023 ] 	Mean test loss of 120 batches: 1.5293070077896118.
[ Tue May 16 11:18:30 2023 ] 	Top1: 53.00%
[ Tue May 16 11:18:30 2023 ] 	Top5: 92.00%
[ Tue May 16 11:18:30 2023 ] Training epoch: 6
[ Tue May 16 11:19:21 2023 ] 	Batch(99/480) done. Loss: 1.1241  lr:0.100000  network_time: 0.0136
[ Tue May 16 11:20:12 2023 ] 	Batch(199/480) done. Loss: 1.2053  lr:0.100000  network_time: 0.0107
[ Tue May 16 11:21:02 2023 ] 	Batch(299/480) done. Loss: 0.9178  lr:0.100000  network_time: 0.0116
[ Tue May 16 11:21:53 2023 ] 	Batch(399/480) done. Loss: 1.7356  lr:0.100000  network_time: 0.0109
[ Tue May 16 11:22:34 2023 ] 	Training Accuracy: 55.21%
[ Tue May 16 11:22:34 2023 ] Eval epoch: 6
[ Tue May 16 11:22:51 2023 ] 	Mean test loss of 120 batches: 1.8032454252243042.
[ Tue May 16 11:22:51 2023 ] 	Top1: 46.00%
[ Tue May 16 11:22:51 2023 ] 	Top5: 85.33%
[ Tue May 16 11:22:51 2023 ] Training epoch: 7
[ Tue May 16 11:23:01 2023 ] 	Batch(19/480) done. Loss: 1.4421  lr:0.100000  network_time: 0.0109
[ Tue May 16 11:23:52 2023 ] 	Batch(119/480) done. Loss: 1.0886  lr:0.100000  network_time: 0.0107
[ Tue May 16 11:24:43 2023 ] 	Batch(219/480) done. Loss: 1.1886  lr:0.100000  network_time: 0.0112
[ Tue May 16 11:25:33 2023 ] 	Batch(319/480) done. Loss: 0.9848  lr:0.100000  network_time: 0.0111
[ Tue May 16 11:26:24 2023 ] 	Batch(419/480) done. Loss: 1.2600  lr:0.100000  network_time: 0.0108
[ Tue May 16 11:26:55 2023 ] 	Training Accuracy: 59.00%
[ Tue May 16 11:26:55 2023 ] Eval epoch: 7
[ Tue May 16 11:27:12 2023 ] 	Mean test loss of 120 batches: 1.2104750871658325.
[ Tue May 16 11:27:12 2023 ] 	Top1: 65.00%
[ Tue May 16 11:27:12 2023 ] 	Top5: 95.17%
[ Tue May 16 11:27:12 2023 ] Training epoch: 8
[ Tue May 16 11:27:32 2023 ] 	Batch(39/480) done. Loss: 0.5768  lr:0.100000  network_time: 0.0111
[ Tue May 16 11:28:23 2023 ] 	Batch(139/480) done. Loss: 1.5613  lr:0.100000  network_time: 0.0134
[ Tue May 16 11:29:14 2023 ] 	Batch(239/480) done. Loss: 2.2681  lr:0.100000  network_time: 0.0106
[ Tue May 16 11:30:05 2023 ] 	Batch(339/480) done. Loss: 1.2960  lr:0.100000  network_time: 0.0110
[ Tue May 16 11:30:55 2023 ] 	Batch(439/480) done. Loss: 0.0889  lr:0.100000  network_time: 0.0129
[ Tue May 16 11:31:16 2023 ] 	Training Accuracy: 65.25%
[ Tue May 16 11:31:16 2023 ] Eval epoch: 8
[ Tue May 16 11:31:33 2023 ] 	Mean test loss of 120 batches: 0.9479860067367554.
[ Tue May 16 11:31:33 2023 ] 	Top1: 69.17%
[ Tue May 16 11:31:33 2023 ] 	Top5: 96.83%
[ Tue May 16 11:31:33 2023 ] Training epoch: 9
[ Tue May 16 11:32:03 2023 ] 	Batch(59/480) done. Loss: 0.4574  lr:0.100000  network_time: 0.0108
[ Tue May 16 11:32:54 2023 ] 	Batch(159/480) done. Loss: 0.3729  lr:0.100000  network_time: 0.0109
[ Tue May 16 11:33:45 2023 ] 	Batch(259/480) done. Loss: 1.1294  lr:0.100000  network_time: 0.0107
[ Tue May 16 11:34:35 2023 ] 	Batch(359/480) done. Loss: 0.2180  lr:0.100000  network_time: 0.0133
[ Tue May 16 11:35:26 2023 ] 	Batch(459/480) done. Loss: 2.1043  lr:0.100000  network_time: 0.0117
[ Tue May 16 11:35:36 2023 ] 	Training Accuracy: 71.04%
[ Tue May 16 11:35:36 2023 ] Eval epoch: 9
[ Tue May 16 11:35:53 2023 ] 	Mean test loss of 120 batches: 1.0635101795196533.
[ Tue May 16 11:35:53 2023 ] 	Top1: 72.83%
[ Tue May 16 11:35:53 2023 ] 	Top5: 95.67%
[ Tue May 16 11:35:53 2023 ] Training epoch: 10
[ Tue May 16 11:36:34 2023 ] 	Batch(79/480) done. Loss: 0.8832  lr:0.100000  network_time: 0.0106
[ Tue May 16 11:37:24 2023 ] 	Batch(179/480) done. Loss: 0.6258  lr:0.100000  network_time: 0.0108
[ Tue May 16 11:38:15 2023 ] 	Batch(279/480) done. Loss: 0.9050  lr:0.100000  network_time: 0.0132
[ Tue May 16 11:39:06 2023 ] 	Batch(379/480) done. Loss: 0.7776  lr:0.100000  network_time: 0.0136
[ Tue May 16 11:39:57 2023 ] 	Batch(479/480) done. Loss: 0.6305  lr:0.100000  network_time: 0.0110
[ Tue May 16 11:39:57 2023 ] 	Training Accuracy: 72.29%
[ Tue May 16 11:39:57 2023 ] Eval epoch: 10
[ Tue May 16 11:40:14 2023 ] 	Mean test loss of 120 batches: 0.7203242182731628.
[ Tue May 16 11:40:14 2023 ] 	Top1: 73.67%
[ Tue May 16 11:40:14 2023 ] 	Top5: 100.00%
[ Tue May 16 11:40:14 2023 ] Training epoch: 11
[ Tue May 16 11:41:04 2023 ] 	Batch(99/480) done. Loss: 0.4367  lr:0.100000  network_time: 0.0116
[ Tue May 16 11:41:55 2023 ] 	Batch(199/480) done. Loss: 1.1930  lr:0.100000  network_time: 0.0107
[ Tue May 16 11:42:46 2023 ] 	Batch(299/480) done. Loss: 0.9284  lr:0.100000  network_time: 0.0110
[ Tue May 16 11:43:37 2023 ] 	Batch(399/480) done. Loss: 0.5597  lr:0.100000  network_time: 0.0142
[ Tue May 16 11:44:17 2023 ] 	Training Accuracy: 77.04%
[ Tue May 16 11:44:17 2023 ] Eval epoch: 11
[ Tue May 16 11:44:34 2023 ] 	Mean test loss of 120 batches: 0.557245135307312.
[ Tue May 16 11:44:34 2023 ] 	Top1: 82.67%
[ Tue May 16 11:44:34 2023 ] 	Top5: 99.50%
[ Tue May 16 11:44:34 2023 ] Training epoch: 12
[ Tue May 16 11:44:45 2023 ] 	Batch(19/480) done. Loss: 0.5080  lr:0.100000  network_time: 0.0108
[ Tue May 16 11:45:35 2023 ] 	Batch(119/480) done. Loss: 1.2321  lr:0.100000  network_time: 0.0131
[ Tue May 16 11:46:26 2023 ] 	Batch(219/480) done. Loss: 0.4217  lr:0.100000  network_time: 0.0108
[ Tue May 16 11:47:17 2023 ] 	Batch(319/480) done. Loss: 0.8088  lr:0.100000  network_time: 0.0108
[ Tue May 16 11:48:08 2023 ] 	Batch(419/480) done. Loss: 0.5374  lr:0.100000  network_time: 0.0131
[ Tue May 16 11:48:38 2023 ] 	Training Accuracy: 78.67%
[ Tue May 16 11:48:38 2023 ] Eval epoch: 12
[ Tue May 16 11:48:55 2023 ] 	Mean test loss of 120 batches: 0.5134916305541992.
[ Tue May 16 11:48:55 2023 ] 	Top1: 82.33%
[ Tue May 16 11:48:55 2023 ] 	Top5: 99.83%
[ Tue May 16 11:48:55 2023 ] Training epoch: 13
[ Tue May 16 11:49:15 2023 ] 	Batch(39/480) done. Loss: 0.7757  lr:0.100000  network_time: 0.0109
[ Tue May 16 11:50:06 2023 ] 	Batch(139/480) done. Loss: 1.1379  lr:0.100000  network_time: 0.0107
[ Tue May 16 11:50:57 2023 ] 	Batch(239/480) done. Loss: 0.3536  lr:0.100000  network_time: 0.0108
[ Tue May 16 11:51:48 2023 ] 	Batch(339/480) done. Loss: 1.1559  lr:0.100000  network_time: 0.0133
[ Tue May 16 11:52:39 2023 ] 	Batch(439/480) done. Loss: 0.2888  lr:0.100000  network_time: 0.0134
[ Tue May 16 11:52:59 2023 ] 	Training Accuracy: 82.04%
[ Tue May 16 11:52:59 2023 ] Eval epoch: 13
[ Tue May 16 11:53:16 2023 ] 	Mean test loss of 120 batches: 0.568745493888855.
[ Tue May 16 11:53:16 2023 ] 	Top1: 86.33%
[ Tue May 16 11:53:16 2023 ] 	Top5: 98.83%
[ Tue May 16 11:53:16 2023 ] Training epoch: 14
[ Tue May 16 11:53:47 2023 ] 	Batch(59/480) done. Loss: 0.8587  lr:0.100000  network_time: 0.0111
[ Tue May 16 11:54:37 2023 ] 	Batch(159/480) done. Loss: 0.6468  lr:0.100000  network_time: 0.0123
[ Tue May 16 11:55:28 2023 ] 	Batch(259/480) done. Loss: 0.7207  lr:0.100000  network_time: 0.0107
[ Tue May 16 11:56:19 2023 ] 	Batch(359/480) done. Loss: 1.7716  lr:0.100000  network_time: 0.0106
[ Tue May 16 11:57:10 2023 ] 	Batch(459/480) done. Loss: 0.1625  lr:0.100000  network_time: 0.0107
[ Tue May 16 11:57:20 2023 ] 	Training Accuracy: 83.79%
[ Tue May 16 11:57:20 2023 ] Eval epoch: 14
[ Tue May 16 11:57:37 2023 ] 	Mean test loss of 120 batches: 0.4379875063896179.
[ Tue May 16 11:57:37 2023 ] 	Top1: 88.00%
[ Tue May 16 11:57:37 2023 ] 	Top5: 98.67%
[ Tue May 16 11:57:37 2023 ] Training epoch: 15
[ Tue May 16 11:58:18 2023 ] 	Batch(79/480) done. Loss: 0.7525  lr:0.100000  network_time: 0.0129
[ Tue May 16 11:59:08 2023 ] 	Batch(179/480) done. Loss: 0.2071  lr:0.100000  network_time: 0.0119
[ Tue May 16 11:59:59 2023 ] 	Batch(279/480) done. Loss: 0.3127  lr:0.100000  network_time: 0.0112
[ Tue May 16 12:00:50 2023 ] 	Batch(379/480) done. Loss: 0.3016  lr:0.100000  network_time: 0.0112
[ Tue May 16 12:01:41 2023 ] 	Batch(479/480) done. Loss: 0.7217  lr:0.100000  network_time: 0.0109
[ Tue May 16 12:01:41 2023 ] 	Training Accuracy: 84.08%
[ Tue May 16 12:01:41 2023 ] Eval epoch: 15
[ Tue May 16 12:01:58 2023 ] 	Mean test loss of 120 batches: 0.6093297600746155.
[ Tue May 16 12:01:58 2023 ] 	Top1: 82.17%
[ Tue May 16 12:01:58 2023 ] 	Top5: 99.33%
[ Tue May 16 12:01:58 2023 ] Training epoch: 16
[ Tue May 16 12:02:49 2023 ] 	Batch(99/480) done. Loss: 2.3655  lr:0.100000  network_time: 0.0104
[ Tue May 16 12:03:40 2023 ] 	Batch(199/480) done. Loss: 0.1417  lr:0.100000  network_time: 0.0117
[ Tue May 16 12:04:30 2023 ] 	Batch(299/480) done. Loss: 0.6734  lr:0.100000  network_time: 0.0110
[ Tue May 16 12:05:21 2023 ] 	Batch(399/480) done. Loss: 0.6009  lr:0.100000  network_time: 0.0109
[ Tue May 16 12:06:02 2023 ] 	Training Accuracy: 84.71%
[ Tue May 16 12:06:02 2023 ] Eval epoch: 16
[ Tue May 16 12:06:19 2023 ] 	Mean test loss of 120 batches: 0.2803584933280945.
[ Tue May 16 12:06:19 2023 ] 	Top1: 91.67%
[ Tue May 16 12:06:19 2023 ] 	Top5: 100.00%
[ Tue May 16 12:06:19 2023 ] Training epoch: 17
[ Tue May 16 12:06:29 2023 ] 	Batch(19/480) done. Loss: 0.4453  lr:0.100000  network_time: 0.0106
[ Tue May 16 12:07:20 2023 ] 	Batch(119/480) done. Loss: 0.3322  lr:0.100000  network_time: 0.0108
[ Tue May 16 12:08:11 2023 ] 	Batch(219/480) done. Loss: 0.0338  lr:0.100000  network_time: 0.0107
[ Tue May 16 12:09:02 2023 ] 	Batch(319/480) done. Loss: 0.6957  lr:0.100000  network_time: 0.0132
[ Tue May 16 12:09:52 2023 ] 	Batch(419/480) done. Loss: 0.9976  lr:0.100000  network_time: 0.0108
[ Tue May 16 12:10:23 2023 ] 	Training Accuracy: 86.92%
[ Tue May 16 12:10:23 2023 ] Eval epoch: 17
[ Tue May 16 12:10:40 2023 ] 	Mean test loss of 120 batches: 0.4609074890613556.
[ Tue May 16 12:10:40 2023 ] 	Top1: 83.67%
[ Tue May 16 12:10:40 2023 ] 	Top5: 99.50%
[ Tue May 16 12:10:40 2023 ] Training epoch: 18
[ Tue May 16 12:11:00 2023 ] 	Batch(39/480) done. Loss: 0.6989  lr:0.100000  network_time: 0.0107
[ Tue May 16 12:11:51 2023 ] 	Batch(139/480) done. Loss: 1.0820  lr:0.100000  network_time: 0.0112
[ Tue May 16 12:12:42 2023 ] 	Batch(239/480) done. Loss: 0.1826  lr:0.100000  network_time: 0.0108
[ Tue May 16 12:13:33 2023 ] 	Batch(339/480) done. Loss: 0.4706  lr:0.100000  network_time: 0.0106
[ Tue May 16 12:14:24 2023 ] 	Batch(439/480) done. Loss: 0.2142  lr:0.100000  network_time: 0.0111
[ Tue May 16 12:14:44 2023 ] 	Training Accuracy: 86.50%
[ Tue May 16 12:14:44 2023 ] Eval epoch: 18
[ Tue May 16 12:15:01 2023 ] 	Mean test loss of 120 batches: 0.7713146805763245.
[ Tue May 16 12:15:01 2023 ] 	Top1: 78.17%
[ Tue May 16 12:15:01 2023 ] 	Top5: 99.50%
[ Tue May 16 12:15:01 2023 ] Training epoch: 19
[ Tue May 16 12:15:32 2023 ] 	Batch(59/480) done. Loss: 0.1857  lr:0.100000  network_time: 0.0130
[ Tue May 16 12:16:22 2023 ] 	Batch(159/480) done. Loss: 0.0317  lr:0.100000  network_time: 0.0107
[ Tue May 16 12:17:13 2023 ] 	Batch(259/480) done. Loss: 0.0753  lr:0.100000  network_time: 0.0111
[ Tue May 16 12:18:04 2023 ] 	Batch(359/480) done. Loss: 0.0538  lr:0.100000  network_time: 0.0130
[ Tue May 16 12:18:54 2023 ] 	Batch(459/480) done. Loss: 0.4749  lr:0.100000  network_time: 0.0119
[ Tue May 16 12:19:04 2023 ] 	Training Accuracy: 87.83%
[ Tue May 16 12:19:04 2023 ] Eval epoch: 19
[ Tue May 16 12:19:21 2023 ] 	Mean test loss of 120 batches: 0.3235827684402466.
[ Tue May 16 12:19:21 2023 ] 	Top1: 89.67%
[ Tue May 16 12:19:21 2023 ] 	Top5: 100.00%
[ Tue May 16 12:19:21 2023 ] Training epoch: 20
[ Tue May 16 12:20:02 2023 ] 	Batch(79/480) done. Loss: 0.0723  lr:0.100000  network_time: 0.0106
[ Tue May 16 12:20:53 2023 ] 	Batch(179/480) done. Loss: 0.4763  lr:0.100000  network_time: 0.0110
[ Tue May 16 12:21:43 2023 ] 	Batch(279/480) done. Loss: 0.7024  lr:0.100000  network_time: 0.0107
[ Tue May 16 12:22:34 2023 ] 	Batch(379/480) done. Loss: 0.5091  lr:0.100000  network_time: 0.0110
[ Tue May 16 12:23:25 2023 ] 	Batch(479/480) done. Loss: 0.0634  lr:0.100000  network_time: 0.0108
[ Tue May 16 12:23:25 2023 ] 	Training Accuracy: 86.79%
[ Tue May 16 12:23:25 2023 ] Eval epoch: 20
[ Tue May 16 12:23:42 2023 ] 	Mean test loss of 120 batches: 0.40841352939605713.
[ Tue May 16 12:23:42 2023 ] 	Top1: 87.17%
[ Tue May 16 12:23:42 2023 ] 	Top5: 99.67%
[ Tue May 16 12:23:42 2023 ] Training epoch: 21
[ Tue May 16 12:24:32 2023 ] 	Batch(99/480) done. Loss: 0.9698  lr:0.010000  network_time: 0.0108
[ Tue May 16 12:25:23 2023 ] 	Batch(199/480) done. Loss: 0.0146  lr:0.010000  network_time: 0.0107
[ Tue May 16 12:26:14 2023 ] 	Batch(299/480) done. Loss: 0.1393  lr:0.010000  network_time: 0.0108
[ Tue May 16 12:27:04 2023 ] 	Batch(399/480) done. Loss: 0.0299  lr:0.010000  network_time: 0.0107
[ Tue May 16 12:27:45 2023 ] 	Training Accuracy: 95.96%
[ Tue May 16 12:27:45 2023 ] Eval epoch: 21
[ Tue May 16 12:28:02 2023 ] 	Mean test loss of 120 batches: 0.03667508438229561.
[ Tue May 16 12:28:02 2023 ] 	Top1: 99.00%
[ Tue May 16 12:28:02 2023 ] 	Top5: 100.00%
[ Tue May 16 12:28:02 2023 ] Training epoch: 22
[ Tue May 16 12:28:12 2023 ] 	Batch(19/480) done. Loss: 0.0638  lr:0.010000  network_time: 0.0107
[ Tue May 16 12:29:03 2023 ] 	Batch(119/480) done. Loss: 0.0112  lr:0.010000  network_time: 0.0130
[ Tue May 16 12:29:53 2023 ] 	Batch(219/480) done. Loss: 0.0157  lr:0.010000  network_time: 0.0110
[ Tue May 16 12:30:44 2023 ] 	Batch(319/480) done. Loss: 0.0044  lr:0.010000  network_time: 0.0110
[ Tue May 16 12:31:35 2023 ] 	Batch(419/480) done. Loss: 0.2072  lr:0.010000  network_time: 0.0108
[ Tue May 16 12:32:05 2023 ] 	Training Accuracy: 98.38%
[ Tue May 16 12:32:05 2023 ] Eval epoch: 22
[ Tue May 16 12:32:22 2023 ] 	Mean test loss of 120 batches: 0.024716712534427643.
[ Tue May 16 12:32:22 2023 ] 	Top1: 99.83%
[ Tue May 16 12:32:22 2023 ] 	Top5: 100.00%
[ Tue May 16 12:32:22 2023 ] Training epoch: 23
[ Tue May 16 12:32:42 2023 ] 	Batch(39/480) done. Loss: 0.0342  lr:0.010000  network_time: 0.0106
[ Tue May 16 12:33:33 2023 ] 	Batch(139/480) done. Loss: 0.0275  lr:0.010000  network_time: 0.0106
[ Tue May 16 12:34:24 2023 ] 	Batch(239/480) done. Loss: 0.0202  lr:0.010000  network_time: 0.0107
[ Tue May 16 12:35:14 2023 ] 	Batch(339/480) done. Loss: 0.0372  lr:0.010000  network_time: 0.0110
[ Tue May 16 12:36:05 2023 ] 	Batch(439/480) done. Loss: 0.0072  lr:0.010000  network_time: 0.0131
[ Tue May 16 12:36:25 2023 ] 	Training Accuracy: 98.75%
[ Tue May 16 12:36:25 2023 ] Eval epoch: 23
[ Tue May 16 12:36:42 2023 ] 	Mean test loss of 120 batches: 0.024215692654252052.
[ Tue May 16 12:36:42 2023 ] 	Top1: 99.67%
[ Tue May 16 12:36:42 2023 ] 	Top5: 100.00%
[ Tue May 16 12:36:42 2023 ] Training epoch: 24
[ Tue May 16 12:37:13 2023 ] 	Batch(59/480) done. Loss: 0.0061  lr:0.010000  network_time: 0.0108
[ Tue May 16 12:38:03 2023 ] 	Batch(159/480) done. Loss: 0.0326  lr:0.010000  network_time: 0.0106
[ Tue May 16 12:38:54 2023 ] 	Batch(259/480) done. Loss: 0.0043  lr:0.010000  network_time: 0.0112
[ Tue May 16 12:39:45 2023 ] 	Batch(359/480) done. Loss: 0.0051  lr:0.010000  network_time: 0.0111
[ Tue May 16 12:40:35 2023 ] 	Batch(459/480) done. Loss: 0.0020  lr:0.010000  network_time: 0.0109
[ Tue May 16 12:40:45 2023 ] 	Training Accuracy: 98.96%
[ Tue May 16 12:40:45 2023 ] Eval epoch: 24
[ Tue May 16 12:41:02 2023 ] 	Mean test loss of 120 batches: 0.009644429199397564.
[ Tue May 16 12:41:02 2023 ] 	Top1: 100.00%
[ Tue May 16 12:41:03 2023 ] 	Top5: 100.00%
[ Tue May 16 12:41:03 2023 ] Training epoch: 25
[ Tue May 16 12:41:43 2023 ] 	Batch(79/480) done. Loss: 0.0554  lr:0.010000  network_time: 0.0108
[ Tue May 16 12:42:34 2023 ] 	Batch(179/480) done. Loss: 0.0317  lr:0.010000  network_time: 0.0118
[ Tue May 16 12:43:24 2023 ] 	Batch(279/480) done. Loss: 0.0107  lr:0.010000  network_time: 0.0132
[ Tue May 16 12:44:15 2023 ] 	Batch(379/480) done. Loss: 0.0067  lr:0.010000  network_time: 0.0112
[ Tue May 16 12:45:06 2023 ] 	Batch(479/480) done. Loss: 0.0080  lr:0.010000  network_time: 0.0108
[ Tue May 16 12:45:06 2023 ] 	Training Accuracy: 98.83%
[ Tue May 16 12:45:06 2023 ] Eval epoch: 25
[ Tue May 16 12:45:23 2023 ] 	Mean test loss of 120 batches: 0.011756811290979385.
[ Tue May 16 12:45:23 2023 ] 	Top1: 99.83%
[ Tue May 16 12:45:23 2023 ] 	Top5: 100.00%
[ Tue May 16 12:45:23 2023 ] Training epoch: 26
[ Tue May 16 12:46:14 2023 ] 	Batch(99/480) done. Loss: 0.0606  lr:0.001000  network_time: 0.0123
[ Tue May 16 12:47:04 2023 ] 	Batch(199/480) done. Loss: 0.2515  lr:0.001000  network_time: 0.0107
[ Tue May 16 12:47:55 2023 ] 	Batch(299/480) done. Loss: 0.0080  lr:0.001000  network_time: 0.0108
[ Tue May 16 12:48:45 2023 ] 	Batch(399/480) done. Loss: 0.0145  lr:0.001000  network_time: 0.0115
[ Tue May 16 12:49:26 2023 ] 	Training Accuracy: 99.38%
[ Tue May 16 12:49:26 2023 ] Eval epoch: 26
[ Tue May 16 12:49:43 2023 ] 	Mean test loss of 120 batches: 0.012968639843165874.
[ Tue May 16 12:49:43 2023 ] 	Top1: 99.83%
[ Tue May 16 12:49:43 2023 ] 	Top5: 100.00%
[ Tue May 16 12:49:43 2023 ] Training epoch: 27
[ Tue May 16 12:49:53 2023 ] 	Batch(19/480) done. Loss: 0.0067  lr:0.001000  network_time: 0.0138
[ Tue May 16 12:50:44 2023 ] 	Batch(119/480) done. Loss: 0.0097  lr:0.001000  network_time: 0.0109
[ Tue May 16 12:51:35 2023 ] 	Batch(219/480) done. Loss: 0.0260  lr:0.001000  network_time: 0.0110
[ Tue May 16 12:52:26 2023 ] 	Batch(319/480) done. Loss: 0.0022  lr:0.001000  network_time: 0.0132
[ Tue May 16 12:53:16 2023 ] 	Batch(419/480) done. Loss: 0.0252  lr:0.001000  network_time: 0.0105
[ Tue May 16 12:53:47 2023 ] 	Training Accuracy: 99.29%
[ Tue May 16 12:53:47 2023 ] Eval epoch: 27
[ Tue May 16 12:54:04 2023 ] 	Mean test loss of 120 batches: 0.010190651752054691.
[ Tue May 16 12:54:04 2023 ] 	Top1: 100.00%
[ Tue May 16 12:54:04 2023 ] 	Top5: 100.00%
[ Tue May 16 12:54:04 2023 ] Training epoch: 28
[ Tue May 16 12:54:24 2023 ] 	Batch(39/480) done. Loss: 0.0291  lr:0.001000  network_time: 0.0108
[ Tue May 16 12:55:15 2023 ] 	Batch(139/480) done. Loss: 0.0419  lr:0.001000  network_time: 0.0109
[ Tue May 16 12:56:06 2023 ] 	Batch(239/480) done. Loss: 0.0289  lr:0.001000  network_time: 0.0140
[ Tue May 16 12:56:57 2023 ] 	Batch(339/480) done. Loss: 0.1865  lr:0.001000  network_time: 0.0108
[ Tue May 16 12:57:47 2023 ] 	Batch(439/480) done. Loss: 0.0925  lr:0.001000  network_time: 0.0133
[ Tue May 16 12:58:08 2023 ] 	Training Accuracy: 99.08%
[ Tue May 16 12:58:08 2023 ] Eval epoch: 28
[ Tue May 16 12:58:25 2023 ] 	Mean test loss of 120 batches: 0.008104560896754265.
[ Tue May 16 12:58:25 2023 ] 	Top1: 100.00%
[ Tue May 16 12:58:25 2023 ] 	Top5: 100.00%
[ Tue May 16 12:58:25 2023 ] Training epoch: 29
[ Tue May 16 12:58:55 2023 ] 	Batch(59/480) done. Loss: 0.0334  lr:0.001000  network_time: 0.0108
[ Tue May 16 12:59:46 2023 ] 	Batch(159/480) done. Loss: 0.0165  lr:0.001000  network_time: 0.0114
[ Tue May 16 13:00:37 2023 ] 	Batch(259/480) done. Loss: 0.0157  lr:0.001000  network_time: 0.0106
[ Tue May 16 13:01:28 2023 ] 	Batch(359/480) done. Loss: 0.0059  lr:0.001000  network_time: 0.0133
[ Tue May 16 13:02:18 2023 ] 	Batch(459/480) done. Loss: 0.0194  lr:0.001000  network_time: 0.0110
[ Tue May 16 13:02:29 2023 ] 	Training Accuracy: 99.12%
[ Tue May 16 13:02:29 2023 ] Eval epoch: 29
[ Tue May 16 13:02:46 2023 ] 	Mean test loss of 120 batches: 0.007337510585784912.
[ Tue May 16 13:02:46 2023 ] 	Top1: 100.00%
[ Tue May 16 13:02:46 2023 ] 	Top5: 100.00%
[ Tue May 16 13:02:46 2023 ] Training epoch: 30
[ Tue May 16 13:03:26 2023 ] 	Batch(79/480) done. Loss: 0.0037  lr:0.001000  network_time: 0.0106
[ Tue May 16 13:04:17 2023 ] 	Batch(179/480) done. Loss: 0.0101  lr:0.001000  network_time: 0.0109
[ Tue May 16 13:05:08 2023 ] 	Batch(279/480) done. Loss: 0.0162  lr:0.001000  network_time: 0.0107
[ Tue May 16 13:05:59 2023 ] 	Batch(379/480) done. Loss: 0.0339  lr:0.001000  network_time: 0.0109
[ Tue May 16 13:06:49 2023 ] 	Batch(479/480) done. Loss: 0.0145  lr:0.001000  network_time: 0.0108
[ Tue May 16 13:06:49 2023 ] 	Training Accuracy: 99.21%
[ Tue May 16 13:06:49 2023 ] Eval epoch: 30
[ Tue May 16 13:07:06 2023 ] 	Mean test loss of 120 batches: 0.010899114422500134.
[ Tue May 16 13:07:06 2023 ] 	Top1: 99.83%
[ Tue May 16 13:07:06 2023 ] 	Top5: 100.00%
