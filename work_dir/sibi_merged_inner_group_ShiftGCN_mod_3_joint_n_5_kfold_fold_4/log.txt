[ Mon May 15 18:23:03 2023 ] NUM WORKER: 1
[ Mon May 15 19:01:13 2023 ] Parameters:
{'work_dir': './work_dir/sibi_merged_inner_group_ShiftGCN_mod_3_joint_n_5_kfold_fold_4', 'model_saved_name': './save_models/sibi_merged_inner_group_ShiftGCN_mod_3_joint_n_5_kfold_fold_4', 'Experiment_name': 'sibi_merged_inner_group_ShiftGCN_mod_3_joint_n_5_kfold', 'config': './config/recalculated/train_sibi_with_mouth_augmented_merged_inner_group_shift_joint_mod_3.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 2, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'n_splits': 5, 'feeder': 'feeders.feeder_hsd.Feeder', 'num_worker': 1, 'train_feeder_args': {'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': -1, 'normalization': False}, 'test_feeder_args': None, 'data_path': './data/augmented_recalculate_normalized', 'model': 'model.shift_gcn.Model', 'model_args': {'num_class': 50, 'num_person': 1, 'num_point': 115, 'graph_group': [[0, 81], [82, 114]], 'method': 'grouped.inner', 'weight': 3, 'graph': 'graph.skeleton_with_mouth.SkeletonWithMouth', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [20, 25], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 5, 'test_batch_size': 5, 'start_epoch': 0, 'num_epoch': 30, 'folds_range': [3, 5], 'weight_decay': 0.0001, 'only_train_part': True, 'only_train_epoch': 1, 'warm_up_epoch': 0}

[ Mon May 15 19:01:13 2023 ] Training epoch: 1
[ Mon May 15 19:02:06 2023 ] 	Batch(99/480) done. Loss: 3.8240  lr:0.100000  network_time: 0.0108
[ Mon May 15 19:02:57 2023 ] 	Batch(199/480) done. Loss: 3.2281  lr:0.100000  network_time: 0.0107
[ Mon May 15 19:03:48 2023 ] 	Batch(299/480) done. Loss: 3.8500  lr:0.100000  network_time: 0.0108
[ Mon May 15 19:04:39 2023 ] 	Batch(399/480) done. Loss: 3.9645  lr:0.100000  network_time: 0.0105
[ Mon May 15 19:05:19 2023 ] 	Training Accuracy: 6.71%
[ Mon May 15 19:05:19 2023 ] Eval epoch: 1
[ Mon May 15 19:05:36 2023 ] 	Mean test loss of 120 batches: 3.1584365367889404.
[ Mon May 15 19:05:36 2023 ] 	Top1: 12.00%
[ Mon May 15 19:05:36 2023 ] 	Top5: 45.50%
[ Mon May 15 19:05:36 2023 ] Training epoch: 2
[ Mon May 15 19:05:47 2023 ] 	Batch(19/480) done. Loss: 2.9688  lr:0.100000  network_time: 0.0107
[ Mon May 15 19:06:37 2023 ] 	Batch(119/480) done. Loss: 3.5020  lr:0.100000  network_time: 0.0131
[ Mon May 15 19:07:28 2023 ] 	Batch(219/480) done. Loss: 2.7971  lr:0.100000  network_time: 0.0112
[ Mon May 15 19:08:19 2023 ] 	Batch(319/480) done. Loss: 2.6440  lr:0.100000  network_time: 0.0110
[ Mon May 15 19:09:10 2023 ] 	Batch(419/480) done. Loss: 2.5858  lr:0.100000  network_time: 0.0110
[ Mon May 15 19:09:40 2023 ] 	Training Accuracy: 13.62%
[ Mon May 15 19:09:40 2023 ] Eval epoch: 2
[ Mon May 15 19:09:57 2023 ] 	Mean test loss of 120 batches: 3.0417377948760986.
[ Mon May 15 19:09:57 2023 ] 	Top1: 19.33%
[ Mon May 15 19:09:57 2023 ] 	Top5: 53.33%
[ Mon May 15 19:09:57 2023 ] Training epoch: 3
[ Mon May 15 19:10:18 2023 ] 	Batch(39/480) done. Loss: 2.6944  lr:0.100000  network_time: 0.0105
[ Mon May 15 19:11:08 2023 ] 	Batch(139/480) done. Loss: 3.2271  lr:0.100000  network_time: 0.0110
[ Mon May 15 19:11:59 2023 ] 	Batch(239/480) done. Loss: 2.5372  lr:0.100000  network_time: 0.0131
[ Mon May 15 19:12:50 2023 ] 	Batch(339/480) done. Loss: 2.6616  lr:0.100000  network_time: 0.0117
[ Mon May 15 19:13:40 2023 ] 	Batch(439/480) done. Loss: 2.0227  lr:0.100000  network_time: 0.0108
[ Mon May 15 19:14:01 2023 ] 	Training Accuracy: 21.13%
[ Mon May 15 19:14:01 2023 ] Eval epoch: 3
[ Mon May 15 19:14:18 2023 ] 	Mean test loss of 120 batches: 2.3167905807495117.
[ Mon May 15 19:14:18 2023 ] 	Top1: 31.50%
[ Mon May 15 19:14:18 2023 ] 	Top5: 76.83%
[ Mon May 15 19:14:18 2023 ] Training epoch: 4
[ Mon May 15 19:14:49 2023 ] 	Batch(59/480) done. Loss: 2.7851  lr:0.100000  network_time: 0.0132
[ Mon May 15 19:15:39 2023 ] 	Batch(159/480) done. Loss: 1.6739  lr:0.100000  network_time: 0.0151
[ Mon May 15 19:16:30 2023 ] 	Batch(259/480) done. Loss: 2.0074  lr:0.100000  network_time: 0.0107
[ Mon May 15 19:17:21 2023 ] 	Batch(359/480) done. Loss: 1.7647  lr:0.100000  network_time: 0.0109
[ Mon May 15 19:18:12 2023 ] 	Batch(459/480) done. Loss: 2.5166  lr:0.100000  network_time: 0.0131
[ Mon May 15 19:18:22 2023 ] 	Training Accuracy: 31.71%
[ Mon May 15 19:18:22 2023 ] Eval epoch: 4
[ Mon May 15 19:18:39 2023 ] 	Mean test loss of 120 batches: 1.9739402532577515.
[ Mon May 15 19:18:39 2023 ] 	Top1: 44.00%
[ Mon May 15 19:18:39 2023 ] 	Top5: 81.17%
[ Mon May 15 19:18:39 2023 ] Training epoch: 5
[ Mon May 15 19:19:20 2023 ] 	Batch(79/480) done. Loss: 1.7884  lr:0.100000  network_time: 0.0105
[ Mon May 15 19:20:10 2023 ] 	Batch(179/480) done. Loss: 2.1105  lr:0.100000  network_time: 0.0107
[ Mon May 15 19:21:01 2023 ] 	Batch(279/480) done. Loss: 2.8543  lr:0.100000  network_time: 0.0133
[ Mon May 15 19:21:52 2023 ] 	Batch(379/480) done. Loss: 1.2249  lr:0.100000  network_time: 0.0131
[ Mon May 15 19:22:43 2023 ] 	Batch(479/480) done. Loss: 0.7720  lr:0.100000  network_time: 0.0109
[ Mon May 15 19:22:43 2023 ] 	Training Accuracy: 43.12%
[ Mon May 15 19:22:43 2023 ] Eval epoch: 5
[ Mon May 15 19:23:00 2023 ] 	Mean test loss of 120 batches: 1.3226512670516968.
[ Mon May 15 19:23:00 2023 ] 	Top1: 53.50%
[ Mon May 15 19:23:00 2023 ] 	Top5: 93.17%
[ Mon May 15 19:23:00 2023 ] Training epoch: 6
[ Mon May 15 19:23:51 2023 ] 	Batch(99/480) done. Loss: 1.8005  lr:0.100000  network_time: 0.0132
[ Mon May 15 19:24:42 2023 ] 	Batch(199/480) done. Loss: 1.0448  lr:0.100000  network_time: 0.0115
[ Mon May 15 19:25:33 2023 ] 	Batch(299/480) done. Loss: 1.5104  lr:0.100000  network_time: 0.0106
[ Mon May 15 19:26:24 2023 ] 	Batch(399/480) done. Loss: 1.0703  lr:0.100000  network_time: 0.0133
[ Mon May 15 19:27:04 2023 ] 	Training Accuracy: 51.04%
[ Mon May 15 19:27:04 2023 ] Eval epoch: 6
[ Mon May 15 19:27:22 2023 ] 	Mean test loss of 120 batches: 1.4841136932373047.
[ Mon May 15 19:27:22 2023 ] 	Top1: 54.50%
[ Mon May 15 19:27:22 2023 ] 	Top5: 87.00%
[ Mon May 15 19:27:22 2023 ] Training epoch: 7
[ Mon May 15 19:27:32 2023 ] 	Batch(19/480) done. Loss: 1.9383  lr:0.100000  network_time: 0.0129
[ Mon May 15 19:28:23 2023 ] 	Batch(119/480) done. Loss: 1.7801  lr:0.100000  network_time: 0.0104
[ Mon May 15 19:29:14 2023 ] 	Batch(219/480) done. Loss: 1.5921  lr:0.100000  network_time: 0.0107
[ Mon May 15 19:30:05 2023 ] 	Batch(319/480) done. Loss: 0.9484  lr:0.100000  network_time: 0.0109
[ Mon May 15 19:30:55 2023 ] 	Batch(419/480) done. Loss: 1.2667  lr:0.100000  network_time: 0.0105
[ Mon May 15 19:31:26 2023 ] 	Training Accuracy: 59.50%
[ Mon May 15 19:31:26 2023 ] Eval epoch: 7
[ Mon May 15 19:31:43 2023 ] 	Mean test loss of 120 batches: 2.34507417678833.
[ Mon May 15 19:31:43 2023 ] 	Top1: 51.67%
[ Mon May 15 19:31:43 2023 ] 	Top5: 82.33%
[ Mon May 15 19:31:43 2023 ] Training epoch: 8
[ Mon May 15 19:32:03 2023 ] 	Batch(39/480) done. Loss: 0.8960  lr:0.100000  network_time: 0.0105
[ Mon May 15 19:32:54 2023 ] 	Batch(139/480) done. Loss: 0.6611  lr:0.100000  network_time: 0.0136
[ Mon May 15 19:33:45 2023 ] 	Batch(239/480) done. Loss: 2.6107  lr:0.100000  network_time: 0.0116
[ Mon May 15 19:34:36 2023 ] 	Batch(339/480) done. Loss: 0.7265  lr:0.100000  network_time: 0.0130
[ Mon May 15 19:35:26 2023 ] 	Batch(439/480) done. Loss: 0.8017  lr:0.100000  network_time: 0.0130
[ Mon May 15 19:35:47 2023 ] 	Training Accuracy: 66.50%
[ Mon May 15 19:35:47 2023 ] Eval epoch: 8
[ Mon May 15 19:36:04 2023 ] 	Mean test loss of 120 batches: 1.2100247144699097.
[ Mon May 15 19:36:04 2023 ] 	Top1: 61.33%
[ Mon May 15 19:36:04 2023 ] 	Top5: 92.17%
[ Mon May 15 19:36:04 2023 ] Training epoch: 9
[ Mon May 15 19:36:34 2023 ] 	Batch(59/480) done. Loss: 0.4381  lr:0.100000  network_time: 0.0105
[ Mon May 15 19:37:25 2023 ] 	Batch(159/480) done. Loss: 0.5654  lr:0.100000  network_time: 0.0109
[ Mon May 15 19:38:16 2023 ] 	Batch(259/480) done. Loss: 0.2590  lr:0.100000  network_time: 0.0108
[ Mon May 15 19:39:07 2023 ] 	Batch(359/480) done. Loss: 1.5834  lr:0.100000  network_time: 0.0132
[ Mon May 15 19:39:58 2023 ] 	Batch(459/480) done. Loss: 1.7906  lr:0.100000  network_time: 0.0106
[ Mon May 15 19:40:08 2023 ] 	Training Accuracy: 72.21%
[ Mon May 15 19:40:08 2023 ] Eval epoch: 9
[ Mon May 15 19:40:25 2023 ] 	Mean test loss of 120 batches: 0.8374105095863342.
[ Mon May 15 19:40:25 2023 ] 	Top1: 74.17%
[ Mon May 15 19:40:25 2023 ] 	Top5: 98.83%
[ Mon May 15 19:40:25 2023 ] Training epoch: 10
[ Mon May 15 19:41:06 2023 ] 	Batch(79/480) done. Loss: 1.3141  lr:0.100000  network_time: 0.0109
[ Mon May 15 19:41:57 2023 ] 	Batch(179/480) done. Loss: 0.6883  lr:0.100000  network_time: 0.0110
[ Mon May 15 19:42:47 2023 ] 	Batch(279/480) done. Loss: 1.2465  lr:0.100000  network_time: 0.0109
[ Mon May 15 19:43:38 2023 ] 	Batch(379/480) done. Loss: 0.9410  lr:0.100000  network_time: 0.0109
[ Mon May 15 19:44:29 2023 ] 	Batch(479/480) done. Loss: 0.9774  lr:0.100000  network_time: 0.0110
[ Mon May 15 19:44:29 2023 ] 	Training Accuracy: 75.33%
[ Mon May 15 19:44:29 2023 ] Eval epoch: 10
[ Mon May 15 19:44:46 2023 ] 	Mean test loss of 120 batches: 1.00575852394104.
[ Mon May 15 19:44:46 2023 ] 	Top1: 68.00%
[ Mon May 15 19:44:46 2023 ] 	Top5: 95.00%
[ Mon May 15 19:44:46 2023 ] Training epoch: 11
[ Mon May 15 19:45:37 2023 ] 	Batch(99/480) done. Loss: 0.9505  lr:0.100000  network_time: 0.0112
[ Mon May 15 19:46:28 2023 ] 	Batch(199/480) done. Loss: 0.8874  lr:0.100000  network_time: 0.0111
[ Mon May 15 19:47:19 2023 ] 	Batch(299/480) done. Loss: 0.3168  lr:0.100000  network_time: 0.0110
[ Mon May 15 19:48:10 2023 ] 	Batch(399/480) done. Loss: 0.4406  lr:0.100000  network_time: 0.0107
[ Mon May 15 19:48:51 2023 ] 	Training Accuracy: 76.50%
[ Mon May 15 19:48:51 2023 ] Eval epoch: 11
[ Mon May 15 19:49:08 2023 ] 	Mean test loss of 120 batches: 0.535724401473999.
[ Mon May 15 19:49:08 2023 ] 	Top1: 83.50%
[ Mon May 15 19:49:08 2023 ] 	Top5: 98.67%
[ Mon May 15 19:49:08 2023 ] Training epoch: 12
[ Mon May 15 19:49:18 2023 ] 	Batch(19/480) done. Loss: 1.3342  lr:0.100000  network_time: 0.0109
[ Mon May 15 19:50:09 2023 ] 	Batch(119/480) done. Loss: 0.8283  lr:0.100000  network_time: 0.0108
[ Mon May 15 19:51:00 2023 ] 	Batch(219/480) done. Loss: 0.1191  lr:0.100000  network_time: 0.0109
[ Mon May 15 19:51:51 2023 ] 	Batch(319/480) done. Loss: 0.3217  lr:0.100000  network_time: 0.0132
[ Mon May 15 19:52:42 2023 ] 	Batch(419/480) done. Loss: 1.7962  lr:0.100000  network_time: 0.0107
[ Mon May 15 19:53:13 2023 ] 	Training Accuracy: 81.00%
[ Mon May 15 19:53:13 2023 ] Eval epoch: 12
[ Mon May 15 19:53:30 2023 ] 	Mean test loss of 120 batches: 0.935766339302063.
[ Mon May 15 19:53:30 2023 ] 	Top1: 74.33%
[ Mon May 15 19:53:30 2023 ] 	Top5: 97.83%
[ Mon May 15 19:53:30 2023 ] Training epoch: 13
[ Mon May 15 19:53:50 2023 ] 	Batch(39/480) done. Loss: 0.7452  lr:0.100000  network_time: 0.0131
[ Mon May 15 19:54:41 2023 ] 	Batch(139/480) done. Loss: 0.8453  lr:0.100000  network_time: 0.0109
[ Mon May 15 19:55:32 2023 ] 	Batch(239/480) done. Loss: 0.1650  lr:0.100000  network_time: 0.0118
[ Mon May 15 19:56:23 2023 ] 	Batch(339/480) done. Loss: 0.2916  lr:0.100000  network_time: 0.0130
[ Mon May 15 19:57:14 2023 ] 	Batch(439/480) done. Loss: 0.2654  lr:0.100000  network_time: 0.0131
[ Mon May 15 19:57:34 2023 ] 	Training Accuracy: 82.96%
[ Mon May 15 19:57:34 2023 ] Eval epoch: 13
[ Mon May 15 19:57:51 2023 ] 	Mean test loss of 120 batches: 0.510305643081665.
[ Mon May 15 19:57:51 2023 ] 	Top1: 81.50%
[ Mon May 15 19:57:51 2023 ] 	Top5: 99.67%
[ Mon May 15 19:57:51 2023 ] Training epoch: 14
[ Mon May 15 19:58:22 2023 ] 	Batch(59/480) done. Loss: 0.2116  lr:0.100000  network_time: 0.0109
[ Mon May 15 19:59:13 2023 ] 	Batch(159/480) done. Loss: 0.2050  lr:0.100000  network_time: 0.0107
[ Mon May 15 20:00:03 2023 ] 	Batch(259/480) done. Loss: 0.0985  lr:0.100000  network_time: 0.0108
[ Mon May 15 20:00:54 2023 ] 	Batch(359/480) done. Loss: 0.2102  lr:0.100000  network_time: 0.0131
[ Mon May 15 20:01:45 2023 ] 	Batch(459/480) done. Loss: 0.8446  lr:0.100000  network_time: 0.0105
[ Mon May 15 20:01:55 2023 ] 	Training Accuracy: 85.08%
[ Mon May 15 20:01:55 2023 ] Eval epoch: 14
[ Mon May 15 20:02:12 2023 ] 	Mean test loss of 120 batches: 0.32006004452705383.
[ Mon May 15 20:02:12 2023 ] 	Top1: 90.33%
[ Mon May 15 20:02:12 2023 ] 	Top5: 100.00%
[ Mon May 15 20:02:13 2023 ] Training epoch: 15
[ Mon May 15 20:02:53 2023 ] 	Batch(79/480) done. Loss: 1.5814  lr:0.100000  network_time: 0.0106
[ Mon May 15 20:03:44 2023 ] 	Batch(179/480) done. Loss: 0.1576  lr:0.100000  network_time: 0.0110
[ Mon May 15 20:04:35 2023 ] 	Batch(279/480) done. Loss: 0.2955  lr:0.100000  network_time: 0.0105
[ Mon May 15 20:05:26 2023 ] 	Batch(379/480) done. Loss: 0.1428  lr:0.100000  network_time: 0.0133
[ Mon May 15 20:06:17 2023 ] 	Batch(479/480) done. Loss: 0.0439  lr:0.100000  network_time: 0.0127
[ Mon May 15 20:06:17 2023 ] 	Training Accuracy: 86.63%
[ Mon May 15 20:06:17 2023 ] Eval epoch: 15
[ Mon May 15 20:06:34 2023 ] 	Mean test loss of 120 batches: 0.35039833188056946.
[ Mon May 15 20:06:34 2023 ] 	Top1: 88.17%
[ Mon May 15 20:06:34 2023 ] 	Top5: 99.67%
[ Mon May 15 20:06:34 2023 ] Training epoch: 16
[ Mon May 15 20:07:25 2023 ] 	Batch(99/480) done. Loss: 0.8587  lr:0.100000  network_time: 0.0107
[ Mon May 15 20:08:16 2023 ] 	Batch(199/480) done. Loss: 0.5543  lr:0.100000  network_time: 0.0106
[ Mon May 15 20:09:07 2023 ] 	Batch(299/480) done. Loss: 1.6865  lr:0.100000  network_time: 0.0111
[ Mon May 15 20:09:58 2023 ] 	Batch(399/480) done. Loss: 0.1869  lr:0.100000  network_time: 0.0112
[ Mon May 15 20:10:39 2023 ] 	Training Accuracy: 88.08%
[ Mon May 15 20:10:39 2023 ] Eval epoch: 16
[ Mon May 15 20:10:56 2023 ] 	Mean test loss of 120 batches: 0.5926293134689331.
[ Mon May 15 20:10:56 2023 ] 	Top1: 82.67%
[ Mon May 15 20:10:56 2023 ] 	Top5: 97.83%
[ Mon May 15 20:10:56 2023 ] Training epoch: 17
[ Mon May 15 20:11:06 2023 ] 	Batch(19/480) done. Loss: 0.1972  lr:0.100000  network_time: 0.0107
[ Mon May 15 20:11:57 2023 ] 	Batch(119/480) done. Loss: 0.6154  lr:0.100000  network_time: 0.0129
[ Mon May 15 20:12:48 2023 ] 	Batch(219/480) done. Loss: 0.1583  lr:0.100000  network_time: 0.0114
[ Mon May 15 20:13:39 2023 ] 	Batch(319/480) done. Loss: 0.1216  lr:0.100000  network_time: 0.0109
[ Mon May 15 20:14:30 2023 ] 	Batch(419/480) done. Loss: 0.1330  lr:0.100000  network_time: 0.0128
[ Mon May 15 20:15:00 2023 ] 	Training Accuracy: 89.04%
[ Mon May 15 20:15:00 2023 ] Eval epoch: 17
[ Mon May 15 20:15:18 2023 ] 	Mean test loss of 120 batches: 0.27664729952812195.
[ Mon May 15 20:15:18 2023 ] 	Top1: 91.33%
[ Mon May 15 20:15:18 2023 ] 	Top5: 99.83%
[ Mon May 15 20:15:18 2023 ] Training epoch: 18
[ Mon May 15 20:15:38 2023 ] 	Batch(39/480) done. Loss: 0.1233  lr:0.100000  network_time: 0.0129
[ Mon May 15 20:16:29 2023 ] 	Batch(139/480) done. Loss: 1.3550  lr:0.100000  network_time: 0.0135
[ Mon May 15 20:17:20 2023 ] 	Batch(239/480) done. Loss: 0.3913  lr:0.100000  network_time: 0.0107
[ Mon May 15 20:18:11 2023 ] 	Batch(339/480) done. Loss: 0.0255  lr:0.100000  network_time: 0.0107
[ Mon May 15 20:19:02 2023 ] 	Batch(439/480) done. Loss: 0.0978  lr:0.100000  network_time: 0.0106
[ Mon May 15 20:19:22 2023 ] 	Training Accuracy: 89.04%
[ Mon May 15 20:19:22 2023 ] Eval epoch: 18
[ Mon May 15 20:19:40 2023 ] 	Mean test loss of 120 batches: 0.25503650307655334.
[ Mon May 15 20:19:40 2023 ] 	Top1: 93.50%
[ Mon May 15 20:19:40 2023 ] 	Top5: 100.00%
[ Mon May 15 20:19:40 2023 ] Training epoch: 19
[ Mon May 15 20:20:10 2023 ] 	Batch(59/480) done. Loss: 0.0584  lr:0.100000  network_time: 0.0108
[ Mon May 15 20:21:01 2023 ] 	Batch(159/480) done. Loss: 0.4492  lr:0.100000  network_time: 0.0108
[ Mon May 15 20:21:52 2023 ] 	Batch(259/480) done. Loss: 0.4315  lr:0.100000  network_time: 0.0108
[ Mon May 15 20:22:43 2023 ] 	Batch(359/480) done. Loss: 0.0532  lr:0.100000  network_time: 0.0107
[ Mon May 15 20:23:34 2023 ] 	Batch(459/480) done. Loss: 0.2895  lr:0.100000  network_time: 0.0107
[ Mon May 15 20:23:44 2023 ] 	Training Accuracy: 91.17%
[ Mon May 15 20:23:44 2023 ] Eval epoch: 19
[ Mon May 15 20:24:01 2023 ] 	Mean test loss of 120 batches: 0.16714277863502502.
[ Mon May 15 20:24:01 2023 ] 	Top1: 94.17%
[ Mon May 15 20:24:01 2023 ] 	Top5: 100.00%
[ Mon May 15 20:24:01 2023 ] Training epoch: 20
[ Mon May 15 20:24:42 2023 ] 	Batch(79/480) done. Loss: 0.0628  lr:0.100000  network_time: 0.0131
[ Mon May 15 20:25:33 2023 ] 	Batch(179/480) done. Loss: 0.1732  lr:0.100000  network_time: 0.0107
[ Mon May 15 20:26:24 2023 ] 	Batch(279/480) done. Loss: 0.0336  lr:0.100000  network_time: 0.0107
[ Mon May 15 20:27:15 2023 ] 	Batch(379/480) done. Loss: 0.1869  lr:0.100000  network_time: 0.0128
[ Mon May 15 20:28:06 2023 ] 	Batch(479/480) done. Loss: 1.2985  lr:0.100000  network_time: 0.0112
[ Mon May 15 20:28:06 2023 ] 	Training Accuracy: 88.42%
[ Mon May 15 20:28:06 2023 ] Eval epoch: 20
[ Mon May 15 20:28:23 2023 ] 	Mean test loss of 120 batches: 0.371832013130188.
[ Mon May 15 20:28:23 2023 ] 	Top1: 89.83%
[ Mon May 15 20:28:23 2023 ] 	Top5: 99.83%
[ Mon May 15 20:28:23 2023 ] Training epoch: 21
[ Mon May 15 20:29:14 2023 ] 	Batch(99/480) done. Loss: 0.1022  lr:0.010000  network_time: 0.0117
[ Mon May 15 20:30:05 2023 ] 	Batch(199/480) done. Loss: 0.8775  lr:0.010000  network_time: 0.0109
[ Mon May 15 20:30:56 2023 ] 	Batch(299/480) done. Loss: 0.0122  lr:0.010000  network_time: 0.0131
[ Mon May 15 20:31:47 2023 ] 	Batch(399/480) done. Loss: 0.0612  lr:0.010000  network_time: 0.0111
[ Mon May 15 20:32:27 2023 ] 	Training Accuracy: 97.42%
[ Mon May 15 20:32:27 2023 ] Eval epoch: 21
[ Mon May 15 20:32:45 2023 ] 	Mean test loss of 120 batches: 0.028614679351449013.
[ Mon May 15 20:32:45 2023 ] 	Top1: 99.50%
[ Mon May 15 20:32:45 2023 ] 	Top5: 100.00%
[ Mon May 15 20:32:45 2023 ] Training epoch: 22
[ Mon May 15 20:32:55 2023 ] 	Batch(19/480) done. Loss: 0.0157  lr:0.010000  network_time: 0.0132
[ Mon May 15 20:33:46 2023 ] 	Batch(119/480) done. Loss: 0.0256  lr:0.010000  network_time: 0.0131
[ Mon May 15 20:34:37 2023 ] 	Batch(219/480) done. Loss: 0.0144  lr:0.010000  network_time: 0.0129
[ Mon May 15 20:35:28 2023 ] 	Batch(319/480) done. Loss: 0.0142  lr:0.010000  network_time: 0.0107
[ Mon May 15 20:36:19 2023 ] 	Batch(419/480) done. Loss: 0.0148  lr:0.010000  network_time: 0.0109
[ Mon May 15 20:36:49 2023 ] 	Training Accuracy: 98.83%
[ Mon May 15 20:36:49 2023 ] Eval epoch: 22
[ Mon May 15 20:37:06 2023 ] 	Mean test loss of 120 batches: 0.018911754712462425.
[ Mon May 15 20:37:06 2023 ] 	Top1: 99.67%
[ Mon May 15 20:37:06 2023 ] 	Top5: 100.00%
[ Mon May 15 20:37:06 2023 ] Training epoch: 23
[ Mon May 15 20:37:27 2023 ] 	Batch(39/480) done. Loss: 0.0054  lr:0.010000  network_time: 0.0105
[ Mon May 15 20:38:18 2023 ] 	Batch(139/480) done. Loss: 0.0222  lr:0.010000  network_time: 0.0106
[ Mon May 15 20:39:09 2023 ] 	Batch(239/480) done. Loss: 0.0681  lr:0.010000  network_time: 0.0132
[ Mon May 15 20:39:59 2023 ] 	Batch(339/480) done. Loss: 0.0361  lr:0.010000  network_time: 0.0109
[ Mon May 15 20:40:50 2023 ] 	Batch(439/480) done. Loss: 0.0044  lr:0.010000  network_time: 0.0108
[ Mon May 15 20:41:11 2023 ] 	Training Accuracy: 99.21%
[ Mon May 15 20:41:11 2023 ] Eval epoch: 23
[ Mon May 15 20:41:28 2023 ] 	Mean test loss of 120 batches: 0.01669168472290039.
[ Mon May 15 20:41:28 2023 ] 	Top1: 99.67%
[ Mon May 15 20:41:28 2023 ] 	Top5: 100.00%
[ Mon May 15 20:41:28 2023 ] Training epoch: 24
[ Mon May 15 20:41:59 2023 ] 	Batch(59/480) done. Loss: 0.0029  lr:0.010000  network_time: 0.0104
[ Mon May 15 20:42:50 2023 ] 	Batch(159/480) done. Loss: 0.0068  lr:0.010000  network_time: 0.0107
[ Mon May 15 20:43:40 2023 ] 	Batch(259/480) done. Loss: 0.0052  lr:0.010000  network_time: 0.0106
[ Mon May 15 20:44:31 2023 ] 	Batch(359/480) done. Loss: 0.0752  lr:0.010000  network_time: 0.0105
[ Mon May 15 20:45:22 2023 ] 	Batch(459/480) done. Loss: 0.0066  lr:0.010000  network_time: 0.0109
[ Mon May 15 20:45:32 2023 ] 	Training Accuracy: 99.25%
[ Mon May 15 20:45:32 2023 ] Eval epoch: 24
[ Mon May 15 20:45:50 2023 ] 	Mean test loss of 120 batches: 0.021731307730078697.
[ Mon May 15 20:45:50 2023 ] 	Top1: 99.33%
[ Mon May 15 20:45:50 2023 ] 	Top5: 100.00%
[ Mon May 15 20:45:50 2023 ] Training epoch: 25
[ Mon May 15 20:46:30 2023 ] 	Batch(79/480) done. Loss: 0.0205  lr:0.010000  network_time: 0.0104
[ Mon May 15 20:47:21 2023 ] 	Batch(179/480) done. Loss: 0.0072  lr:0.010000  network_time: 0.0130
[ Mon May 15 20:48:12 2023 ] 	Batch(279/480) done. Loss: 0.0033  lr:0.010000  network_time: 0.0133
[ Mon May 15 20:49:03 2023 ] 	Batch(379/480) done. Loss: 0.0150  lr:0.010000  network_time: 0.0107
[ Mon May 15 20:49:54 2023 ] 	Batch(479/480) done. Loss: 0.2813  lr:0.010000  network_time: 0.0123
[ Mon May 15 20:49:54 2023 ] 	Training Accuracy: 99.33%
[ Mon May 15 20:49:54 2023 ] Eval epoch: 25
[ Mon May 15 20:50:11 2023 ] 	Mean test loss of 120 batches: 0.0086293276399374.
[ Mon May 15 20:50:11 2023 ] 	Top1: 100.00%
[ Mon May 15 20:50:11 2023 ] 	Top5: 100.00%
[ Mon May 15 20:50:11 2023 ] Training epoch: 26
[ Mon May 15 20:51:02 2023 ] 	Batch(99/480) done. Loss: 0.0056  lr:0.001000  network_time: 0.0107
[ Mon May 15 20:51:53 2023 ] 	Batch(199/480) done. Loss: 0.4040  lr:0.001000  network_time: 0.0107
[ Mon May 15 20:52:44 2023 ] 	Batch(299/480) done. Loss: 0.0118  lr:0.001000  network_time: 0.0130
[ Mon May 15 20:53:35 2023 ] 	Batch(399/480) done. Loss: 0.0101  lr:0.001000  network_time: 0.0107
[ Mon May 15 20:54:15 2023 ] 	Training Accuracy: 99.46%
[ Mon May 15 20:54:15 2023 ] Eval epoch: 26
[ Mon May 15 20:54:33 2023 ] 	Mean test loss of 120 batches: 0.010145206935703754.
[ Mon May 15 20:54:33 2023 ] 	Top1: 100.00%
[ Mon May 15 20:54:33 2023 ] 	Top5: 100.00%
[ Mon May 15 20:54:33 2023 ] Training epoch: 27
[ Mon May 15 20:54:43 2023 ] 	Batch(19/480) done. Loss: 0.0184  lr:0.001000  network_time: 0.0104
[ Mon May 15 20:55:34 2023 ] 	Batch(119/480) done. Loss: 0.0057  lr:0.001000  network_time: 0.0105
[ Mon May 15 20:56:25 2023 ] 	Batch(219/480) done. Loss: 0.0060  lr:0.001000  network_time: 0.0106
[ Mon May 15 20:57:16 2023 ] 	Batch(319/480) done. Loss: 0.0240  lr:0.001000  network_time: 0.0131
[ Mon May 15 20:58:07 2023 ] 	Batch(419/480) done. Loss: 0.0882  lr:0.001000  network_time: 0.0106
[ Mon May 15 20:58:37 2023 ] 	Training Accuracy: 99.54%
[ Mon May 15 20:58:37 2023 ] Eval epoch: 27
[ Mon May 15 20:58:54 2023 ] 	Mean test loss of 120 batches: 0.010971440002322197.
[ Mon May 15 20:58:54 2023 ] 	Top1: 99.67%
[ Mon May 15 20:58:54 2023 ] 	Top5: 100.00%
[ Mon May 15 20:58:54 2023 ] Training epoch: 28
[ Mon May 15 20:59:15 2023 ] 	Batch(39/480) done. Loss: 0.0107  lr:0.001000  network_time: 0.0107
[ Mon May 15 21:00:06 2023 ] 	Batch(139/480) done. Loss: 0.0331  lr:0.001000  network_time: 0.0106
[ Mon May 15 21:00:57 2023 ] 	Batch(239/480) done. Loss: 0.0481  lr:0.001000  network_time: 0.0107
[ Mon May 15 21:01:48 2023 ] 	Batch(339/480) done. Loss: 0.0551  lr:0.001000  network_time: 0.0107
[ Mon May 15 21:02:39 2023 ] 	Batch(439/480) done. Loss: 0.0192  lr:0.001000  network_time: 0.0107
[ Mon May 15 21:02:59 2023 ] 	Training Accuracy: 99.62%
[ Mon May 15 21:02:59 2023 ] Eval epoch: 28
[ Mon May 15 21:03:16 2023 ] 	Mean test loss of 120 batches: 0.007499442435801029.
[ Mon May 15 21:03:16 2023 ] 	Top1: 100.00%
[ Mon May 15 21:03:16 2023 ] 	Top5: 100.00%
[ Mon May 15 21:03:16 2023 ] Training epoch: 29
[ Mon May 15 21:03:47 2023 ] 	Batch(59/480) done. Loss: 0.0049  lr:0.001000  network_time: 0.0109
[ Mon May 15 21:04:38 2023 ] 	Batch(159/480) done. Loss: 0.0072  lr:0.001000  network_time: 0.0107
[ Mon May 15 21:05:29 2023 ] 	Batch(259/480) done. Loss: 0.0326  lr:0.001000  network_time: 0.0108
[ Mon May 15 21:06:20 2023 ] 	Batch(359/480) done. Loss: 0.0180  lr:0.001000  network_time: 0.0129
[ Mon May 15 21:07:11 2023 ] 	Batch(459/480) done. Loss: 0.0301  lr:0.001000  network_time: 0.0107
[ Mon May 15 21:07:21 2023 ] 	Training Accuracy: 99.37%
[ Mon May 15 21:07:21 2023 ] Eval epoch: 29
[ Mon May 15 21:07:38 2023 ] 	Mean test loss of 120 batches: 0.007223533466458321.
[ Mon May 15 21:07:38 2023 ] 	Top1: 100.00%
[ Mon May 15 21:07:38 2023 ] 	Top5: 100.00%
[ Mon May 15 21:07:39 2023 ] Training epoch: 30
[ Mon May 15 21:08:19 2023 ] 	Batch(79/480) done. Loss: 0.0037  lr:0.001000  network_time: 0.0111
[ Mon May 15 21:09:10 2023 ] 	Batch(179/480) done. Loss: 0.0326  lr:0.001000  network_time: 0.0106
[ Mon May 15 21:10:01 2023 ] 	Batch(279/480) done. Loss: 0.0472  lr:0.001000  network_time: 0.0107
[ Mon May 15 21:10:52 2023 ] 	Batch(379/480) done. Loss: 0.0044  lr:0.001000  network_time: 0.0106
[ Mon May 15 21:11:43 2023 ] 	Batch(479/480) done. Loss: 0.0555  lr:0.001000  network_time: 0.0107
[ Mon May 15 21:11:43 2023 ] 	Training Accuracy: 99.67%
[ Mon May 15 21:11:43 2023 ] Eval epoch: 30
[ Mon May 15 21:12:01 2023 ] 	Mean test loss of 120 batches: 0.007717153988778591.
[ Mon May 15 21:12:01 2023 ] 	Top1: 100.00%
[ Mon May 15 21:12:01 2023 ] 	Top5: 100.00%
