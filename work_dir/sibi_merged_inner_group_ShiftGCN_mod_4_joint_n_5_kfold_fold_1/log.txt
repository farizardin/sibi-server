[ Mon May 15 23:23:19 2023 ] NUM WORKER: 1
[ Mon May 15 23:24:10 2023 ] Parameters:
{'work_dir': './work_dir/sibi_merged_inner_group_ShiftGCN_mod_4_joint_n_5_kfold_fold_1', 'model_saved_name': './save_models/sibi_merged_inner_group_ShiftGCN_mod_4_joint_n_5_kfold_fold_1', 'Experiment_name': 'sibi_merged_inner_group_ShiftGCN_mod_4_joint_n_5_kfold', 'config': './config/recalculated/train_sibi_with_mouth_augmented_merged_inner_group_shift_joint_mod_4.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 2, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'n_splits': 5, 'feeder': 'feeders.feeder_hsd.Feeder', 'num_worker': 1, 'train_feeder_args': {'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': -1, 'normalization': False}, 'test_feeder_args': None, 'data_path': './data/augmented_recalculate_normalized', 'model': 'model.shift_gcn.Model', 'model_args': {'num_class': 50, 'num_person': 1, 'num_point': 115, 'graph_group': [[0, 81], [82, 114]], 'method': 'grouped.inner', 'weight': 4, 'graph': 'graph.skeleton_with_mouth.SkeletonWithMouth', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [20, 25], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 5, 'test_batch_size': 5, 'start_epoch': 0, 'num_epoch': 30, 'folds_range': [0, 5], 'weight_decay': 0.0001, 'only_train_part': True, 'only_train_epoch': 1, 'warm_up_epoch': 0}

[ Mon May 15 23:24:10 2023 ] Training epoch: 1
[ Mon May 15 23:25:02 2023 ] 	Batch(99/480) done. Loss: 3.6840  lr:0.100000  network_time: 0.0105
[ Mon May 15 23:25:52 2023 ] 	Batch(199/480) done. Loss: 3.4474  lr:0.100000  network_time: 0.0128
[ Mon May 15 23:26:42 2023 ] 	Batch(299/480) done. Loss: 3.0020  lr:0.100000  network_time: 0.0143
[ Mon May 15 23:27:33 2023 ] 	Batch(399/480) done. Loss: 3.9419  lr:0.100000  network_time: 0.0105
[ Mon May 15 23:28:13 2023 ] 	Training Accuracy: 5.75%
[ Mon May 15 23:28:13 2023 ] Eval epoch: 1
[ Mon May 15 23:28:30 2023 ] 	Mean test loss of 120 batches: 3.245231866836548.
[ Mon May 15 23:28:30 2023 ] 	Top1: 11.83%
[ Mon May 15 23:28:30 2023 ] 	Top5: 42.83%
[ Mon May 15 23:28:30 2023 ] Training epoch: 2
[ Mon May 15 23:28:40 2023 ] 	Batch(19/480) done. Loss: 2.8003  lr:0.100000  network_time: 0.0107
[ Mon May 15 23:29:30 2023 ] 	Batch(119/480) done. Loss: 3.3084  lr:0.100000  network_time: 0.0128
[ Mon May 15 23:30:21 2023 ] 	Batch(219/480) done. Loss: 2.7143  lr:0.100000  network_time: 0.0131
[ Mon May 15 23:31:11 2023 ] 	Batch(319/480) done. Loss: 2.9643  lr:0.100000  network_time: 0.0106
[ Mon May 15 23:32:01 2023 ] 	Batch(419/480) done. Loss: 2.5263  lr:0.100000  network_time: 0.0104
[ Mon May 15 23:32:32 2023 ] 	Training Accuracy: 16.25%
[ Mon May 15 23:32:32 2023 ] Eval epoch: 2
[ Mon May 15 23:32:49 2023 ] 	Mean test loss of 120 batches: 2.5523529052734375.
[ Mon May 15 23:32:49 2023 ] 	Top1: 27.33%
[ Mon May 15 23:32:49 2023 ] 	Top5: 67.50%
[ Mon May 15 23:32:49 2023 ] Training epoch: 3
[ Mon May 15 23:33:09 2023 ] 	Batch(39/480) done. Loss: 2.4714  lr:0.100000  network_time: 0.0128
[ Mon May 15 23:34:00 2023 ] 	Batch(139/480) done. Loss: 2.8012  lr:0.100000  network_time: 0.0105
[ Mon May 15 23:34:50 2023 ] 	Batch(239/480) done. Loss: 2.0708  lr:0.100000  network_time: 0.0131
[ Mon May 15 23:35:40 2023 ] 	Batch(339/480) done. Loss: 3.0421  lr:0.100000  network_time: 0.0106
[ Mon May 15 23:36:31 2023 ] 	Batch(439/480) done. Loss: 2.0049  lr:0.100000  network_time: 0.0121
[ Mon May 15 23:36:51 2023 ] 	Training Accuracy: 24.75%
[ Mon May 15 23:36:51 2023 ] Eval epoch: 3
[ Mon May 15 23:37:08 2023 ] 	Mean test loss of 120 batches: 2.0593373775482178.
[ Mon May 15 23:37:08 2023 ] 	Top1: 33.17%
[ Mon May 15 23:37:08 2023 ] 	Top5: 80.50%
[ Mon May 15 23:37:08 2023 ] Training epoch: 4
[ Mon May 15 23:37:38 2023 ] 	Batch(59/480) done. Loss: 2.0997  lr:0.100000  network_time: 0.0104
[ Mon May 15 23:38:29 2023 ] 	Batch(159/480) done. Loss: 2.4577  lr:0.100000  network_time: 0.0106
[ Mon May 15 23:39:19 2023 ] 	Batch(259/480) done. Loss: 2.7297  lr:0.100000  network_time: 0.0112
[ Mon May 15 23:40:09 2023 ] 	Batch(359/480) done. Loss: 2.1220  lr:0.100000  network_time: 0.0129
[ Mon May 15 23:41:00 2023 ] 	Batch(459/480) done. Loss: 2.8927  lr:0.100000  network_time: 0.0105
[ Mon May 15 23:41:10 2023 ] 	Training Accuracy: 31.12%
[ Mon May 15 23:41:10 2023 ] Eval epoch: 4
[ Mon May 15 23:41:27 2023 ] 	Mean test loss of 120 batches: 1.8248436450958252.
[ Mon May 15 23:41:27 2023 ] 	Top1: 43.50%
[ Mon May 15 23:41:27 2023 ] 	Top5: 84.33%
[ Mon May 15 23:41:27 2023 ] Training epoch: 5
[ Mon May 15 23:42:07 2023 ] 	Batch(79/480) done. Loss: 1.6264  lr:0.100000  network_time: 0.0130
[ Mon May 15 23:42:57 2023 ] 	Batch(179/480) done. Loss: 1.1900  lr:0.100000  network_time: 0.0106
[ Mon May 15 23:43:48 2023 ] 	Batch(279/480) done. Loss: 2.2347  lr:0.100000  network_time: 0.0106
[ Mon May 15 23:44:38 2023 ] 	Batch(379/480) done. Loss: 1.8458  lr:0.100000  network_time: 0.0106
[ Mon May 15 23:45:28 2023 ] 	Batch(479/480) done. Loss: 1.4120  lr:0.100000  network_time: 0.0106
[ Mon May 15 23:45:28 2023 ] 	Training Accuracy: 35.83%
[ Mon May 15 23:45:28 2023 ] Eval epoch: 5
[ Mon May 15 23:45:46 2023 ] 	Mean test loss of 120 batches: 1.6811256408691406.
[ Mon May 15 23:45:46 2023 ] 	Top1: 46.83%
[ Mon May 15 23:45:46 2023 ] 	Top5: 88.50%
[ Mon May 15 23:45:46 2023 ] Training epoch: 6
[ Mon May 15 23:46:36 2023 ] 	Batch(99/480) done. Loss: 0.9871  lr:0.100000  network_time: 0.0137
[ Mon May 15 23:47:26 2023 ] 	Batch(199/480) done. Loss: 3.8835  lr:0.100000  network_time: 0.0107
[ Mon May 15 23:48:17 2023 ] 	Batch(299/480) done. Loss: 1.5676  lr:0.100000  network_time: 0.0111
[ Mon May 15 23:49:07 2023 ] 	Batch(399/480) done. Loss: 1.9121  lr:0.100000  network_time: 0.0108
[ Mon May 15 23:49:47 2023 ] 	Training Accuracy: 45.46%
[ Mon May 15 23:49:47 2023 ] Eval epoch: 6
[ Mon May 15 23:50:05 2023 ] 	Mean test loss of 120 batches: 1.5535832643508911.
[ Mon May 15 23:50:05 2023 ] 	Top1: 48.00%
[ Mon May 15 23:50:05 2023 ] 	Top5: 87.33%
[ Mon May 15 23:50:05 2023 ] Training epoch: 7
[ Mon May 15 23:50:15 2023 ] 	Batch(19/480) done. Loss: 1.0672  lr:0.100000  network_time: 0.0139
[ Mon May 15 23:51:05 2023 ] 	Batch(119/480) done. Loss: 1.7121  lr:0.100000  network_time: 0.0106
[ Mon May 15 23:51:55 2023 ] 	Batch(219/480) done. Loss: 1.0493  lr:0.100000  network_time: 0.0129
[ Mon May 15 23:52:46 2023 ] 	Batch(319/480) done. Loss: 0.5130  lr:0.100000  network_time: 0.0107
[ Mon May 15 23:53:36 2023 ] 	Batch(419/480) done. Loss: 1.4348  lr:0.100000  network_time: 0.0108
[ Mon May 15 23:54:06 2023 ] 	Training Accuracy: 50.63%
[ Mon May 15 23:54:06 2023 ] Eval epoch: 7
[ Mon May 15 23:54:24 2023 ] 	Mean test loss of 120 batches: 1.6079579591751099.
[ Mon May 15 23:54:24 2023 ] 	Top1: 57.17%
[ Mon May 15 23:54:24 2023 ] 	Top5: 92.17%
[ Mon May 15 23:54:24 2023 ] Training epoch: 8
[ Mon May 15 23:54:44 2023 ] 	Batch(39/480) done. Loss: 1.3147  lr:0.100000  network_time: 0.0117
[ Mon May 15 23:55:34 2023 ] 	Batch(139/480) done. Loss: 1.3796  lr:0.100000  network_time: 0.0108
[ Mon May 15 23:56:25 2023 ] 	Batch(239/480) done. Loss: 4.7249  lr:0.100000  network_time: 0.0104
[ Mon May 15 23:57:15 2023 ] 	Batch(339/480) done. Loss: 0.8202  lr:0.100000  network_time: 0.0107
[ Mon May 15 23:58:06 2023 ] 	Batch(439/480) done. Loss: 1.1063  lr:0.100000  network_time: 0.0106
[ Mon May 15 23:58:26 2023 ] 	Training Accuracy: 58.17%
[ Mon May 15 23:58:26 2023 ] Eval epoch: 8
[ Mon May 15 23:58:43 2023 ] 	Mean test loss of 120 batches: 1.6374536752700806.
[ Mon May 15 23:58:43 2023 ] 	Top1: 46.17%
[ Mon May 15 23:58:43 2023 ] 	Top5: 89.50%
[ Mon May 15 23:58:43 2023 ] Training epoch: 9
[ Mon May 15 23:59:13 2023 ] 	Batch(59/480) done. Loss: 1.0227  lr:0.100000  network_time: 0.0104
[ Tue May 16 00:00:04 2023 ] 	Batch(159/480) done. Loss: 0.5298  lr:0.100000  network_time: 0.0111
[ Tue May 16 00:00:54 2023 ] 	Batch(259/480) done. Loss: 0.7050  lr:0.100000  network_time: 0.0108
[ Tue May 16 00:01:45 2023 ] 	Batch(359/480) done. Loss: 0.8987  lr:0.100000  network_time: 0.0106
[ Tue May 16 00:02:35 2023 ] 	Batch(459/480) done. Loss: 1.1228  lr:0.100000  network_time: 0.0106
[ Tue May 16 00:02:45 2023 ] 	Training Accuracy: 63.96%
[ Tue May 16 00:02:45 2023 ] Eval epoch: 9
[ Tue May 16 00:03:02 2023 ] 	Mean test loss of 120 batches: 1.0115771293640137.
[ Tue May 16 00:03:02 2023 ] 	Top1: 69.33%
[ Tue May 16 00:03:02 2023 ] 	Top5: 96.83%
[ Tue May 16 00:03:02 2023 ] Training epoch: 10
[ Tue May 16 00:03:43 2023 ] 	Batch(79/480) done. Loss: 2.0444  lr:0.100000  network_time: 0.0129
[ Tue May 16 00:04:33 2023 ] 	Batch(179/480) done. Loss: 0.7613  lr:0.100000  network_time: 0.0130
[ Tue May 16 00:05:23 2023 ] 	Batch(279/480) done. Loss: 1.1170  lr:0.100000  network_time: 0.0106
[ Tue May 16 00:06:14 2023 ] 	Batch(379/480) done. Loss: 1.1860  lr:0.100000  network_time: 0.0106
[ Tue May 16 00:07:04 2023 ] 	Batch(479/480) done. Loss: 1.2280  lr:0.100000  network_time: 0.0119
[ Tue May 16 00:07:04 2023 ] 	Training Accuracy: 67.54%
[ Tue May 16 00:07:04 2023 ] Eval epoch: 10
[ Tue May 16 00:07:21 2023 ] 	Mean test loss of 120 batches: 0.9716837406158447.
[ Tue May 16 00:07:22 2023 ] 	Top1: 66.67%
[ Tue May 16 00:07:22 2023 ] 	Top5: 95.17%
[ Tue May 16 00:07:22 2023 ] Training epoch: 11
[ Tue May 16 00:08:12 2023 ] 	Batch(99/480) done. Loss: 1.5320  lr:0.100000  network_time: 0.0103
[ Tue May 16 00:09:02 2023 ] 	Batch(199/480) done. Loss: 0.7012  lr:0.100000  network_time: 0.0109
[ Tue May 16 00:09:53 2023 ] 	Batch(299/480) done. Loss: 0.6903  lr:0.100000  network_time: 0.0132
[ Tue May 16 00:10:43 2023 ] 	Batch(399/480) done. Loss: 0.6435  lr:0.100000  network_time: 0.0130
[ Tue May 16 00:11:24 2023 ] 	Training Accuracy: 71.33%
[ Tue May 16 00:11:24 2023 ] Eval epoch: 11
[ Tue May 16 00:11:41 2023 ] 	Mean test loss of 120 batches: 1.1573959589004517.
[ Tue May 16 00:11:41 2023 ] 	Top1: 66.17%
[ Tue May 16 00:11:41 2023 ] 	Top5: 97.50%
[ Tue May 16 00:11:41 2023 ] Training epoch: 12
[ Tue May 16 00:11:51 2023 ] 	Batch(19/480) done. Loss: 1.9814  lr:0.100000  network_time: 0.0112
[ Tue May 16 00:12:41 2023 ] 	Batch(119/480) done. Loss: 0.3756  lr:0.100000  network_time: 0.0122
[ Tue May 16 00:13:32 2023 ] 	Batch(219/480) done. Loss: 0.3888  lr:0.100000  network_time: 0.0129
[ Tue May 16 00:14:22 2023 ] 	Batch(319/480) done. Loss: 0.5000  lr:0.100000  network_time: 0.0131
[ Tue May 16 00:15:13 2023 ] 	Batch(419/480) done. Loss: 1.1487  lr:0.100000  network_time: 0.0106
[ Tue May 16 00:15:43 2023 ] 	Training Accuracy: 74.67%
[ Tue May 16 00:15:43 2023 ] Eval epoch: 12
[ Tue May 16 00:16:00 2023 ] 	Mean test loss of 120 batches: 0.7345228791236877.
[ Tue May 16 00:16:00 2023 ] 	Top1: 78.17%
[ Tue May 16 00:16:00 2023 ] 	Top5: 97.00%
[ Tue May 16 00:16:00 2023 ] Training epoch: 13
[ Tue May 16 00:16:20 2023 ] 	Batch(39/480) done. Loss: 0.3882  lr:0.100000  network_time: 0.0108
[ Tue May 16 00:17:11 2023 ] 	Batch(139/480) done. Loss: 0.6662  lr:0.100000  network_time: 0.0107
[ Tue May 16 00:18:01 2023 ] 	Batch(239/480) done. Loss: 0.4073  lr:0.100000  network_time: 0.0130
[ Tue May 16 00:18:52 2023 ] 	Batch(339/480) done. Loss: 0.6041  lr:0.100000  network_time: 0.0131
[ Tue May 16 00:19:42 2023 ] 	Batch(439/480) done. Loss: 0.9010  lr:0.100000  network_time: 0.0131
[ Tue May 16 00:20:02 2023 ] 	Training Accuracy: 78.00%
[ Tue May 16 00:20:02 2023 ] Eval epoch: 13
[ Tue May 16 00:20:20 2023 ] 	Mean test loss of 120 batches: 0.5704013705253601.
[ Tue May 16 00:20:20 2023 ] 	Top1: 84.17%
[ Tue May 16 00:20:20 2023 ] 	Top5: 98.17%
[ Tue May 16 00:20:20 2023 ] Training epoch: 14
[ Tue May 16 00:20:50 2023 ] 	Batch(59/480) done. Loss: 1.4485  lr:0.100000  network_time: 0.0116
[ Tue May 16 00:21:40 2023 ] 	Batch(159/480) done. Loss: 0.2966  lr:0.100000  network_time: 0.0114
[ Tue May 16 00:22:31 2023 ] 	Batch(259/480) done. Loss: 0.5665  lr:0.100000  network_time: 0.0130
[ Tue May 16 00:23:21 2023 ] 	Batch(359/480) done. Loss: 0.9872  lr:0.100000  network_time: 0.0106
[ Tue May 16 00:24:12 2023 ] 	Batch(459/480) done. Loss: 0.1642  lr:0.100000  network_time: 0.0105
[ Tue May 16 00:24:22 2023 ] 	Training Accuracy: 79.04%
[ Tue May 16 00:24:22 2023 ] Eval epoch: 14
[ Tue May 16 00:24:39 2023 ] 	Mean test loss of 120 batches: 0.5108106732368469.
[ Tue May 16 00:24:39 2023 ] 	Top1: 84.17%
[ Tue May 16 00:24:39 2023 ] 	Top5: 99.83%
[ Tue May 16 00:24:39 2023 ] Training epoch: 15
[ Tue May 16 00:25:20 2023 ] 	Batch(79/480) done. Loss: 0.1631  lr:0.100000  network_time: 0.0104
[ Tue May 16 00:26:10 2023 ] 	Batch(179/480) done. Loss: 0.2490  lr:0.100000  network_time: 0.0104
[ Tue May 16 00:27:01 2023 ] 	Batch(279/480) done. Loss: 0.3576  lr:0.100000  network_time: 0.0108
[ Tue May 16 00:27:51 2023 ] 	Batch(379/480) done. Loss: 0.8425  lr:0.100000  network_time: 0.0108
[ Tue May 16 00:28:42 2023 ] 	Batch(479/480) done. Loss: 1.1960  lr:0.100000  network_time: 0.0105
[ Tue May 16 00:28:42 2023 ] 	Training Accuracy: 81.63%
[ Tue May 16 00:28:42 2023 ] Eval epoch: 15
[ Tue May 16 00:28:59 2023 ] 	Mean test loss of 120 batches: 0.6951539516448975.
[ Tue May 16 00:28:59 2023 ] 	Top1: 80.33%
[ Tue May 16 00:28:59 2023 ] 	Top5: 97.67%
[ Tue May 16 00:28:59 2023 ] Training epoch: 16
[ Tue May 16 00:29:50 2023 ] 	Batch(99/480) done. Loss: 0.1843  lr:0.100000  network_time: 0.0128
[ Tue May 16 00:30:40 2023 ] 	Batch(199/480) done. Loss: 1.3346  lr:0.100000  network_time: 0.0132
[ Tue May 16 00:31:31 2023 ] 	Batch(299/480) done. Loss: 0.6108  lr:0.100000  network_time: 0.0128
[ Tue May 16 00:32:21 2023 ] 	Batch(399/480) done. Loss: 0.6825  lr:0.100000  network_time: 0.0111
[ Tue May 16 00:33:02 2023 ] 	Training Accuracy: 84.25%
[ Tue May 16 00:33:02 2023 ] Eval epoch: 16
[ Tue May 16 00:33:19 2023 ] 	Mean test loss of 120 batches: 4.390799522399902.
[ Tue May 16 00:33:19 2023 ] 	Top1: 43.67%
[ Tue May 16 00:33:19 2023 ] 	Top5: 76.17%
[ Tue May 16 00:33:19 2023 ] Training epoch: 17
[ Tue May 16 00:33:29 2023 ] 	Batch(19/480) done. Loss: 0.1045  lr:0.100000  network_time: 0.0106
[ Tue May 16 00:34:19 2023 ] 	Batch(119/480) done. Loss: 0.0861  lr:0.100000  network_time: 0.0129
[ Tue May 16 00:35:10 2023 ] 	Batch(219/480) done. Loss: 0.0245  lr:0.100000  network_time: 0.0107
[ Tue May 16 00:36:00 2023 ] 	Batch(319/480) done. Loss: 0.2970  lr:0.100000  network_time: 0.0110
[ Tue May 16 00:36:51 2023 ] 	Batch(419/480) done. Loss: 0.7538  lr:0.100000  network_time: 0.0137
[ Tue May 16 00:37:21 2023 ] 	Training Accuracy: 83.92%
[ Tue May 16 00:37:21 2023 ] Eval epoch: 17
[ Tue May 16 00:37:38 2023 ] 	Mean test loss of 120 batches: 0.5250959396362305.
[ Tue May 16 00:37:38 2023 ] 	Top1: 82.67%
[ Tue May 16 00:37:38 2023 ] 	Top5: 99.67%
[ Tue May 16 00:37:38 2023 ] Training epoch: 18
[ Tue May 16 00:37:59 2023 ] 	Batch(39/480) done. Loss: 0.0763  lr:0.100000  network_time: 0.0130
[ Tue May 16 00:38:49 2023 ] 	Batch(139/480) done. Loss: 0.8377  lr:0.100000  network_time: 0.0129
[ Tue May 16 00:39:40 2023 ] 	Batch(239/480) done. Loss: 0.1355  lr:0.100000  network_time: 0.0130
[ Tue May 16 00:40:30 2023 ] 	Batch(339/480) done. Loss: 0.5041  lr:0.100000  network_time: 0.0108
[ Tue May 16 00:41:21 2023 ] 	Batch(439/480) done. Loss: 0.0951  lr:0.100000  network_time: 0.0107
[ Tue May 16 00:41:41 2023 ] 	Training Accuracy: 85.92%
[ Tue May 16 00:41:41 2023 ] Eval epoch: 18
[ Tue May 16 00:41:58 2023 ] 	Mean test loss of 120 batches: 0.3132639527320862.
[ Tue May 16 00:41:58 2023 ] 	Top1: 89.17%
[ Tue May 16 00:41:58 2023 ] 	Top5: 99.50%
[ Tue May 16 00:41:58 2023 ] Training epoch: 19
[ Tue May 16 00:42:28 2023 ] 	Batch(59/480) done. Loss: 0.1122  lr:0.100000  network_time: 0.0131
[ Tue May 16 00:43:19 2023 ] 	Batch(159/480) done. Loss: 1.0088  lr:0.100000  network_time: 0.0132
[ Tue May 16 00:44:09 2023 ] 	Batch(259/480) done. Loss: 0.2184  lr:0.100000  network_time: 0.0107
[ Tue May 16 00:45:00 2023 ] 	Batch(359/480) done. Loss: 0.0885  lr:0.100000  network_time: 0.0106
[ Tue May 16 00:45:50 2023 ] 	Batch(459/480) done. Loss: 0.8632  lr:0.100000  network_time: 0.0129
[ Tue May 16 00:46:00 2023 ] 	Training Accuracy: 85.42%
[ Tue May 16 00:46:00 2023 ] Eval epoch: 19
[ Tue May 16 00:46:17 2023 ] 	Mean test loss of 120 batches: 0.47286874055862427.
[ Tue May 16 00:46:17 2023 ] 	Top1: 86.50%
[ Tue May 16 00:46:17 2023 ] 	Top5: 98.83%
[ Tue May 16 00:46:18 2023 ] Training epoch: 20
[ Tue May 16 00:46:58 2023 ] 	Batch(79/480) done. Loss: 0.1454  lr:0.100000  network_time: 0.0130
[ Tue May 16 00:47:48 2023 ] 	Batch(179/480) done. Loss: 0.9450  lr:0.100000  network_time: 0.0109
[ Tue May 16 00:48:39 2023 ] 	Batch(279/480) done. Loss: 0.3367  lr:0.100000  network_time: 0.0107
[ Tue May 16 00:49:29 2023 ] 	Batch(379/480) done. Loss: 0.2081  lr:0.100000  network_time: 0.0111
[ Tue May 16 00:50:19 2023 ] 	Batch(479/480) done. Loss: 0.5852  lr:0.100000  network_time: 0.0108
[ Tue May 16 00:50:20 2023 ] 	Training Accuracy: 86.33%
[ Tue May 16 00:50:20 2023 ] Eval epoch: 20
[ Tue May 16 00:50:37 2023 ] 	Mean test loss of 120 batches: 0.36515554785728455.
[ Tue May 16 00:50:37 2023 ] 	Top1: 89.33%
[ Tue May 16 00:50:37 2023 ] 	Top5: 99.00%
[ Tue May 16 00:50:37 2023 ] Training epoch: 21
[ Tue May 16 00:51:27 2023 ] 	Batch(99/480) done. Loss: 0.3534  lr:0.010000  network_time: 0.0107
[ Tue May 16 00:52:18 2023 ] 	Batch(199/480) done. Loss: 0.2249  lr:0.010000  network_time: 0.0132
[ Tue May 16 00:53:08 2023 ] 	Batch(299/480) done. Loss: 0.0793  lr:0.010000  network_time: 0.0131
[ Tue May 16 00:53:59 2023 ] 	Batch(399/480) done. Loss: 0.0136  lr:0.010000  network_time: 0.0105
[ Tue May 16 00:54:39 2023 ] 	Training Accuracy: 95.37%
[ Tue May 16 00:54:39 2023 ] Eval epoch: 21
[ Tue May 16 00:54:56 2023 ] 	Mean test loss of 120 batches: 0.04852555692195892.
[ Tue May 16 00:54:56 2023 ] 	Top1: 98.83%
[ Tue May 16 00:54:56 2023 ] 	Top5: 100.00%
[ Tue May 16 00:54:56 2023 ] Training epoch: 22
[ Tue May 16 00:55:06 2023 ] 	Batch(19/480) done. Loss: 0.0213  lr:0.010000  network_time: 0.0107
[ Tue May 16 00:55:57 2023 ] 	Batch(119/480) done. Loss: 0.1120  lr:0.010000  network_time: 0.0109
[ Tue May 16 00:56:47 2023 ] 	Batch(219/480) done. Loss: 0.0208  lr:0.010000  network_time: 0.0109
[ Tue May 16 00:57:38 2023 ] 	Batch(319/480) done. Loss: 0.0186  lr:0.010000  network_time: 0.0139
[ Tue May 16 00:58:28 2023 ] 	Batch(419/480) done. Loss: 0.0900  lr:0.010000  network_time: 0.0108
[ Tue May 16 00:58:58 2023 ] 	Training Accuracy: 97.92%
[ Tue May 16 00:58:59 2023 ] Eval epoch: 22
[ Tue May 16 00:59:16 2023 ] 	Mean test loss of 120 batches: 0.04518827423453331.
[ Tue May 16 00:59:16 2023 ] 	Top1: 98.50%
[ Tue May 16 00:59:16 2023 ] 	Top5: 100.00%
[ Tue May 16 00:59:16 2023 ] Training epoch: 23
[ Tue May 16 00:59:36 2023 ] 	Batch(39/480) done. Loss: 0.0073  lr:0.010000  network_time: 0.0141
[ Tue May 16 01:00:26 2023 ] 	Batch(139/480) done. Loss: 0.0472  lr:0.010000  network_time: 0.0134
[ Tue May 16 01:01:17 2023 ] 	Batch(239/480) done. Loss: 0.1347  lr:0.010000  network_time: 0.0104
[ Tue May 16 01:02:07 2023 ] 	Batch(339/480) done. Loss: 0.1445  lr:0.010000  network_time: 0.0110
[ Tue May 16 01:02:58 2023 ] 	Batch(439/480) done. Loss: 0.0066  lr:0.010000  network_time: 0.0123
[ Tue May 16 01:03:18 2023 ] 	Training Accuracy: 98.46%
[ Tue May 16 01:03:18 2023 ] Eval epoch: 23
[ Tue May 16 01:03:35 2023 ] 	Mean test loss of 120 batches: 0.03376491740345955.
[ Tue May 16 01:03:35 2023 ] 	Top1: 99.33%
[ Tue May 16 01:03:35 2023 ] 	Top5: 100.00%
[ Tue May 16 01:03:35 2023 ] Training epoch: 24
[ Tue May 16 01:04:05 2023 ] 	Batch(59/480) done. Loss: 0.0195  lr:0.010000  network_time: 0.0147
[ Tue May 16 01:04:56 2023 ] 	Batch(159/480) done. Loss: 0.0950  lr:0.010000  network_time: 0.0103
[ Tue May 16 01:05:46 2023 ] 	Batch(259/480) done. Loss: 0.0361  lr:0.010000  network_time: 0.0108
[ Tue May 16 01:06:37 2023 ] 	Batch(359/480) done. Loss: 0.0068  lr:0.010000  network_time: 0.0105
[ Tue May 16 01:07:27 2023 ] 	Batch(459/480) done. Loss: 0.0074  lr:0.010000  network_time: 0.0115
[ Tue May 16 01:07:37 2023 ] 	Training Accuracy: 98.17%
[ Tue May 16 01:07:37 2023 ] Eval epoch: 24
[ Tue May 16 01:07:54 2023 ] 	Mean test loss of 120 batches: 0.02768607996404171.
[ Tue May 16 01:07:54 2023 ] 	Top1: 99.33%
[ Tue May 16 01:07:54 2023 ] 	Top5: 100.00%
[ Tue May 16 01:07:54 2023 ] Training epoch: 25
[ Tue May 16 01:08:35 2023 ] 	Batch(79/480) done. Loss: 0.1157  lr:0.010000  network_time: 0.0132
[ Tue May 16 01:09:25 2023 ] 	Batch(179/480) done. Loss: 0.0256  lr:0.010000  network_time: 0.0108
[ Tue May 16 01:10:16 2023 ] 	Batch(279/480) done. Loss: 0.0301  lr:0.010000  network_time: 0.0107
[ Tue May 16 01:11:06 2023 ] 	Batch(379/480) done. Loss: 0.0224  lr:0.010000  network_time: 0.0108
[ Tue May 16 01:11:56 2023 ] 	Batch(479/480) done. Loss: 0.0859  lr:0.010000  network_time: 0.0108
[ Tue May 16 01:11:57 2023 ] 	Training Accuracy: 98.71%
[ Tue May 16 01:11:57 2023 ] Eval epoch: 25
[ Tue May 16 01:12:14 2023 ] 	Mean test loss of 120 batches: 0.03568553924560547.
[ Tue May 16 01:12:14 2023 ] 	Top1: 98.67%
[ Tue May 16 01:12:14 2023 ] 	Top5: 100.00%
[ Tue May 16 01:12:14 2023 ] Training epoch: 26
[ Tue May 16 01:13:04 2023 ] 	Batch(99/480) done. Loss: 0.0061  lr:0.001000  network_time: 0.0131
[ Tue May 16 01:13:55 2023 ] 	Batch(199/480) done. Loss: 0.3560  lr:0.001000  network_time: 0.0111
[ Tue May 16 01:14:45 2023 ] 	Batch(299/480) done. Loss: 0.0229  lr:0.001000  network_time: 0.0113
[ Tue May 16 01:15:36 2023 ] 	Batch(399/480) done. Loss: 0.1071  lr:0.001000  network_time: 0.0131
[ Tue May 16 01:16:16 2023 ] 	Training Accuracy: 98.96%
[ Tue May 16 01:16:16 2023 ] Eval epoch: 26
[ Tue May 16 01:16:33 2023 ] 	Mean test loss of 120 batches: 0.0355122908949852.
[ Tue May 16 01:16:33 2023 ] 	Top1: 98.50%
[ Tue May 16 01:16:33 2023 ] 	Top5: 100.00%
[ Tue May 16 01:16:33 2023 ] Training epoch: 27
[ Tue May 16 01:16:43 2023 ] 	Batch(19/480) done. Loss: 0.0435  lr:0.001000  network_time: 0.0143
[ Tue May 16 01:17:33 2023 ] 	Batch(119/480) done. Loss: 0.0096  lr:0.001000  network_time: 0.0104
[ Tue May 16 01:18:24 2023 ] 	Batch(219/480) done. Loss: 0.0632  lr:0.001000  network_time: 0.0104
[ Tue May 16 01:19:14 2023 ] 	Batch(319/480) done. Loss: 0.2714  lr:0.001000  network_time: 0.0147
[ Tue May 16 01:20:05 2023 ] 	Batch(419/480) done. Loss: 0.0096  lr:0.001000  network_time: 0.0106
[ Tue May 16 01:20:35 2023 ] 	Training Accuracy: 99.04%
[ Tue May 16 01:20:35 2023 ] Eval epoch: 27
[ Tue May 16 01:20:52 2023 ] 	Mean test loss of 120 batches: 0.02774018794298172.
[ Tue May 16 01:20:52 2023 ] 	Top1: 99.50%
[ Tue May 16 01:20:52 2023 ] 	Top5: 100.00%
[ Tue May 16 01:20:52 2023 ] Training epoch: 28
[ Tue May 16 01:21:12 2023 ] 	Batch(39/480) done. Loss: 0.0615  lr:0.001000  network_time: 0.0108
[ Tue May 16 01:22:03 2023 ] 	Batch(139/480) done. Loss: 0.1702  lr:0.001000  network_time: 0.0106
[ Tue May 16 01:22:53 2023 ] 	Batch(239/480) done. Loss: 0.0276  lr:0.001000  network_time: 0.0109
[ Tue May 16 01:23:44 2023 ] 	Batch(339/480) done. Loss: 0.3528  lr:0.001000  network_time: 0.0126
[ Tue May 16 01:24:34 2023 ] 	Batch(439/480) done. Loss: 0.0323  lr:0.001000  network_time: 0.0106
[ Tue May 16 01:24:54 2023 ] 	Training Accuracy: 98.83%
[ Tue May 16 01:24:54 2023 ] Eval epoch: 28
[ Tue May 16 01:25:12 2023 ] 	Mean test loss of 120 batches: 0.027270805090665817.
[ Tue May 16 01:25:12 2023 ] 	Top1: 99.17%
[ Tue May 16 01:25:12 2023 ] 	Top5: 100.00%
[ Tue May 16 01:25:12 2023 ] Training epoch: 29
[ Tue May 16 01:25:42 2023 ] 	Batch(59/480) done. Loss: 0.0170  lr:0.001000  network_time: 0.0109
[ Tue May 16 01:26:32 2023 ] 	Batch(159/480) done. Loss: 0.0658  lr:0.001000  network_time: 0.0106
[ Tue May 16 01:27:23 2023 ] 	Batch(259/480) done. Loss: 0.0129  lr:0.001000  network_time: 0.0107
[ Tue May 16 01:28:13 2023 ] 	Batch(359/480) done. Loss: 0.0280  lr:0.001000  network_time: 0.0106
[ Tue May 16 01:29:04 2023 ] 	Batch(459/480) done. Loss: 0.0329  lr:0.001000  network_time: 0.0131
[ Tue May 16 01:29:14 2023 ] 	Training Accuracy: 99.00%
[ Tue May 16 01:29:14 2023 ] Eval epoch: 29
[ Tue May 16 01:29:31 2023 ] 	Mean test loss of 120 batches: 0.025600139051675797.
[ Tue May 16 01:29:31 2023 ] 	Top1: 99.17%
[ Tue May 16 01:29:31 2023 ] 	Top5: 100.00%
[ Tue May 16 01:29:31 2023 ] Training epoch: 30
[ Tue May 16 01:30:11 2023 ] 	Batch(79/480) done. Loss: 0.0040  lr:0.001000  network_time: 0.0109
[ Tue May 16 01:31:02 2023 ] 	Batch(179/480) done. Loss: 0.0416  lr:0.001000  network_time: 0.0132
[ Tue May 16 01:31:52 2023 ] 	Batch(279/480) done. Loss: 0.0600  lr:0.001000  network_time: 0.0112
[ Tue May 16 01:32:43 2023 ] 	Batch(379/480) done. Loss: 0.1119  lr:0.001000  network_time: 0.0109
[ Tue May 16 01:33:33 2023 ] 	Batch(479/480) done. Loss: 0.0086  lr:0.001000  network_time: 0.0131
[ Tue May 16 01:33:33 2023 ] 	Training Accuracy: 99.08%
[ Tue May 16 01:33:33 2023 ] Eval epoch: 30
[ Tue May 16 01:33:50 2023 ] 	Mean test loss of 120 batches: 0.02266770228743553.
[ Tue May 16 01:33:50 2023 ] 	Top1: 99.67%
[ Tue May 16 01:33:50 2023 ] 	Top5: 100.00%
