[ Wed May 17 22:57:46 2023 ] NUM WORKER: 1
[ Wed May 17 22:58:41 2023 ] Parameters:
{'work_dir': './work_dir/sibi_modified_ShiftGCN_mod_3_joint_n_5_kfold_fold_3', 'model_saved_name': './save_models/sibi_modified_ShiftGCN_mod_3_joint_n_5_kfold_fold_3', 'Experiment_name': 'sibi_modified_ShiftGCN_mod_3_joint_n_5_kfold', 'config': './config/recalculated/train_sibi_with_mouth_augmented_modified_shift_joint_mod_3.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 2, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'n_splits': 5, 'feeder': 'feeders.feeder_hsd.Feeder', 'num_worker': 1, 'train_feeder_args': {'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': -1, 'normalization': False}, 'test_feeder_args': None, 'data_path': './data/augmented_recalculate_normalized', 'model': 'model.shift_gcn.Model', 'model_args': {'num_class': 50, 'num_person': 1, 'num_point': 115, 'method': 'modified', 'weight': 3, 'graph': 'graph.skeleton_with_mouth.SkeletonWithMouth', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [20, 25], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 5, 'test_batch_size': 5, 'start_epoch': 0, 'num_epoch': 30, 'folds_range': [0, 5], 'weight_decay': 0.0001, 'only_train_part': True, 'only_train_epoch': 1, 'warm_up_epoch': 0}

[ Wed May 17 22:58:41 2023 ] Training epoch: 1
[ Wed May 17 22:59:30 2023 ] 	Batch(99/480) done. Loss: 3.3501  lr:0.100000  network_time: 0.0113
[ Wed May 17 23:00:18 2023 ] 	Batch(199/480) done. Loss: 3.5221  lr:0.100000  network_time: 0.0118
[ Wed May 17 23:01:07 2023 ] 	Batch(299/480) done. Loss: 3.1250  lr:0.100000  network_time: 0.0112
[ Wed May 17 23:01:55 2023 ] 	Batch(399/480) done. Loss: 3.3989  lr:0.100000  network_time: 0.0112
[ Wed May 17 23:02:34 2023 ] 	Training Accuracy: 7.67%
[ Wed May 17 23:02:34 2023 ] Eval epoch: 1
[ Wed May 17 23:02:50 2023 ] 	Mean test loss of 120 batches: 2.92710018157959.
[ Wed May 17 23:02:50 2023 ] 	Top1: 16.67%
[ Wed May 17 23:02:50 2023 ] 	Top5: 61.33%
[ Wed May 17 23:02:50 2023 ] Training epoch: 2
[ Wed May 17 23:03:00 2023 ] 	Batch(19/480) done. Loss: 3.7750  lr:0.100000  network_time: 0.0122
[ Wed May 17 23:03:49 2023 ] 	Batch(119/480) done. Loss: 2.6646  lr:0.100000  network_time: 0.0114
[ Wed May 17 23:04:37 2023 ] 	Batch(219/480) done. Loss: 3.4136  lr:0.100000  network_time: 0.0117
[ Wed May 17 23:05:26 2023 ] 	Batch(319/480) done. Loss: 2.1512  lr:0.100000  network_time: 0.0115
[ Wed May 17 23:06:15 2023 ] 	Batch(419/480) done. Loss: 3.8659  lr:0.100000  network_time: 0.0111
[ Wed May 17 23:06:44 2023 ] 	Training Accuracy: 18.92%
[ Wed May 17 23:06:44 2023 ] Eval epoch: 2
[ Wed May 17 23:07:00 2023 ] 	Mean test loss of 120 batches: 5.4150214195251465.
[ Wed May 17 23:07:00 2023 ] 	Top1: 19.83%
[ Wed May 17 23:07:00 2023 ] 	Top5: 55.17%
[ Wed May 17 23:07:00 2023 ] Training epoch: 3
[ Wed May 17 23:07:19 2023 ] 	Batch(39/480) done. Loss: 1.9444  lr:0.100000  network_time: 0.0111
[ Wed May 17 23:08:08 2023 ] 	Batch(139/480) done. Loss: 2.5535  lr:0.100000  network_time: 0.0115
[ Wed May 17 23:08:57 2023 ] 	Batch(239/480) done. Loss: 2.2928  lr:0.100000  network_time: 0.0112
[ Wed May 17 23:09:45 2023 ] 	Batch(339/480) done. Loss: 2.6442  lr:0.100000  network_time: 0.0116
[ Wed May 17 23:10:34 2023 ] 	Batch(439/480) done. Loss: 2.2505  lr:0.100000  network_time: 0.0114
[ Wed May 17 23:10:53 2023 ] 	Training Accuracy: 30.42%
[ Wed May 17 23:10:53 2023 ] Eval epoch: 3
[ Wed May 17 23:11:09 2023 ] 	Mean test loss of 120 batches: 3.004986047744751.
[ Wed May 17 23:11:09 2023 ] 	Top1: 29.50%
[ Wed May 17 23:11:09 2023 ] 	Top5: 75.17%
[ Wed May 17 23:11:09 2023 ] Training epoch: 4
[ Wed May 17 23:11:39 2023 ] 	Batch(59/480) done. Loss: 1.3928  lr:0.100000  network_time: 0.0109
[ Wed May 17 23:12:27 2023 ] 	Batch(159/480) done. Loss: 2.7513  lr:0.100000  network_time: 0.0116
[ Wed May 17 23:13:16 2023 ] 	Batch(259/480) done. Loss: 1.5883  lr:0.100000  network_time: 0.0118
[ Wed May 17 23:14:04 2023 ] 	Batch(359/480) done. Loss: 2.9578  lr:0.100000  network_time: 0.0118
[ Wed May 17 23:14:53 2023 ] 	Batch(459/480) done. Loss: 2.1546  lr:0.100000  network_time: 0.0112
[ Wed May 17 23:15:02 2023 ] 	Training Accuracy: 42.62%
[ Wed May 17 23:15:03 2023 ] Eval epoch: 4
[ Wed May 17 23:15:19 2023 ] 	Mean test loss of 120 batches: 1.5321698188781738.
[ Wed May 17 23:15:19 2023 ] 	Top1: 52.17%
[ Wed May 17 23:15:19 2023 ] 	Top5: 93.83%
[ Wed May 17 23:15:19 2023 ] Training epoch: 5
[ Wed May 17 23:15:58 2023 ] 	Batch(79/480) done. Loss: 1.3465  lr:0.100000  network_time: 0.0115
[ Wed May 17 23:16:46 2023 ] 	Batch(179/480) done. Loss: 0.7754  lr:0.100000  network_time: 0.0117
[ Wed May 17 23:17:35 2023 ] 	Batch(279/480) done. Loss: 1.4724  lr:0.100000  network_time: 0.0126
[ Wed May 17 23:18:23 2023 ] 	Batch(379/480) done. Loss: 1.5178  lr:0.100000  network_time: 0.0114
[ Wed May 17 23:19:12 2023 ] 	Batch(479/480) done. Loss: 0.4385  lr:0.100000  network_time: 0.0112
[ Wed May 17 23:19:12 2023 ] 	Training Accuracy: 54.58%
[ Wed May 17 23:19:12 2023 ] Eval epoch: 5
[ Wed May 17 23:19:28 2023 ] 	Mean test loss of 120 batches: 1.4498317241668701.
[ Wed May 17 23:19:28 2023 ] 	Top1: 60.67%
[ Wed May 17 23:19:28 2023 ] 	Top5: 90.17%
[ Wed May 17 23:19:28 2023 ] Training epoch: 6
[ Wed May 17 23:20:17 2023 ] 	Batch(99/480) done. Loss: 1.9269  lr:0.100000  network_time: 0.0119
[ Wed May 17 23:21:05 2023 ] 	Batch(199/480) done. Loss: 0.9065  lr:0.100000  network_time: 0.0115
[ Wed May 17 23:21:54 2023 ] 	Batch(299/480) done. Loss: 1.4356  lr:0.100000  network_time: 0.0119
[ Wed May 17 23:22:42 2023 ] 	Batch(399/480) done. Loss: 0.9588  lr:0.100000  network_time: 0.0114
[ Wed May 17 23:23:21 2023 ] 	Training Accuracy: 64.21%
[ Wed May 17 23:23:21 2023 ] Eval epoch: 6
[ Wed May 17 23:23:38 2023 ] 	Mean test loss of 120 batches: 1.0957412719726562.
[ Wed May 17 23:23:38 2023 ] 	Top1: 66.17%
[ Wed May 17 23:23:38 2023 ] 	Top5: 95.17%
[ Wed May 17 23:23:38 2023 ] Training epoch: 7
[ Wed May 17 23:23:47 2023 ] 	Batch(19/480) done. Loss: 0.4964  lr:0.100000  network_time: 0.0117
[ Wed May 17 23:24:36 2023 ] 	Batch(119/480) done. Loss: 1.4441  lr:0.100000  network_time: 0.0113
[ Wed May 17 23:25:25 2023 ] 	Batch(219/480) done. Loss: 0.9355  lr:0.100000  network_time: 0.0112
[ Wed May 17 23:26:13 2023 ] 	Batch(319/480) done. Loss: 1.0072  lr:0.100000  network_time: 0.0119
[ Wed May 17 23:27:02 2023 ] 	Batch(419/480) done. Loss: 1.9263  lr:0.100000  network_time: 0.0111
[ Wed May 17 23:27:31 2023 ] 	Training Accuracy: 67.83%
[ Wed May 17 23:27:31 2023 ] Eval epoch: 7
[ Wed May 17 23:27:47 2023 ] 	Mean test loss of 120 batches: 0.7321414947509766.
[ Wed May 17 23:27:47 2023 ] 	Top1: 77.00%
[ Wed May 17 23:27:47 2023 ] 	Top5: 98.83%
[ Wed May 17 23:27:47 2023 ] Training epoch: 8
[ Wed May 17 23:28:06 2023 ] 	Batch(39/480) done. Loss: 0.4537  lr:0.100000  network_time: 0.0111
[ Wed May 17 23:28:55 2023 ] 	Batch(139/480) done. Loss: 0.5159  lr:0.100000  network_time: 0.0114
[ Wed May 17 23:29:44 2023 ] 	Batch(239/480) done. Loss: 0.3773  lr:0.100000  network_time: 0.0118
[ Wed May 17 23:30:32 2023 ] 	Batch(339/480) done. Loss: 0.6395  lr:0.100000  network_time: 0.0114
[ Wed May 17 23:31:21 2023 ] 	Batch(439/480) done. Loss: 0.7766  lr:0.100000  network_time: 0.0112
[ Wed May 17 23:31:40 2023 ] 	Training Accuracy: 73.79%
[ Wed May 17 23:31:40 2023 ] Eval epoch: 8
[ Wed May 17 23:31:56 2023 ] 	Mean test loss of 120 batches: 0.5746256709098816.
[ Wed May 17 23:31:56 2023 ] 	Top1: 80.83%
[ Wed May 17 23:31:56 2023 ] 	Top5: 99.83%
[ Wed May 17 23:31:56 2023 ] Training epoch: 9
[ Wed May 17 23:32:26 2023 ] 	Batch(59/480) done. Loss: 0.2491  lr:0.100000  network_time: 0.0110
[ Wed May 17 23:33:14 2023 ] 	Batch(159/480) done. Loss: 0.8310  lr:0.100000  network_time: 0.0114
[ Wed May 17 23:34:03 2023 ] 	Batch(259/480) done. Loss: 0.1745  lr:0.100000  network_time: 0.0117
[ Wed May 17 23:34:51 2023 ] 	Batch(359/480) done. Loss: 0.9723  lr:0.100000  network_time: 0.0113
[ Wed May 17 23:35:40 2023 ] 	Batch(459/480) done. Loss: 0.5050  lr:0.100000  network_time: 0.0115
[ Wed May 17 23:35:50 2023 ] 	Training Accuracy: 76.79%
[ Wed May 17 23:35:50 2023 ] Eval epoch: 9
[ Wed May 17 23:36:06 2023 ] 	Mean test loss of 120 batches: 0.7337414622306824.
[ Wed May 17 23:36:06 2023 ] 	Top1: 79.00%
[ Wed May 17 23:36:06 2023 ] 	Top5: 99.00%
[ Wed May 17 23:36:06 2023 ] Training epoch: 10
[ Wed May 17 23:36:45 2023 ] 	Batch(79/480) done. Loss: 0.0483  lr:0.100000  network_time: 0.0111
[ Wed May 17 23:37:33 2023 ] 	Batch(179/480) done. Loss: 0.7189  lr:0.100000  network_time: 0.0111
[ Wed May 17 23:38:22 2023 ] 	Batch(279/480) done. Loss: 0.2706  lr:0.100000  network_time: 0.0110
[ Wed May 17 23:39:10 2023 ] 	Batch(379/480) done. Loss: 0.2366  lr:0.100000  network_time: 0.0119
[ Wed May 17 23:39:59 2023 ] 	Batch(479/480) done. Loss: 0.8421  lr:0.100000  network_time: 0.0112
[ Wed May 17 23:39:59 2023 ] 	Training Accuracy: 82.50%
[ Wed May 17 23:39:59 2023 ] Eval epoch: 10
[ Wed May 17 23:40:15 2023 ] 	Mean test loss of 120 batches: 0.5046766400337219.
[ Wed May 17 23:40:15 2023 ] 	Top1: 87.67%
[ Wed May 17 23:40:15 2023 ] 	Top5: 99.33%
[ Wed May 17 23:40:15 2023 ] Training epoch: 11
[ Wed May 17 23:41:04 2023 ] 	Batch(99/480) done. Loss: 0.4135  lr:0.100000  network_time: 0.0114
[ Wed May 17 23:41:52 2023 ] 	Batch(199/480) done. Loss: 0.2659  lr:0.100000  network_time: 0.0115
[ Wed May 17 23:42:41 2023 ] 	Batch(299/480) done. Loss: 0.1434  lr:0.100000  network_time: 0.0115
[ Wed May 17 23:43:30 2023 ] 	Batch(399/480) done. Loss: 0.7077  lr:0.100000  network_time: 0.0110
[ Wed May 17 23:44:08 2023 ] 	Training Accuracy: 83.67%
[ Wed May 17 23:44:08 2023 ] Eval epoch: 11
[ Wed May 17 23:44:25 2023 ] 	Mean test loss of 120 batches: 0.3180345594882965.
[ Wed May 17 23:44:25 2023 ] 	Top1: 89.33%
[ Wed May 17 23:44:25 2023 ] 	Top5: 99.83%
[ Wed May 17 23:44:25 2023 ] Training epoch: 12
[ Wed May 17 23:44:34 2023 ] 	Batch(19/480) done. Loss: 0.3151  lr:0.100000  network_time: 0.0112
[ Wed May 17 23:45:23 2023 ] 	Batch(119/480) done. Loss: 0.4334  lr:0.100000  network_time: 0.0115
[ Wed May 17 23:46:12 2023 ] 	Batch(219/480) done. Loss: 0.3986  lr:0.100000  network_time: 0.0109
[ Wed May 17 23:47:00 2023 ] 	Batch(319/480) done. Loss: 0.6899  lr:0.100000  network_time: 0.0115
[ Wed May 17 23:47:49 2023 ] 	Batch(419/480) done. Loss: 0.4831  lr:0.100000  network_time: 0.0117
[ Wed May 17 23:48:18 2023 ] 	Training Accuracy: 86.17%
[ Wed May 17 23:48:18 2023 ] Eval epoch: 12
[ Wed May 17 23:48:34 2023 ] 	Mean test loss of 120 batches: 0.5135270953178406.
[ Wed May 17 23:48:34 2023 ] 	Top1: 84.67%
[ Wed May 17 23:48:34 2023 ] 	Top5: 99.50%
[ Wed May 17 23:48:34 2023 ] Training epoch: 13
[ Wed May 17 23:48:54 2023 ] 	Batch(39/480) done. Loss: 0.1823  lr:0.100000  network_time: 0.0112
[ Wed May 17 23:49:42 2023 ] 	Batch(139/480) done. Loss: 0.0182  lr:0.100000  network_time: 0.0121
[ Wed May 17 23:50:31 2023 ] 	Batch(239/480) done. Loss: 0.1581  lr:0.100000  network_time: 0.0112
[ Wed May 17 23:51:19 2023 ] 	Batch(339/480) done. Loss: 0.5176  lr:0.100000  network_time: 0.0119
[ Wed May 17 23:52:08 2023 ] 	Batch(439/480) done. Loss: 0.0840  lr:0.100000  network_time: 0.0113
[ Wed May 17 23:52:28 2023 ] 	Training Accuracy: 86.33%
[ Wed May 17 23:52:28 2023 ] Eval epoch: 13
[ Wed May 17 23:52:44 2023 ] 	Mean test loss of 120 batches: 0.7887751460075378.
[ Wed May 17 23:52:44 2023 ] 	Top1: 88.50%
[ Wed May 17 23:52:44 2023 ] 	Top5: 99.33%
[ Wed May 17 23:52:44 2023 ] Training epoch: 14
[ Wed May 17 23:53:13 2023 ] 	Batch(59/480) done. Loss: 0.2647  lr:0.100000  network_time: 0.0109
[ Wed May 17 23:54:02 2023 ] 	Batch(159/480) done. Loss: 0.2348  lr:0.100000  network_time: 0.0110
[ Wed May 17 23:54:50 2023 ] 	Batch(259/480) done. Loss: 0.1326  lr:0.100000  network_time: 0.0114
[ Wed May 17 23:55:39 2023 ] 	Batch(359/480) done. Loss: 0.5135  lr:0.100000  network_time: 0.0112
[ Wed May 17 23:56:27 2023 ] 	Batch(459/480) done. Loss: 0.0581  lr:0.100000  network_time: 0.0113
[ Wed May 17 23:56:37 2023 ] 	Training Accuracy: 88.08%
[ Wed May 17 23:56:37 2023 ] Eval epoch: 14
[ Wed May 17 23:56:53 2023 ] 	Mean test loss of 120 batches: 0.5009081363677979.
[ Wed May 17 23:56:53 2023 ] 	Top1: 85.50%
[ Wed May 17 23:56:53 2023 ] 	Top5: 99.67%
[ Wed May 17 23:56:53 2023 ] Training epoch: 15
[ Wed May 17 23:57:32 2023 ] 	Batch(79/480) done. Loss: 0.3742  lr:0.100000  network_time: 0.0110
[ Wed May 17 23:58:21 2023 ] 	Batch(179/480) done. Loss: 0.4826  lr:0.100000  network_time: 0.0118
[ Wed May 17 23:59:09 2023 ] 	Batch(279/480) done. Loss: 0.2865  lr:0.100000  network_time: 0.0112
[ Wed May 17 23:59:58 2023 ] 	Batch(379/480) done. Loss: 0.8430  lr:0.100000  network_time: 0.0112
[ Thu May 18 00:00:47 2023 ] 	Batch(479/480) done. Loss: 0.1928  lr:0.100000  network_time: 0.0124
[ Thu May 18 00:00:47 2023 ] 	Training Accuracy: 87.92%
[ Thu May 18 00:00:47 2023 ] Eval epoch: 15
[ Thu May 18 00:01:03 2023 ] 	Mean test loss of 120 batches: 0.5020100474357605.
[ Thu May 18 00:01:03 2023 ] 	Top1: 84.17%
[ Thu May 18 00:01:03 2023 ] 	Top5: 100.00%
[ Thu May 18 00:01:03 2023 ] Training epoch: 16
[ Thu May 18 00:01:52 2023 ] 	Batch(99/480) done. Loss: 0.0132  lr:0.100000  network_time: 0.0110
[ Thu May 18 00:02:40 2023 ] 	Batch(199/480) done. Loss: 0.4860  lr:0.100000  network_time: 0.0123
[ Thu May 18 00:03:29 2023 ] 	Batch(299/480) done. Loss: 0.2350  lr:0.100000  network_time: 0.0111
[ Thu May 18 00:04:17 2023 ] 	Batch(399/480) done. Loss: 0.4501  lr:0.100000  network_time: 0.0114
[ Thu May 18 00:04:56 2023 ] 	Training Accuracy: 91.50%
[ Thu May 18 00:04:56 2023 ] Eval epoch: 16
[ Thu May 18 00:05:12 2023 ] 	Mean test loss of 120 batches: 0.20536717772483826.
[ Thu May 18 00:05:12 2023 ] 	Top1: 94.00%
[ Thu May 18 00:05:12 2023 ] 	Top5: 99.33%
[ Thu May 18 00:05:12 2023 ] Training epoch: 17
[ Thu May 18 00:05:22 2023 ] 	Batch(19/480) done. Loss: 0.0842  lr:0.100000  network_time: 0.0115
[ Thu May 18 00:06:11 2023 ] 	Batch(119/480) done. Loss: 1.0823  lr:0.100000  network_time: 0.0111
[ Thu May 18 00:06:59 2023 ] 	Batch(219/480) done. Loss: 0.0421  lr:0.100000  network_time: 0.0121
[ Thu May 18 00:07:48 2023 ] 	Batch(319/480) done. Loss: 0.2797  lr:0.100000  network_time: 0.0111
[ Thu May 18 00:08:37 2023 ] 	Batch(419/480) done. Loss: 0.1254  lr:0.100000  network_time: 0.0112
[ Thu May 18 00:09:06 2023 ] 	Training Accuracy: 91.38%
[ Thu May 18 00:09:06 2023 ] Eval epoch: 17
[ Thu May 18 00:09:22 2023 ] 	Mean test loss of 120 batches: 0.9122121334075928.
[ Thu May 18 00:09:22 2023 ] 	Top1: 80.00%
[ Thu May 18 00:09:22 2023 ] 	Top5: 98.67%
[ Thu May 18 00:09:22 2023 ] Training epoch: 18
[ Thu May 18 00:09:41 2023 ] 	Batch(39/480) done. Loss: 0.1531  lr:0.100000  network_time: 0.0111
[ Thu May 18 00:10:30 2023 ] 	Batch(139/480) done. Loss: 0.0219  lr:0.100000  network_time: 0.0120
[ Thu May 18 00:11:19 2023 ] 	Batch(239/480) done. Loss: 0.0865  lr:0.100000  network_time: 0.0113
[ Thu May 18 00:12:07 2023 ] 	Batch(339/480) done. Loss: 0.0457  lr:0.100000  network_time: 0.0112
[ Thu May 18 00:12:56 2023 ] 	Batch(439/480) done. Loss: 0.0502  lr:0.100000  network_time: 0.0118
[ Thu May 18 00:13:15 2023 ] 	Training Accuracy: 89.96%
[ Thu May 18 00:13:15 2023 ] Eval epoch: 18
[ Thu May 18 00:13:31 2023 ] 	Mean test loss of 120 batches: 0.15819033980369568.
[ Thu May 18 00:13:31 2023 ] 	Top1: 94.83%
[ Thu May 18 00:13:31 2023 ] 	Top5: 99.67%
[ Thu May 18 00:13:31 2023 ] Training epoch: 19
[ Thu May 18 00:14:01 2023 ] 	Batch(59/480) done. Loss: 0.0427  lr:0.100000  network_time: 0.0112
[ Thu May 18 00:14:49 2023 ] 	Batch(159/480) done. Loss: 0.4690  lr:0.100000  network_time: 0.0110
[ Thu May 18 00:15:38 2023 ] 	Batch(259/480) done. Loss: 0.0586  lr:0.100000  network_time: 0.0109
[ Thu May 18 00:16:26 2023 ] 	Batch(359/480) done. Loss: 0.5942  lr:0.100000  network_time: 0.0110
[ Thu May 18 00:17:15 2023 ] 	Batch(459/480) done. Loss: 0.0828  lr:0.100000  network_time: 0.0116
[ Thu May 18 00:17:25 2023 ] 	Training Accuracy: 90.83%
[ Thu May 18 00:17:25 2023 ] Eval epoch: 19
[ Thu May 18 00:17:41 2023 ] 	Mean test loss of 120 batches: 0.2684800922870636.
[ Thu May 18 00:17:41 2023 ] 	Top1: 93.00%
[ Thu May 18 00:17:41 2023 ] 	Top5: 99.67%
[ Thu May 18 00:17:41 2023 ] Training epoch: 20
[ Thu May 18 00:18:20 2023 ] 	Batch(79/480) done. Loss: 0.0308  lr:0.100000  network_time: 0.0116
[ Thu May 18 00:19:09 2023 ] 	Batch(179/480) done. Loss: 0.6172  lr:0.100000  network_time: 0.0112
[ Thu May 18 00:19:57 2023 ] 	Batch(279/480) done. Loss: 0.1244  lr:0.100000  network_time: 0.0113
[ Thu May 18 00:20:46 2023 ] 	Batch(379/480) done. Loss: 0.0471  lr:0.100000  network_time: 0.0111
[ Thu May 18 00:21:34 2023 ] 	Batch(479/480) done. Loss: 1.1737  lr:0.100000  network_time: 0.0116
[ Thu May 18 00:21:34 2023 ] 	Training Accuracy: 92.29%
[ Thu May 18 00:21:34 2023 ] Eval epoch: 20
[ Thu May 18 00:21:51 2023 ] 	Mean test loss of 120 batches: 0.18193092942237854.
[ Thu May 18 00:21:51 2023 ] 	Top1: 94.33%
[ Thu May 18 00:21:51 2023 ] 	Top5: 100.00%
[ Thu May 18 00:21:51 2023 ] Training epoch: 21
[ Thu May 18 00:22:39 2023 ] 	Batch(99/480) done. Loss: 0.1498  lr:0.010000  network_time: 0.0111
[ Thu May 18 00:23:28 2023 ] 	Batch(199/480) done. Loss: 0.0199  lr:0.010000  network_time: 0.0116
[ Thu May 18 00:24:17 2023 ] 	Batch(299/480) done. Loss: 0.0146  lr:0.010000  network_time: 0.0123
[ Thu May 18 00:25:05 2023 ] 	Batch(399/480) done. Loss: 0.0138  lr:0.010000  network_time: 0.0112
[ Thu May 18 00:25:44 2023 ] 	Training Accuracy: 98.62%
[ Thu May 18 00:25:44 2023 ] Eval epoch: 21
[ Thu May 18 00:26:00 2023 ] 	Mean test loss of 120 batches: 0.011528704315423965.
[ Thu May 18 00:26:00 2023 ] 	Top1: 99.50%
[ Thu May 18 00:26:00 2023 ] 	Top5: 100.00%
[ Thu May 18 00:26:00 2023 ] Training epoch: 22
[ Thu May 18 00:26:10 2023 ] 	Batch(19/480) done. Loss: 0.0180  lr:0.010000  network_time: 0.0113
[ Thu May 18 00:26:59 2023 ] 	Batch(119/480) done. Loss: 0.1538  lr:0.010000  network_time: 0.0112
[ Thu May 18 00:27:47 2023 ] 	Batch(219/480) done. Loss: 0.1960  lr:0.010000  network_time: 0.0113
[ Thu May 18 00:28:36 2023 ] 	Batch(319/480) done. Loss: 0.0858  lr:0.010000  network_time: 0.0117
[ Thu May 18 00:29:24 2023 ] 	Batch(419/480) done. Loss: 0.0039  lr:0.010000  network_time: 0.0112
[ Thu May 18 00:29:54 2023 ] 	Training Accuracy: 99.25%
[ Thu May 18 00:29:54 2023 ] Eval epoch: 22
[ Thu May 18 00:30:10 2023 ] 	Mean test loss of 120 batches: 0.025058560073375702.
[ Thu May 18 00:30:10 2023 ] 	Top1: 99.50%
[ Thu May 18 00:30:10 2023 ] 	Top5: 100.00%
[ Thu May 18 00:30:10 2023 ] Training epoch: 23
[ Thu May 18 00:30:29 2023 ] 	Batch(39/480) done. Loss: 0.0069  lr:0.010000  network_time: 0.0116
[ Thu May 18 00:31:18 2023 ] 	Batch(139/480) done. Loss: 0.0109  lr:0.010000  network_time: 0.0127
[ Thu May 18 00:32:07 2023 ] 	Batch(239/480) done. Loss: 0.0041  lr:0.010000  network_time: 0.0111
[ Thu May 18 00:32:55 2023 ] 	Batch(339/480) done. Loss: 0.0151  lr:0.010000  network_time: 0.0121
[ Thu May 18 00:33:44 2023 ] 	Batch(439/480) done. Loss: 0.0075  lr:0.010000  network_time: 0.0116
[ Thu May 18 00:34:03 2023 ] 	Training Accuracy: 99.50%
[ Thu May 18 00:34:03 2023 ] Eval epoch: 23
[ Thu May 18 00:34:20 2023 ] 	Mean test loss of 120 batches: 0.02838173322379589.
[ Thu May 18 00:34:20 2023 ] 	Top1: 99.33%
[ Thu May 18 00:34:20 2023 ] 	Top5: 100.00%
[ Thu May 18 00:34:20 2023 ] Training epoch: 24
[ Thu May 18 00:34:49 2023 ] 	Batch(59/480) done. Loss: 0.0056  lr:0.010000  network_time: 0.0112
[ Thu May 18 00:35:37 2023 ] 	Batch(159/480) done. Loss: 0.0071  lr:0.010000  network_time: 0.0114
[ Thu May 18 00:36:26 2023 ] 	Batch(259/480) done. Loss: 0.0042  lr:0.010000  network_time: 0.0111
[ Thu May 18 00:37:15 2023 ] 	Batch(359/480) done. Loss: 0.0166  lr:0.010000  network_time: 0.0110
[ Thu May 18 00:38:03 2023 ] 	Batch(459/480) done. Loss: 0.0149  lr:0.010000  network_time: 0.0112
[ Thu May 18 00:38:13 2023 ] 	Training Accuracy: 99.58%
[ Thu May 18 00:38:13 2023 ] Eval epoch: 24
[ Thu May 18 00:38:29 2023 ] 	Mean test loss of 120 batches: 0.004653178155422211.
[ Thu May 18 00:38:29 2023 ] 	Top1: 100.00%
[ Thu May 18 00:38:29 2023 ] 	Top5: 100.00%
[ Thu May 18 00:38:29 2023 ] Training epoch: 25
[ Thu May 18 00:39:08 2023 ] 	Batch(79/480) done. Loss: 0.0483  lr:0.010000  network_time: 0.0111
[ Thu May 18 00:39:57 2023 ] 	Batch(179/480) done. Loss: 0.0025  lr:0.010000  network_time: 0.0113
[ Thu May 18 00:40:45 2023 ] 	Batch(279/480) done. Loss: 0.0029  lr:0.010000  network_time: 0.0110
[ Thu May 18 00:41:34 2023 ] 	Batch(379/480) done. Loss: 0.0116  lr:0.010000  network_time: 0.0110
[ Thu May 18 00:42:23 2023 ] 	Batch(479/480) done. Loss: 0.0215  lr:0.010000  network_time: 0.0115
[ Thu May 18 00:42:23 2023 ] 	Training Accuracy: 99.75%
[ Thu May 18 00:42:23 2023 ] Eval epoch: 25
[ Thu May 18 00:42:39 2023 ] 	Mean test loss of 120 batches: 0.007010399363934994.
[ Thu May 18 00:42:39 2023 ] 	Top1: 99.50%
[ Thu May 18 00:42:39 2023 ] 	Top5: 100.00%
[ Thu May 18 00:42:39 2023 ] Training epoch: 26
[ Thu May 18 00:43:28 2023 ] 	Batch(99/480) done. Loss: 0.0167  lr:0.001000  network_time: 0.0114
[ Thu May 18 00:44:16 2023 ] 	Batch(199/480) done. Loss: 0.0186  lr:0.001000  network_time: 0.0114
[ Thu May 18 00:45:05 2023 ] 	Batch(299/480) done. Loss: 0.0043  lr:0.001000  network_time: 0.0111
[ Thu May 18 00:45:54 2023 ] 	Batch(399/480) done. Loss: 0.0057  lr:0.001000  network_time: 0.0111
[ Thu May 18 00:46:33 2023 ] 	Training Accuracy: 99.75%
[ Thu May 18 00:46:33 2023 ] Eval epoch: 26
[ Thu May 18 00:46:49 2023 ] 	Mean test loss of 120 batches: 0.00923840794712305.
[ Thu May 18 00:46:49 2023 ] 	Top1: 99.50%
[ Thu May 18 00:46:49 2023 ] 	Top5: 100.00%
[ Thu May 18 00:46:49 2023 ] Training epoch: 27
[ Thu May 18 00:46:59 2023 ] 	Batch(19/480) done. Loss: 0.0141  lr:0.001000  network_time: 0.0111
[ Thu May 18 00:47:47 2023 ] 	Batch(119/480) done. Loss: 0.0017  lr:0.001000  network_time: 0.0110
[ Thu May 18 00:48:36 2023 ] 	Batch(219/480) done. Loss: 0.0027  lr:0.001000  network_time: 0.0117
[ Thu May 18 00:49:24 2023 ] 	Batch(319/480) done. Loss: 0.1323  lr:0.001000  network_time: 0.0112
[ Thu May 18 00:50:13 2023 ] 	Batch(419/480) done. Loss: 0.0044  lr:0.001000  network_time: 0.0111
[ Thu May 18 00:50:42 2023 ] 	Training Accuracy: 99.58%
[ Thu May 18 00:50:42 2023 ] Eval epoch: 27
[ Thu May 18 00:50:58 2023 ] 	Mean test loss of 120 batches: 0.00736469030380249.
[ Thu May 18 00:50:58 2023 ] 	Top1: 99.83%
[ Thu May 18 00:50:58 2023 ] 	Top5: 100.00%
[ Thu May 18 00:50:58 2023 ] Training epoch: 28
[ Thu May 18 00:51:18 2023 ] 	Batch(39/480) done. Loss: 0.0109  lr:0.001000  network_time: 0.0111
[ Thu May 18 00:52:06 2023 ] 	Batch(139/480) done. Loss: 0.0145  lr:0.001000  network_time: 0.0110
[ Thu May 18 00:52:55 2023 ] 	Batch(239/480) done. Loss: 0.0185  lr:0.001000  network_time: 0.0118
[ Thu May 18 00:53:44 2023 ] 	Batch(339/480) done. Loss: 0.0348  lr:0.001000  network_time: 0.0115
[ Thu May 18 00:54:32 2023 ] 	Batch(439/480) done. Loss: 0.0467  lr:0.001000  network_time: 0.0113
[ Thu May 18 00:54:52 2023 ] 	Training Accuracy: 99.79%
[ Thu May 18 00:54:52 2023 ] Eval epoch: 28
[ Thu May 18 00:55:08 2023 ] 	Mean test loss of 120 batches: 0.00802118144929409.
[ Thu May 18 00:55:08 2023 ] 	Top1: 99.50%
[ Thu May 18 00:55:08 2023 ] 	Top5: 100.00%
[ Thu May 18 00:55:08 2023 ] Training epoch: 29
[ Thu May 18 00:55:37 2023 ] 	Batch(59/480) done. Loss: 0.0077  lr:0.001000  network_time: 0.0113
[ Thu May 18 00:56:26 2023 ] 	Batch(159/480) done. Loss: 0.0331  lr:0.001000  network_time: 0.0116
[ Thu May 18 00:57:14 2023 ] 	Batch(259/480) done. Loss: 0.0306  lr:0.001000  network_time: 0.0116
[ Thu May 18 00:58:03 2023 ] 	Batch(359/480) done. Loss: 0.0021  lr:0.001000  network_time: 0.0113
[ Thu May 18 00:58:52 2023 ] 	Batch(459/480) done. Loss: 0.0101  lr:0.001000  network_time: 0.0139
[ Thu May 18 00:59:01 2023 ] 	Training Accuracy: 99.58%
[ Thu May 18 00:59:01 2023 ] Eval epoch: 29
[ Thu May 18 00:59:18 2023 ] 	Mean test loss of 120 batches: 0.007241792511194944.
[ Thu May 18 00:59:18 2023 ] 	Top1: 99.50%
[ Thu May 18 00:59:18 2023 ] 	Top5: 100.00%
[ Thu May 18 00:59:18 2023 ] Training epoch: 30
[ Thu May 18 00:59:57 2023 ] 	Batch(79/480) done. Loss: 0.0051  lr:0.001000  network_time: 0.0118
[ Thu May 18 01:00:45 2023 ] 	Batch(179/480) done. Loss: 0.0126  lr:0.001000  network_time: 0.0111
[ Thu May 18 01:01:34 2023 ] 	Batch(279/480) done. Loss: 0.0207  lr:0.001000  network_time: 0.0113
[ Thu May 18 01:02:22 2023 ] 	Batch(379/480) done. Loss: 0.0149  lr:0.001000  network_time: 0.0114
[ Thu May 18 01:03:11 2023 ] 	Batch(479/480) done. Loss: 0.0121  lr:0.001000  network_time: 0.0116
[ Thu May 18 01:03:11 2023 ] 	Training Accuracy: 99.67%
[ Thu May 18 01:03:11 2023 ] Eval epoch: 30
[ Thu May 18 01:03:27 2023 ] 	Mean test loss of 120 batches: 0.0027324180118739605.
[ Thu May 18 01:03:27 2023 ] 	Top1: 100.00%
[ Thu May 18 01:03:27 2023 ] 	Top5: 100.00%
