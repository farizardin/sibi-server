[ Thu May 18 08:22:05 2023 ] NUM WORKER: 1
[ Thu May 18 08:25:01 2023 ] Parameters:
{'work_dir': './work_dir/sibi_modified_ShiftGCN_mod_4_joint_n_5_kfold_fold_4', 'model_saved_name': './save_models/sibi_modified_ShiftGCN_mod_4_joint_n_5_kfold_fold_4', 'Experiment_name': 'sibi_modified_ShiftGCN_mod_4_joint_n_5_kfold', 'config': './config/recalculated/train_sibi_with_mouth_augmented_modified_shift_joint_mod_4.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 2, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'n_splits': 5, 'feeder': 'feeders.feeder_hsd.Feeder', 'num_worker': 1, 'train_feeder_args': {'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': -1, 'normalization': False}, 'test_feeder_args': None, 'data_path': './data/augmented_recalculate_normalized', 'model': 'model.shift_gcn.Model', 'model_args': {'num_class': 50, 'num_person': 1, 'num_point': 115, 'method': 'modified', 'weight': 4, 'graph': 'graph.skeleton_with_mouth.SkeletonWithMouth', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [20, 25], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 5, 'test_batch_size': 5, 'start_epoch': 0, 'num_epoch': 30, 'folds_range': [3, 5], 'weight_decay': 0.0001, 'only_train_part': True, 'only_train_epoch': 1, 'warm_up_epoch': 0}

[ Thu May 18 08:25:01 2023 ] Training epoch: 1
[ Thu May 18 08:25:51 2023 ] 	Batch(99/480) done. Loss: 3.5810  lr:0.100000  network_time: 0.0116
[ Thu May 18 08:26:42 2023 ] 	Batch(199/480) done. Loss: 3.2828  lr:0.100000  network_time: 0.0113
[ Thu May 18 08:27:33 2023 ] 	Batch(299/480) done. Loss: 3.4141  lr:0.100000  network_time: 0.0110
[ Thu May 18 08:28:24 2023 ] 	Batch(399/480) done. Loss: 4.1704  lr:0.100000  network_time: 0.0114
[ Thu May 18 08:29:04 2023 ] 	Training Accuracy: 6.17%
[ Thu May 18 08:29:04 2023 ] Eval epoch: 1
[ Thu May 18 08:29:21 2023 ] 	Mean test loss of 120 batches: 3.1657333374023438.
[ Thu May 18 08:29:21 2023 ] 	Top1: 11.50%
[ Thu May 18 08:29:21 2023 ] 	Top5: 46.33%
[ Thu May 18 08:29:21 2023 ] Training epoch: 2
[ Thu May 18 08:29:32 2023 ] 	Batch(19/480) done. Loss: 3.1461  lr:0.100000  network_time: 0.0119
[ Thu May 18 08:30:22 2023 ] 	Batch(119/480) done. Loss: 3.3879  lr:0.100000  network_time: 0.0114
[ Thu May 18 08:31:13 2023 ] 	Batch(219/480) done. Loss: 2.7975  lr:0.100000  network_time: 0.0115
[ Thu May 18 08:32:04 2023 ] 	Batch(319/480) done. Loss: 2.9479  lr:0.100000  network_time: 0.0113
[ Thu May 18 08:32:54 2023 ] 	Batch(419/480) done. Loss: 2.3056  lr:0.100000  network_time: 0.0121
[ Thu May 18 08:33:25 2023 ] 	Training Accuracy: 15.92%
[ Thu May 18 08:33:25 2023 ] Eval epoch: 2
[ Thu May 18 08:33:42 2023 ] 	Mean test loss of 120 batches: 2.535853147506714.
[ Thu May 18 08:33:42 2023 ] 	Top1: 24.83%
[ Thu May 18 08:33:42 2023 ] 	Top5: 66.50%
[ Thu May 18 08:33:42 2023 ] Training epoch: 3
[ Thu May 18 08:34:02 2023 ] 	Batch(39/480) done. Loss: 2.6714  lr:0.100000  network_time: 0.0113
[ Thu May 18 08:34:53 2023 ] 	Batch(139/480) done. Loss: 2.5013  lr:0.100000  network_time: 0.0117
[ Thu May 18 08:35:44 2023 ] 	Batch(239/480) done. Loss: 2.0783  lr:0.100000  network_time: 0.0109
[ Thu May 18 08:36:34 2023 ] 	Batch(339/480) done. Loss: 2.2130  lr:0.100000  network_time: 0.0110
[ Thu May 18 08:37:25 2023 ] 	Batch(439/480) done. Loss: 1.2597  lr:0.100000  network_time: 0.0118
[ Thu May 18 08:37:45 2023 ] 	Training Accuracy: 27.75%
[ Thu May 18 08:37:45 2023 ] Eval epoch: 3
[ Thu May 18 08:38:02 2023 ] 	Mean test loss of 120 batches: 1.8255393505096436.
[ Thu May 18 08:38:02 2023 ] 	Top1: 45.00%
[ Thu May 18 08:38:02 2023 ] 	Top5: 82.00%
[ Thu May 18 08:38:02 2023 ] Training epoch: 4
[ Thu May 18 08:38:33 2023 ] 	Batch(59/480) done. Loss: 2.5420  lr:0.100000  network_time: 0.0114
[ Thu May 18 08:39:24 2023 ] 	Batch(159/480) done. Loss: 1.7249  lr:0.100000  network_time: 0.0109
[ Thu May 18 08:40:14 2023 ] 	Batch(259/480) done. Loss: 2.3202  lr:0.100000  network_time: 0.0111
[ Thu May 18 08:41:05 2023 ] 	Batch(359/480) done. Loss: 1.4223  lr:0.100000  network_time: 0.0114
[ Thu May 18 08:41:56 2023 ] 	Batch(459/480) done. Loss: 2.7594  lr:0.100000  network_time: 0.0120
[ Thu May 18 08:42:06 2023 ] 	Training Accuracy: 39.71%
[ Thu May 18 08:42:06 2023 ] Eval epoch: 4
[ Thu May 18 08:42:23 2023 ] 	Mean test loss of 120 batches: 2.5152244567871094.
[ Thu May 18 08:42:23 2023 ] 	Top1: 32.17%
[ Thu May 18 08:42:23 2023 ] 	Top5: 79.17%
[ Thu May 18 08:42:23 2023 ] Training epoch: 5
[ Thu May 18 08:43:04 2023 ] 	Batch(79/480) done. Loss: 0.9542  lr:0.100000  network_time: 0.0113
[ Thu May 18 08:43:54 2023 ] 	Batch(179/480) done. Loss: 1.2665  lr:0.100000  network_time: 0.0109
[ Thu May 18 08:44:45 2023 ] 	Batch(279/480) done. Loss: 1.9333  lr:0.100000  network_time: 0.0113
[ Thu May 18 08:45:36 2023 ] 	Batch(379/480) done. Loss: 1.0469  lr:0.100000  network_time: 0.0111
[ Thu May 18 08:46:27 2023 ] 	Batch(479/480) done. Loss: 0.9191  lr:0.100000  network_time: 0.0113
[ Thu May 18 08:46:27 2023 ] 	Training Accuracy: 51.96%
[ Thu May 18 08:46:27 2023 ] Eval epoch: 5
[ Thu May 18 08:46:44 2023 ] 	Mean test loss of 120 batches: 1.6596423387527466.
[ Thu May 18 08:46:44 2023 ] 	Top1: 54.50%
[ Thu May 18 08:46:44 2023 ] 	Top5: 91.83%
[ Thu May 18 08:46:44 2023 ] Training epoch: 6
[ Thu May 18 08:47:35 2023 ] 	Batch(99/480) done. Loss: 1.4072  lr:0.100000  network_time: 0.0109
[ Thu May 18 08:48:25 2023 ] 	Batch(199/480) done. Loss: 0.9187  lr:0.100000  network_time: 0.0114
[ Thu May 18 08:49:16 2023 ] 	Batch(299/480) done. Loss: 0.6252  lr:0.100000  network_time: 0.0115
[ Thu May 18 08:50:07 2023 ] 	Batch(399/480) done. Loss: 1.4335  lr:0.100000  network_time: 0.0109
[ Thu May 18 08:50:47 2023 ] 	Training Accuracy: 60.33%
[ Thu May 18 08:50:47 2023 ] Eval epoch: 6
[ Thu May 18 08:51:05 2023 ] 	Mean test loss of 120 batches: 1.069117784500122.
[ Thu May 18 08:51:05 2023 ] 	Top1: 70.17%
[ Thu May 18 08:51:05 2023 ] 	Top5: 93.83%
[ Thu May 18 08:51:05 2023 ] Training epoch: 7
[ Thu May 18 08:51:15 2023 ] 	Batch(19/480) done. Loss: 0.5981  lr:0.100000  network_time: 0.0110
[ Thu May 18 08:52:06 2023 ] 	Batch(119/480) done. Loss: 0.8905  lr:0.100000  network_time: 0.0105
[ Thu May 18 08:52:56 2023 ] 	Batch(219/480) done. Loss: 1.2079  lr:0.100000  network_time: 0.0110
[ Thu May 18 08:53:47 2023 ] 	Batch(319/480) done. Loss: 0.2302  lr:0.100000  network_time: 0.0125
[ Thu May 18 08:54:38 2023 ] 	Batch(419/480) done. Loss: 3.2187  lr:0.100000  network_time: 0.0112
[ Thu May 18 08:55:08 2023 ] 	Training Accuracy: 67.21%
[ Thu May 18 08:55:08 2023 ] Eval epoch: 7
[ Thu May 18 08:55:25 2023 ] 	Mean test loss of 120 batches: 0.8246448636054993.
[ Thu May 18 08:55:25 2023 ] 	Top1: 74.67%
[ Thu May 18 08:55:25 2023 ] 	Top5: 97.17%
[ Thu May 18 08:55:25 2023 ] Training epoch: 8
[ Thu May 18 08:55:46 2023 ] 	Batch(39/480) done. Loss: 0.4224  lr:0.100000  network_time: 0.0110
[ Thu May 18 08:56:36 2023 ] 	Batch(139/480) done. Loss: 0.5261  lr:0.100000  network_time: 0.0108
[ Thu May 18 08:57:27 2023 ] 	Batch(239/480) done. Loss: 1.1633  lr:0.100000  network_time: 0.0115
[ Thu May 18 08:58:18 2023 ] 	Batch(339/480) done. Loss: 1.1473  lr:0.100000  network_time: 0.0119
[ Thu May 18 08:59:08 2023 ] 	Batch(439/480) done. Loss: 0.6190  lr:0.100000  network_time: 0.0110
[ Thu May 18 08:59:29 2023 ] 	Training Accuracy: 72.29%
[ Thu May 18 08:59:29 2023 ] Eval epoch: 8
[ Thu May 18 08:59:46 2023 ] 	Mean test loss of 120 batches: 0.5138670802116394.
[ Thu May 18 08:59:46 2023 ] 	Top1: 85.33%
[ Thu May 18 08:59:46 2023 ] 	Top5: 98.67%
[ Thu May 18 08:59:46 2023 ] Training epoch: 9
[ Thu May 18 09:00:16 2023 ] 	Batch(59/480) done. Loss: 0.2673  lr:0.100000  network_time: 0.0108
[ Thu May 18 09:01:07 2023 ] 	Batch(159/480) done. Loss: 0.5142  lr:0.100000  network_time: 0.0120
[ Thu May 18 09:01:58 2023 ] 	Batch(259/480) done. Loss: 1.0377  lr:0.100000  network_time: 0.0118
[ Thu May 18 09:02:49 2023 ] 	Batch(359/480) done. Loss: 2.1166  lr:0.100000  network_time: 0.0116
[ Thu May 18 09:03:40 2023 ] 	Batch(459/480) done. Loss: 0.3030  lr:0.100000  network_time: 0.0112
[ Thu May 18 09:03:50 2023 ] 	Training Accuracy: 77.75%
[ Thu May 18 09:03:50 2023 ] Eval epoch: 9
[ Thu May 18 09:04:07 2023 ] 	Mean test loss of 120 batches: 0.7929917573928833.
[ Thu May 18 09:04:07 2023 ] 	Top1: 77.33%
[ Thu May 18 09:04:07 2023 ] 	Top5: 98.33%
[ Thu May 18 09:04:07 2023 ] Training epoch: 10
[ Thu May 18 09:04:48 2023 ] 	Batch(79/480) done. Loss: 0.4990  lr:0.100000  network_time: 0.0111
[ Thu May 18 09:05:38 2023 ] 	Batch(179/480) done. Loss: 0.2836  lr:0.100000  network_time: 0.0112
[ Thu May 18 09:06:29 2023 ] 	Batch(279/480) done. Loss: 1.0569  lr:0.100000  network_time: 0.0108
[ Thu May 18 09:07:20 2023 ] 	Batch(379/480) done. Loss: 0.5156  lr:0.100000  network_time: 0.0117
[ Thu May 18 09:08:11 2023 ] 	Batch(479/480) done. Loss: 0.3425  lr:0.100000  network_time: 0.0113
[ Thu May 18 09:08:11 2023 ] 	Training Accuracy: 81.17%
[ Thu May 18 09:08:11 2023 ] Eval epoch: 10
[ Thu May 18 09:08:28 2023 ] 	Mean test loss of 120 batches: 0.5093311071395874.
[ Thu May 18 09:08:28 2023 ] 	Top1: 82.83%
[ Thu May 18 09:08:28 2023 ] 	Top5: 99.00%
[ Thu May 18 09:08:28 2023 ] Training epoch: 11
[ Thu May 18 09:09:19 2023 ] 	Batch(99/480) done. Loss: 0.6253  lr:0.100000  network_time: 0.0106
[ Thu May 18 09:10:10 2023 ] 	Batch(199/480) done. Loss: 0.3231  lr:0.100000  network_time: 0.0111
[ Thu May 18 09:11:00 2023 ] 	Batch(299/480) done. Loss: 0.0499  lr:0.100000  network_time: 0.0115
[ Thu May 18 09:11:51 2023 ] 	Batch(399/480) done. Loss: 0.4315  lr:0.100000  network_time: 0.0109
[ Thu May 18 09:12:32 2023 ] 	Training Accuracy: 84.88%
[ Thu May 18 09:12:32 2023 ] Eval epoch: 11
[ Thu May 18 09:12:49 2023 ] 	Mean test loss of 120 batches: 0.5098288655281067.
[ Thu May 18 09:12:49 2023 ] 	Top1: 86.67%
[ Thu May 18 09:12:49 2023 ] 	Top5: 99.67%
[ Thu May 18 09:12:49 2023 ] Training epoch: 12
[ Thu May 18 09:12:59 2023 ] 	Batch(19/480) done. Loss: 0.6598  lr:0.100000  network_time: 0.0109
[ Thu May 18 09:13:50 2023 ] 	Batch(119/480) done. Loss: 0.2372  lr:0.100000  network_time: 0.0118
[ Thu May 18 09:14:41 2023 ] 	Batch(219/480) done. Loss: 0.7659  lr:0.100000  network_time: 0.0110
[ Thu May 18 09:15:31 2023 ] 	Batch(319/480) done. Loss: 0.3857  lr:0.100000  network_time: 0.0114
[ Thu May 18 09:16:22 2023 ] 	Batch(419/480) done. Loss: 0.7273  lr:0.100000  network_time: 0.0109
[ Thu May 18 09:16:53 2023 ] 	Training Accuracy: 86.54%
[ Thu May 18 09:16:53 2023 ] Eval epoch: 12
[ Thu May 18 09:17:10 2023 ] 	Mean test loss of 120 batches: 0.44937556982040405.
[ Thu May 18 09:17:10 2023 ] 	Top1: 85.83%
[ Thu May 18 09:17:10 2023 ] 	Top5: 100.00%
[ Thu May 18 09:17:10 2023 ] Training epoch: 13
[ Thu May 18 09:17:30 2023 ] 	Batch(39/480) done. Loss: 0.2284  lr:0.100000  network_time: 0.0108
[ Thu May 18 09:18:21 2023 ] 	Batch(139/480) done. Loss: 0.2025  lr:0.100000  network_time: 0.0122
[ Thu May 18 09:19:12 2023 ] 	Batch(239/480) done. Loss: 0.5610  lr:0.100000  network_time: 0.0111
[ Thu May 18 09:20:03 2023 ] 	Batch(339/480) done. Loss: 0.4458  lr:0.100000  network_time: 0.0115
[ Thu May 18 09:20:53 2023 ] 	Batch(439/480) done. Loss: 0.1914  lr:0.100000  network_time: 0.0113
[ Thu May 18 09:21:14 2023 ] 	Training Accuracy: 87.67%
[ Thu May 18 09:21:14 2023 ] Eval epoch: 13
[ Thu May 18 09:21:31 2023 ] 	Mean test loss of 120 batches: 0.4765265882015228.
[ Thu May 18 09:21:31 2023 ] 	Top1: 83.67%
[ Thu May 18 09:21:31 2023 ] 	Top5: 99.67%
[ Thu May 18 09:21:31 2023 ] Training epoch: 14
[ Thu May 18 09:22:01 2023 ] 	Batch(59/480) done. Loss: 0.0962  lr:0.100000  network_time: 0.0105
[ Thu May 18 09:22:52 2023 ] 	Batch(159/480) done. Loss: 0.4837  lr:0.100000  network_time: 0.0109
[ Thu May 18 09:23:43 2023 ] 	Batch(259/480) done. Loss: 0.0504  lr:0.100000  network_time: 0.0116
[ Thu May 18 09:24:34 2023 ] 	Batch(359/480) done. Loss: 0.3200  lr:0.100000  network_time: 0.0105
[ Thu May 18 09:25:24 2023 ] 	Batch(459/480) done. Loss: 0.1060  lr:0.100000  network_time: 0.0109
[ Thu May 18 09:25:34 2023 ] 	Training Accuracy: 89.83%
[ Thu May 18 09:25:34 2023 ] Eval epoch: 14
[ Thu May 18 09:25:52 2023 ] 	Mean test loss of 120 batches: 0.2811526954174042.
[ Thu May 18 09:25:52 2023 ] 	Top1: 90.83%
[ Thu May 18 09:25:52 2023 ] 	Top5: 99.67%
[ Thu May 18 09:25:52 2023 ] Training epoch: 15
[ Thu May 18 09:26:32 2023 ] 	Batch(79/480) done. Loss: 0.4580  lr:0.100000  network_time: 0.0109
[ Thu May 18 09:27:23 2023 ] 	Batch(179/480) done. Loss: 0.0752  lr:0.100000  network_time: 0.0108
[ Thu May 18 09:28:14 2023 ] 	Batch(279/480) done. Loss: 0.1447  lr:0.100000  network_time: 0.0110
[ Thu May 18 09:29:04 2023 ] 	Batch(379/480) done. Loss: 0.1592  lr:0.100000  network_time: 0.0112
[ Thu May 18 09:29:55 2023 ] 	Batch(479/480) done. Loss: 0.1519  lr:0.100000  network_time: 0.0112
[ Thu May 18 09:29:55 2023 ] 	Training Accuracy: 87.63%
[ Thu May 18 09:29:55 2023 ] Eval epoch: 15
[ Thu May 18 09:30:12 2023 ] 	Mean test loss of 120 batches: 0.4780844449996948.
[ Thu May 18 09:30:12 2023 ] 	Top1: 87.00%
[ Thu May 18 09:30:12 2023 ] 	Top5: 99.00%
[ Thu May 18 09:30:12 2023 ] Training epoch: 16
[ Thu May 18 09:31:03 2023 ] 	Batch(99/480) done. Loss: 1.5950  lr:0.100000  network_time: 0.0114
[ Thu May 18 09:31:54 2023 ] 	Batch(199/480) done. Loss: 0.1149  lr:0.100000  network_time: 0.0113
[ Thu May 18 09:32:45 2023 ] 	Batch(299/480) done. Loss: 1.8782  lr:0.100000  network_time: 0.0113
[ Thu May 18 09:33:35 2023 ] 	Batch(399/480) done. Loss: 0.0252  lr:0.100000  network_time: 0.0112
[ Thu May 18 09:34:16 2023 ] 	Training Accuracy: 89.54%
[ Thu May 18 09:34:16 2023 ] Eval epoch: 16
[ Thu May 18 09:34:33 2023 ] 	Mean test loss of 120 batches: 0.5825393199920654.
[ Thu May 18 09:34:33 2023 ] 	Top1: 86.00%
[ Thu May 18 09:34:33 2023 ] 	Top5: 99.33%
[ Thu May 18 09:34:33 2023 ] Training epoch: 17
[ Thu May 18 09:34:43 2023 ] 	Batch(19/480) done. Loss: 0.5237  lr:0.100000  network_time: 0.0113
[ Thu May 18 09:35:34 2023 ] 	Batch(119/480) done. Loss: 0.1009  lr:0.100000  network_time: 0.0112
[ Thu May 18 09:36:25 2023 ] 	Batch(219/480) done. Loss: 0.0391  lr:0.100000  network_time: 0.0112
[ Thu May 18 09:37:16 2023 ] 	Batch(319/480) done. Loss: 0.1213  lr:0.100000  network_time: 0.0110
[ Thu May 18 09:38:07 2023 ] 	Batch(419/480) done. Loss: 0.3376  lr:0.100000  network_time: 0.0111
[ Thu May 18 09:38:37 2023 ] 	Training Accuracy: 89.33%
[ Thu May 18 09:38:37 2023 ] Eval epoch: 17
[ Thu May 18 09:38:54 2023 ] 	Mean test loss of 120 batches: 0.2726561725139618.
[ Thu May 18 09:38:54 2023 ] 	Top1: 91.00%
[ Thu May 18 09:38:54 2023 ] 	Top5: 99.83%
[ Thu May 18 09:38:54 2023 ] Training epoch: 18
[ Thu May 18 09:39:14 2023 ] 	Batch(39/480) done. Loss: 0.6998  lr:0.100000  network_time: 0.0107
[ Thu May 18 09:40:05 2023 ] 	Batch(139/480) done. Loss: 0.9884  lr:0.100000  network_time: 0.0111
[ Thu May 18 09:40:56 2023 ] 	Batch(239/480) done. Loss: 0.7240  lr:0.100000  network_time: 0.0106
[ Thu May 18 09:41:47 2023 ] 	Batch(339/480) done. Loss: 0.1444  lr:0.100000  network_time: 0.0108
[ Thu May 18 09:42:38 2023 ] 	Batch(439/480) done. Loss: 0.0513  lr:0.100000  network_time: 0.0113
[ Thu May 18 09:42:58 2023 ] 	Training Accuracy: 90.75%
[ Thu May 18 09:42:58 2023 ] Eval epoch: 18
[ Thu May 18 09:43:15 2023 ] 	Mean test loss of 120 batches: 0.3017056882381439.
[ Thu May 18 09:43:15 2023 ] 	Top1: 91.67%
[ Thu May 18 09:43:15 2023 ] 	Top5: 99.83%
[ Thu May 18 09:43:15 2023 ] Training epoch: 19
[ Thu May 18 09:43:46 2023 ] 	Batch(59/480) done. Loss: 0.2795  lr:0.100000  network_time: 0.0111
[ Thu May 18 09:44:36 2023 ] 	Batch(159/480) done. Loss: 0.5160  lr:0.100000  network_time: 0.0107
[ Thu May 18 09:45:27 2023 ] 	Batch(259/480) done. Loss: 0.0882  lr:0.100000  network_time: 0.0110
[ Thu May 18 09:46:18 2023 ] 	Batch(359/480) done. Loss: 0.0945  lr:0.100000  network_time: 0.0110
[ Thu May 18 09:47:09 2023 ] 	Batch(459/480) done. Loss: 0.2844  lr:0.100000  network_time: 0.0109
[ Thu May 18 09:47:19 2023 ] 	Training Accuracy: 90.75%
[ Thu May 18 09:47:19 2023 ] Eval epoch: 19
[ Thu May 18 09:47:36 2023 ] 	Mean test loss of 120 batches: 0.11647477746009827.
[ Thu May 18 09:47:36 2023 ] 	Top1: 95.67%
[ Thu May 18 09:47:36 2023 ] 	Top5: 100.00%
[ Thu May 18 09:47:36 2023 ] Training epoch: 20
[ Thu May 18 09:48:17 2023 ] 	Batch(79/480) done. Loss: 0.0997  lr:0.100000  network_time: 0.0109
[ Thu May 18 09:49:08 2023 ] 	Batch(179/480) done. Loss: 0.5874  lr:0.100000  network_time: 0.0113
[ Thu May 18 09:49:58 2023 ] 	Batch(279/480) done. Loss: 0.1281  lr:0.100000  network_time: 0.0111
[ Thu May 18 09:50:49 2023 ] 	Batch(379/480) done. Loss: 0.2941  lr:0.100000  network_time: 0.0114
[ Thu May 18 09:51:40 2023 ] 	Batch(479/480) done. Loss: 0.1926  lr:0.100000  network_time: 0.0111
[ Thu May 18 09:51:40 2023 ] 	Training Accuracy: 92.33%
[ Thu May 18 09:51:40 2023 ] Eval epoch: 20
[ Thu May 18 09:51:57 2023 ] 	Mean test loss of 120 batches: 0.24322064220905304.
[ Thu May 18 09:51:57 2023 ] 	Top1: 90.83%
[ Thu May 18 09:51:57 2023 ] 	Top5: 100.00%
[ Thu May 18 09:51:57 2023 ] Training epoch: 21
[ Thu May 18 09:52:48 2023 ] 	Batch(99/480) done. Loss: 0.2232  lr:0.010000  network_time: 0.0117
[ Thu May 18 09:53:39 2023 ] 	Batch(199/480) done. Loss: 0.1634  lr:0.010000  network_time: 0.0125
[ Thu May 18 09:54:30 2023 ] 	Batch(299/480) done. Loss: 0.0163  lr:0.010000  network_time: 0.0117
[ Thu May 18 09:55:20 2023 ] 	Batch(399/480) done. Loss: 0.0091  lr:0.010000  network_time: 0.0111
[ Thu May 18 09:56:01 2023 ] 	Training Accuracy: 97.17%
[ Thu May 18 09:56:01 2023 ] Eval epoch: 21
[ Thu May 18 09:56:18 2023 ] 	Mean test loss of 120 batches: 0.021729476749897003.
[ Thu May 18 09:56:18 2023 ] 	Top1: 99.83%
[ Thu May 18 09:56:18 2023 ] 	Top5: 100.00%
[ Thu May 18 09:56:18 2023 ] Training epoch: 22
[ Thu May 18 09:56:28 2023 ] 	Batch(19/480) done. Loss: 0.0387  lr:0.010000  network_time: 0.0106
[ Thu May 18 09:57:19 2023 ] 	Batch(119/480) done. Loss: 0.1677  lr:0.010000  network_time: 0.0114
[ Thu May 18 09:58:10 2023 ] 	Batch(219/480) done. Loss: 0.0253  lr:0.010000  network_time: 0.0112
[ Thu May 18 09:59:01 2023 ] 	Batch(319/480) done. Loss: 0.0098  lr:0.010000  network_time: 0.0107
[ Thu May 18 09:59:52 2023 ] 	Batch(419/480) done. Loss: 0.1688  lr:0.010000  network_time: 0.0111
[ Thu May 18 10:00:22 2023 ] 	Training Accuracy: 99.17%
[ Thu May 18 10:00:22 2023 ] Eval epoch: 22
[ Thu May 18 10:00:39 2023 ] 	Mean test loss of 120 batches: 0.011892219074070454.
[ Thu May 18 10:00:39 2023 ] 	Top1: 99.83%
[ Thu May 18 10:00:39 2023 ] 	Top5: 100.00%
[ Thu May 18 10:00:39 2023 ] Training epoch: 23
[ Thu May 18 10:01:00 2023 ] 	Batch(39/480) done. Loss: 0.0058  lr:0.010000  network_time: 0.0109
[ Thu May 18 10:01:50 2023 ] 	Batch(139/480) done. Loss: 0.0091  lr:0.010000  network_time: 0.0114
[ Thu May 18 10:02:41 2023 ] 	Batch(239/480) done. Loss: 0.0096  lr:0.010000  network_time: 0.0113
[ Thu May 18 10:03:32 2023 ] 	Batch(339/480) done. Loss: 0.0216  lr:0.010000  network_time: 0.0109
[ Thu May 18 10:04:23 2023 ] 	Batch(439/480) done. Loss: 0.0042  lr:0.010000  network_time: 0.0109
[ Thu May 18 10:04:43 2023 ] 	Training Accuracy: 99.62%
[ Thu May 18 10:04:43 2023 ] Eval epoch: 23
[ Thu May 18 10:05:00 2023 ] 	Mean test loss of 120 batches: 0.006880693603307009.
[ Thu May 18 10:05:00 2023 ] 	Top1: 100.00%
[ Thu May 18 10:05:00 2023 ] 	Top5: 100.00%
[ Thu May 18 10:05:00 2023 ] Training epoch: 24
[ Thu May 18 10:05:31 2023 ] 	Batch(59/480) done. Loss: 0.0121  lr:0.010000  network_time: 0.0108
[ Thu May 18 10:06:22 2023 ] 	Batch(159/480) done. Loss: 0.0227  lr:0.010000  network_time: 0.0121
[ Thu May 18 10:07:12 2023 ] 	Batch(259/480) done. Loss: 0.0061  lr:0.010000  network_time: 0.0106
[ Thu May 18 10:08:03 2023 ] 	Batch(359/480) done. Loss: 0.0110  lr:0.010000  network_time: 0.0110
[ Thu May 18 10:08:54 2023 ] 	Batch(459/480) done. Loss: 0.0102  lr:0.010000  network_time: 0.0113
[ Thu May 18 10:09:04 2023 ] 	Training Accuracy: 99.46%
[ Thu May 18 10:09:04 2023 ] Eval epoch: 24
[ Thu May 18 10:09:21 2023 ] 	Mean test loss of 120 batches: 0.005984778981655836.
[ Thu May 18 10:09:21 2023 ] 	Top1: 99.83%
[ Thu May 18 10:09:21 2023 ] 	Top5: 100.00%
[ Thu May 18 10:09:21 2023 ] Training epoch: 25
[ Thu May 18 10:10:02 2023 ] 	Batch(79/480) done. Loss: 0.0224  lr:0.010000  network_time: 0.0109
[ Thu May 18 10:10:53 2023 ] 	Batch(179/480) done. Loss: 0.0033  lr:0.010000  network_time: 0.0109
[ Thu May 18 10:11:44 2023 ] 	Batch(279/480) done. Loss: 0.0029  lr:0.010000  network_time: 0.0111
[ Thu May 18 10:12:34 2023 ] 	Batch(379/480) done. Loss: 0.0019  lr:0.010000  network_time: 0.0112
[ Thu May 18 10:13:25 2023 ] 	Batch(479/480) done. Loss: 0.1094  lr:0.010000  network_time: 0.0107
[ Thu May 18 10:13:25 2023 ] 	Training Accuracy: 99.50%
[ Thu May 18 10:13:25 2023 ] Eval epoch: 25
[ Thu May 18 10:13:42 2023 ] 	Mean test loss of 120 batches: 0.004677663557231426.
[ Thu May 18 10:13:42 2023 ] 	Top1: 99.83%
[ Thu May 18 10:13:42 2023 ] 	Top5: 100.00%
[ Thu May 18 10:13:42 2023 ] Training epoch: 26
[ Thu May 18 10:14:33 2023 ] 	Batch(99/480) done. Loss: 0.0065  lr:0.001000  network_time: 0.0113
[ Thu May 18 10:15:24 2023 ] 	Batch(199/480) done. Loss: 0.3110  lr:0.001000  network_time: 0.0109
[ Thu May 18 10:16:15 2023 ] 	Batch(299/480) done. Loss: 0.0318  lr:0.001000  network_time: 0.0108
[ Thu May 18 10:17:06 2023 ] 	Batch(399/480) done. Loss: 0.1044  lr:0.001000  network_time: 0.0116
[ Thu May 18 10:17:46 2023 ] 	Training Accuracy: 99.58%
[ Thu May 18 10:17:46 2023 ] Eval epoch: 26
[ Thu May 18 10:18:04 2023 ] 	Mean test loss of 120 batches: 0.006200009491294622.
[ Thu May 18 10:18:04 2023 ] 	Top1: 100.00%
[ Thu May 18 10:18:04 2023 ] 	Top5: 100.00%
[ Thu May 18 10:18:04 2023 ] Training epoch: 27
[ Thu May 18 10:18:14 2023 ] 	Batch(19/480) done. Loss: 0.0038  lr:0.001000  network_time: 0.0108
[ Thu May 18 10:19:05 2023 ] 	Batch(119/480) done. Loss: 0.0027  lr:0.001000  network_time: 0.0113
[ Thu May 18 10:19:55 2023 ] 	Batch(219/480) done. Loss: 0.0032  lr:0.001000  network_time: 0.0109
[ Thu May 18 10:20:46 2023 ] 	Batch(319/480) done. Loss: 0.0044  lr:0.001000  network_time: 0.0106
[ Thu May 18 10:21:37 2023 ] 	Batch(419/480) done. Loss: 0.0176  lr:0.001000  network_time: 0.0108
[ Thu May 18 10:22:07 2023 ] 	Training Accuracy: 99.75%
[ Thu May 18 10:22:07 2023 ] Eval epoch: 27
[ Thu May 18 10:22:24 2023 ] 	Mean test loss of 120 batches: 0.005632276181131601.
[ Thu May 18 10:22:24 2023 ] 	Top1: 99.83%
[ Thu May 18 10:22:24 2023 ] 	Top5: 100.00%
[ Thu May 18 10:22:24 2023 ] Training epoch: 28
[ Thu May 18 10:22:45 2023 ] 	Batch(39/480) done. Loss: 0.0284  lr:0.001000  network_time: 0.0106
[ Thu May 18 10:23:35 2023 ] 	Batch(139/480) done. Loss: 0.0343  lr:0.001000  network_time: 0.0107
[ Thu May 18 10:24:26 2023 ] 	Batch(239/480) done. Loss: 0.0689  lr:0.001000  network_time: 0.0107
[ Thu May 18 10:25:17 2023 ] 	Batch(339/480) done. Loss: 0.1008  lr:0.001000  network_time: 0.0108
[ Thu May 18 10:26:08 2023 ] 	Batch(439/480) done. Loss: 0.0438  lr:0.001000  network_time: 0.0112
[ Thu May 18 10:26:28 2023 ] 	Training Accuracy: 99.75%
[ Thu May 18 10:26:28 2023 ] Eval epoch: 28
[ Thu May 18 10:26:45 2023 ] 	Mean test loss of 120 batches: 0.003780327271670103.
[ Thu May 18 10:26:45 2023 ] 	Top1: 100.00%
[ Thu May 18 10:26:45 2023 ] 	Top5: 100.00%
[ Thu May 18 10:26:45 2023 ] Training epoch: 29
[ Thu May 18 10:27:16 2023 ] 	Batch(59/480) done. Loss: 0.0082  lr:0.001000  network_time: 0.0107
[ Thu May 18 10:28:07 2023 ] 	Batch(159/480) done. Loss: 0.0026  lr:0.001000  network_time: 0.0107
[ Thu May 18 10:28:57 2023 ] 	Batch(259/480) done. Loss: 0.0188  lr:0.001000  network_time: 0.0108
[ Thu May 18 10:29:48 2023 ] 	Batch(359/480) done. Loss: 0.0577  lr:0.001000  network_time: 0.0119
[ Thu May 18 10:30:39 2023 ] 	Batch(459/480) done. Loss: 0.3091  lr:0.001000  network_time: 0.0105
[ Thu May 18 10:30:49 2023 ] 	Training Accuracy: 99.71%
[ Thu May 18 10:30:49 2023 ] Eval epoch: 29
[ Thu May 18 10:31:06 2023 ] 	Mean test loss of 120 batches: 0.005891039501875639.
[ Thu May 18 10:31:06 2023 ] 	Top1: 99.83%
[ Thu May 18 10:31:06 2023 ] 	Top5: 100.00%
[ Thu May 18 10:31:06 2023 ] Training epoch: 30
[ Thu May 18 10:31:47 2023 ] 	Batch(79/480) done. Loss: 0.0011  lr:0.001000  network_time: 0.0110
[ Thu May 18 10:32:38 2023 ] 	Batch(179/480) done. Loss: 0.0092  lr:0.001000  network_time: 0.0109
[ Thu May 18 10:33:28 2023 ] 	Batch(279/480) done. Loss: 0.0027  lr:0.001000  network_time: 0.0110
[ Thu May 18 10:34:19 2023 ] 	Batch(379/480) done. Loss: 0.0350  lr:0.001000  network_time: 0.0108
[ Thu May 18 10:35:10 2023 ] 	Batch(479/480) done. Loss: 0.0668  lr:0.001000  network_time: 0.0105
[ Thu May 18 10:35:10 2023 ] 	Training Accuracy: 99.54%
[ Thu May 18 10:35:10 2023 ] Eval epoch: 30
[ Thu May 18 10:35:27 2023 ] 	Mean test loss of 120 batches: 0.0034378140699118376.
[ Thu May 18 10:35:27 2023 ] 	Top1: 100.00%
[ Thu May 18 10:35:27 2023 ] 	Top5: 100.00%
