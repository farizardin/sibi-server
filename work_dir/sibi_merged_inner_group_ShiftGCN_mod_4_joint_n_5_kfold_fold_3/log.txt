[ Tue May 16 06:49:35 2023 ] NUM WORKER: 1
[ Tue May 16 06:52:43 2023 ] Parameters:
{'work_dir': './work_dir/sibi_merged_inner_group_ShiftGCN_mod_4_joint_n_5_kfold_fold_3', 'model_saved_name': './save_models/sibi_merged_inner_group_ShiftGCN_mod_4_joint_n_5_kfold_fold_3', 'Experiment_name': 'sibi_merged_inner_group_ShiftGCN_mod_4_joint_n_5_kfold', 'config': './config/recalculated/train_sibi_with_mouth_augmented_merged_inner_group_shift_joint_mod_4.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 2, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'n_splits': 5, 'feeder': 'feeders.feeder_hsd.Feeder', 'num_worker': 1, 'train_feeder_args': {'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': -1, 'normalization': False}, 'test_feeder_args': None, 'data_path': './data/augmented_recalculate_normalized', 'model': 'model.shift_gcn.Model', 'model_args': {'num_class': 50, 'num_person': 1, 'num_point': 115, 'graph_group': [[0, 81], [82, 114]], 'method': 'grouped.inner', 'weight': 4, 'graph': 'graph.skeleton_with_mouth.SkeletonWithMouth', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [20, 25], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 5, 'test_batch_size': 5, 'start_epoch': 0, 'num_epoch': 30, 'folds_range': [2, 5], 'weight_decay': 0.0001, 'only_train_part': True, 'only_train_epoch': 1, 'warm_up_epoch': 0}

[ Tue May 16 06:52:43 2023 ] Training epoch: 1
[ Tue May 16 06:53:32 2023 ] 	Batch(99/480) done. Loss: 3.5205  lr:0.100000  network_time: 0.0114
[ Tue May 16 06:54:21 2023 ] 	Batch(199/480) done. Loss: 3.3742  lr:0.100000  network_time: 0.0119
[ Tue May 16 06:55:09 2023 ] 	Batch(299/480) done. Loss: 3.5608  lr:0.100000  network_time: 0.0114
[ Tue May 16 06:55:58 2023 ] 	Batch(399/480) done. Loss: 4.0462  lr:0.100000  network_time: 0.0116
[ Tue May 16 06:56:37 2023 ] 	Training Accuracy: 4.50%
[ Tue May 16 06:56:37 2023 ] Eval epoch: 1
[ Tue May 16 06:56:54 2023 ] 	Mean test loss of 120 batches: 3.570326566696167.
[ Tue May 16 06:56:54 2023 ] 	Top1: 8.67%
[ Tue May 16 06:56:54 2023 ] 	Top5: 30.50%
[ Tue May 16 06:56:54 2023 ] Training epoch: 2
[ Tue May 16 06:57:03 2023 ] 	Batch(19/480) done. Loss: 3.3863  lr:0.100000  network_time: 0.0115
[ Tue May 16 06:57:52 2023 ] 	Batch(119/480) done. Loss: 3.6600  lr:0.100000  network_time: 0.0120
[ Tue May 16 06:58:41 2023 ] 	Batch(219/480) done. Loss: 3.1056  lr:0.100000  network_time: 0.0119
[ Tue May 16 06:59:30 2023 ] 	Batch(319/480) done. Loss: 3.8871  lr:0.100000  network_time: 0.0113
[ Tue May 16 07:00:18 2023 ] 	Batch(419/480) done. Loss: 2.8274  lr:0.100000  network_time: 0.0115
[ Tue May 16 07:00:48 2023 ] 	Training Accuracy: 9.58%
[ Tue May 16 07:00:48 2023 ] Eval epoch: 2
[ Tue May 16 07:01:04 2023 ] 	Mean test loss of 120 batches: 3.1071152687072754.
[ Tue May 16 07:01:04 2023 ] 	Top1: 15.50%
[ Tue May 16 07:01:04 2023 ] 	Top5: 57.17%
[ Tue May 16 07:01:04 2023 ] Training epoch: 3
[ Tue May 16 07:01:24 2023 ] 	Batch(39/480) done. Loss: 3.0305  lr:0.100000  network_time: 0.0113
[ Tue May 16 07:02:13 2023 ] 	Batch(139/480) done. Loss: 2.7485  lr:0.100000  network_time: 0.0118
[ Tue May 16 07:03:01 2023 ] 	Batch(239/480) done. Loss: 2.7520  lr:0.100000  network_time: 0.0114
[ Tue May 16 07:03:50 2023 ] 	Batch(339/480) done. Loss: 2.9603  lr:0.100000  network_time: 0.0113
[ Tue May 16 07:04:39 2023 ] 	Batch(439/480) done. Loss: 2.1941  lr:0.100000  network_time: 0.0112
[ Tue May 16 07:04:58 2023 ] 	Training Accuracy: 17.17%
[ Tue May 16 07:04:58 2023 ] Eval epoch: 3
[ Tue May 16 07:05:15 2023 ] 	Mean test loss of 120 batches: 2.3456263542175293.
[ Tue May 16 07:05:15 2023 ] 	Top1: 27.50%
[ Tue May 16 07:05:15 2023 ] 	Top5: 70.33%
[ Tue May 16 07:05:15 2023 ] Training epoch: 4
[ Tue May 16 07:05:44 2023 ] 	Batch(59/480) done. Loss: 2.4033  lr:0.100000  network_time: 0.0113
[ Tue May 16 07:06:33 2023 ] 	Batch(159/480) done. Loss: 3.1429  lr:0.100000  network_time: 0.0117
[ Tue May 16 07:07:21 2023 ] 	Batch(259/480) done. Loss: 2.7628  lr:0.100000  network_time: 0.0116
[ Tue May 16 07:08:10 2023 ] 	Batch(359/480) done. Loss: 1.9106  lr:0.100000  network_time: 0.0114
[ Tue May 16 07:08:59 2023 ] 	Batch(459/480) done. Loss: 2.4796  lr:0.100000  network_time: 0.0115
[ Tue May 16 07:09:09 2023 ] 	Training Accuracy: 25.29%
[ Tue May 16 07:09:09 2023 ] Eval epoch: 4
[ Tue May 16 07:09:25 2023 ] 	Mean test loss of 120 batches: 2.083016872406006.
[ Tue May 16 07:09:25 2023 ] 	Top1: 35.33%
[ Tue May 16 07:09:25 2023 ] 	Top5: 78.00%
[ Tue May 16 07:09:25 2023 ] Training epoch: 5
[ Tue May 16 07:10:04 2023 ] 	Batch(79/480) done. Loss: 2.1993  lr:0.100000  network_time: 0.0114
[ Tue May 16 07:10:53 2023 ] 	Batch(179/480) done. Loss: 2.2897  lr:0.100000  network_time: 0.0114
[ Tue May 16 07:11:42 2023 ] 	Batch(279/480) done. Loss: 1.8031  lr:0.100000  network_time: 0.0114
[ Tue May 16 07:12:31 2023 ] 	Batch(379/480) done. Loss: 2.8290  lr:0.100000  network_time: 0.0115
[ Tue May 16 07:13:19 2023 ] 	Batch(479/480) done. Loss: 1.4426  lr:0.100000  network_time: 0.0112
[ Tue May 16 07:13:19 2023 ] 	Training Accuracy: 30.71%
[ Tue May 16 07:13:19 2023 ] Eval epoch: 5
[ Tue May 16 07:13:36 2023 ] 	Mean test loss of 120 batches: 2.0235869884490967.
[ Tue May 16 07:13:36 2023 ] 	Top1: 36.33%
[ Tue May 16 07:13:36 2023 ] 	Top5: 85.17%
[ Tue May 16 07:13:36 2023 ] Training epoch: 6
[ Tue May 16 07:14:25 2023 ] 	Batch(99/480) done. Loss: 1.9358  lr:0.100000  network_time: 0.0121
[ Tue May 16 07:15:14 2023 ] 	Batch(199/480) done. Loss: 2.1996  lr:0.100000  network_time: 0.0117
[ Tue May 16 07:16:02 2023 ] 	Batch(299/480) done. Loss: 1.1120  lr:0.100000  network_time: 0.0129
[ Tue May 16 07:16:51 2023 ] 	Batch(399/480) done. Loss: 2.0707  lr:0.100000  network_time: 0.0111
[ Tue May 16 07:17:30 2023 ] 	Training Accuracy: 42.21%
[ Tue May 16 07:17:30 2023 ] Eval epoch: 6
[ Tue May 16 07:17:47 2023 ] 	Mean test loss of 120 batches: 1.6441712379455566.
[ Tue May 16 07:17:47 2023 ] 	Top1: 53.00%
[ Tue May 16 07:17:47 2023 ] 	Top5: 91.67%
[ Tue May 16 07:17:47 2023 ] Training epoch: 7
[ Tue May 16 07:17:56 2023 ] 	Batch(19/480) done. Loss: 1.4830  lr:0.100000  network_time: 0.0119
[ Tue May 16 07:18:45 2023 ] 	Batch(119/480) done. Loss: 1.0611  lr:0.100000  network_time: 0.0115
[ Tue May 16 07:19:34 2023 ] 	Batch(219/480) done. Loss: 1.1580  lr:0.100000  network_time: 0.0123
[ Tue May 16 07:20:23 2023 ] 	Batch(319/480) done. Loss: 0.7526  lr:0.100000  network_time: 0.0113
[ Tue May 16 07:21:12 2023 ] 	Batch(419/480) done. Loss: 1.6909  lr:0.100000  network_time: 0.0114
[ Tue May 16 07:21:41 2023 ] 	Training Accuracy: 52.54%
[ Tue May 16 07:21:41 2023 ] Eval epoch: 7
[ Tue May 16 07:21:58 2023 ] 	Mean test loss of 120 batches: 2.2171342372894287.
[ Tue May 16 07:21:58 2023 ] 	Top1: 47.17%
[ Tue May 16 07:21:58 2023 ] 	Top5: 91.33%
[ Tue May 16 07:21:58 2023 ] Training epoch: 8
[ Tue May 16 07:22:17 2023 ] 	Batch(39/480) done. Loss: 2.1891  lr:0.100000  network_time: 0.0112
[ Tue May 16 07:23:06 2023 ] 	Batch(139/480) done. Loss: 0.9913  lr:0.100000  network_time: 0.0109
[ Tue May 16 07:23:54 2023 ] 	Batch(239/480) done. Loss: 2.4079  lr:0.100000  network_time: 0.0115
[ Tue May 16 07:24:43 2023 ] 	Batch(339/480) done. Loss: 1.3021  lr:0.100000  network_time: 0.0111
[ Tue May 16 07:25:32 2023 ] 	Batch(439/480) done. Loss: 0.6510  lr:0.100000  network_time: 0.0116
[ Tue May 16 07:25:51 2023 ] 	Training Accuracy: 61.54%
[ Tue May 16 07:25:51 2023 ] Eval epoch: 8
[ Tue May 16 07:26:08 2023 ] 	Mean test loss of 120 batches: 1.2486770153045654.
[ Tue May 16 07:26:08 2023 ] 	Top1: 62.67%
[ Tue May 16 07:26:08 2023 ] 	Top5: 95.00%
[ Tue May 16 07:26:08 2023 ] Training epoch: 9
[ Tue May 16 07:26:37 2023 ] 	Batch(59/480) done. Loss: 0.7417  lr:0.100000  network_time: 0.0113
[ Tue May 16 07:27:26 2023 ] 	Batch(159/480) done. Loss: 0.3363  lr:0.100000  network_time: 0.0117
[ Tue May 16 07:28:15 2023 ] 	Batch(259/480) done. Loss: 1.2965  lr:0.100000  network_time: 0.0115
[ Tue May 16 07:29:04 2023 ] 	Batch(359/480) done. Loss: 1.2042  lr:0.100000  network_time: 0.0120
[ Tue May 16 07:29:53 2023 ] 	Batch(459/480) done. Loss: 1.1791  lr:0.100000  network_time: 0.0118
[ Tue May 16 07:30:02 2023 ] 	Training Accuracy: 68.04%
[ Tue May 16 07:30:03 2023 ] Eval epoch: 9
[ Tue May 16 07:30:19 2023 ] 	Mean test loss of 120 batches: 0.9857447147369385.
[ Tue May 16 07:30:19 2023 ] 	Top1: 69.67%
[ Tue May 16 07:30:19 2023 ] 	Top5: 95.50%
[ Tue May 16 07:30:19 2023 ] Training epoch: 10
[ Tue May 16 07:30:58 2023 ] 	Batch(79/480) done. Loss: 1.3256  lr:0.100000  network_time: 0.0115
[ Tue May 16 07:31:47 2023 ] 	Batch(179/480) done. Loss: 1.2487  lr:0.100000  network_time: 0.0111
[ Tue May 16 07:32:36 2023 ] 	Batch(279/480) done. Loss: 0.4191  lr:0.100000  network_time: 0.0111
[ Tue May 16 07:33:24 2023 ] 	Batch(379/480) done. Loss: 1.1486  lr:0.100000  network_time: 0.0114
[ Tue May 16 07:34:13 2023 ] 	Batch(479/480) done. Loss: 0.8899  lr:0.100000  network_time: 0.0112
[ Tue May 16 07:34:13 2023 ] 	Training Accuracy: 70.13%
[ Tue May 16 07:34:13 2023 ] Eval epoch: 10
[ Tue May 16 07:34:30 2023 ] 	Mean test loss of 120 batches: 0.691297709941864.
[ Tue May 16 07:34:30 2023 ] 	Top1: 79.17%
[ Tue May 16 07:34:30 2023 ] 	Top5: 98.67%
[ Tue May 16 07:34:30 2023 ] Training epoch: 11
[ Tue May 16 07:35:19 2023 ] 	Batch(99/480) done. Loss: 1.0739  lr:0.100000  network_time: 0.0110
[ Tue May 16 07:36:08 2023 ] 	Batch(199/480) done. Loss: 1.0676  lr:0.100000  network_time: 0.0119
[ Tue May 16 07:36:56 2023 ] 	Batch(299/480) done. Loss: 0.8666  lr:0.100000  network_time: 0.0118
[ Tue May 16 07:37:45 2023 ] 	Batch(399/480) done. Loss: 0.5394  lr:0.100000  network_time: 0.0114
[ Tue May 16 07:38:24 2023 ] 	Training Accuracy: 75.96%
[ Tue May 16 07:38:24 2023 ] Eval epoch: 11
[ Tue May 16 07:38:41 2023 ] 	Mean test loss of 120 batches: 0.8161693811416626.
[ Tue May 16 07:38:41 2023 ] 	Top1: 75.50%
[ Tue May 16 07:38:41 2023 ] 	Top5: 97.50%
[ Tue May 16 07:38:41 2023 ] Training epoch: 12
[ Tue May 16 07:38:51 2023 ] 	Batch(19/480) done. Loss: 0.9431  lr:0.100000  network_time: 0.0109
[ Tue May 16 07:39:39 2023 ] 	Batch(119/480) done. Loss: 0.2651  lr:0.100000  network_time: 0.0116
[ Tue May 16 07:40:28 2023 ] 	Batch(219/480) done. Loss: 0.0742  lr:0.100000  network_time: 0.0116
[ Tue May 16 07:41:17 2023 ] 	Batch(319/480) done. Loss: 2.0723  lr:0.100000  network_time: 0.0118
[ Tue May 16 07:42:06 2023 ] 	Batch(419/480) done. Loss: 0.5418  lr:0.100000  network_time: 0.0113
[ Tue May 16 07:42:35 2023 ] 	Training Accuracy: 79.17%
[ Tue May 16 07:42:35 2023 ] Eval epoch: 12
[ Tue May 16 07:42:52 2023 ] 	Mean test loss of 120 batches: 0.571490466594696.
[ Tue May 16 07:42:52 2023 ] 	Top1: 82.67%
[ Tue May 16 07:42:52 2023 ] 	Top5: 99.00%
[ Tue May 16 07:42:52 2023 ] Training epoch: 13
[ Tue May 16 07:43:11 2023 ] 	Batch(39/480) done. Loss: 0.2881  lr:0.100000  network_time: 0.0116
[ Tue May 16 07:44:00 2023 ] 	Batch(139/480) done. Loss: 0.5431  lr:0.100000  network_time: 0.0111
[ Tue May 16 07:44:49 2023 ] 	Batch(239/480) done. Loss: 0.9146  lr:0.100000  network_time: 0.0113
[ Tue May 16 07:45:37 2023 ] 	Batch(339/480) done. Loss: 0.9787  lr:0.100000  network_time: 0.0112
[ Tue May 16 07:46:26 2023 ] 	Batch(439/480) done. Loss: 0.7532  lr:0.100000  network_time: 0.0116
[ Tue May 16 07:46:46 2023 ] 	Training Accuracy: 78.63%
[ Tue May 16 07:46:46 2023 ] Eval epoch: 13
[ Tue May 16 07:47:02 2023 ] 	Mean test loss of 120 batches: 0.6081365942955017.
[ Tue May 16 07:47:02 2023 ] 	Top1: 79.00%
[ Tue May 16 07:47:02 2023 ] 	Top5: 98.33%
[ Tue May 16 07:47:02 2023 ] Training epoch: 14
[ Tue May 16 07:47:32 2023 ] 	Batch(59/480) done. Loss: 1.0439  lr:0.100000  network_time: 0.0116
[ Tue May 16 07:48:21 2023 ] 	Batch(159/480) done. Loss: 0.8070  lr:0.100000  network_time: 0.0113
[ Tue May 16 07:49:09 2023 ] 	Batch(259/480) done. Loss: 1.1170  lr:0.100000  network_time: 0.0112
[ Tue May 16 07:49:58 2023 ] 	Batch(359/480) done. Loss: 0.2788  lr:0.100000  network_time: 0.0121
[ Tue May 16 07:50:47 2023 ] 	Batch(459/480) done. Loss: 0.2092  lr:0.100000  network_time: 0.0116
[ Tue May 16 07:50:57 2023 ] 	Training Accuracy: 82.75%
[ Tue May 16 07:50:57 2023 ] Eval epoch: 14
[ Tue May 16 07:51:13 2023 ] 	Mean test loss of 120 batches: 0.378826767206192.
[ Tue May 16 07:51:13 2023 ] 	Top1: 88.67%
[ Tue May 16 07:51:13 2023 ] 	Top5: 99.50%
[ Tue May 16 07:51:13 2023 ] Training epoch: 15
[ Tue May 16 07:51:52 2023 ] 	Batch(79/480) done. Loss: 0.7718  lr:0.100000  network_time: 0.0115
[ Tue May 16 07:52:41 2023 ] 	Batch(179/480) done. Loss: 0.1266  lr:0.100000  network_time: 0.0112
[ Tue May 16 07:53:30 2023 ] 	Batch(279/480) done. Loss: 0.2282  lr:0.100000  network_time: 0.0112
[ Tue May 16 07:54:19 2023 ] 	Batch(379/480) done. Loss: 1.0690  lr:0.100000  network_time: 0.0117
[ Tue May 16 07:55:08 2023 ] 	Batch(479/480) done. Loss: 0.1309  lr:0.100000  network_time: 0.0113
[ Tue May 16 07:55:08 2023 ] 	Training Accuracy: 83.13%
[ Tue May 16 07:55:08 2023 ] Eval epoch: 15
[ Tue May 16 07:55:24 2023 ] 	Mean test loss of 120 batches: 0.3747045397758484.
[ Tue May 16 07:55:24 2023 ] 	Top1: 87.83%
[ Tue May 16 07:55:24 2023 ] 	Top5: 100.00%
[ Tue May 16 07:55:24 2023 ] Training epoch: 16
[ Tue May 16 07:56:13 2023 ] 	Batch(99/480) done. Loss: 0.1845  lr:0.100000  network_time: 0.0111
[ Tue May 16 07:57:02 2023 ] 	Batch(199/480) done. Loss: 0.2267  lr:0.100000  network_time: 0.0113
[ Tue May 16 07:57:51 2023 ] 	Batch(299/480) done. Loss: 0.2724  lr:0.100000  network_time: 0.0113
[ Tue May 16 07:58:39 2023 ] 	Batch(399/480) done. Loss: 0.0675  lr:0.100000  network_time: 0.0112
[ Tue May 16 07:59:18 2023 ] 	Training Accuracy: 85.92%
[ Tue May 16 07:59:18 2023 ] Eval epoch: 16
[ Tue May 16 07:59:35 2023 ] 	Mean test loss of 120 batches: 0.3070944547653198.
[ Tue May 16 07:59:35 2023 ] 	Top1: 90.17%
[ Tue May 16 07:59:35 2023 ] 	Top5: 99.67%
[ Tue May 16 07:59:35 2023 ] Training epoch: 17
[ Tue May 16 07:59:45 2023 ] 	Batch(19/480) done. Loss: 0.1519  lr:0.100000  network_time: 0.0116
[ Tue May 16 08:00:34 2023 ] 	Batch(119/480) done. Loss: 0.0613  lr:0.100000  network_time: 0.0111
[ Tue May 16 08:01:23 2023 ] 	Batch(219/480) done. Loss: 0.0796  lr:0.100000  network_time: 0.0113
[ Tue May 16 08:02:11 2023 ] 	Batch(319/480) done. Loss: 0.7823  lr:0.100000  network_time: 0.0113
[ Tue May 16 08:03:00 2023 ] 	Batch(419/480) done. Loss: 0.4417  lr:0.100000  network_time: 0.0115
[ Tue May 16 08:03:29 2023 ] 	Training Accuracy: 87.92%
[ Tue May 16 08:03:29 2023 ] Eval epoch: 17
[ Tue May 16 08:03:46 2023 ] 	Mean test loss of 120 batches: 0.39203986525535583.
[ Tue May 16 08:03:46 2023 ] 	Top1: 89.50%
[ Tue May 16 08:03:46 2023 ] 	Top5: 99.83%
[ Tue May 16 08:03:46 2023 ] Training epoch: 18
[ Tue May 16 08:04:06 2023 ] 	Batch(39/480) done. Loss: 0.1756  lr:0.100000  network_time: 0.0120
[ Tue May 16 08:04:54 2023 ] 	Batch(139/480) done. Loss: 0.5915  lr:0.100000  network_time: 0.0123
[ Tue May 16 08:05:43 2023 ] 	Batch(239/480) done. Loss: 0.4954  lr:0.100000  network_time: 0.0109
[ Tue May 16 08:06:32 2023 ] 	Batch(339/480) done. Loss: 0.7086  lr:0.100000  network_time: 0.0111
[ Tue May 16 08:07:21 2023 ] 	Batch(439/480) done. Loss: 0.1912  lr:0.100000  network_time: 0.0112
[ Tue May 16 08:07:40 2023 ] 	Training Accuracy: 87.63%
[ Tue May 16 08:07:40 2023 ] Eval epoch: 18
[ Tue May 16 08:07:57 2023 ] 	Mean test loss of 120 batches: 0.5475047826766968.
[ Tue May 16 08:07:57 2023 ] 	Top1: 86.33%
[ Tue May 16 08:07:57 2023 ] 	Top5: 99.33%
[ Tue May 16 08:07:57 2023 ] Training epoch: 19
[ Tue May 16 08:08:26 2023 ] 	Batch(59/480) done. Loss: 0.0795  lr:0.100000  network_time: 0.0114
[ Tue May 16 08:09:15 2023 ] 	Batch(159/480) done. Loss: 0.2217  lr:0.100000  network_time: 0.0113
[ Tue May 16 08:10:04 2023 ] 	Batch(259/480) done. Loss: 0.2075  lr:0.100000  network_time: 0.0111
[ Tue May 16 08:10:53 2023 ] 	Batch(359/480) done. Loss: 0.3238  lr:0.100000  network_time: 0.0113
[ Tue May 16 08:11:41 2023 ] 	Batch(459/480) done. Loss: 0.1117  lr:0.100000  network_time: 0.0115
[ Tue May 16 08:11:51 2023 ] 	Training Accuracy: 88.29%
[ Tue May 16 08:11:51 2023 ] Eval epoch: 19
[ Tue May 16 08:12:08 2023 ] 	Mean test loss of 120 batches: 0.12865708768367767.
[ Tue May 16 08:12:08 2023 ] 	Top1: 96.33%
[ Tue May 16 08:12:08 2023 ] 	Top5: 100.00%
[ Tue May 16 08:12:08 2023 ] Training epoch: 20
[ Tue May 16 08:12:47 2023 ] 	Batch(79/480) done. Loss: 0.1477  lr:0.100000  network_time: 0.0112
[ Tue May 16 08:13:36 2023 ] 	Batch(179/480) done. Loss: 1.1081  lr:0.100000  network_time: 0.0110
[ Tue May 16 08:14:24 2023 ] 	Batch(279/480) done. Loss: 0.8202  lr:0.100000  network_time: 0.0111
[ Tue May 16 08:15:13 2023 ] 	Batch(379/480) done. Loss: 0.0517  lr:0.100000  network_time: 0.0114
[ Tue May 16 08:16:02 2023 ] 	Batch(479/480) done. Loss: 0.2450  lr:0.100000  network_time: 0.0109
[ Tue May 16 08:16:02 2023 ] 	Training Accuracy: 89.79%
[ Tue May 16 08:16:02 2023 ] Eval epoch: 20
[ Tue May 16 08:16:19 2023 ] 	Mean test loss of 120 batches: 0.31398093700408936.
[ Tue May 16 08:16:19 2023 ] 	Top1: 89.50%
[ Tue May 16 08:16:19 2023 ] 	Top5: 99.17%
[ Tue May 16 08:16:19 2023 ] Training epoch: 21
[ Tue May 16 08:17:07 2023 ] 	Batch(99/480) done. Loss: 0.3871  lr:0.010000  network_time: 0.0110
[ Tue May 16 08:17:56 2023 ] 	Batch(199/480) done. Loss: 0.0821  lr:0.010000  network_time: 0.0112
[ Tue May 16 08:18:45 2023 ] 	Batch(299/480) done. Loss: 0.0080  lr:0.010000  network_time: 0.0113
[ Tue May 16 08:19:34 2023 ] 	Batch(399/480) done. Loss: 0.0157  lr:0.010000  network_time: 0.0122
[ Tue May 16 08:20:13 2023 ] 	Training Accuracy: 96.75%
[ Tue May 16 08:20:13 2023 ] Eval epoch: 21
[ Tue May 16 08:20:30 2023 ] 	Mean test loss of 120 batches: 0.051302600651979446.
[ Tue May 16 08:20:30 2023 ] 	Top1: 98.50%
[ Tue May 16 08:20:30 2023 ] 	Top5: 100.00%
[ Tue May 16 08:20:30 2023 ] Training epoch: 22
[ Tue May 16 08:20:40 2023 ] 	Batch(19/480) done. Loss: 0.0243  lr:0.010000  network_time: 0.0111
[ Tue May 16 08:21:28 2023 ] 	Batch(119/480) done. Loss: 0.1172  lr:0.010000  network_time: 0.0110
[ Tue May 16 08:22:17 2023 ] 	Batch(219/480) done. Loss: 0.0050  lr:0.010000  network_time: 0.0112
[ Tue May 16 08:23:06 2023 ] 	Batch(319/480) done. Loss: 0.0320  lr:0.010000  network_time: 0.0118
[ Tue May 16 08:23:55 2023 ] 	Batch(419/480) done. Loss: 0.0516  lr:0.010000  network_time: 0.0111
[ Tue May 16 08:24:24 2023 ] 	Training Accuracy: 98.08%
[ Tue May 16 08:24:24 2023 ] Eval epoch: 22
[ Tue May 16 08:24:41 2023 ] 	Mean test loss of 120 batches: 0.05763138458132744.
[ Tue May 16 08:24:41 2023 ] 	Top1: 97.67%
[ Tue May 16 08:24:41 2023 ] 	Top5: 100.00%
[ Tue May 16 08:24:41 2023 ] Training epoch: 23
[ Tue May 16 08:25:00 2023 ] 	Batch(39/480) done. Loss: 0.0361  lr:0.010000  network_time: 0.0111
[ Tue May 16 08:25:49 2023 ] 	Batch(139/480) done. Loss: 0.0414  lr:0.010000  network_time: 0.0112
[ Tue May 16 08:26:38 2023 ] 	Batch(239/480) done. Loss: 0.1020  lr:0.010000  network_time: 0.0119
[ Tue May 16 08:27:27 2023 ] 	Batch(339/480) done. Loss: 0.0100  lr:0.010000  network_time: 0.0113
[ Tue May 16 08:28:16 2023 ] 	Batch(439/480) done. Loss: 0.0614  lr:0.010000  network_time: 0.0117
[ Tue May 16 08:28:35 2023 ] 	Training Accuracy: 98.96%
[ Tue May 16 08:28:35 2023 ] Eval epoch: 23
[ Tue May 16 08:28:52 2023 ] 	Mean test loss of 120 batches: 0.030979391187429428.
[ Tue May 16 08:28:52 2023 ] 	Top1: 98.50%
[ Tue May 16 08:28:52 2023 ] 	Top5: 100.00%
[ Tue May 16 08:28:52 2023 ] Training epoch: 24
[ Tue May 16 08:29:21 2023 ] 	Batch(59/480) done. Loss: 0.0718  lr:0.010000  network_time: 0.0108
[ Tue May 16 08:30:10 2023 ] 	Batch(159/480) done. Loss: 0.1045  lr:0.010000  network_time: 0.0109
[ Tue May 16 08:30:59 2023 ] 	Batch(259/480) done. Loss: 0.0381  lr:0.010000  network_time: 0.0108
[ Tue May 16 08:31:48 2023 ] 	Batch(359/480) done. Loss: 0.0280  lr:0.010000  network_time: 0.0119
[ Tue May 16 08:32:36 2023 ] 	Batch(459/480) done. Loss: 0.0031  lr:0.010000  network_time: 0.0112
[ Tue May 16 08:32:46 2023 ] 	Training Accuracy: 98.67%
[ Tue May 16 08:32:46 2023 ] Eval epoch: 24
[ Tue May 16 08:33:03 2023 ] 	Mean test loss of 120 batches: 0.03148907423019409.
[ Tue May 16 08:33:03 2023 ] 	Top1: 99.17%
[ Tue May 16 08:33:03 2023 ] 	Top5: 100.00%
[ Tue May 16 08:33:03 2023 ] Training epoch: 25
[ Tue May 16 08:33:42 2023 ] 	Batch(79/480) done. Loss: 0.0093  lr:0.010000  network_time: 0.0115
[ Tue May 16 08:34:31 2023 ] 	Batch(179/480) done. Loss: 0.0384  lr:0.010000  network_time: 0.0111
[ Tue May 16 08:35:20 2023 ] 	Batch(279/480) done. Loss: 0.0079  lr:0.010000  network_time: 0.0113
[ Tue May 16 08:36:09 2023 ] 	Batch(379/480) done. Loss: 0.0329  lr:0.010000  network_time: 0.0115
[ Tue May 16 08:36:57 2023 ] 	Batch(479/480) done. Loss: 0.0401  lr:0.010000  network_time: 0.0109
[ Tue May 16 08:36:57 2023 ] 	Training Accuracy: 98.79%
[ Tue May 16 08:36:57 2023 ] Eval epoch: 25
[ Tue May 16 08:37:14 2023 ] 	Mean test loss of 120 batches: 0.014190427027642727.
[ Tue May 16 08:37:14 2023 ] 	Top1: 100.00%
[ Tue May 16 08:37:14 2023 ] 	Top5: 100.00%
[ Tue May 16 08:37:14 2023 ] Training epoch: 26
[ Tue May 16 08:38:03 2023 ] 	Batch(99/480) done. Loss: 0.0070  lr:0.001000  network_time: 0.0115
[ Tue May 16 08:38:52 2023 ] 	Batch(199/480) done. Loss: 0.0982  lr:0.001000  network_time: 0.0117
[ Tue May 16 08:39:41 2023 ] 	Batch(299/480) done. Loss: 0.0858  lr:0.001000  network_time: 0.0111
[ Tue May 16 08:40:29 2023 ] 	Batch(399/480) done. Loss: 0.1131  lr:0.001000  network_time: 0.0113
[ Tue May 16 08:41:08 2023 ] 	Training Accuracy: 99.50%
[ Tue May 16 08:41:08 2023 ] Eval epoch: 26
[ Tue May 16 08:41:25 2023 ] 	Mean test loss of 120 batches: 0.01918720453977585.
[ Tue May 16 08:41:25 2023 ] 	Top1: 99.83%
[ Tue May 16 08:41:25 2023 ] 	Top5: 100.00%
[ Tue May 16 08:41:25 2023 ] Training epoch: 27
[ Tue May 16 08:41:35 2023 ] 	Batch(19/480) done. Loss: 0.0061  lr:0.001000  network_time: 0.0113
[ Tue May 16 08:42:24 2023 ] 	Batch(119/480) done. Loss: 0.0062  lr:0.001000  network_time: 0.0113
[ Tue May 16 08:43:13 2023 ] 	Batch(219/480) done. Loss: 0.0639  lr:0.001000  network_time: 0.0111
[ Tue May 16 08:44:01 2023 ] 	Batch(319/480) done. Loss: 0.0529  lr:0.001000  network_time: 0.0110
[ Tue May 16 08:44:50 2023 ] 	Batch(419/480) done. Loss: 0.0219  lr:0.001000  network_time: 0.0112
[ Tue May 16 08:45:19 2023 ] 	Training Accuracy: 99.25%
[ Tue May 16 08:45:20 2023 ] Eval epoch: 27
[ Tue May 16 08:45:36 2023 ] 	Mean test loss of 120 batches: 0.021591242402791977.
[ Tue May 16 08:45:36 2023 ] 	Top1: 99.83%
[ Tue May 16 08:45:36 2023 ] 	Top5: 100.00%
[ Tue May 16 08:45:36 2023 ] Training epoch: 28
[ Tue May 16 08:45:56 2023 ] 	Batch(39/480) done. Loss: 0.0646  lr:0.001000  network_time: 0.0112
[ Tue May 16 08:46:45 2023 ] 	Batch(139/480) done. Loss: 0.3226  lr:0.001000  network_time: 0.0111
[ Tue May 16 08:47:33 2023 ] 	Batch(239/480) done. Loss: 0.0931  lr:0.001000  network_time: 0.0114
[ Tue May 16 08:48:22 2023 ] 	Batch(339/480) done. Loss: 0.1179  lr:0.001000  network_time: 0.0113
[ Tue May 16 08:49:11 2023 ] 	Batch(439/480) done. Loss: 0.0428  lr:0.001000  network_time: 0.0113
[ Tue May 16 08:49:31 2023 ] 	Training Accuracy: 99.21%
[ Tue May 16 08:49:31 2023 ] Eval epoch: 28
[ Tue May 16 08:49:47 2023 ] 	Mean test loss of 120 batches: 0.018257806077599525.
[ Tue May 16 08:49:47 2023 ] 	Top1: 99.33%
[ Tue May 16 08:49:47 2023 ] 	Top5: 100.00%
[ Tue May 16 08:49:47 2023 ] Training epoch: 29
[ Tue May 16 08:50:17 2023 ] 	Batch(59/480) done. Loss: 0.0708  lr:0.001000  network_time: 0.0109
[ Tue May 16 08:51:05 2023 ] 	Batch(159/480) done. Loss: 0.0341  lr:0.001000  network_time: 0.0112
[ Tue May 16 08:51:54 2023 ] 	Batch(259/480) done. Loss: 0.0235  lr:0.001000  network_time: 0.0109
[ Tue May 16 08:52:43 2023 ] 	Batch(359/480) done. Loss: 0.0263  lr:0.001000  network_time: 0.0109
[ Tue May 16 08:53:32 2023 ] 	Batch(459/480) done. Loss: 0.0584  lr:0.001000  network_time: 0.0112
[ Tue May 16 08:53:42 2023 ] 	Training Accuracy: 99.17%
[ Tue May 16 08:53:42 2023 ] Eval epoch: 29
[ Tue May 16 08:53:58 2023 ] 	Mean test loss of 120 batches: 0.014973489567637444.
[ Tue May 16 08:53:58 2023 ] 	Top1: 100.00%
[ Tue May 16 08:53:58 2023 ] 	Top5: 100.00%
[ Tue May 16 08:53:58 2023 ] Training epoch: 30
[ Tue May 16 08:54:38 2023 ] 	Batch(79/480) done. Loss: 0.0030  lr:0.001000  network_time: 0.0112
[ Tue May 16 08:55:26 2023 ] 	Batch(179/480) done. Loss: 0.0166  lr:0.001000  network_time: 0.0113
[ Tue May 16 08:56:15 2023 ] 	Batch(279/480) done. Loss: 0.0224  lr:0.001000  network_time: 0.0111
[ Tue May 16 08:57:04 2023 ] 	Batch(379/480) done. Loss: 0.0139  lr:0.001000  network_time: 0.0114
[ Tue May 16 08:57:53 2023 ] 	Batch(479/480) done. Loss: 0.0076  lr:0.001000  network_time: 0.0110
[ Tue May 16 08:57:53 2023 ] 	Training Accuracy: 99.04%
[ Tue May 16 08:57:53 2023 ] Eval epoch: 30
[ Tue May 16 08:58:10 2023 ] 	Mean test loss of 120 batches: 0.02293648011982441.
[ Tue May 16 08:58:10 2023 ] 	Top1: 99.33%
[ Tue May 16 08:58:10 2023 ] 	Top5: 100.00%
