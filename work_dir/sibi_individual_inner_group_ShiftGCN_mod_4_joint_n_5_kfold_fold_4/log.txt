[ Fri May 12 05:11:41 2023 ] NUM WORKER: 1
[ Fri May 12 05:15:06 2023 ] Parameters:
{'work_dir': './work_dir/sibi_individual_inner_group_ShiftGCN_mod_4_joint_n_5_kfold_fold_4', 'model_saved_name': './save_models/sibi_individual_inner_group_ShiftGCN_mod_4_joint_n_5_kfold_fold_4', 'Experiment_name': 'sibi_individual_inner_group_ShiftGCN_mod_4_joint_n_5_kfold', 'config': './config/recalculated/train_sibi_with_mouth_augmented_individual_inner_group_shift_joint_mod_4.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 2, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'n_splits': 5, 'feeder': 'feeders.feeder_hsd.Feeder', 'num_worker': 1, 'train_feeder_args': {'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': -1, 'normalization': False}, 'test_feeder_args': None, 'data_path': './data/augmented_recalculate_normalized', 'model': 'model.shift_gcn.Model', 'model_args': {'num_class': 50, 'num_person': 1, 'num_point': 115, 'graph_group': [[0, 39], [40, 60], [61, 81], [82, 114]], 'method': 'grouped.inner', 'weight': 4, 'graph': 'graph.skeleton_with_mouth.SkeletonWithMouth', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [20, 25], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 5, 'test_batch_size': 5, 'start_epoch': 0, 'num_epoch': 30, 'folds_range': [3, 5], 'weight_decay': 0.0001, 'only_train_part': True, 'only_train_epoch': 1, 'warm_up_epoch': 0}

[ Fri May 12 05:15:06 2023 ] Training epoch: 1
[ Fri May 12 05:15:55 2023 ] 	Batch(99/480) done. Loss: 3.7623  lr:0.100000  network_time: 0.0114
[ Fri May 12 05:16:42 2023 ] 	Batch(199/480) done. Loss: 3.2515  lr:0.100000  network_time: 0.0118
[ Fri May 12 05:17:30 2023 ] 	Batch(299/480) done. Loss: 3.4469  lr:0.100000  network_time: 0.0115
[ Fri May 12 05:18:17 2023 ] 	Batch(399/480) done. Loss: 4.1800  lr:0.100000  network_time: 0.0112
[ Fri May 12 05:18:55 2023 ] 	Training Accuracy: 5.12%
[ Fri May 12 05:18:55 2023 ] Eval epoch: 1
[ Fri May 12 05:19:11 2023 ] 	Mean test loss of 120 batches: 3.6004562377929688.
[ Fri May 12 05:19:11 2023 ] 	Top1: 10.67%
[ Fri May 12 05:19:11 2023 ] 	Top5: 42.50%
[ Fri May 12 05:19:12 2023 ] Training epoch: 2
[ Fri May 12 05:19:21 2023 ] 	Batch(19/480) done. Loss: 2.7284  lr:0.100000  network_time: 0.0112
[ Fri May 12 05:20:09 2023 ] 	Batch(119/480) done. Loss: 3.5870  lr:0.100000  network_time: 0.0119
[ Fri May 12 05:20:56 2023 ] 	Batch(219/480) done. Loss: 2.8089  lr:0.100000  network_time: 0.0115
[ Fri May 12 05:21:43 2023 ] 	Batch(319/480) done. Loss: 2.8701  lr:0.100000  network_time: 0.0110
[ Fri May 12 05:22:31 2023 ] 	Batch(419/480) done. Loss: 2.0945  lr:0.100000  network_time: 0.0116
[ Fri May 12 05:22:59 2023 ] 	Training Accuracy: 13.00%
[ Fri May 12 05:22:59 2023 ] Eval epoch: 2
[ Fri May 12 05:23:16 2023 ] 	Mean test loss of 120 batches: 2.6409828662872314.
[ Fri May 12 05:23:16 2023 ] 	Top1: 20.17%
[ Fri May 12 05:23:16 2023 ] 	Top5: 62.67%
[ Fri May 12 05:23:16 2023 ] Training epoch: 3
[ Fri May 12 05:23:35 2023 ] 	Batch(39/480) done. Loss: 2.9907  lr:0.100000  network_time: 0.0116
[ Fri May 12 05:24:22 2023 ] 	Batch(139/480) done. Loss: 2.6536  lr:0.100000  network_time: 0.0114
[ Fri May 12 05:25:10 2023 ] 	Batch(239/480) done. Loss: 2.3221  lr:0.100000  network_time: 0.0120
[ Fri May 12 05:25:57 2023 ] 	Batch(339/480) done. Loss: 2.5715  lr:0.100000  network_time: 0.0117
[ Fri May 12 05:26:45 2023 ] 	Batch(439/480) done. Loss: 1.9976  lr:0.100000  network_time: 0.0116
[ Fri May 12 05:27:03 2023 ] 	Training Accuracy: 22.33%
[ Fri May 12 05:27:04 2023 ] Eval epoch: 3
[ Fri May 12 05:27:20 2023 ] 	Mean test loss of 120 batches: 2.2741622924804688.
[ Fri May 12 05:27:20 2023 ] 	Top1: 29.83%
[ Fri May 12 05:27:20 2023 ] 	Top5: 77.83%
[ Fri May 12 05:27:20 2023 ] Training epoch: 4
[ Fri May 12 05:27:49 2023 ] 	Batch(59/480) done. Loss: 2.3020  lr:0.100000  network_time: 0.0113
[ Fri May 12 05:28:36 2023 ] 	Batch(159/480) done. Loss: 2.8756  lr:0.100000  network_time: 0.0112
[ Fri May 12 05:29:24 2023 ] 	Batch(259/480) done. Loss: 2.5069  lr:0.100000  network_time: 0.0114
[ Fri May 12 05:30:11 2023 ] 	Batch(359/480) done. Loss: 2.0206  lr:0.100000  network_time: 0.0117
[ Fri May 12 05:30:59 2023 ] 	Batch(459/480) done. Loss: 2.5347  lr:0.100000  network_time: 0.0123
[ Fri May 12 05:31:08 2023 ] 	Training Accuracy: 30.29%
[ Fri May 12 05:31:08 2023 ] Eval epoch: 4
[ Fri May 12 05:31:25 2023 ] 	Mean test loss of 120 batches: 2.4981653690338135.
[ Fri May 12 05:31:25 2023 ] 	Top1: 31.17%
[ Fri May 12 05:31:25 2023 ] 	Top5: 65.67%
[ Fri May 12 05:31:25 2023 ] Training epoch: 5
[ Fri May 12 05:32:02 2023 ] 	Batch(79/480) done. Loss: 1.2842  lr:0.100000  network_time: 0.0114
[ Fri May 12 05:32:50 2023 ] 	Batch(179/480) done. Loss: 1.3354  lr:0.100000  network_time: 0.0114
[ Fri May 12 05:33:37 2023 ] 	Batch(279/480) done. Loss: 1.9761  lr:0.100000  network_time: 0.0120
[ Fri May 12 05:34:25 2023 ] 	Batch(379/480) done. Loss: 1.4530  lr:0.100000  network_time: 0.0118
[ Fri May 12 05:35:12 2023 ] 	Batch(479/480) done. Loss: 1.3586  lr:0.100000  network_time: 0.0148
[ Fri May 12 05:35:12 2023 ] 	Training Accuracy: 36.96%
[ Fri May 12 05:35:12 2023 ] Eval epoch: 5
[ Fri May 12 05:35:29 2023 ] 	Mean test loss of 120 batches: 1.7799530029296875.
[ Fri May 12 05:35:29 2023 ] 	Top1: 47.00%
[ Fri May 12 05:35:29 2023 ] 	Top5: 89.00%
[ Fri May 12 05:35:29 2023 ] Training epoch: 6
[ Fri May 12 05:36:16 2023 ] 	Batch(99/480) done. Loss: 2.3375  lr:0.100000  network_time: 0.0119
[ Fri May 12 05:37:04 2023 ] 	Batch(199/480) done. Loss: 1.0212  lr:0.100000  network_time: 0.0116
[ Fri May 12 05:37:51 2023 ] 	Batch(299/480) done. Loss: 2.5481  lr:0.100000  network_time: 0.0116
[ Fri May 12 05:38:39 2023 ] 	Batch(399/480) done. Loss: 1.4086  lr:0.100000  network_time: 0.0114
[ Fri May 12 05:39:17 2023 ] 	Training Accuracy: 49.33%
[ Fri May 12 05:39:17 2023 ] Eval epoch: 6
[ Fri May 12 05:39:33 2023 ] 	Mean test loss of 120 batches: 13.120049476623535.
[ Fri May 12 05:39:33 2023 ] 	Top1: 9.17%
[ Fri May 12 05:39:33 2023 ] 	Top5: 32.00%
[ Fri May 12 05:39:33 2023 ] Training epoch: 7
[ Fri May 12 05:39:43 2023 ] 	Batch(19/480) done. Loss: 1.9868  lr:0.100000  network_time: 0.0119
[ Fri May 12 05:40:30 2023 ] 	Batch(119/480) done. Loss: 1.3163  lr:0.100000  network_time: 0.0112
[ Fri May 12 05:41:18 2023 ] 	Batch(219/480) done. Loss: 1.9684  lr:0.100000  network_time: 0.0114
[ Fri May 12 05:42:05 2023 ] 	Batch(319/480) done. Loss: 0.9269  lr:0.100000  network_time: 0.0117
[ Fri May 12 05:42:53 2023 ] 	Batch(419/480) done. Loss: 1.6328  lr:0.100000  network_time: 0.0115
[ Fri May 12 05:43:21 2023 ] 	Training Accuracy: 56.46%
[ Fri May 12 05:43:21 2023 ] Eval epoch: 7
[ Fri May 12 05:43:38 2023 ] 	Mean test loss of 120 batches: 4.809998035430908.
[ Fri May 12 05:43:38 2023 ] 	Top1: 18.50%
[ Fri May 12 05:43:38 2023 ] 	Top5: 48.67%
[ Fri May 12 05:43:38 2023 ] Training epoch: 8
[ Fri May 12 05:43:57 2023 ] 	Batch(39/480) done. Loss: 1.7624  lr:0.100000  network_time: 0.0111
[ Fri May 12 05:44:44 2023 ] 	Batch(139/480) done. Loss: 1.7680  lr:0.100000  network_time: 0.0123
[ Fri May 12 05:45:32 2023 ] 	Batch(239/480) done. Loss: 4.1434  lr:0.100000  network_time: 0.0119
[ Fri May 12 05:46:20 2023 ] 	Batch(339/480) done. Loss: 0.7420  lr:0.100000  network_time: 0.0118
[ Fri May 12 05:47:07 2023 ] 	Batch(439/480) done. Loss: 0.4780  lr:0.100000  network_time: 0.0118
[ Fri May 12 05:47:26 2023 ] 	Training Accuracy: 62.42%
[ Fri May 12 05:47:26 2023 ] Eval epoch: 8
[ Fri May 12 05:47:43 2023 ] 	Mean test loss of 120 batches: 0.9679092168807983.
[ Fri May 12 05:47:43 2023 ] 	Top1: 72.00%
[ Fri May 12 05:47:43 2023 ] 	Top5: 94.17%
[ Fri May 12 05:47:43 2023 ] Training epoch: 9
[ Fri May 12 05:48:11 2023 ] 	Batch(59/480) done. Loss: 0.9731  lr:0.100000  network_time: 0.0115
[ Fri May 12 05:48:59 2023 ] 	Batch(159/480) done. Loss: 0.4120  lr:0.100000  network_time: 0.0117
[ Fri May 12 05:49:46 2023 ] 	Batch(259/480) done. Loss: 0.7712  lr:0.100000  network_time: 0.0122
[ Fri May 12 05:50:34 2023 ] 	Batch(359/480) done. Loss: 0.7774  lr:0.100000  network_time: 0.0116
[ Fri May 12 05:51:21 2023 ] 	Batch(459/480) done. Loss: 0.9496  lr:0.100000  network_time: 0.0114
[ Fri May 12 05:51:31 2023 ] 	Training Accuracy: 70.42%
[ Fri May 12 05:51:31 2023 ] Eval epoch: 9
[ Fri May 12 05:51:47 2023 ] 	Mean test loss of 120 batches: 1.1839779615402222.
[ Fri May 12 05:51:47 2023 ] 	Top1: 67.83%
[ Fri May 12 05:51:47 2023 ] 	Top5: 94.67%
[ Fri May 12 05:51:47 2023 ] Training epoch: 10
[ Fri May 12 05:52:25 2023 ] 	Batch(79/480) done. Loss: 1.3214  lr:0.100000  network_time: 0.0114
[ Fri May 12 05:53:13 2023 ] 	Batch(179/480) done. Loss: 0.2508  lr:0.100000  network_time: 0.0116
[ Fri May 12 05:54:01 2023 ] 	Batch(279/480) done. Loss: 0.7738  lr:0.100000  network_time: 0.0115
[ Fri May 12 05:54:48 2023 ] 	Batch(379/480) done. Loss: 0.5557  lr:0.100000  network_time: 0.0121
[ Fri May 12 05:55:36 2023 ] 	Batch(479/480) done. Loss: 0.4990  lr:0.100000  network_time: 0.0119
[ Fri May 12 05:55:36 2023 ] 	Training Accuracy: 74.12%
[ Fri May 12 05:55:36 2023 ] Eval epoch: 10
[ Fri May 12 05:55:52 2023 ] 	Mean test loss of 120 batches: 0.9064821600914001.
[ Fri May 12 05:55:52 2023 ] 	Top1: 73.33%
[ Fri May 12 05:55:52 2023 ] 	Top5: 96.67%
[ Fri May 12 05:55:52 2023 ] Training epoch: 11
[ Fri May 12 05:56:40 2023 ] 	Batch(99/480) done. Loss: 0.0400  lr:0.100000  network_time: 0.0118
[ Fri May 12 05:57:27 2023 ] 	Batch(199/480) done. Loss: 0.3517  lr:0.100000  network_time: 0.0115
[ Fri May 12 05:58:15 2023 ] 	Batch(299/480) done. Loss: 0.7434  lr:0.100000  network_time: 0.0115
[ Fri May 12 05:59:02 2023 ] 	Batch(399/480) done. Loss: 0.3919  lr:0.100000  network_time: 0.0122
[ Fri May 12 05:59:41 2023 ] 	Training Accuracy: 79.75%
[ Fri May 12 05:59:41 2023 ] Eval epoch: 11
[ Fri May 12 05:59:57 2023 ] 	Mean test loss of 120 batches: 4.463304042816162.
[ Fri May 12 05:59:57 2023 ] 	Top1: 38.33%
[ Fri May 12 05:59:57 2023 ] 	Top5: 67.67%
[ Fri May 12 05:59:57 2023 ] Training epoch: 12
[ Fri May 12 06:00:07 2023 ] 	Batch(19/480) done. Loss: 2.3122  lr:0.100000  network_time: 0.0113
[ Fri May 12 06:00:54 2023 ] 	Batch(119/480) done. Loss: 2.1941  lr:0.100000  network_time: 0.0113
[ Fri May 12 06:01:42 2023 ] 	Batch(219/480) done. Loss: 0.1589  lr:0.100000  network_time: 0.0116
[ Fri May 12 06:02:29 2023 ] 	Batch(319/480) done. Loss: 0.8502  lr:0.100000  network_time: 0.0125
[ Fri May 12 06:03:17 2023 ] 	Batch(419/480) done. Loss: 0.7104  lr:0.100000  network_time: 0.0114
[ Fri May 12 06:03:45 2023 ] 	Training Accuracy: 80.71%
[ Fri May 12 06:03:45 2023 ] Eval epoch: 12
[ Fri May 12 06:04:02 2023 ] 	Mean test loss of 120 batches: 0.6236401796340942.
[ Fri May 12 06:04:02 2023 ] 	Top1: 80.33%
[ Fri May 12 06:04:02 2023 ] 	Top5: 97.67%
[ Fri May 12 06:04:02 2023 ] Training epoch: 13
[ Fri May 12 06:04:21 2023 ] 	Batch(39/480) done. Loss: 0.2641  lr:0.100000  network_time: 0.0119
[ Fri May 12 06:05:09 2023 ] 	Batch(139/480) done. Loss: 0.0738  lr:0.100000  network_time: 0.0111
[ Fri May 12 06:05:56 2023 ] 	Batch(239/480) done. Loss: 0.2446  lr:0.100000  network_time: 0.0121
[ Fri May 12 06:06:44 2023 ] 	Batch(339/480) done. Loss: 0.0281  lr:0.100000  network_time: 0.0126
[ Fri May 12 06:07:31 2023 ] 	Batch(439/480) done. Loss: 0.1878  lr:0.100000  network_time: 0.0119
[ Fri May 12 06:07:51 2023 ] 	Training Accuracy: 85.67%
[ Fri May 12 06:07:51 2023 ] Eval epoch: 13
[ Fri May 12 06:08:07 2023 ] 	Mean test loss of 120 batches: 0.617064356803894.
[ Fri May 12 06:08:07 2023 ] 	Top1: 80.83%
[ Fri May 12 06:08:07 2023 ] 	Top5: 98.50%
[ Fri May 12 06:08:07 2023 ] Training epoch: 14
[ Fri May 12 06:08:36 2023 ] 	Batch(59/480) done. Loss: 0.0440  lr:0.100000  network_time: 0.0114
[ Fri May 12 06:09:23 2023 ] 	Batch(159/480) done. Loss: 0.2869  lr:0.100000  network_time: 0.0129
[ Fri May 12 06:10:11 2023 ] 	Batch(259/480) done. Loss: 0.0593  lr:0.100000  network_time: 0.0124
[ Fri May 12 06:10:58 2023 ] 	Batch(359/480) done. Loss: 0.3461  lr:0.100000  network_time: 0.0115
[ Fri May 12 06:11:46 2023 ] 	Batch(459/480) done. Loss: 0.2653  lr:0.100000  network_time: 0.0119
[ Fri May 12 06:11:55 2023 ] 	Training Accuracy: 85.96%
[ Fri May 12 06:11:55 2023 ] Eval epoch: 14
[ Fri May 12 06:12:12 2023 ] 	Mean test loss of 120 batches: 0.33029359579086304.
[ Fri May 12 06:12:12 2023 ] 	Top1: 88.83%
[ Fri May 12 06:12:12 2023 ] 	Top5: 100.00%
[ Fri May 12 06:12:12 2023 ] Training epoch: 15
[ Fri May 12 06:12:50 2023 ] 	Batch(79/480) done. Loss: 1.4901  lr:0.100000  network_time: 0.0111
[ Fri May 12 06:13:38 2023 ] 	Batch(179/480) done. Loss: 0.8530  lr:0.100000  network_time: 0.0118
[ Fri May 12 06:14:25 2023 ] 	Batch(279/480) done. Loss: 0.7045  lr:0.100000  network_time: 0.0110
[ Fri May 12 06:15:13 2023 ] 	Batch(379/480) done. Loss: 0.1938  lr:0.100000  network_time: 0.0113
[ Fri May 12 06:16:01 2023 ] 	Batch(479/480) done. Loss: 0.0067  lr:0.100000  network_time: 0.0115
[ Fri May 12 06:16:01 2023 ] 	Training Accuracy: 86.92%
[ Fri May 12 06:16:01 2023 ] Eval epoch: 15
[ Fri May 12 06:16:17 2023 ] 	Mean test loss of 120 batches: 0.2513706386089325.
[ Fri May 12 06:16:17 2023 ] 	Top1: 92.33%
[ Fri May 12 06:16:17 2023 ] 	Top5: 100.00%
[ Fri May 12 06:16:17 2023 ] Training epoch: 16
[ Fri May 12 06:17:05 2023 ] 	Batch(99/480) done. Loss: 0.4950  lr:0.100000  network_time: 0.0112
[ Fri May 12 06:17:52 2023 ] 	Batch(199/480) done. Loss: 0.7484  lr:0.100000  network_time: 0.0115
[ Fri May 12 06:18:40 2023 ] 	Batch(299/480) done. Loss: 0.4407  lr:0.100000  network_time: 0.0113
[ Fri May 12 06:19:28 2023 ] 	Batch(399/480) done. Loss: 0.0537  lr:0.100000  network_time: 0.0122
[ Fri May 12 06:20:06 2023 ] 	Training Accuracy: 90.00%
[ Fri May 12 06:20:06 2023 ] Eval epoch: 16
[ Fri May 12 06:20:22 2023 ] 	Mean test loss of 120 batches: 0.23566749691963196.
[ Fri May 12 06:20:22 2023 ] 	Top1: 92.83%
[ Fri May 12 06:20:22 2023 ] 	Top5: 99.50%
[ Fri May 12 06:20:22 2023 ] Training epoch: 17
[ Fri May 12 06:20:32 2023 ] 	Batch(19/480) done. Loss: 0.2717  lr:0.100000  network_time: 0.0115
[ Fri May 12 06:21:19 2023 ] 	Batch(119/480) done. Loss: 0.2642  lr:0.100000  network_time: 0.0122
[ Fri May 12 06:22:07 2023 ] 	Batch(219/480) done. Loss: 0.3094  lr:0.100000  network_time: 0.0124
[ Fri May 12 06:22:55 2023 ] 	Batch(319/480) done. Loss: 0.4889  lr:0.100000  network_time: 0.0112
[ Fri May 12 06:23:42 2023 ] 	Batch(419/480) done. Loss: 0.0643  lr:0.100000  network_time: 0.0117
[ Fri May 12 06:24:11 2023 ] 	Training Accuracy: 88.25%
[ Fri May 12 06:24:11 2023 ] Eval epoch: 17
[ Fri May 12 06:24:27 2023 ] 	Mean test loss of 120 batches: 0.32114043831825256.
[ Fri May 12 06:24:27 2023 ] 	Top1: 90.17%
[ Fri May 12 06:24:27 2023 ] 	Top5: 100.00%
[ Fri May 12 06:24:27 2023 ] Training epoch: 18
[ Fri May 12 06:24:46 2023 ] 	Batch(39/480) done. Loss: 0.3023  lr:0.100000  network_time: 0.0121
[ Fri May 12 06:25:34 2023 ] 	Batch(139/480) done. Loss: 0.5084  lr:0.100000  network_time: 0.0114
[ Fri May 12 06:26:22 2023 ] 	Batch(239/480) done. Loss: 0.1049  lr:0.100000  network_time: 0.0117
[ Fri May 12 06:27:09 2023 ] 	Batch(339/480) done. Loss: 0.0881  lr:0.100000  network_time: 0.0118
[ Fri May 12 06:27:57 2023 ] 	Batch(439/480) done. Loss: 0.2670  lr:0.100000  network_time: 0.0116
[ Fri May 12 06:28:16 2023 ] 	Training Accuracy: 91.96%
[ Fri May 12 06:28:16 2023 ] Eval epoch: 18
[ Fri May 12 06:28:32 2023 ] 	Mean test loss of 120 batches: 0.4985736608505249.
[ Fri May 12 06:28:33 2023 ] 	Top1: 85.67%
[ Fri May 12 06:28:33 2023 ] 	Top5: 99.67%
[ Fri May 12 06:28:33 2023 ] Training epoch: 19
[ Fri May 12 06:29:01 2023 ] 	Batch(59/480) done. Loss: 0.0256  lr:0.100000  network_time: 0.0115
[ Fri May 12 06:29:49 2023 ] 	Batch(159/480) done. Loss: 0.0141  lr:0.100000  network_time: 0.0116
[ Fri May 12 06:30:36 2023 ] 	Batch(259/480) done. Loss: 0.0113  lr:0.100000  network_time: 0.0112
[ Fri May 12 06:31:24 2023 ] 	Batch(359/480) done. Loss: 0.0610  lr:0.100000  network_time: 0.0118
[ Fri May 12 06:32:12 2023 ] 	Batch(459/480) done. Loss: 0.4712  lr:0.100000  network_time: 0.0117
[ Fri May 12 06:32:21 2023 ] 	Training Accuracy: 93.46%
[ Fri May 12 06:32:21 2023 ] Eval epoch: 19
[ Fri May 12 06:32:38 2023 ] 	Mean test loss of 120 batches: 0.12353907525539398.
[ Fri May 12 06:32:38 2023 ] 	Top1: 95.00%
[ Fri May 12 06:32:38 2023 ] 	Top5: 100.00%
[ Fri May 12 06:32:38 2023 ] Training epoch: 20
[ Fri May 12 06:33:16 2023 ] 	Batch(79/480) done. Loss: 0.2657  lr:0.100000  network_time: 0.0113
[ Fri May 12 06:34:03 2023 ] 	Batch(179/480) done. Loss: 0.3763  lr:0.100000  network_time: 0.0117
[ Fri May 12 06:34:51 2023 ] 	Batch(279/480) done. Loss: 0.7922  lr:0.100000  network_time: 0.0117
[ Fri May 12 06:35:39 2023 ] 	Batch(379/480) done. Loss: 0.7143  lr:0.100000  network_time: 0.0115
[ Fri May 12 06:36:26 2023 ] 	Batch(479/480) done. Loss: 0.0500  lr:0.100000  network_time: 0.0123
[ Fri May 12 06:36:26 2023 ] 	Training Accuracy: 88.67%
[ Fri May 12 06:36:26 2023 ] Eval epoch: 20
[ Fri May 12 06:36:43 2023 ] 	Mean test loss of 120 batches: 0.2936076819896698.
[ Fri May 12 06:36:43 2023 ] 	Top1: 89.33%
[ Fri May 12 06:36:43 2023 ] 	Top5: 99.50%
[ Fri May 12 06:36:43 2023 ] Training epoch: 21
[ Fri May 12 06:37:30 2023 ] 	Batch(99/480) done. Loss: 0.2635  lr:0.010000  network_time: 0.0127
[ Fri May 12 06:38:18 2023 ] 	Batch(199/480) done. Loss: 0.2705  lr:0.010000  network_time: 0.0113
[ Fri May 12 06:39:06 2023 ] 	Batch(299/480) done. Loss: 0.0127  lr:0.010000  network_time: 0.0119
[ Fri May 12 06:39:53 2023 ] 	Batch(399/480) done. Loss: 0.0300  lr:0.010000  network_time: 0.0122
[ Fri May 12 06:40:32 2023 ] 	Training Accuracy: 96.62%
[ Fri May 12 06:40:32 2023 ] Eval epoch: 21
[ Fri May 12 06:40:48 2023 ] 	Mean test loss of 120 batches: 0.03553960844874382.
[ Fri May 12 06:40:48 2023 ] 	Top1: 99.33%
[ Fri May 12 06:40:48 2023 ] 	Top5: 100.00%
[ Fri May 12 06:40:48 2023 ] Training epoch: 22
[ Fri May 12 06:40:58 2023 ] 	Batch(19/480) done. Loss: 0.0573  lr:0.010000  network_time: 0.0114
[ Fri May 12 06:41:45 2023 ] 	Batch(119/480) done. Loss: 0.0337  lr:0.010000  network_time: 0.0110
[ Fri May 12 06:42:33 2023 ] 	Batch(219/480) done. Loss: 0.0105  lr:0.010000  network_time: 0.0112
[ Fri May 12 06:43:21 2023 ] 	Batch(319/480) done. Loss: 0.0132  lr:0.010000  network_time: 0.0114
[ Fri May 12 06:44:08 2023 ] 	Batch(419/480) done. Loss: 0.0569  lr:0.010000  network_time: 0.0114
[ Fri May 12 06:44:37 2023 ] 	Training Accuracy: 98.54%
[ Fri May 12 06:44:37 2023 ] Eval epoch: 22
[ Fri May 12 06:44:53 2023 ] 	Mean test loss of 120 batches: 0.03141820803284645.
[ Fri May 12 06:44:53 2023 ] 	Top1: 99.83%
[ Fri May 12 06:44:53 2023 ] 	Top5: 100.00%
[ Fri May 12 06:44:53 2023 ] Training epoch: 23
[ Fri May 12 06:45:12 2023 ] 	Batch(39/480) done. Loss: 0.0370  lr:0.010000  network_time: 0.0118
[ Fri May 12 06:46:00 2023 ] 	Batch(139/480) done. Loss: 0.0304  lr:0.010000  network_time: 0.0112
[ Fri May 12 06:46:48 2023 ] 	Batch(239/480) done. Loss: 0.0200  lr:0.010000  network_time: 0.0113
[ Fri May 12 06:47:35 2023 ] 	Batch(339/480) done. Loss: 0.0543  lr:0.010000  network_time: 0.0113
[ Fri May 12 06:48:23 2023 ] 	Batch(439/480) done. Loss: 0.0030  lr:0.010000  network_time: 0.0111
[ Fri May 12 06:48:42 2023 ] 	Training Accuracy: 99.04%
[ Fri May 12 06:48:42 2023 ] Eval epoch: 23
[ Fri May 12 06:48:58 2023 ] 	Mean test loss of 120 batches: 0.024822434410452843.
[ Fri May 12 06:48:58 2023 ] 	Top1: 99.83%
[ Fri May 12 06:48:58 2023 ] 	Top5: 100.00%
[ Fri May 12 06:48:58 2023 ] Training epoch: 24
[ Fri May 12 06:49:27 2023 ] 	Batch(59/480) done. Loss: 0.0351  lr:0.010000  network_time: 0.0116
[ Fri May 12 06:50:15 2023 ] 	Batch(159/480) done. Loss: 0.0136  lr:0.010000  network_time: 0.0115
[ Fri May 12 06:51:02 2023 ] 	Batch(259/480) done. Loss: 0.0118  lr:0.010000  network_time: 0.0118
[ Fri May 12 06:51:50 2023 ] 	Batch(359/480) done. Loss: 0.0156  lr:0.010000  network_time: 0.0113
[ Fri May 12 06:52:38 2023 ] 	Batch(459/480) done. Loss: 0.0588  lr:0.010000  network_time: 0.0114
[ Fri May 12 06:52:47 2023 ] 	Training Accuracy: 98.96%
[ Fri May 12 06:52:47 2023 ] Eval epoch: 24
[ Fri May 12 06:53:04 2023 ] 	Mean test loss of 120 batches: 0.018513420596718788.
[ Fri May 12 06:53:04 2023 ] 	Top1: 99.67%
[ Fri May 12 06:53:04 2023 ] 	Top5: 100.00%
[ Fri May 12 06:53:04 2023 ] Training epoch: 25
[ Fri May 12 06:53:42 2023 ] 	Batch(79/480) done. Loss: 0.0471  lr:0.010000  network_time: 0.0115
[ Fri May 12 06:54:29 2023 ] 	Batch(179/480) done. Loss: 0.0064  lr:0.010000  network_time: 0.0112
[ Fri May 12 06:55:17 2023 ] 	Batch(279/480) done. Loss: 0.0382  lr:0.010000  network_time: 0.0115
[ Fri May 12 06:56:05 2023 ] 	Batch(379/480) done. Loss: 0.0021  lr:0.010000  network_time: 0.0119
[ Fri May 12 06:56:52 2023 ] 	Batch(479/480) done. Loss: 0.0908  lr:0.010000  network_time: 0.0112
[ Fri May 12 06:56:52 2023 ] 	Training Accuracy: 99.17%
[ Fri May 12 06:56:52 2023 ] Eval epoch: 25
[ Fri May 12 06:57:09 2023 ] 	Mean test loss of 120 batches: 0.021504679694771767.
[ Fri May 12 06:57:09 2023 ] 	Top1: 99.67%
[ Fri May 12 06:57:09 2023 ] 	Top5: 100.00%
[ Fri May 12 06:57:09 2023 ] Training epoch: 26
[ Fri May 12 06:57:56 2023 ] 	Batch(99/480) done. Loss: 0.0150  lr:0.001000  network_time: 0.0114
[ Fri May 12 06:58:44 2023 ] 	Batch(199/480) done. Loss: 0.1584  lr:0.001000  network_time: 0.0114
[ Fri May 12 06:59:32 2023 ] 	Batch(299/480) done. Loss: 0.0250  lr:0.001000  network_time: 0.0112
[ Fri May 12 07:00:19 2023 ] 	Batch(399/480) done. Loss: 0.1529  lr:0.001000  network_time: 0.0117
[ Fri May 12 07:00:57 2023 ] 	Training Accuracy: 99.38%
[ Fri May 12 07:00:57 2023 ] Eval epoch: 26
[ Fri May 12 07:01:14 2023 ] 	Mean test loss of 120 batches: 0.024142777547240257.
[ Fri May 12 07:01:14 2023 ] 	Top1: 99.67%
[ Fri May 12 07:01:14 2023 ] 	Top5: 100.00%
[ Fri May 12 07:01:14 2023 ] Training epoch: 27
[ Fri May 12 07:01:24 2023 ] 	Batch(19/480) done. Loss: 0.0079  lr:0.001000  network_time: 0.0112
[ Fri May 12 07:02:11 2023 ] 	Batch(119/480) done. Loss: 0.0044  lr:0.001000  network_time: 0.0113
[ Fri May 12 07:02:59 2023 ] 	Batch(219/480) done. Loss: 0.0192  lr:0.001000  network_time: 0.0113
[ Fri May 12 07:03:47 2023 ] 	Batch(319/480) done. Loss: 0.0289  lr:0.001000  network_time: 0.0117
[ Fri May 12 07:04:34 2023 ] 	Batch(419/480) done. Loss: 0.0049  lr:0.001000  network_time: 0.0113
[ Fri May 12 07:05:03 2023 ] 	Training Accuracy: 99.04%
[ Fri May 12 07:05:03 2023 ] Eval epoch: 27
[ Fri May 12 07:05:19 2023 ] 	Mean test loss of 120 batches: 0.01704876497387886.
[ Fri May 12 07:05:19 2023 ] 	Top1: 100.00%
[ Fri May 12 07:05:19 2023 ] 	Top5: 100.00%
[ Fri May 12 07:05:19 2023 ] Training epoch: 28
[ Fri May 12 07:05:38 2023 ] 	Batch(39/480) done. Loss: 0.0114  lr:0.001000  network_time: 0.0115
[ Fri May 12 07:06:26 2023 ] 	Batch(139/480) done. Loss: 0.0186  lr:0.001000  network_time: 0.0114
[ Fri May 12 07:07:14 2023 ] 	Batch(239/480) done. Loss: 0.0346  lr:0.001000  network_time: 0.0115
[ Fri May 12 07:08:01 2023 ] 	Batch(339/480) done. Loss: 0.0247  lr:0.001000  network_time: 0.0117
[ Fri May 12 07:08:49 2023 ] 	Batch(439/480) done. Loss: 0.0185  lr:0.001000  network_time: 0.0120
[ Fri May 12 07:09:08 2023 ] 	Training Accuracy: 99.42%
[ Fri May 12 07:09:08 2023 ] Eval epoch: 28
[ Fri May 12 07:09:25 2023 ] 	Mean test loss of 120 batches: 0.018519137054681778.
[ Fri May 12 07:09:25 2023 ] 	Top1: 99.83%
[ Fri May 12 07:09:25 2023 ] 	Top5: 100.00%
[ Fri May 12 07:09:25 2023 ] Training epoch: 29
[ Fri May 12 07:09:53 2023 ] 	Batch(59/480) done. Loss: 0.0858  lr:0.001000  network_time: 0.0114
[ Fri May 12 07:10:41 2023 ] 	Batch(159/480) done. Loss: 0.1019  lr:0.001000  network_time: 0.0120
[ Fri May 12 07:11:28 2023 ] 	Batch(259/480) done. Loss: 0.0387  lr:0.001000  network_time: 0.0112
[ Fri May 12 07:12:16 2023 ] 	Batch(359/480) done. Loss: 0.0599  lr:0.001000  network_time: 0.0119
[ Fri May 12 07:13:04 2023 ] 	Batch(459/480) done. Loss: 0.4945  lr:0.001000  network_time: 0.0112
[ Fri May 12 07:13:13 2023 ] 	Training Accuracy: 99.58%
[ Fri May 12 07:13:13 2023 ] Eval epoch: 29
[ Fri May 12 07:13:30 2023 ] 	Mean test loss of 120 batches: 0.017975497990846634.
[ Fri May 12 07:13:30 2023 ] 	Top1: 100.00%
[ Fri May 12 07:13:30 2023 ] 	Top5: 100.00%
[ Fri May 12 07:13:30 2023 ] Training epoch: 30
[ Fri May 12 07:14:08 2023 ] 	Batch(79/480) done. Loss: 0.0093  lr:0.001000  network_time: 0.0117
[ Fri May 12 07:14:56 2023 ] 	Batch(179/480) done. Loss: 0.0287  lr:0.001000  network_time: 0.0119
[ Fri May 12 07:15:43 2023 ] 	Batch(279/480) done. Loss: 0.0283  lr:0.001000  network_time: 0.0115
[ Fri May 12 07:16:31 2023 ] 	Batch(379/480) done. Loss: 0.0190  lr:0.001000  network_time: 0.0114
[ Fri May 12 07:17:19 2023 ] 	Batch(479/480) done. Loss: 0.0602  lr:0.001000  network_time: 0.0114
[ Fri May 12 07:17:19 2023 ] 	Training Accuracy: 99.46%
[ Fri May 12 07:17:19 2023 ] Eval epoch: 30
[ Fri May 12 07:17:35 2023 ] 	Mean test loss of 120 batches: 0.014448185451328754.
[ Fri May 12 07:17:35 2023 ] 	Top1: 100.00%
[ Fri May 12 07:17:35 2023 ] 	Top5: 100.00%
